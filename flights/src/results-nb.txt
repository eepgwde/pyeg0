* Flights

weaves

* Method

** Model calibration - LEGTYPE "Weak" at 80th percentile - results0.log

*** Training 

Perfect, so model is working.

> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    180    0
    Weak        0   61
                                     
               Accuracy : 1          
                 95% CI : (0.9848, 1)
    No Information Rate : 0.7469     
    P-Value [Acc > NIR] : < 2.2e-16  
                                     
                  Kappa : 1          
 Mcnemar's Test P-Value : NA         
                                     
            Sensitivity : 1.0000     
            Specificity : 1.0000     
         Pos Pred Value : 1.0000     
         Neg Pred Value : 1.0000     
             Prevalence : 0.2531     
         Detection Rate : 0.2531     
   Detection Prevalence : 0.2531     
      Balanced Accuracy : 1.0000     
                                     
       'Positive' Class : Weak       

*** Test

Not so good, 40% sensitivity (True positive), but specificity is good at
77%. Accuracy of 68% does indicate that is a plausible predictor.

> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     46   12
    Weak       13    8
                                          
               Accuracy : 0.6835          
                 95% CI : (0.5692, 0.7837)
    No Information Rate : 0.7468          
    P-Value [Acc > NIR] : 0.92            
                                          
                  Kappa : 0.1767          
 Mcnemar's Test P-Value : 1.00            
                                          
            Sensitivity : 0.4000          
            Specificity : 0.7797          
         Pos Pred Value : 0.3810          
         Neg Pred Value : 0.7931          
             Prevalence : 0.2532          
         Detection Rate : 0.1013          
   Detection Prevalence : 0.2658          
      Balanced Accuracy : 0.5898          
                                          
       'Positive' Class : Weak            

** Revised model (1) results1.log

The LEGTYPE has been re-classified in the kludgy manner, I wouldn't
recommend. All other parameters are as before.

*** Training

Even the training data has non-ideal accuracy.

Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     77   16
    Weak       31  117
                                         
               Accuracy : 0.805          
                 95% CI : (0.7492, 0.853)
    No Information Rate : 0.5519         
    P-Value [Acc > NIR] : < 2e-16        
                                         
                  Kappa : 0.6005         
 Mcnemar's Test P-Value : 0.04114        
                                         
            Sensitivity : 0.8797         
            Specificity : 0.7130         
         Pos Pred Value : 0.7905         
         Neg Pred Value : 0.8280         
             Prevalence : 0.5519         
         Detection Rate : 0.4855         
   Detection Prevalence : 0.6141         
      Balanced Accuracy : 0.7963         
                                         
       'Positive' Class : Weak           

*** Test

Very poor, mis-classification of true Weak as Strong very marked.

The trellis dove downwards. Airports didn't degrade as predictors as badly
as flight duration or aircraft.

I'll try some revisions in the next Revision below.

Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     18   30
    Weak       17   14
                                         
               Accuracy : 0.4051         
                 95% CI : (0.296, 0.5215)
    No Information Rate : 0.557          
    P-Value [Acc > NIR] : 0.99761        
                                         
                  Kappa : -0.1614        
 Mcnemar's Test P-Value : 0.08005        
                                         
            Sensitivity : 0.3182         
            Specificity : 0.5143         
         Pos Pred Value : 0.4516         
         Neg Pred Value : 0.3750         
             Prevalence : 0.5570         
         Detection Rate : 0.1772         
   Detection Prevalence : 0.3924         
      Balanced Accuracy : 0.4162         
                                         
       'Positive' Class : Weak

** Revision (2)

Because the training result was so poor, counter-intuitively, one should
decrease the correlation cut-off - and remove more variables - in the hope
that more predictive features will be able to emerge. So 0.65 will drop 6
(rather than 5)

ARRSPOKE, SDEPHR, DEPBUCKET, ARRBUCKET, TRNRANKGRP, xAVAILBUCKET 

and accuracy improves, but only marginally for both the training set and
the test - 3%.

We can try increasing the tree size and trying different variables.

Tree size does improve testing 65% accuracy, but again the training set
only marginally (3%).  suggesting I got a lucky partition. The trellis is
still diving very quickly. But after another run, this does appear to have
helped.

Let's try helping the tree by changing its branching structure. Sadly not,
it has degraded both, but I did replace xDURN2, so if I add xDURN2 back.

That has also helped. I'll try one last thing, I'll add DOWNLINEATCIMP to
the tree.


> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     15   10
    Weak       20   34
                                          
               Accuracy : 0.6203          
                 95% CI : (0.5041, 0.7272)
    No Information Rate : 0.557           
    P-Value [Acc > NIR] : 0.1540          
                                          
                  Kappa : 0.2074          
 Mcnemar's Test P-Value : 0.1003          
                                          
            Sensitivity : 0.7727          
            Specificity : 0.4286          
         Pos Pred Value : 0.6296          
         Neg Pred Value : 0.6000          
             Prevalence : 0.5570          
         Detection Rate : 0.4304          
   Detection Prevalence : 0.6835          
      Balanced Accuracy : 0.6006          
                                          
       'Positive' Class : Weak            
                                          
> 
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
 Accuracy     Kappa 
0.8506224 0.6974684 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     89   17
    Weak       19  116
                                          
               Accuracy : 0.8506          
                 95% CI : (0.7992, 0.8931)
    No Information Rate : 0.5519          
    P-Value [Acc > NIR] : <2e-16          
                                          
                  Kappa : 0.6975          
 Mcnemar's Test P-Value : 0.8676          
                                          
            Sensitivity : 0.8722          
            Specificity : 0.8241          
         Pos Pred Value : 0.8593          
         Neg Pred Value : 0.8396          
             Prevalence : 0.5519          
         Detection Rate : 0.4813          
   Detection Prevalence : 0.5602          
      Balanced Accuracy : 0.8481          
                                          
       'Positive' Class : Weak            
                                          


** Notes

*** Reproduciblity

I've re-run just a few times and it works well.

That said, I've haven't kept good track of my use of set.seed() which is
critical when reproducing results.



** This file's Emacs file variables

[  Local Variables: ]
[  mode:text ]
[  mode:outline-minor ]
[  mode:auto-fill ]
[  fill-column: 75 ]
[  coding: iso-8859-1-unix ]
[  comment-column:50 ]
[  comment-start: "[  "  ]
[  comment-end:"]" ]
[  End: ]
