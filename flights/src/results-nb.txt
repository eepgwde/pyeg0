* Flights

weaves

* Method

** Model calibration - LEGTYPE "Weak" at 80th percentile - results0.log

*** Training 

Perfect, so model is working.

> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    180    0
    Weak        0   61
                                     
               Accuracy : 1          
                 95% CI : (0.9848, 1)
    No Information Rate : 0.7469     
    P-Value [Acc > NIR] : < 2.2e-16  
                                     
                  Kappa : 1          
 Mcnemar's Test P-Value : NA         
                                     
            Sensitivity : 1.0000     
            Specificity : 1.0000     
         Pos Pred Value : 1.0000     
         Neg Pred Value : 1.0000     
             Prevalence : 0.2531     
         Detection Rate : 0.2531     
   Detection Prevalence : 0.2531     
      Balanced Accuracy : 1.0000     
                                     
       'Positive' Class : Weak       

*** Test

Not so good, 40% sensitivity (True positive), but specificity is good at
77%. Accuracy of 68% does indicate that is a plausible predictor.

> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     46   12
    Weak       13    8
                                          
               Accuracy : 0.6835          
                 95% CI : (0.5692, 0.7837)
    No Information Rate : 0.7468          
    P-Value [Acc > NIR] : 0.92            
                                          
                  Kappa : 0.1767          
 Mcnemar's Test P-Value : 1.00            
                                          
            Sensitivity : 0.4000          
            Specificity : 0.7797          
         Pos Pred Value : 0.3810          
         Neg Pred Value : 0.7931          
             Prevalence : 0.2532          
         Detection Rate : 0.1013          
   Detection Prevalence : 0.2658          
      Balanced Accuracy : 0.5898          
                                          
       'Positive' Class : Weak            

** Revised model (1) results1.log

The LEGTYPE has been re-classified in the kludgy manner, I wouldn't
recommend. All other parameters are as before.

*** Training

Even the training data has non-ideal accuracy.

Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     77   16
    Weak       31  117
                                         
               Accuracy : 0.805          
                 95% CI : (0.7492, 0.853)
    No Information Rate : 0.5519         
    P-Value [Acc > NIR] : < 2e-16        
                                         
                  Kappa : 0.6005         
 Mcnemar's Test P-Value : 0.04114        
                                         
            Sensitivity : 0.8797         
            Specificity : 0.7130         
         Pos Pred Value : 0.7905         
         Neg Pred Value : 0.8280         
             Prevalence : 0.5519         
         Detection Rate : 0.4855         
   Detection Prevalence : 0.6141         
      Balanced Accuracy : 0.7963         
                                         
       'Positive' Class : Weak           

*** Test

Very poor, mis-classification of true Weak as Strong very marked.

The trellis dove downwards. Airports didn't degrade as predictors as badly
as flight duration or aircraft.

I'll try some revisions in the next Revision below.

Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     18   30
    Weak       17   14
                                         
               Accuracy : 0.4051         
                 95% CI : (0.296, 0.5215)
    No Information Rate : 0.557          
    P-Value [Acc > NIR] : 0.99761        
                                         
                  Kappa : -0.1614        
 Mcnemar's Test P-Value : 0.08005        
                                         
            Sensitivity : 0.3182         
            Specificity : 0.5143         
         Pos Pred Value : 0.4516         
         Neg Pred Value : 0.3750         
             Prevalence : 0.5570         
         Detection Rate : 0.1772         
   Detection Prevalence : 0.3924         
      Balanced Accuracy : 0.4162         
                                         
       'Positive' Class : Weak

** Revision (2) - results1.log

Because the training result was so poor, counter-intuitively, one should
decrease the correlation cut-off - and remove more variables - in the hope
that more predictive features will be able to emerge. So 0.65 will drop 6
(rather than 5)

ARRSPOKE, SDEPHR, DEPBUCKET, ARRBUCKET, TRNRANKGRP, xAVAILBUCKET 

and accuracy improves, but only marginally for both the training set and
the test - 3%.

We can try increasing the tree size and trying different variables for it to
branch on.

Tree size does improve testing to 63% accuracy, but again the training set
only marginally (3%). This might suggest I got a lucky with the test
partition. The trellis is still diving very quickly. But after more
runs, the tree size do appear to have helped.

The xDURN2 seems to be key predictor. Other xAVGSKDAVAIL amongst others
have tended to degrade the training set - never a good sign.

This is my best confusion matrix for the revised data-set. Unfortunately, I
wasn't assiduous enough with Git and made some minor changes to the code
(tree and correlation cutoff) that have meant, the test results have not
been reproducible.

**** Reproducible

These results should be reproducible from the scripts.

> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     22   22
    Weak       28   39
                                          
               Accuracy : 0.5495          
                 95% CI : (0.4522, 0.6441)
    No Information Rate : 0.5495          
    P-Value [Acc > NIR] : 0.5392          
                                          
                  Kappa : 0.0802          
 Mcnemar's Test P-Value : 0.4795          
                                          
            Sensitivity : 0.6393          
            Specificity : 0.4400          
         Pos Pred Value : 0.5821          
         Neg Pred Value : 0.5000          
             Prevalence : 0.5495          
         Detection Rate : 0.3514          
   Detection Prevalence : 0.6036          
      Balanced Accuracy : 0.5397          
                                          
       'Positive' Class : Weak            
                                          

> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)

> postResample(trainPred, trainClass)
 Accuracy     Kappa 
0.8516746 0.6987492 

> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     76   14
    Weak       17  102
                                          
               Accuracy : 0.8517          
                 95% CI : (0.7961, 0.8969)
    No Information Rate : 0.555           
    P-Value [Acc > NIR] : <2e-16          
                                          
                  Kappa : 0.6987          
 Mcnemar's Test P-Value : 0.7194          
                                          
            Sensitivity : 0.8793          
            Specificity : 0.8172          
         Pos Pred Value : 0.8571          
         Neg Pred Value : 0.8444          
             Prevalence : 0.5550          
         Detection Rate : 0.4880          
   Detection Prevalence : 0.5694          
      Balanced Accuracy : 0.8483          
                                          
       'Positive' Class : Weak            
                                          
Warning messages:
1: In eval(expr, envir, enclos) : adjusting
2: In eval(expr, envir, enclos) :
  overfitting: correlations: err.trainDescr: SDEPHR, DEPBUCKET, ARRSPOKE, DEPSPOKE, AVGSQ, TRNRANKGRP, xAVAILBUCKET
> 

**** Best observed (but lost)

I was experimenting with correlation cutoff and the tree structure and
managed to get this result. Sadly, I've been unable to reproduce it. I
suspect it was a fortunate choice of dataset, but I suspect there may have
been something parametrically different because the training set is
slightly different too.

> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     31   22
    Weak       19   39
                                          
               Accuracy : 0.6306          
                 95% CI : (0.5338, 0.7203)
    No Information Rate : 0.5495          
    P-Value [Acc > NIR] : 0.05167         
                                          
                  Kappa : 0.2579          
 Mcnemar's Test P-Value : 0.75478         
                                          
            Sensitivity : 0.6393          
            Specificity : 0.6200          
         Pos Pred Value : 0.6724          
         Neg Pred Value : 0.5849          
             Prevalence : 0.5495          
         Detection Rate : 0.3514          
   Detection Prevalence : 0.5225          
      Balanced Accuracy : 0.6297          
                                          
       'Positive' Class : Weak            
                                          
> 
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
 Accuracy     Kappa 
0.8373206 0.6699489 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     75   16
    Weak       18  100
                                          
               Accuracy : 0.8373          
                 95% CI : (0.7802, 0.8846)
    No Information Rate : 0.555           
    P-Value [Acc > NIR] : <2e-16          
                                          
                  Kappa : 0.6699          
 Mcnemar's Test P-Value : 0.8638          
                                          
            Sensitivity : 0.8621          
            Specificity : 0.8065          
         Pos Pred Value : 0.8475          
         Neg Pred Value : 0.8242          
             Prevalence : 0.5550          
         Detection Rate : 0.4785          
   Detection Prevalence : 0.5646          
      Balanced Accuracy : 0.8343          
                                          
       'Positive' Class : Weak            
                                          


** Notes

*** Reproduciblity

I've re-run just a few times and it works well.

That said, I've haven't kept good track of my use of set.seed() which is
critical when reproducing results.



** This file's Emacs file variables

[  Local Variables: ]
[  mode:text ]
[  mode:outline-minor ]
[  mode:auto-fill ]
[  fill-column: 75 ]
[  coding: iso-8859-1-unix ]
[  comment-column:50 ]
[  comment-start: "[  "  ]
[  comment-end:"]" ]
[  End: ]
