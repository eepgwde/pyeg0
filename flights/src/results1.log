
R version 3.2.5 (2016-04-14) -- "Very, Very Secure Dishes"
Copyright (C) 2016 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> > options(STERM='iESS', str.dendrogram.last="'", editor='emacsclient', show.error.locations=TRUE)
> ### weaves
> 
> ## Processing for flights data.
> 
> ## Following the caret vignette.
> 
> ###################################################
> ### code chunk number 1: loadLibs
> ###################################################
> library(MASS)
> library(caret)
Loading required package: lattice
Loading required package: ggplot2
> library(mlbench)
> library(pROC)
Type 'citation("pROC")' for a citation.

Attaching package: 'pROC'

The following objects are masked from 'package:stats':

    cov, smooth, var

> library(pls)

Attaching package: 'pls'

The following object is masked from 'package:caret':

    R2

The following object is masked from 'package:stats':

    loadings

> 
> library(doMC)
Loading required package: foreach
foreach: simple, scalable parallel programming from Revolution Analytics
Use Revolution R for scalability, fault tolerance and more.
http://www.revolutionanalytics.com
Loading required package: iterators
Loading required package: parallel
> registerDoMC(cores = 4)
> 
> options(useFancyQuotes = FALSE) 
> 
> # Accounting info.
> getInfo <- function(what = "Suggests")
+ {
+   text <- packageDescription("caret")[what][[1]]
+   text <- gsub("\n", ", ", text, fixed = TRUE)
+   text <- gsub(">=", "$\\\\ge$", text, fixed = TRUE)
+   eachPkg <- strsplit(text, ", ", fixed = TRUE)[[1]]
+   eachPkg <- gsub(",", "", eachPkg, fixed = TRUE)
+   # out <- paste("\\\\pkg{", eachPkg[order(tolower(eachPkg))], "}", sep = "")
+   # paste(out, collapse = ", ")
+   length(eachPkg)
+ }
> 
> ### project-specific: begin
> ## Set-seed, load original CSV file, order it
> ## and do some simple-cleaning
> ## Various datasets 
> 
> seed.mine = 107
> set.seed(seed.mine)                     # helpful for testing
> 
> flight <- read.csv("../bak/flight.csv")
> flight <- flight[order(flight$D00),]
> 
> # Backup
> flight.raw <- flight
> 
> # Check warnings
> src.adjust <- TRUE
> source(file = "flight1.R")
Warning message:
In eval(expr, envir, enclos) : adjusting
> 
> # To check adjustment, there is test code in flight-nb.R
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"
> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"
> 
> # And some deletions
> 
> t.cols <- colnames(flight)
> 
> t.drops <- t.cols[grep("^RANK*", t.cols)]
> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])
> t.drops <- c(t.drops, "D80THPCTL")
> 
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR
> flight$xHNGR <- flight$xDURN < 0
> 
> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+ }
> 
> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))
> 
> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE
> t.cols <- colnames(flight)
> 
> t.drops <- c("SARRHR", "xDURN")
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Backup
> 
> flight00 <- flight
> 
> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]
> 
> dim(flight)
[1] 320  23
> dim(flight00)
[1] 1391   23
> flight <- flight[flight$AVGLOFATC >= 3.1 && flight$AVGLOFATC <= 4.4,]
> dim(flight)
[1] 320  23
> ### weaves
> 
> ## Processing for flights data.
> 
> ## Following the caret vignette.
> 
> ###################################################
> ### code chunk number 1: loadLibs
> ###################################################
> library(MASS)
> library(caret)
> library(mlbench)
> library(pROC)
> library(pls)
> 
> library(doMC)
> registerDoMC(cores = 4)
> 
> options(useFancyQuotes = FALSE) 
> 
> # Accounting info.
> getInfo <- function(what = "Suggests")
+ {
+   text <- packageDescription("caret")[what][[1]]
+   text <- gsub("\n", ", ", text, fixed = TRUE)
+   text <- gsub(">=", "$\\\\ge$", text, fixed = TRUE)
+   eachPkg <- strsplit(text, ", ", fixed = TRUE)[[1]]
+   eachPkg <- gsub(",", "", eachPkg, fixed = TRUE)
+   # out <- paste("\\\\pkg{", eachPkg[order(tolower(eachPkg))], "}", sep = "")
+   # paste(out, collapse = ", ")
+   length(eachPkg)
+ }
> 
> ### project-specific: begin
> ## Set-seed, load original CSV file, order it
> ## and do some simple-cleaning
> ## Various datasets 
> 
> seed.mine = 107
> set.seed(seed.mine)                     # helpful for testing
> 
> flight <- read.csv("../bak/flight.csv")
> flight <- flight[order(flight$D00),]
> 
> # Backup
> flight.raw <- flight
> 
> # Check warnings
> src.adjust <- TRUE
> source(file = "flight1.R")
Warning message:
In eval(expr, envir, enclos) : adjusting
> 
> # To check adjustment, there is test code in flight-nb.R
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"
> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"
> 
> # And some deletions
> 
> t.cols <- colnames(flight)
> 
> t.drops <- t.cols[grep("^RANK*", t.cols)]
> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])
> t.drops <- c(t.drops, "D80THPCTL")
> 
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR
> flight$xHNGR <- flight$xDURN < 0
> 
> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+ }
> 
> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))
> 
> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE
> t.cols <- colnames(flight)
> 
> t.drops <- c("SARRHR", "xDURN")
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Backup
> 
> flight00 <- flight
> 
> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 && flight$AVGLOFATC <= 4.4,]
> 
> dim(flight)
[1]  0 23
> dim(flight[flight$AVGLOFATC < 3.1,])
[1]  0 23
> dim(flight[flight00$AVGLOFATC < 3.1,])
[1] 891  23
> dim(flight)
[1]  0 23
> paste("samples in use: ", dim(flight)[1])
[1] "samples in use:  0"
> ### weaves
> 
> ## Processing for flights data.
> 
> ## Following the caret vignette.
> 
> ###################################################
> ### code chunk number 1: loadLibs
> ###################################################
> library(MASS)
> library(caret)
> library(mlbench)
> library(pROC)
> library(pls)
> 
> library(doMC)
> registerDoMC(cores = 4)
> 
> options(useFancyQuotes = FALSE) 
> 
> # Accounting info.
> getInfo <- function(what = "Suggests")
+ {
+   text <- packageDescription("caret")[what][[1]]
+   text <- gsub("\n", ", ", text, fixed = TRUE)
+   text <- gsub(">=", "$\\\\ge$", text, fixed = TRUE)
+   eachPkg <- strsplit(text, ", ", fixed = TRUE)[[1]]
+   eachPkg <- gsub(",", "", eachPkg, fixed = TRUE)
+   # out <- paste("\\\\pkg{", eachPkg[order(tolower(eachPkg))], "}", sep = "")
+   # paste(out, collapse = ", ")
+   length(eachPkg)
+ }
> 
> ### project-specific: begin
> ## Set-seed, load original CSV file, order it
> ## and do some simple-cleaning
> ## Various datasets 
> 
> seed.mine = 107
> set.seed(seed.mine)                     # helpful for testing
> 
> flight <- read.csv("../bak/flight.csv")
> flight <- flight[order(flight$D00),]
> 
> # Backup
> flight.raw <- flight
> 
> # Check warnings
> src.adjust <- TRUE
> source(file = "flight1.R")
Warning message:
In eval(expr, envir, enclos) : adjusting
> 
> # To check adjustment, there is test code in flight-nb.R
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"
> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"
> 
> # And some deletions
> 
> t.cols <- colnames(flight)
> 
> t.drops <- t.cols[grep("^RANK*", t.cols)]
> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])
> t.drops <- c(t.drops, "D80THPCTL")
> 
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR
> flight$xHNGR <- flight$xDURN < 0
> 
> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+ }
> 
> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))
> 
> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE
> t.cols <- colnames(flight)
> 
> t.drops <- c("SARRHR", "xDURN")
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Backup
> 
> flight00 <- flight
> 
> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]
> 
> paste("samples in use: ", dim(flight)[1])
[1] "samples in use:  320"
> t.cols <- colnames(flight)
> t.cols0 <- t.cols[grep("^AV.)*", t.cols)]
> t.cols0 <- append("D00", t.cols0)
> featurePlot(x = flight[, t.cols0],
+             y = flight$LEGTYPE,
+             plot = "pairs",
+             ## Add a key at the top
+             auto.key = list(columns = length(t.cols0) - 1))
Warning message:
In draw.key(simpleKey(...), draw = FALSE) : not enough rows for columns
> t.cols
 [1] "SDEPHR"         "SKDDEPSTA"      "SKDARRSTA"      "SKDEQP"        
 [5] "SKDEPS"         "D00"            "AVGSQ"          "AVGLOFATC"     
 [9] "UPLINEATCIMP"   "DEPSTAATCIMP"   "DOWNLINEATCIMP" "AVGSKDAVAIL"   
[13] "AVAILBUCKET"    "DEPBUCKET"      "ARRBUCKET"      "DEPRANKGRP"    
[17] "TRNRANKGRP"     "ARRRANKGRP"     "LEGTYPE"        "DEPSPOKE"      
[21] "ARRSPOKE"       "xHNGR"          "xDURN2"        
> t.cols0
[1] "D00"         "AVGSQ"       "AVGLOFATC"   "AVGSKDAVAIL" "AVAILBUCKET"
> corrplot::corrplot(flight.cor, method="number")
Error in corrplot::corrplot(flight.cor, method = "number") : 
  object 'flight.cor' not found
> flight.num
Error: object 'flight.num' not found
> ### weaves
> 
> ## Processing for flights data.
> 
> ## Following the caret vignette.
> 
> ###################################################
> ### code chunk number 1: loadLibs
> ###################################################
> library(MASS)
> library(caret)
> library(mlbench)
> library(pROC)
> library(pls)
> 
> library(doMC)
> registerDoMC(cores = 4)
> 
> options(useFancyQuotes = FALSE) 
> 
> # Accounting info.
> getInfo <- function(what = "Suggests")
+ {
+   text <- packageDescription("caret")[what][[1]]
+   text <- gsub("\n", ", ", text, fixed = TRUE)
+   text <- gsub(">=", "$\\\\ge$", text, fixed = TRUE)
+   eachPkg <- strsplit(text, ", ", fixed = TRUE)[[1]]
+   eachPkg <- gsub(",", "", eachPkg, fixed = TRUE)
+   # out <- paste("\\\\pkg{", eachPkg[order(tolower(eachPkg))], "}", sep = "")
+   # paste(out, collapse = ", ")
+   length(eachPkg)
+ }
> 
> ### project-specific: begin
> ## Set-seed, load original CSV file, order it
> ## and do some simple-cleaning
> ## Various datasets 
> 
> seed.mine = 107
> set.seed(seed.mine)                     # helpful for testing
> 
> flight <- read.csv("../bak/flight.csv")
> flight <- flight[order(flight$D00),]
> 
> # Backup
> flight.raw <- flight
> 
> # Check warnings
> src.adjust <- TRUE
> source(file = "flight1.R")
Warning message:
In eval(expr, envir, enclos) : adjusting
> 
> # To check adjustment, there is test code in flight-nb.R
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"
> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"
> 
> # And some deletions
> 
> t.cols <- colnames(flight)
> 
> t.drops <- t.cols[grep("^RANK*", t.cols)]
> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])
> t.drops <- c(t.drops, "D80THPCTL")
> 
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR
> flight$xHNGR <- flight$xDURN < 0
> 
> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+ }
> 
> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))
> 
> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE
> t.cols <- colnames(flight)
> 
> t.drops <- c("SARRHR", "xDURN")
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Backup
> 
> flight00 <- flight
> 
> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]
> 
> paste("samples in use: ", dim(flight)[1])
[1] "samples in use:  320"
> 
> ## Take another copy - this is all we need as the training/prediction
> ## set.
> 
> flight1 <- flight
> 
> ## Data insights
> 
> ## *Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> flight <- flight1
> 
> ## So something is defining the behaviour.
> 
> ## Try to simplify structure
> 
> head(model.matrix(LEGTYPE ~ ., data = flight))
   (Intercept) SDEPHR SKDDEPSTAALB SKDDEPSTAAMS SKDDEPSTAANC SKDDEPSTAATT
2            1     14            0            0            0            0
5            1     11            0            0            0            0
7            1     14            0            0            0            0
13           1     13            0            0            0            0
14           1     16            0            0            0            0
17           1     15            0            0            0            0
   SKDDEPSTAAUA SKDDEPSTAAUS SKDDEPSTABDA SKDDEPSTABDL SKDDEPSTABNA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTABOI SKDDEPSTABOS SKDDEPSTABRU SKDDEPSTABUF SKDDEPSTABWI
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTACCC SKDDEPSTACDG SKDDEPSTACHS SKDDEPSTACLE SKDDEPSTACMH
2             1            0            0            0            0
5             0            0            0            0            0
7             1            0            0            0            0
13            0            0            0            0            0
14            1            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTACUN SKDDEPSTADDD SKDDEPSTADEN SKDDEPSTADFW SKDDEPSTADSM
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            1            0            0            0
   SKDDEPSTADTW SKDDEPSTADUB SKDDEPSTAEWR SKDDEPSTAFCO SKDDEPSTAFLL
2             0            0            0            0            0
5             1            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAFRA SKDDEPSTAGCM SKDDEPSTAGDL SKDDEPSTAGEG SKDDEPSTAGIG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAHNL SKDDEPSTAIAH SKDDEPSTAILM SKDDEPSTAIND SKDDEPSTAJAX
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAJFK SKDDEPSTAKOA SKDDEPSTALAS SKDDEPSTALAX SKDDEPSTALGA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTALGB SKDDEPSTALGW SKDDEPSTALHR SKDDEPSTALIH SKDDEPSTAMAD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMAN SKDDEPSTAMBJ SKDDEPSTAMCI SKDDEPSTAMCO SKDDEPSTAMDT
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMEX SKDDEPSTAMHT SKDDEPSTAMIA SKDDEPSTAMKE SKDDEPSTAMSP
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMSY SKDDEPSTAMUC SKDDEPSTAMZT SKDDEPSTANAS SKDDEPSTAOAK
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAOGG SKDDEPSTAOMA SKDDEPSTAONT SKDDEPSTAORD SKDDEPSTAORF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAPBI SKDDEPSTAPDX SKDDEPSTAPIT SKDDEPSTAPLS SKDDEPSTAPPP
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            1
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAPUJ SKDDEPSTAPVD SKDDEPSTAPVR SKDDEPSTAPWM SKDDEPSTARDU
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTARIC SKDDEPSTARNO SKDDEPSTAROC SKDDEPSTARSW SKDDEPSTASAN
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASAT SKDDEPSTASEA SKDDEPSTASFO SKDDEPSTASJC SKDDEPSTASJD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASJO SKDDEPSTASJU SKDDEPSTASLC SKDDEPSTASMF SKDDEPSTASNA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASRQ SKDDEPSTASTL SKDDEPSTASTT SKDDEPSTASXM SKDDEPSTASYR
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTATLV SKDDEPSTATPA SKDDEPSTAXHP SKDDEPSTAYEG SKDDEPSTAYVR
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAYYC SKDDEPSTAZRH SKDARRSTAALB SKDARRSTAAMS SKDARRSTAANC
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAATT SKDARRSTAAUA SKDARRSTAAUS SKDARRSTABDA SKDARRSTABDL
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTABNA SKDARRSTABOI SKDARRSTABOS SKDARRSTABRU SKDARRSTABUF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            1            0            0
17            0            0            0            0            0
   SKDARRSTABWI SKDARRSTACCC SKDARRSTACDG SKDARRSTACHS SKDARRSTACLE
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            1            0            0            0
   SKDARRSTACMH SKDARRSTACUN SKDARRSTADDD SKDARRSTADEN SKDARRSTADFW
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTADSM SKDARRSTADTW SKDARRSTADUB SKDARRSTAEWR SKDARRSTAFCO
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAFLL SKDARRSTAFRA SKDARRSTAGCM SKDARRSTAGDL SKDARRSTAGEG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAGIG SKDARRSTAHNL SKDARRSTAIAH SKDARRSTAILM SKDARRSTAIND
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAJAX SKDARRSTAJFK SKDARRSTAKOA SKDARRSTALAS SKDARRSTALAX
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTALGA SKDARRSTALGB SKDARRSTALGW SKDARRSTALHR SKDARRSTALIH
2             0            0            0            0            0
5             0            0            0            0            0
7             1            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMAD SKDARRSTAMAN SKDARRSTAMBJ SKDARRSTAMCI SKDARRSTAMCO
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMDT SKDARRSTAMEX SKDARRSTAMHT SKDARRSTAMIA SKDARRSTAMKE
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMSP SKDARRSTAMSY SKDARRSTAMUC SKDARRSTAMZT SKDARRSTANAS
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAOAK SKDARRSTAOGG SKDARRSTAOMA SKDARRSTAONT SKDARRSTAORD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            1
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAORF SKDARRSTAPBI SKDARRSTAPDX SKDARRSTAPIT SKDARRSTAPLS
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAPPP SKDARRSTAPUJ SKDARRSTAPVD SKDARRSTAPVR SKDARRSTAPWM
2             1            0            0            0            0
5             1            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTARDU SKDARRSTARIC SKDARRSTARNO SKDARRSTAROC SKDARRSTARSW
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASAN SKDARRSTASAT SKDARRSTASEA SKDARRSTASFO SKDARRSTASJC
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASJD SKDARRSTASJO SKDARRSTASJU SKDARRSTASLC SKDARRSTASMF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASNA SKDARRSTASRQ SKDARRSTASTL SKDARRSTASTT SKDARRSTASXM
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASYR SKDARRSTATLV SKDARRSTATPA SKDARRSTAXHP SKDARRSTAYEG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAYVR SKDARRSTAYYC SKDARRSTAZRH SKDEQP319 SKDEQP320 SKDEQP321
2             0            0            0         0         0         0
5             0            0            0         0         0         0
7             0            0            0         0         0         1
13            0            0            0         0         0         0
14            0            0            0         0         0         1
17            0            0            0         0         0         0
   SKDEQP332 SKDEQP333 SKDEQP734 SKDEQP75E SKDEQP75H SKDEQP767 SKDEQPA01
2          0         0         1         0         0         0         0
5          0         0         0         0         0         0         0
7          0         0         0         0         0         0         0
13         0         0         1         0         0         0         0
14         0         0         0         0         0         0         0
17         0         0         0         0         0         0         0
   SKDEQPA05 SKDEQPA19 SKDEQPA21 SKDEQPE90 SKDEPS       D00    AVGSQ AVGLOFATC
2          0         0         0         0     32 0.2500000 3.258065  3.258065
5          0         0         0         1     72 0.2916667 2.986111  3.805556
7          0         0         0         0     88 0.3295455 2.551724  3.701149
13         0         0         0         0     32 0.3750000 3.000000  3.903226
14         0         0         0         0     72 0.3750000 3.295775  3.859155
17         0         0         0         0     84 0.3809524 3.939759  3.361446
   UPLINEATCIMPLow UPLINEATCIMPMed UPLINEATCIMPMedHigh UPLINEATCIMPMedLow
2                0               1                   0                  0
5                0               0                   0                  0
7                0               0                   0                  1
13               0               1                   0                  0
14               0               0                   0                  1
17               1               0                   0                  0
   DEPSTAATCIMPLow DOWNLINEATCIMPLow AVGSKDAVAIL AVAILBUCKETA05 AVAILBUCKETA10
2                0                 0   10.903226              0              1
5                1                 0    2.000000              0              0
7                0                 0    9.647059              1              0
13               0                 0   17.354839              0              0
14               0                 0   17.057143              0              0
17               0                 0   10.621951              0              1
   AVAILBUCKETA15 AVAILBUCKETA20 AVAILBUCKETA25 AVAILBUCKETA30 AVAILBUCKETA<0
2               0              0              0              0              0
5               0              0              0              0              0
7               0              0              0              0              0
13              1              0              0              0              0
14              1              0              0              0              0
17              0              0              0              0              0
   DEPBUCKETD2 DEPBUCKETD3 DEPBUCKETD4 DEPBUCKETD5 DEPBUCKETD6 DEPBUCKETD7
2            0           0           0           1           0           0
5            0           0           1           0           0           0
7            0           0           0           1           0           0
13           0           0           0           1           0           0
14           0           0           0           0           1           0
17           0           0           0           0           1           0
   DEPBUCKETD8 ARRBUCKETA2 ARRBUCKETA3 ARRBUCKETA4 ARRBUCKETA5 ARRBUCKETA6
2            0           0           0           0           0           1
5            0           0           0           0           1           0
7            0           0           0           0           0           1
13           0           0           0           0           0           1
14           0           0           0           0           0           0
17           0           0           0           0           0           1
   ARRBUCKETA7 ARRBUCKETA8 DEPRANKGRPLow DEPRANKGRPMed DEPRANKGRPMedHigh
2            0           0             1             0                 0
5            0           0             0             1                 0
7            0           0             1             0                 0
13           0           0             0             0                 0
14           1           0             1             0                 0
17           0           0             0             0                 0
   DEPRANKGRPMedLow TRNRANKGRPLow TRNRANKGRPMed TRNRANKGRPMedHigh
2                 0             1             0                 0
5                 0             1             0                 0
7                 0             1             0                 0
13                1             0             0                 0
14                0             1             0                 0
17                1             0             1                 0
   TRNRANKGRPMedLow ARRRANKGRPLow ARRRANKGRPMed ARRRANKGRPMedHigh
2                 0             0             0                 1
5                 0             0             0                 1
7                 0             0             1                 0
13                1             0             0                 0
14                0             0             0                 1
17                0             0             0                 1
   ARRRANKGRPMedLow DEPSPOKETRUE ARRSPOKETRUE xHNGRTRUE xDURN2
2                 0            0            0         0      2
5                 0            1            0         0      2
7                 0            0            1         0      2
13                1            0            1         0      2
14                0            0            1         0      2
17                0            0            0         0      2
> 
> dummies <- dummyVars(LEGTYPE ~ ., data = flight)
> flight.dum <- predict(dummies, newdata = flight)
> 
> ## It may be too big to use, but useful for inspection.
> 
> ### Numeric variables
> 
> ## Check some more numeric correlations, I haven't scaled yet.
> ## I'd cut correlations above 0.75 because of overfitting.
> 
> x1 <- as.data.frame(as.matrix(sapply(flight, class)))
> 
> flight.num <- flight[,names(x1[which(x1$V1 %in% c("numeric", "integer")),])]
> 
> flight.nzv <- nearZeroVar(flight.num, saveMetrics = TRUE)
> flight.nzv
            freqRatio percentUnique zeroVar   nzv
SDEPHR       1.038462        5.9375   FALSE FALSE
SKDEPS       1.000000       19.0625   FALSE FALSE
D00          1.166667       75.3125   FALSE FALSE
AVGSQ        6.333333       82.8125   FALSE FALSE
AVGLOFATC    1.000000       78.4375   FALSE FALSE
AVGSKDAVAIL  1.000000       87.5000   FALSE FALSE
xDURN2       1.428571        2.5000   FALSE FALSE
> 
> # annoying NA
> flight.cor <- cor(flight.num, use = "pairwise.complete.obs")
> 
> descrCorr <- findCorrelation(flight.cor, cutoff = .65, verbose=TRUE)
Considering row	 1 column	 4 value	 0.956 
  Flagging column	 1 
Considering row	 4 column	 3 value	 0.414 
Considering row	 4 column	 6 value	 0.173 
Considering row	 4 column	 7 value	 0.201 
Considering row	 4 column	 5 value	 0.103 
Considering row	 4 column	 2 value	 0.082 
Considering row	 3 column	 6 value	 0.266 
Considering row	 3 column	 7 value	 0.071 
Considering row	 3 column	 5 value	 0.114 
Considering row	 3 column	 2 value	 0.006 
Considering row	 6 column	 7 value	 0.031 
Considering row	 6 column	 5 value	 0.094 
Considering row	 6 column	 2 value	 0.067 
Considering row	 7 column	 5 value	 0.137 
Considering row	 7 column	 2 value	 0.005 
Considering row	 5 column	 2 value	 0.041 
> 
> colnames(flight.num)[descrCorr]
[1] "SDEPHR"
> 
> ## Which tells me that departure time is very highly correlated to AVGSQ.
> ## AVGSQ is average stand queue?
> 
> ### Try and impute the AVG, it might have more information than the
> ### bucket.
> 
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))
> 
> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1
> 
> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]
> 
> preProcValues <- preProcess(flight.na, method = c("knnImpute"))
> flight.na1 <- predict(preProcValues, flight.na)
> 
> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL
> 
> ## And I'll leave the centered and scale values in for now.
> ## and delete the troublesome ones
> 
> flight$AVGSKDAVAIL <- NULL
> flight$xHNGR <- NULL
> flight$AVAILBUCKET <- NULL
> 
> # This should be deleted, leave it in and the results are ideal because it defines LEGTYPE.
> flight$D00 <- NULL
> 
> ## Keep the results but don't change the order.
> outcomes.flight <- flight$LEGTYPE
> 
> flight$LEGTYPE <- NULL
> 
> ## If you know your factors are definitely factors, you don't need this
> ##  asNumeric <- function(x) as.numeric(as.character(x))
> 
> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))
> 
> flight.num0 <- factors.numeric(flight)
> 
> flight.scl0 <- scale(flight.num0)
> 
> ## Now split the results
> 
> set.seed(seed.mine)
> inTrain <- createDataPartition(outcomes.flight, p = 0.65, list = FALSE)
> 
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> 
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> 
> prop.table(table(flight.scl0))
flight.scl0
    -2.99546983996958     -2.98604368384811     -2.82110052361751 
           0.00281250            0.00015625            0.00015625 
    -2.64037641778924     -2.37742331516569     -2.09431321436608 
           0.00015625            0.00015625            0.00031250 
    -2.02525208119049     -2.02364615961949     -1.96706162425765 
           0.00046875            0.00093750            0.00015625 
    -1.94787383036273     -1.91934227796699     -1.87162293167633 
           0.00125000            0.00015625            0.00015625 
    -1.80813803757891      -1.8064397520718     -1.76880294648328 
           0.00093750            0.00093750            0.00453125 
     -1.7104004231695     -1.67620690253875     -1.63572266525187 
           0.00312500            0.00015625            0.00078125 
    -1.60554554037119     -1.58829697245811     -1.58375887562806 
           0.00265625            0.00062500            0.00031250 
    -1.56068940274137     -1.55266802930898     -1.55257138616628 
           0.00593750            0.00015625            0.00015625 
    -1.54865734259279     -1.54635333101763     -1.54295794614133 
           0.00015625            0.00015625            0.00015625 
    -1.53179508600425     -1.53074294246617     -1.50769426210174 
           0.00203125            0.00015625            0.00015625 
    -1.49330986644838     -1.47983129638045     -1.47646498237513 
           0.00015625            0.00171875            0.00015625 
    -1.44796824755814     -1.43812707979848     -1.43616463590287 
           0.00015625            0.00031250            0.00015625 
     -1.4311495031078     -1.42786750675664     -1.42754311366228 
           0.00062500            0.00031250            0.00015625 
     -1.4230237164245     -1.42196682798086     -1.40691590144974 
           0.00015625            0.00015625            0.00750000 
    -1.40295304316347     -1.39839761187043     -1.38337483337197 
           0.00343750            0.00015625            0.00015625 
    -1.37828409873765     -1.37590371713284      -1.3753288895824 
           0.00031250            0.00078125            0.00015625 
    -1.37383369560894     -1.37045453151584     -1.35466334686085 
           0.00015625            0.00015625            0.00015625 
    -1.33716625322094     -1.33398496346823     -1.33080367371552 
           0.00015625            0.00015625            0.00015625 
    -1.32393992750903      -1.3160853172316     -1.31578091655701 
           0.00093750            0.00015625            0.00015625 
    -1.31443367614047      -1.3133256164209     -1.30151560934568 
           0.00015625            0.00015625            0.00015625 
    -1.30111163600234     -1.29600486257245     -1.28619597667342 
           0.00015625            0.00031250            0.00031250 
    -1.28367748081635     -1.28186181839242      -1.2799413346293 
           0.00031250            0.00015625            0.00015625 
    -1.27197613788523     -1.26773489691459      -1.2671778786613 
           0.00109375            0.00015625            0.00015625 
     -1.2615812276646     -1.25974760485758     -1.25283365916062 
           0.00031250            0.00078125            0.00015625 
    -1.25178454113998     -1.24659260411695     -1.24079645146543 
           0.00015625            0.00015625            0.00015625 
     -1.2302338686483     -1.23020377865797      -1.2268968080815 
           0.00015625            0.00687500            0.00031250 
    -1.22001234826142     -1.21809512250389     -1.21512040999215 
           0.00046875            0.00015625            0.00015625 
    -1.21024953572476     -1.20647153886774     -1.20560405725029 
           0.00015625            0.00015625            0.00015625 
    -1.20188627600106     -1.20036054595575     -1.20011285144544 
           0.00031250            0.00140625            0.00015625 
    -1.19042311450129     -1.18991798468508     -1.18966337127103 
           0.00015625            0.00015625            0.00062500 
    -1.16804855863761     -1.16764210792351     -1.16749679150174 
           0.00093750            0.00015625            0.00015625 
    -1.16258400593847     -1.16018257780086     -1.15839829359119 
           0.00015625            0.00640625            0.00015625 
    -1.14179763548495     -1.13992628855288     -1.13935994002253 
           0.00015625            0.00031250            0.00031250 
    -1.13310730700243     -1.13102279477938     -1.12993289335973 
           0.00015625            0.00015625            0.00015625 
    -1.12915754122589     -1.12753063368423     -1.12667091460446 
           0.00015625            0.00015625            0.00015625 
    -1.12622940836933     -1.12368140470519     -1.12361616254288 
           0.00031250            0.00015625            0.00062500 
    -1.12145428351456     -1.11910330109794     -1.11800948418703 
           0.00015625            0.00015625            0.00015625 
    -1.11608476901381     -1.11429923219746     -1.09261479989672 
           0.00062500            0.00015625            0.00015625 
    -1.09084552937417     -1.09012044993392      -1.0895833019642 
           0.00015625            0.00015625            0.00031250 
    -1.08549109658463     -1.06938028371369     -1.06604781193988 
           0.00031250            0.00015625            0.00015625 
    -1.06587003530766        -1.06412097939     -1.05534288054392 
           0.00015625            0.00046875            0.00015625 
    -1.04945721011816     -1.04845626690162     -1.04766888572427 
           0.00015625            0.00015625            0.00015625 
    -1.04755297964098     -1.04598728075964     -1.04536609890991 
           0.00031250            0.00031250            0.00031250 
    -1.02993885350447     -1.02151758080685     -1.01733580186582 
           0.00015625            0.00203125            0.02453125 
    -1.01577847702439      -1.0138904262493      -1.0121571897662 
           0.00015625            0.00015625            0.00062500 
    -1.00929178081963     -1.00745946934895     -1.00714202059705 
           0.00015625            0.00015625            0.00015625 
    -1.00664275166081     -1.00407661804032     -1.00110637205939 
           0.00046875            0.00015625            0.00015625 
   -0.997768048748026    -0.991929422812267    -0.989060788495757 
           0.00328125            0.00015625            0.00031250 
    -0.98572380365604    -0.979554261682366    -0.976324799963229 
           0.00015625            0.00031250            0.00875000 
   -0.973173077974651    -0.971118460177678     -0.96975725707502 
           0.01640625            0.00015625            0.00015625 
   -0.963461694934854    -0.961159884505833    -0.960193400142389 
           0.00015625            0.00015625            0.00046875 
   -0.958010282948452    -0.957720936633644    -0.955230663538487 
           0.00015625            0.00015625            0.00015625 
   -0.953451859649493    -0.952397629449069    -0.951677411170411 
           0.00031250            0.00015625            0.01765625 
   -0.947281520180146    -0.946066444247069    -0.942123167843126 
           0.00015625            0.00015625            0.00015625 
   -0.941185041055857    -0.939666457415937    -0.937914389255748 
           0.00015625            0.00031250            0.00015625 
   -0.937428692031181    -0.937143144639067    -0.929006249994557 
           0.00015625            0.00203125            0.00031250 
   -0.928956547037233    -0.927234345076844    -0.926325405165677 
           0.00015625            0.00015625            0.00015625 
   -0.926208874394783     -0.92432711582923    -0.923751900565718 
           0.00015625            0.00015625            0.00015625 
   -0.921447647976772    -0.920026610901552    -0.919775930100724 
           0.00015625            0.00015625            0.00031250 
   -0.919418999070816    -0.918979533540974    -0.918834367344145 
           0.00093750            0.00015625            0.00015625 
   -0.918602057207572    -0.918233359080158    -0.916620305783416 
           0.00015625            0.00015625            0.00031250 
   -0.908229610518583    -0.907879271266391    -0.907626204980156 
           0.00031250            0.00015625            0.00015625 
   -0.906631706666217    -0.905610577820333    -0.905104725277818 
           0.00015625            0.00015625            0.00015625 
   -0.904170844231002    -0.902563699445797    -0.902495470961171 
           0.00031250            0.00015625            0.00046875 
   -0.902207570970879    -0.900277820755885    -0.900269127160796 
           0.00015625            0.00609375            0.00015625 
   -0.900105713501894    -0.897103060359799    -0.896252308815885 
           0.00015625            0.00015625            0.00015625 
   -0.895759768448355    -0.895685333371447    -0.891948830933419 
           0.00015625            0.00015625            0.00015625 
   -0.891482707849845     -0.89086838304768    -0.889814536282523 
           0.00015625            0.02343750            0.00015625 
   -0.886894039811436    -0.885423108336021    -0.885386138492139 
           0.00093750            0.00015625            0.01593750 
   -0.884574764423174    -0.881181388644532    -0.881133728915611 
           0.00015625            0.00015625            0.00015625 
   -0.879323305434347    -0.878872666379052    -0.877901133624378 
           0.00015625            0.00015625            0.00015625 
   -0.876749332956921    -0.876685019263073    -0.875765771148607 
           0.00031250            0.00015625            0.00031250 
   -0.875473779114446     -0.87537693015952    -0.872246314823305 
           0.00015625            0.00015625            0.00015625 
   -0.871001261435858    -0.870353841103083    -0.869162583211394 
           0.00015625            0.00015625            0.00015625 
   -0.866780745576637    -0.866244907634358    -0.858819232798091 
           0.00015625            0.00015625            0.00015625 
   -0.856265820894777    -0.844253476212177    -0.844066341550782 
           0.00078125            0.00015625            0.00015625 
   -0.842025743633279    -0.831738843759029    -0.830837909586882 
           0.02921875            0.00015625            0.02515625 
   -0.829374923233683    -0.828920190368225    -0.827915178181078 
           0.00015625            0.00093750            0.00015625 
   -0.827728686266157    -0.826039032973297    -0.822416105203804 
           0.00015625            0.00015625            0.00015625 
   -0.821797313281808    -0.819285769008092    -0.816336564086851 
           0.00015625            0.00015625            0.00015625 
   -0.814051297945908    -0.811605617460827    -0.809148421270981 
           0.00015625            0.00015625            0.00015625 
   -0.804302031270971    -0.800154571238789    -0.795175551540305 
           0.00062500            0.00015625            0.00171875 
   -0.792845872277945    -0.790185643279993    -0.789212464897955 
           0.02015625            0.00859375            0.00046875 
   -0.787996109659257    -0.785742695872334    -0.783287556756109 
           0.00015625            0.00015625            0.00015625 
    -0.78222517242437    -0.777611190965241    -0.777259256743858 
           0.00015625            0.00015625            0.00015625 
   -0.775052088417874    -0.768725111385422      -0.7653899578722 
           0.00031250            0.00015625            0.00015625 
   -0.764328853007072    -0.759372004638613    -0.759121665238872 
           0.00015625            0.00015625            0.00015625 
   -0.758171518227594    -0.752387355098689    -0.752338241647165 
           0.00015625            0.00015625            0.00031250 
   -0.751716727129916    -0.750007134146443    -0.748171465050933 
           0.00015625            0.00562500            0.00015625 
   -0.743693425437366     -0.74226506946404    -0.738477819728135 
           0.00718750            0.00015625            0.00015625 
   -0.735940818773818    -0.734501921638923    -0.723911474638978 
           0.00015625            0.00015625            0.00015625 
   -0.720697236097384    -0.718445199078953    -0.715142805531928 
           0.00031250            0.00015625            0.00031250 
   -0.713461500253351    -0.710452171936934    -0.708684788599593 
           0.00015625            0.00015625            0.00015625 
   -0.708003561812545    -0.702080356630785     -0.70037445202336 
           0.00015625            0.00015625            0.00203125 
    -0.69602539257426     -0.69280361708918    -0.687853983052082 
           0.00015625            0.03375000            0.00015625 
    -0.68694861300278    -0.684622918007104    -0.682222958529648 
           0.00015625            0.00015625            0.00015625 
   -0.681188975020078    -0.673798181086569     -0.66884926915034 
           0.00187500            0.00015625            0.00015625 
     -0.6653122497357    -0.654779601264497    -0.648410662399554 
           0.00015625            0.00015625            0.00078125 
   -0.647068571912601    -0.646559789740211    -0.633905116384853 
           0.00015625            0.00015625            0.00015625 
   -0.633276439235621    -0.626480919280269    -0.624813955253419 
           0.00015625            0.00015625            0.00015625 
   -0.621563193776932    -0.615573756562581    -0.613123253862724 
           0.00015625            0.00015625            0.00171875 
   -0.604038319371604    -0.596446872775748    -0.596237216599971 
           0.00015625            0.00046875            0.00015625 
   -0.596137826610777    -0.592583054332584    -0.590968847296576 
           0.00015625            0.00359375            0.00015625 
   -0.581016668721787     -0.57842864719944    -0.577046832499099 
           0.00015625            0.00015625            0.00015625 
   -0.576399963736262    -0.567294133064953    -0.562646449882806 
           0.00187500            0.00015625            0.00031250 
   -0.559949234902497    -0.553868745195444    -0.551562209118441 
           0.00031250            0.00015625            0.00859375 
   -0.548486073402725    -0.545057532705371    -0.544483083151942 
           0.00015625            0.00046875            0.00093750 
   -0.543553164656681    -0.542887786706365    -0.542791834600063 
           0.00015625            0.00015625            0.03859375 
   -0.535816263171991    -0.529620965141671    -0.523583345339874 
           0.00031250            0.00015625            0.00015625 
   -0.522876883678594    -0.515144874010522    -0.511242837482551 
           0.00015625            0.00015625            0.00015625 
   -0.511062050911504    -0.509452501139644    -0.507981951223969 
           0.00500000            0.00015625            0.00015625 
   -0.506004946851197    -0.504251327555701    -0.503668338010739 
           0.00015625            0.00203125            0.00015625 
   -0.497665904683127    -0.492519293528136    -0.488304476973275 
           0.00015625            0.00062500            0.00015625 
   -0.486275884354524    -0.480531685495119    -0.479070530598709 
           0.00015625            0.00015625            0.00015625 
   -0.476991811548017    -0.475764665500524    -0.473473045518126 
           0.00078125            0.00015625            0.00015625 
   -0.472612890303562    -0.464757185992567    -0.456186401194196 
           0.00015625            0.00015625            0.00015625 
   -0.454553689487183    -0.453074332488957    -0.452195518537862 
           0.00015625            0.00015625            0.00015625 
   -0.450040882361118    -0.446015592229304    -0.443168278929009 
           0.00015625            0.00015625            0.00015625 
    -0.44055550390433    -0.439275967288811    -0.439064986884659 
           0.00093750            0.00015625            0.00031250 
   -0.436572045333686    -0.433356062339654     -0.43210269137514 
           0.00015625            0.00015625            0.00031250 
   -0.429159183376661     -0.42811270638386    -0.424489571114943 
           0.00015625            0.00015625            0.00015625 
   -0.424136094192972    -0.422368710855631    -0.422286506964679 
           0.00015625            0.00015625            0.00015625 
     -0.4217879739841     -0.42160028367728    -0.408926090390664 
           0.00015625            0.00015625            0.00062500 
   -0.406238662084726    -0.405337563546837    -0.402845924603104 
           0.00015625            0.00015625            0.00015625 
   -0.398392401687235    -0.392753100892855    -0.392721940787981 
           0.00015625            0.00015625            0.00015625 
   -0.389990557124863    -0.383778543291898    -0.381829344162238 
           0.00203125            0.00031250            0.00031250 
   -0.378610740922975    -0.377352421209284     -0.37278098800314 
           0.00015625            0.00015625            0.00015625 
   -0.368704530397105    -0.364033384865912    -0.363121805899083 
           0.00015625            0.00015625            0.00015625 
   -0.361905601371654    -0.360992312891898     -0.36077985218898 
           0.00015625            0.00015625            0.00015625 
    -0.35995405519458    -0.354602189779798    -0.354221703071568 
           0.00046875            0.00015625            0.00015625 
   -0.354125613590753     -0.35383985286255    -0.350820163721666 
           0.00015625            0.00015625            0.00015625 
   -0.347880750045415    -0.347682518083072    -0.344794514479224 
           0.00031250            0.00015625            0.00015625 
   -0.344246401931106    -0.340586009596143    -0.338241270869783 
           0.00015625            0.00015625            0.00031250 
   -0.336627924656718    -0.333999550987416    -0.331679860754818 
           0.00015625            0.00015625            0.00015625 
   -0.327473828580897    -0.325591270635287    -0.320604647133837 
           0.00015625            0.00015625            0.00015625 
   -0.320293393650012    -0.318998347766866    -0.313800886365509 
           0.00015625            0.00015625            0.00015625 
   -0.308729731711204     -0.30775968479621    -0.307488803472333 
           0.00015625            0.00062500            0.00015625 
   -0.305912488397539    -0.300040013990283    -0.299281804870489 
           0.00015625            0.00015625            0.00015625 
   -0.297576089117692    -0.294612153988498    -0.290886990303406 
           0.00015625            0.00015625            0.00015625 
   -0.289476667647491    -0.287805419014019    -0.284664135032912 
           0.00015625            0.00031250            0.00062500 
   -0.283279035792871    -0.278947445070673    -0.278430676385642 
           0.00015625            0.00015625            0.01140625 
   -0.277028655971768    -0.274352800845479    -0.269810489634915 
           0.00015625            0.00015625            0.00875000 
   -0.268327804913194    -0.264273008183568    -0.263991250766728 
           0.00015625            0.00015625            0.00015625 
   -0.263633329101249    -0.256569345435893    -0.255210887064625 
           0.00015625            0.00015625            0.00015625 
   -0.254264930167697    -0.253205544043426    -0.250717006205447 
           0.00015625            0.00015625            0.00015625 
   -0.250531752899298    -0.249985351299549    -0.247578088366761 
           0.00015625            0.00015625            0.00015625 
   -0.244437996150226    -0.243268618233703    -0.242824942853484 
           0.00015625            0.00015625            0.00015625 
   -0.233740722783471    -0.232700345409106    -0.232349973253986 
           0.00015625            0.00015625            0.00015625 
   -0.231815214890401    -0.231309362347886     -0.23037548130107 
           0.00015625            0.00015625            0.00015625 
   -0.228412208040947    -0.226589859802479    -0.224837647995068 
           0.00015625            0.01656250            0.00015625 
   -0.223464759128966     -0.22331717855311    -0.222588752387258 
           0.00015625            0.00015625            0.00015625 
   -0.222456945885953    -0.220222816737245    -0.217487288707678 
           0.00015625            0.00031250            0.00046875 
   -0.216388232760497    -0.213098676881504    -0.212807560710942 
           0.00015625            0.00093750            0.00015625 
   -0.205527942504415    -0.202889656333141    -0.199061273711729 
           0.00015625            0.00015625            0.00015625 
   -0.197285663071406    -0.196655198635886    -0.187398059917142 
           0.00015625            0.00015625            0.00328125 
    -0.18553936273967    -0.184426534107832      -0.1807365557853 
           0.00015625            0.00015625            0.00031250 
   -0.173455385110242    -0.170696066339926    -0.167983070845547 
           0.00953125            0.00062500            0.00015625 
    -0.16706735776498     -0.16549287956689    -0.163323851054559 
           0.00015625            0.00015625            0.00015625 
   -0.163005226779217    -0.155721964916119     -0.15557956030375 
           0.00015625            0.00015625            0.00015625 
   -0.145050220201077    -0.140627037006184    -0.136663205761249 
           0.00015625            0.00015625            0.00015625 
   -0.135547666352963    -0.135353058341049    -0.135168941442998 
           0.00015625            0.00015625            0.00015625 
    -0.13422823788067    -0.128983100398563    -0.128772766161494 
           0.00015625            0.00015625            0.00062500 
   -0.128276147190878    -0.124732071896041    -0.122750748897942 
           0.00015625            0.00015625            0.00015625 
   -0.121913567685457    -0.114572129500928    -0.113273027561381 
           0.00015625            0.00015625            0.00015625 
   -0.107405286684043    -0.105529863556612    -0.103356043915892 
           0.00015625            0.00953125            0.00015625 
  -0.0959919473132286   -0.0946576344451732   -0.0921610479659292 
           0.00015625            0.00031250            0.00015625 
  -0.0897276946329045    -0.082082912166815   -0.0820786945748793 
           0.00015625            0.00015625            0.00031250 
  -0.0807439358161152   -0.0768089765376881   -0.0759616047321375 
           0.00015625            0.00140625            0.00015625 
  -0.0741942213947964   -0.0733788467156504   -0.0726315828860554 
           0.00015625            0.00718750            0.00015625 
  -0.0685974846038955   -0.0532150311664168   -0.0498043335027671 
           0.00093750            0.00015625            0.00015625 
  -0.0497543467601004   -0.0473016251818649   -0.0451490777305966 
           0.00015625            0.00015625            0.00031250 
  -0.0446498361490209   -0.0392160026639466   -0.0373582346840002 
           0.00015625            0.00015625            0.00015625 
  -0.0352851923820555   -0.0345646240252186   -0.0326438116903773 
           0.00031250            0.00031250            0.00015625 
  -0.0248451869138821   -0.0188880173129063    -0.013807090586871 
           0.00109375            0.00015625            0.00015625 
  -0.0119657325121257   -0.0114810502208166  -0.00721676013122688 
           0.00015625            0.00015625            0.00015625 
 -0.00368424503602545 -0.000580656453063986   0.00425466589044258 
           0.00015625            0.00015625            0.00015625 
  0.00624696207963468   0.00661720265702806    0.0104887638020741 
           0.00015625            0.00015625            0.00015625 
   0.0151944372905789    0.0177528116242494    0.0194770878491831 
           0.00421875            0.00015625            0.00015625 
   0.0217087977522383    0.0235168212825711    0.0255537765734798 
           0.00015625            0.00015625            0.00015625 
   0.0264730080152699    0.0271186027099238    0.0361351573082595 
           0.00015625            0.00031250            0.00015625 
   0.0362911121323546    0.0368634437985054    0.0454309894047899 
           0.00015625            0.00015625            0.00015625 
   0.0533298995579193    0.0570581595639766    0.0585759323236618 
           0.00015625            0.00937500            0.00015625 
   0.0675339577108118    0.0702113818864803    0.0729377618887858 
           0.00046875            0.00015625            0.00062500 
   0.0788793134968683    0.0789059252411879    0.0790823923337298 
           0.00015625            0.02343750            0.00046875 
   0.0797510873183287    0.0806069942083428    0.0841639835120876 
           0.00015625            0.00015625            0.00015625 
   0.0899621750174284    0.0966606496804153    0.0972018193465008 
           0.00015625            0.00015625            0.00015625 
    0.101566818289489     0.108411810410797     0.109012079979066 
           0.00062500            0.00015625            0.00046875 
     0.11244290268093     0.119444894039026     0.131046181957536 
           0.00015625            0.00015625            0.00203125 
    0.134889340170799     0.135028927523559     0.136658265622521 
           0.00015625            0.00015625            0.00015625 
    0.144157938789208     0.146258849789861     0.147318188850963 
           0.00015625            0.00015625            0.02984375 
    0.151115033119933     0.152349655315244     0.154426066228552 
           0.00015625            0.00015625            0.00015625 
     0.15737266071083     0.162873929857665     0.162973153669365 
           0.00015625            0.00015625            0.00015625 
    0.164891939398059     0.165580765616732     0.173693095305534 
           0.00015625            0.00015625            0.00015625 
    0.183009971581342     0.186789363756051     0.187969991368742 
           0.00093750            0.00015625            0.00015625 
    0.192709893790261     0.194724832331223     0.194735738184732 
           0.00015625            0.00015625            0.00015625 
    0.195991364801127     0.206802781312992     0.210386154876613 
           0.00015625            0.00015625            0.00500000 
    0.217235034249908       0.2177869344983     0.234906769563277 
           0.00031250            0.00203125            0.00015625 
    0.234973761205148     0.238837237065174     0.241127733319099 
           0.00031250            0.00015625            0.00015625 
    0.250135635132824      0.25028785413495     0.253309352340188 
           0.00015625            0.00015625            0.00078125 
    0.254814769298151     0.260835355687548     0.264960519475955 
           0.00015625            0.00015625            0.00015625 
    0.266044692238248      0.27127954776092     0.273304013334367 
           0.00015625            0.00015625            0.00015625 
    0.273531307307048     0.274822103147971     0.280770740587068 
           0.00015625            0.00015625            0.00015625 
    0.284591080073122     0.285810915205503     0.286937550828954 
           0.00015625            0.00015625            0.00046875 
    0.289640625615739     0.301307082566931     0.302882181759369 
           0.00015625            0.00015625            0.00015625 
    0.304256560508303     0.309710068792923     0.311251030414092 
           0.00015625            0.00015625            0.00015625 
    0.311802268812853     0.318128929047187     0.318922298138204 
           0.00015625            0.00031250            0.00015625 
    0.320852365313198     0.322875645177539     0.334350357273903 
           0.00015625            0.00015625            0.00015625 
    0.337167536402539     0.338400625416362     0.338901340452759 
           0.00015625            0.00031250            0.00140625 
    0.346939027258188     0.348766831423466     0.358991725758732 
           0.00015625            0.00015625            0.00015625 
    0.364034892089946     0.365884194608935     0.368674799710984 
           0.00015625            0.00015625            0.00015625 
    0.369643258716518     0.373829702918903     0.379821273586168 
           0.00015625            0.00062500            0.00015625 
    0.382087226815338      0.38685609839469       0.3878539441829 
           0.00015625            0.00015625            0.00015625 
     0.38923354153609     0.390865130076565     0.393785793790202 
           0.00015625            0.00093750            0.00015625 
    0.402956322412276     0.404247945632944      0.40569298299336 
           0.00015625            0.00015625            0.00015625 
    0.406064629649282      0.40786256349758     0.408056423319527 
           0.00015625            0.00109375            0.00015625 
    0.412247177017014     0.414419483912049     0.416346031539166 
           0.00015625            0.00046875            0.00015625 
     0.41794166276908     0.419463447191946     0.420106603846799 
           0.00015625            0.01078125            0.00015625 
    0.420379431706021     0.420869449539072     0.431214346889845 
           0.00406250            0.00015625            0.00015625 
    0.433937840525743     0.440278644951702     0.441895424076257 
           0.00031250            0.00015625            0.00015625 
    0.442828919700371     0.443274873059508     0.446173888246631 
           0.00046875            0.00984375            0.00015625 
    0.450718587802467     0.456900610463576     0.459555681956315 
           0.00015625            0.00031250            0.00015625 
    0.460696686048428     0.467876105484108     0.472728746197005 
           0.00015625            0.00015625            0.00015625 
    0.474472217743954     0.474601080341499     0.474734089218203 
           0.00015625            0.00031250            0.00015625 
    0.477973490467994     0.484307789443022     0.484652344952628 
           0.00015625            0.00015625            0.00015625 
    0.494792709324177     0.498497691565453     0.500784787450151 
           0.00109375            0.00515625            0.00015625 
    0.504691880000581     0.508425703980646      0.50861676779181 
           0.00031250            0.00015625            0.00015625 
     0.50996114523361     0.514344382856681     0.516995457862692 
           0.00015625            0.00015625            0.00015625 
    0.518586102739047     0.521829770584971     0.523840570430114 
           0.00015625            0.00015625            0.00015625 
    0.524285913333902     0.525227742436545     0.527917885589494 
           0.00015625            0.00015625            0.00015625 
    0.531983533422768     0.539966728864973     0.541903897062432 
           0.00015625            0.00015625            0.00046875 
    0.543994005812287     0.545724786000498     0.546756498947983 
           0.00125000            0.00015625            0.00203125 
    0.548923619243861     0.549353970396232       0.5588553176537 
           0.00015625            0.00015625            0.00031250 
    0.564138483610525     0.566992546543754     0.569133261860447 
           0.00015625            0.00015625            0.00015625 
    0.574903744908869     0.577978215152712     0.578343495716271 
           0.00031250            0.00109375            0.00015625 
    0.580241024741447     0.581634314964003     0.583204933976379 
           0.00015625            0.00015625            0.00015625 
     0.58873859479558     0.595455758634415     0.597057916427158 
           0.00015625            0.00031250            0.00015625 
    0.598720288571789     0.599162991111384     0.599578938399305 
           0.00031250            0.00015625            0.00015625 
     0.60342049593258     0.604292419065582     0.607847397763963 
           0.00015625            0.00015625            0.00015625 
    0.611956869618315     0.612059726969641     0.612784292101807 
           0.00015625            0.00062500            0.00015625 
    0.613557486760981     0.620580331763515     0.622971928913742 
           0.00015625            0.00015625            0.00375000 
     0.63588348041021     0.641390081029809     0.643182929950686 
           0.00015625            0.00015625            0.00015625 
    0.648293425210027     0.650684078195595     0.657754904789885 
           0.00015625            0.00046875            0.00015625 
    0.664732625480728     0.665678528246394     0.665791697835918 
           0.00015625            0.00984375            0.00015625 
    0.666578602798705     0.678050028820375     0.678379635730825 
           0.00015625            0.00015625            0.00015625 
    0.679808655934455     0.680412565586961     0.680711498268701 
           0.00328125            0.00015625            0.00015625 
    0.684080216155581     0.684149053017272     0.685295140133807 
           0.00281250            0.00015625            0.00031250 
    0.686201169423553     0.690582799388141     0.692180702201577 
           0.00015625            0.00421875            0.00015625 
    0.696595449900374     0.697435597111395     0.698914306548046 
           0.00015625            0.00015625            0.00015625 
     0.70193206265865     0.702647867819401     0.707754986014002 
           0.00015625            0.00062500            0.00015625 
    0.711210346763156     0.712920206015224     0.713369947147153 
           0.00015625            0.00015625            0.00015625 
    0.715327471836729     0.722275487513834     0.722728216151602 
           0.00031250            0.00156250            0.00015625 
      0.7239248415172      0.72708089915877     0.729737150343281 
           0.00015625            0.00015625            0.00015625 
    0.735388003016973     0.740385327518889     0.741422651587756 
           0.00031250            0.00015625            0.00015625 
    0.741444754160499     0.747108762937508     0.748191169284348 
           0.00015625            0.00031250            0.00015625 
    0.751436430272142     0.752533256420978     0.752674676426801 
           0.00015625            0.00015625            0.00015625 
    0.754611657443207     0.754889027400603     0.756349639135923 
           0.00125000            0.00015625            0.00015625 
    0.763526062479594     0.768717423291569     0.770997182276433 
           0.00015625            0.00015625            0.00015625 
     0.77805655959217     0.780455501601279      0.79111659134251 
           0.00015625            0.00015625            0.00015625 
    0.794424123694395     0.794542595446869     0.797594367513394 
           0.00046875            0.00015625            0.00015625 
    0.806459604893308     0.806575447067013     0.815325824113437 
           0.00015625            0.00171875            0.00031250 
    0.820054212719794     0.821566079066492     0.822735985643791 
           0.00015625            0.00015625            0.00015625 
    0.824910396049865     0.825564426121463     0.827093295015157 
           0.00015625            0.00281250            0.00015625 
    0.830498441784675     0.839706577696515     0.854374875678462 
           0.00031250            0.00015625            0.00015625 
    0.857045424718981     0.857046899457354     0.858539236690819 
           0.00031250            0.00015625            0.00109375 
    0.861958482401254     0.864973903806387     0.868060666977836 
           0.00015625            0.00031250            0.00015625 
    0.871547517399078     0.877907606552374     0.878620392468042 
           0.00015625            0.00031250            0.00015625 
    0.882079910398028     0.886773165429333     0.895872264013794 
           0.00015625            0.00015625            0.00031250 
    0.902874892971196     0.909893594892982     0.910503026314625 
           0.00015625            0.00015625            0.00015625 
    0.918355472177732     0.923930998062757     0.928610132228083 
           0.00156250            0.00015625            0.00015625 
    0.930580294371997     0.932353440099381     0.933043163131344 
           0.00015625            0.00015625            0.00015625 
    0.935865275090846     0.938721396055517      0.94732667023698 
           0.00015625            0.00015625            0.00015625 
    0.952388332756409     0.953472399517577     0.960457391255192 
           0.00046875            0.00015625            0.00015625 
    0.962466815938431     0.974608403263273     0.977273131185975 
           0.00031250            0.00015625            0.00015625 
    0.979887858238853     0.981765099822977     0.982533764258785 
           0.02546875            0.00015625            0.00015625 
    0.986421193335086     0.991131333762411      0.99464772824313 
           0.00046875            0.00015625            0.00015625 
     1.00529335053186      1.01443060556224       1.0145402019372 
           0.00015625            0.00062500            0.00015625 
     1.02257036343242      1.02480443153783      1.02810330735672 
           0.00015625            0.00015625            0.00015625 
     1.02815692332918       1.0286099206142      1.03278708868866 
           0.00265625            0.00015625            0.00015625 
     1.03867605371823      1.04030809775545      1.05026762861212 
           0.00015625            0.00046875            0.00015625 
     1.05448691449244       1.0552263521649      1.05588258974527 
           0.00125000            0.00015625            0.00015625 
     1.06000513122926      1.06639439518604      1.07107601485988 
           0.00906250            0.00078125            0.00015625 
     1.07323792501438      1.07985999257921      1.08185178624946 
           0.00015625            0.00015625            0.00015625 
     1.08200577310599      1.08501442587133      1.08924264046828 
           0.00015625            0.00015625            0.00015625 
     1.09237983879524      1.09858922192811      1.09934822043348 
           0.00015625            0.00015625            0.00015625 
      1.1078948637414      1.11407400788163      1.11835818480985 
           0.00015625            0.00015625            0.00093750 
     1.11909298650692      1.12255263564979      1.13098492845703 
           0.00125000            0.00640625            0.00718750 
     1.13520899613199      1.13659865262031      1.14324263811607 
           0.00015625            0.00031250            0.00015625 
      1.1444495252129       1.1551673045972      1.15841602768456 
           0.00578125            0.00046875            0.00015625 
     1.17032197443365      1.17077944389967      1.17660425916148 
           0.00156250            0.01546875            0.00015625 
     1.17671971786951      1.18390085758965      1.19061835680715 
           0.00031250            0.02078125            0.00078125 
     1.19124162268748      1.19491419845781      1.20187158527135 
           0.00046875            0.01000000            0.00015625 
     1.20935820034015      1.21534749252995      1.21684078311872 
           0.00015625            0.00015625            0.00015625 
     1.22228576405746      1.22358524293339       1.2307494205369 
           0.00046875            0.00375000            0.00359375 
     1.23190824585799      1.23309624815214       1.2482497077686 
           0.00015625            0.00015625            0.00015625 
     1.24914605564843      1.25030062698194      1.25167385090479 
           0.00015625            0.00015625            0.00015625 
      1.2521388586462      1.25403638767138      1.25696184836792 
           0.00015625            0.00015625            0.00015625 
     1.25865710330342      1.26219503016375      1.26339025886804 
           0.00015625            0.00015625            0.00062500 
     1.27424955368127      1.27429889692881      1.27581391381442 
           0.00062500            0.01093750            0.00015625 
     1.28103448636196      1.28422435170195      1.28502302740832 
           0.00015625            0.00015625            0.00015625 
     1.28694332261892      1.28862136579613      1.29135133286724 
           0.00015625            0.00015625            0.00015625 
     1.29271693854318      1.29352984392642      1.29416501801516 
           0.00093750            0.00015625            0.00015625 
     1.32000923372796      1.32621334330507      1.32674979912185 
           0.00015625            0.00031250            0.00031250 
      1.3355388950486      1.33819762355126      1.34572143844383 
           0.00703125            0.00015625            0.00015625 
     1.34900429115538      1.35106912963136      1.35909050306374 
           0.00015625            0.00015625            0.00015625 
     1.36740896432616      1.37732504122682      1.37817713292888 
           0.00015625            0.00015625            0.00171875 
     1.38155034894393      1.38244688032714      1.38971756538262 
           0.00015625            0.00015625            0.00015625 
     1.39337346848199      1.39481552027921      1.39920925968592 
           0.00015625            0.00015625            0.00015625 
     1.40401019415033      1.40768753122916      1.42034462702771 
           0.00015625            0.00046875            0.00031250 
     1.42884838085788      1.43014092255268      1.43175470937195 
           0.00062500            0.00078125            0.00015625 
     1.43334191774463      1.43396654425843      1.43750664054499 
           0.00046875            0.00015625            0.00015625 
     1.43754219334743       1.4388998201083      1.44153927902681 
           0.00015625            0.01625000            0.01421875 
     1.44769121849116      1.44889234688456      1.45317034273597 
           0.00015625            0.00015625            0.00015625 
     1.45756717172523      1.46514717542552      1.48152004641465 
           0.00015625            0.01359375            0.00015625 
     1.48210471217649       1.4854271336131      1.49691410201524 
           0.00187500            0.00015625            0.00031250 
     1.50460499505036          1.5159104855      1.51944062018193 
           0.00015625            0.00062500            0.00015625 
     1.51951797036384      1.52322014302823      1.52914361888698 
           0.00015625            0.00015625            0.00015625 
     1.53094696259391      1.53185854523801      1.54534195968881 
           0.00015625            0.00015625            0.00015625 
     1.55198480359028      1.55950143190504      1.56497982317259 
           0.00031250            0.00015625            0.00015625 
     1.58262031982126      1.59616721426295      1.60437565730193 
           0.00062500            0.00015625            0.00015625 
     1.61266940307664      1.61805143272205      1.63593441495235 
           0.00015625            0.00015625            0.00390625 
     1.66020775786113      1.67542635415394      1.67673538939901 
           0.00046875            0.00015625            0.00437500 
     1.68035708519021      1.68346836697786      1.68837599513398 
           0.00015625            0.00015625            0.00015625 
     1.68938234802037      1.70189867028665      1.70300688645049 
           0.00015625            0.00015625            0.00015625 
     1.70487078400102      1.71353493899627      1.72834558905075 
           0.00015625            0.00015625            0.00015625 
     1.72915591888238      1.73426417234817      1.74021109248258 
           0.00015625            0.00015625            0.00015625 
     1.74232222740301      1.74349939634561       1.7580041756475 
           0.00015625            0.00015625            0.00015625 
     1.76113921780106      1.76617520172517      1.77211632108358 
           0.00015625            0.00015625            0.00015625 
     1.77514993495452      1.79958280830507      1.81629669477704 
           0.00015625            0.00015625            0.00031250 
     1.81990457312901      1.83656963213994      1.83724270780201 
           0.00015625            0.01140625            0.00015625 
     1.84610801109783      1.87127556838068      1.87941151145041 
           0.00015625            0.00031250            0.00015625 
     1.88207392317223      1.89017691499225      1.91733288828094 
           0.00031250            0.00015625            0.00015625 
     1.94867279430132      1.95578696468731      1.95652907096428 
           0.00687500            0.00015625            0.00015625 
     1.96029188648611      1.97337415011671      1.97682872944693 
           0.00015625            0.00015625            0.00015625 
     1.97898223695928      2.01790204562771      2.04143987127407 
           0.00015625            0.00015625            0.00171875 
     2.04788306887298      2.07547273185274      2.09309957494449 
           0.00062500            0.00031250            0.00015625 
     2.09950420993508      2.10052429104874      2.10697756530747 
           0.00031250            0.00015625            0.00015625 
     2.11999156344762      2.12917389303477      2.15933629269958 
           0.00015625            0.00015625            0.00015625 
     2.18306393167287      2.18323513022319      2.18704108088277 
           0.00187500            0.00015625            0.00015625 
     2.23887211958444      2.24380917557826      2.28051444339884 
           0.00015625            0.00015625            0.00562500 
     2.28417103037285      2.30954548348617      2.34561980157645 
           0.00015625            0.00125000            0.00015625 
     2.52385907644018      3.01185818638057      3.23514293488871 
           0.00015625            0.00015625            0.00031250 
     3.52347021972545      4.91171482734768      5.33930094132038 
           0.00015625            0.00015625            0.00015625 
     6.39137994453622      6.97999767626588 
           0.00015625            0.00015625 
> 
> prop.table(table(trainClass))
trainClass
   Strong      Weak 
0.4449761 0.5550239 
> 
> dim(trainDescr)
[1] 209  20
> dim(testDescr)
[1] 111  20
> 
> ## Check Near-zero variance
> 
> nzv <- nearZeroVar(trainDescr, saveMetrics= TRUE)
> stopifnot( all(nzv$nzv == FALSE) )
> 
> # It's imputed and behaves well, no need for this.
> # descrCorr <- cor(scale(trainDescr), use = "pairwise.complete.obs")
> 
> descrCorr <- cor(scale(trainDescr))
> 
> ## This cut-off should be under src.adjust control.
> ## I'm under Git, so I can tinker with it.
> highCorr <- findCorrelation(descrCorr, cutoff = .65, verbose = TRUE)
Considering row	 1 column	 11 value	 0.988 
  Flagging column	 1 
Considering row	 11 column	 10 value	 0.353 
Considering row	 11 column	 17 value	 0.312 
Considering row	 11 column	 16 value	 0.284 
Considering row	 11 column	 6 value	 0.953 
  Flagging column	 11 
Considering row	 10 column	 17 value	 0.63 
Considering row	 10 column	 16 value	 0.547 
Considering row	 10 column	 6 value	 0.362 
Considering row	 10 column	 12 value	 0.33 
Considering row	 10 column	 14 value	 0.299 
Considering row	 10 column	 2 value	 0.354 
Considering row	 10 column	 8 value	 0.363 
Considering row	 10 column	 9 value	 0.386 
Considering row	 10 column	 13 value	 0.27 
Considering row	 10 column	 18 value	 0.222 
Considering row	 10 column	 19 value	 0.135 
Considering row	 10 column	 3 value	 0.435 
Considering row	 10 column	 20 value	 0.069 
Considering row	 10 column	 15 value	 0.25 
Considering row	 10 column	 7 value	 0.182 
Considering row	 10 column	 5 value	 0.082 
Considering row	 10 column	 4 value	 0.041 
Considering row	 17 column	 16 value	 0.873 
  Flagging column	 17 
Considering row	 16 column	 6 value	 0.22 
Considering row	 16 column	 12 value	 0.231 
Considering row	 16 column	 14 value	 0.24 
Considering row	 16 column	 2 value	 0.341 
Considering row	 16 column	 8 value	 0.605 
Considering row	 16 column	 9 value	 0.657 
  Flagging column	 16 
Considering row	 6 column	 12 value	 0.891 
  Flagging column	 6 
Considering row	 12 column	 14 value	 0.167 
Considering row	 12 column	 2 value	 0.103 
Considering row	 12 column	 8 value	 0.14 
Considering row	 12 column	 9 value	 0.076 
Considering row	 12 column	 13 value	 0.154 
Considering row	 12 column	 18 value	 0.145 
Considering row	 12 column	 19 value	 0.108 
Considering row	 12 column	 3 value	 0.111 
Considering row	 12 column	 20 value	 0.145 
Considering row	 12 column	 15 value	 0.187 
Considering row	 12 column	 7 value	 0.159 
Considering row	 12 column	 5 value	 0.093 
Considering row	 12 column	 4 value	 0.005 
Considering row	 14 column	 2 value	 0.593 
Considering row	 14 column	 8 value	 0.122 
Considering row	 14 column	 9 value	 0.098 
Considering row	 14 column	 13 value	 0.668 
  Flagging column	 14 
Considering row	 2 column	 8 value	 0.24 
Considering row	 2 column	 9 value	 0.485 
Considering row	 2 column	 13 value	 0.585 
Considering row	 2 column	 18 value	 0.187 
Considering row	 2 column	 19 value	 0.085 
Considering row	 2 column	 3 value	 0.262 
Considering row	 2 column	 20 value	 0.022 
Considering row	 2 column	 15 value	 0.117 
Considering row	 2 column	 7 value	 0.05 
Considering row	 2 column	 5 value	 0.104 
Considering row	 2 column	 4 value	 0.165 
Considering row	 8 column	 9 value	 0.481 
Considering row	 8 column	 13 value	 0.11 
Considering row	 8 column	 18 value	 0.175 
Considering row	 8 column	 19 value	 0.297 
Considering row	 8 column	 3 value	 0.265 
Considering row	 8 column	 20 value	 0.22 
Considering row	 8 column	 15 value	 0.043 
Considering row	 8 column	 7 value	 0.1 
Considering row	 8 column	 5 value	 0.045 
Considering row	 8 column	 4 value	 0.007 
Considering row	 9 column	 13 value	 0.139 
Considering row	 9 column	 18 value	 0.014 
Considering row	 9 column	 19 value	 0.351 
Considering row	 9 column	 3 value	 0.279 
Considering row	 9 column	 20 value	 0.223 
Considering row	 9 column	 15 value	 0.033 
Considering row	 9 column	 7 value	 0.141 
Considering row	 9 column	 5 value	 0.115 
Considering row	 9 column	 4 value	 0.002 
Considering row	 13 column	 18 value	 0.185 
Considering row	 13 column	 19 value	 0.105 
Considering row	 13 column	 3 value	 0.167 
Considering row	 13 column	 20 value	 0.143 
Considering row	 13 column	 15 value	 0.178 
Considering row	 13 column	 7 value	 0.073 
Considering row	 13 column	 5 value	 0.014 
Considering row	 13 column	 4 value	 0.152 
Considering row	 18 column	 19 value	 0.146 
Considering row	 18 column	 3 value	 0.012 
Considering row	 18 column	 20 value	 0.032 
Considering row	 18 column	 15 value	 0.186 
Considering row	 18 column	 7 value	 0.09 
Considering row	 18 column	 5 value	 0.047 
Considering row	 18 column	 4 value	 0.04 
Considering row	 19 column	 3 value	 0.151 
Considering row	 19 column	 20 value	 0.854 
  Flagging column	 19 
Considering row	 3 column	 20 value	 0.025 
Considering row	 3 column	 15 value	 0.063 
Considering row	 3 column	 7 value	 0.127 
Considering row	 3 column	 5 value	 0.076 
Considering row	 3 column	 4 value	 0.127 
Considering row	 20 column	 15 value	 0.023 
Considering row	 20 column	 7 value	 0.034 
Considering row	 20 column	 5 value	 0.084 
Considering row	 20 column	 4 value	 0.029 
Considering row	 15 column	 7 value	 0.076 
Considering row	 15 column	 5 value	 0.082 
Considering row	 15 column	 4 value	 0.029 
Considering row	 7 column	 5 value	 0.009 
Considering row	 7 column	 4 value	 0.006 
Considering row	 5 column	 4 value	 0.211 
> 
> colnames(trainDescr)[highCorr]
[1] "SDEPHR"       "DEPBUCKET"    "ARRSPOKE"     "DEPSPOKE"     "AVGSQ"       
[6] "TRNRANKGRP"   "xAVAILBUCKET"
> 
> descr.ncol0 <- ncol(trainDescr)
> 
> # I've switched off the correlation remover and the results are better.
> if (sum(highCorr) > 0) {
+     warning("overfitting: correlations: err.trainDescr: ", paste(colnames(trainDescr)[highCorr], collapse = ", ") )
+     err.trainDescr <- trainDescr
+     trainDescr <- trainDescr[,-highCorr]
+ }
Warning message:
overfitting: correlations: err.trainDescr: SDEPHR, DEPBUCKET, ARRSPOKE, DEPSPOKE, AVGSQ, TRNRANKGRP, xAVAILBUCKET 
> 
> descr.ncol1 <- ncol(trainDescr)
> 
> paste("Dropped: ", as.character(descr.ncol0 - descr.ncol1))
[1] "Dropped:  7"
> 
> descrCorr <- cor(trainDescr)
> summary(descrCorr[upper.tri(descrCorr)])
     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
-0.480800 -0.123900 -0.009124 -0.005226  0.104300  0.585100 
> 
> ## Dominant correlations
> ## At 0.9, there are some big ones that might need re-thinking.
> 
> table.descrCorr <- as.data.frame(as.table(descrCorr))
> table.descrCorr <- table.descrCorr[which(table.descrCorr$Var1 != table.descrCorr$Var2),]
> table.descrCorr[order(abs(table.descrCorr$Freq), decreasing = TRUE),]
              Var1           Var2         Freq
10      DEPRANKGRP      SKDDEPSTA  0.585062502
118      SKDDEPSTA     DEPRANKGRP  0.585062502
7     DEPSTAATCIMP      SKDDEPSTA  0.484804073
79       SKDDEPSTA   DEPSTAATCIMP  0.484804073
72    DEPSTAATCIMP   UPLINEATCIMP -0.480791418
84    UPLINEATCIMP   DEPSTAATCIMP -0.480791418
21  DOWNLINEATCIMP      SKDARRSTA  0.434797243
93       SKDARRSTA DOWNLINEATCIMP  0.434797243
86  DOWNLINEATCIMP   DEPSTAATCIMP -0.385976171
98    DEPSTAATCIMP DOWNLINEATCIMP -0.385976171
73  DOWNLINEATCIMP   UPLINEATCIMP  0.363095078
97    UPLINEATCIMP DOWNLINEATCIMP  0.363095078
8   DOWNLINEATCIMP      SKDDEPSTA -0.354153144
92       SKDDEPSTA DOWNLINEATCIMP -0.354153144
100      ARRBUCKET DOWNLINEATCIMP  0.330120221
112 DOWNLINEATCIMP      ARRBUCKET  0.330120221
20    DEPSTAATCIMP      SKDARRSTA -0.279028496
80       SKDARRSTA   DEPSTAATCIMP -0.279028496
101     DEPRANKGRP DOWNLINEATCIMP -0.269803961
125 DOWNLINEATCIMP     DEPRANKGRP -0.269803961
19    UPLINEATCIMP      SKDARRSTA  0.264657060
67       SKDARRSTA   UPLINEATCIMP  0.264657060
2        SKDARRSTA      SKDDEPSTA -0.261984855
14       SKDDEPSTA      SKDARRSTA -0.261984855
102     ARRRANKGRP DOWNLINEATCIMP -0.250417711
138 DOWNLINEATCIMP     ARRRANKGRP -0.250417711
6     UPLINEATCIMP      SKDDEPSTA -0.239643735
66       SKDDEPSTA   UPLINEATCIMP -0.239643735
91    xAVGSKDAVAIL   DEPSTAATCIMP -0.222706877
163   DEPSTAATCIMP   xAVGSKDAVAIL -0.222706877
103         xDURN2 DOWNLINEATCIMP -0.221781577
151 DOWNLINEATCIMP         xDURN2 -0.221781577
78    xAVGSKDAVAIL   UPLINEATCIMP  0.219674015
162   UPLINEATCIMP   xAVGSKDAVAIL  0.219674015
30          SKDEPS         SKDEQP  0.210956794
42          SKDEQP         SKDEPS  0.210956794
12          xDURN2      SKDDEPSTA  0.187430706
144      SKDDEPSTA         xDURN2  0.187430706
115     ARRRANKGRP      ARRBUCKET -0.187028885
139      ARRBUCKET     ARRRANKGRP -0.187028885
142         xDURN2     ARRRANKGRP  0.185835094
154     ARRRANKGRP         xDURN2  0.185835094
129         xDURN2     DEPRANKGRP  0.184991436
153     DEPRANKGRP         xDURN2  0.184991436
60  DOWNLINEATCIMP      AVGLOFATC -0.181924349
96       AVGLOFATC DOWNLINEATCIMP -0.181924349
128     ARRRANKGRP     DEPRANKGRP  0.177915590
140     DEPRANKGRP     ARRRANKGRP  0.177915590
77          xDURN2   UPLINEATCIMP -0.174824454
149   UPLINEATCIMP         xDURN2 -0.174824454
23      DEPRANKGRP      SKDARRSTA -0.167141066
119      SKDARRSTA     DEPRANKGRP -0.167141066
3           SKDEQP      SKDDEPSTA  0.164894903
27       SKDDEPSTA         SKDEQP  0.164894903
61       ARRBUCKET      AVGLOFATC -0.158812104
109      AVGLOFATC      ARRBUCKET -0.158812104
114     DEPRANKGRP      ARRBUCKET -0.154476581
126      ARRBUCKET     DEPRANKGRP -0.154476581
36      DEPRANKGRP         SKDEQP  0.152214336
120         SKDEQP     DEPRANKGRP  0.152214336
116         xDURN2      ARRBUCKET -0.145215791
152      ARRBUCKET         xDURN2 -0.145215791
117   xAVGSKDAVAIL      ARRBUCKET -0.144677002
165      ARRBUCKET   xAVGSKDAVAIL -0.144677002
130   xAVGSKDAVAIL     DEPRANKGRP  0.142956616
166     DEPRANKGRP   xAVGSKDAVAIL  0.142956616
59    DEPSTAATCIMP      AVGLOFATC -0.141107173
83       AVGLOFATC   DEPSTAATCIMP -0.141107173
74       ARRBUCKET   UPLINEATCIMP  0.140056918
110   UPLINEATCIMP      ARRBUCKET  0.140056918
88      DEPRANKGRP   DEPSTAATCIMP  0.139329660
124   DEPSTAATCIMP     DEPRANKGRP  0.139329660
18       AVGLOFATC      SKDARRSTA -0.126735710
54       SKDARRSTA      AVGLOFATC -0.126735710
16          SKDEQP      SKDARRSTA  0.126617684
28       SKDARRSTA         SKDEQP  0.126617684
11      ARRRANKGRP      SKDDEPSTA  0.116715200
131      SKDDEPSTA     ARRRANKGRP  0.116715200
46    DEPSTAATCIMP         SKDEPS -0.115428724
82          SKDEPS   DEPSTAATCIMP -0.115428724
22       ARRBUCKET      SKDARRSTA  0.111222093
106      SKDARRSTA      ARRBUCKET  0.111222093
75      DEPRANKGRP   UPLINEATCIMP -0.109652113
123   UPLINEATCIMP     DEPRANKGRP -0.109652113
4           SKDEPS      SKDDEPSTA -0.103573343
40       SKDDEPSTA         SKDEPS -0.103573343
9        ARRBUCKET      SKDDEPSTA -0.103178190
105      SKDDEPSTA      ARRBUCKET -0.103178190
58    UPLINEATCIMP      AVGLOFATC -0.099921957
70       AVGLOFATC   UPLINEATCIMP -0.099921957
48       ARRBUCKET         SKDEPS -0.093262124
108         SKDEPS      ARRBUCKET -0.093262124
64          xDURN2      AVGLOFATC -0.089998526
148      AVGLOFATC         xDURN2 -0.089998526
52    xAVGSKDAVAIL         SKDEPS  0.083630672
160         SKDEPS   xAVGSKDAVAIL  0.083630672
50      ARRRANKGRP         SKDEPS  0.081740209
134         SKDEPS     ARRRANKGRP  0.081740209
47  DOWNLINEATCIMP         SKDEPS -0.081550414
95          SKDEPS DOWNLINEATCIMP -0.081550414
87       ARRBUCKET   DEPSTAATCIMP -0.076383973
111   DEPSTAATCIMP      ARRBUCKET -0.076383973
17          SKDEPS      SKDARRSTA -0.076186486
41       SKDARRSTA         SKDEPS -0.076186486
63      ARRRANKGRP      AVGLOFATC -0.075502916
135      AVGLOFATC     ARRRANKGRP -0.075502916
62      DEPRANKGRP      AVGLOFATC  0.073089053
122      AVGLOFATC     DEPRANKGRP  0.073089053
104   xAVGSKDAVAIL DOWNLINEATCIMP  0.069107989
164 DOWNLINEATCIMP   xAVGSKDAVAIL  0.069107989
24      ARRRANKGRP      SKDARRSTA  0.063294417
132      SKDARRSTA     ARRRANKGRP  0.063294417
5        AVGLOFATC      SKDDEPSTA -0.049562063
53       SKDDEPSTA      AVGLOFATC -0.049562063
51          xDURN2         SKDEPS  0.046951938
147         SKDEPS         xDURN2  0.046951938
45    UPLINEATCIMP         SKDEPS  0.045346781
69          SKDEPS   UPLINEATCIMP  0.045346781
76      ARRRANKGRP   UPLINEATCIMP  0.043157477
136   UPLINEATCIMP     ARRRANKGRP  0.043157477
34  DOWNLINEATCIMP         SKDEQP -0.041016354
94          SKDEQP DOWNLINEATCIMP -0.041016354
38          xDURN2         SKDEQP  0.039910387
146         SKDEQP         xDURN2  0.039910387
65    xAVGSKDAVAIL      AVGLOFATC -0.033981120
161      AVGLOFATC   xAVGSKDAVAIL -0.033981120
89      ARRRANKGRP   DEPSTAATCIMP  0.032959657
137   DEPSTAATCIMP     ARRRANKGRP  0.032959657
156   xAVGSKDAVAIL         xDURN2 -0.031789386
168         xDURN2   xAVGSKDAVAIL -0.031789386
39    xAVGSKDAVAIL         SKDEQP  0.029020869
159         SKDEQP   xAVGSKDAVAIL  0.029020869
37      ARRRANKGRP         SKDEQP -0.028886971
133         SKDEQP     ARRRANKGRP -0.028886971
26    xAVGSKDAVAIL      SKDARRSTA  0.024887817
158      SKDARRSTA   xAVGSKDAVAIL  0.024887817
143   xAVGSKDAVAIL     ARRRANKGRP -0.022846170
167     ARRRANKGRP   xAVGSKDAVAIL -0.022846170
13    xAVGSKDAVAIL      SKDDEPSTA  0.022173013
157      SKDDEPSTA   xAVGSKDAVAIL  0.022173013
90          xDURN2   DEPSTAATCIMP  0.013934108
150   DEPSTAATCIMP         xDURN2  0.013934108
49      DEPRANKGRP         SKDEPS -0.013622262
121         SKDEPS     DEPRANKGRP -0.013622262
25          xDURN2      SKDARRSTA -0.012137713
145      SKDARRSTA         xDURN2 -0.012137713
44       AVGLOFATC         SKDEPS  0.008864044
56          SKDEPS      AVGLOFATC  0.008864044
32    UPLINEATCIMP         SKDEQP  0.006900743
68          SKDEQP   UPLINEATCIMP  0.006900743
31       AVGLOFATC         SKDEQP -0.006110755
55          SKDEQP      AVGLOFATC -0.006110755
35       ARRBUCKET         SKDEQP -0.005395458
107         SKDEQP      ARRBUCKET -0.005395458
33    DEPSTAATCIMP         SKDEQP  0.002281473
81          SKDEQP   DEPSTAATCIMP  0.002281473
> flight.num
     SDEPHR SKDEPS       D00    AVGSQ AVGLOFATC AVGSKDAVAIL xDURN2
2        14     32 0.2500000 3.258065  3.258065  10.9032258      2
5        11     72 0.2916667 2.986111  3.805556   2.0000000      2
7        14     88 0.3295455 2.551724  3.701149   9.6470588      2
13       13     32 0.3750000 3.000000  3.903226  17.3548387      2
14       16     72 0.3750000 3.295775  3.859155  17.0571429      2
17       15     84 0.3809524 3.939759  3.361446  10.6219512      2
18       17     63 0.3809524 4.213115  4.196721   6.1639344      2
20       17     90 0.3888889 4.388889  3.255556   3.0000000      1
33       16     32 0.4062500 4.000000  3.903226  15.0000000      3
34       22     64 0.4062500 5.111111  3.746032  20.8064516      1
36       19     65 0.4153846 5.174603  3.412698   2.4603175      2
37       13     31 0.4193548 2.870968  3.548387   4.7096774      4
43        9     72 0.4305556 1.986111  3.805556   1.3768116      1
44        9     44 0.4318182 1.886364  3.181818   8.9047619      2
45       16     67 0.4328358 3.348485  3.954545  16.5846154      1
46       17     90 0.4333333 4.449438  3.303371   9.0674157      2
57       20     83 0.4457831 4.358025  3.382716  21.1358025      2
63       14     46 0.4565217 3.326087  3.108696  18.2391304      2
68       17     39 0.4615385 4.025641  3.615385   8.3589744      3
71       19     84 0.4642857 5.321429  3.595238  25.8518518      2
74       16     62 0.4677419 3.816667  3.716667   9.0666667      4
76       16     64 0.4687500 4.656250  3.109375   1.6250000      3
81       14     51 0.4705882 3.156863  3.254902  18.0638298      2
82       18     34 0.4705882 4.588235  3.294118  20.7058823      2
83       19     55 0.4727273 4.600000  4.054545   5.3272727      2
84       22     59 0.4745763 5.881356  3.508475  36.5593220      1
86       20     69 0.4782609 4.731343  3.910448  17.2089552      1
87       22     69 0.4782609 5.925373  4.208955  15.7462687      1
88       14     73 0.4794521 3.194444  4.027778  23.0142857      2
99       14     37 0.4864865 3.540541  3.405405  18.1081081      2
103      18     49 0.4897959 3.918367  3.265306  23.8367347      2
108      18     75 0.4933333 4.351351  3.216216  12.4594595      1
114      13     82 0.5000000 3.085366  3.243902   0.1585366      4
117      19     40 0.5000000 4.700000  3.175000   6.4500000      2
123      22     60 0.5000000 4.600000  3.416667  27.8166667      1
133      15     39 0.5128205 4.179487  3.358974   5.7435897      2
134      17     35 0.5142857 4.500000  3.411765  13.1470588      2
140      19     33 0.5151515 4.875000  3.343750  11.0000000      2
143      20     89 0.5168539 4.218391  3.321839  13.6279070      2
144      18     56 0.5178571 4.017857  3.250000  18.2857143      2
147      15     48 0.5208333 3.000000  3.854167  16.1875000      4
150      14     86 0.5232558 2.953488  3.267442  13.0697674      2
155      11     36 0.5277778 2.971429  3.714286   3.7714286      2
165      18     64 0.5312500 4.200000  3.716667  36.7796610      1
170      14     90 0.5333333 3.483146  3.303371   8.1235955      2
171      19     75 0.5333333 4.773333  3.946667   9.2266667      2
172      16     56 0.5357143 3.607143  4.053571  16.0545454      2
184      18     33 0.5454545 4.969697  3.303030  11.0909091      2
186      22     33 0.5454545 5.424242  3.333333  49.3750000      2
188      14     53 0.5471698 3.849057  3.264151  15.0943396      2
189      16     53 0.5471698 3.792453  3.169811  21.1153846      2
196      22     78 0.5512821 5.697368  3.302632  27.3289474      1
197      16     56 0.5535714 3.000000  3.518519  21.4074074      4
199      22     65 0.5538462 5.937500  3.765625  40.7580645      1
202      17     88 0.5568182 3.558140  3.732558  11.9767442      2
205      14     77 0.5584416 3.460526  3.157895   9.1578947      2
208      13     68 0.5588235 3.015152  3.530303  14.9090909      3
213      16     41 0.5609756 4.609756  3.634146   3.4146341      1
214      19     41 0.5609756 5.400000  3.275000   9.6500000      2
215      19     41 0.5609756 5.146341  3.219512  32.4000000      2
217      10     80 0.5625000 2.725000  3.450000   7.9473684      2
218      11     48 0.5625000 2.937500  3.500000   5.2083333      1
223      11     39 0.5641026 2.026316  3.473684  21.0000000      2
227      13     60 0.5666667 3.516667  4.083333  16.9655172      1
228      16     60 0.5666667 3.883333  3.216667  14.9322034      1
229      17     60 0.5666667 4.883333  3.216667   2.4666667      2
232      16     88 0.5681818 3.738636  3.693182  15.7951807      2
233      17     65 0.5692308 4.174603  3.412698  30.0000000      2
234      17     72 0.5694444 4.722222  4.013889   8.0277778      2
238      17     61 0.5737705 5.366667  4.333333   1.9500000      2
242      18     66 0.5757576 3.893939  3.151515  33.2539682      2
249      19     76 0.5789474 4.526316  3.552632  10.0394737      1
250      17     88 0.5795455 4.181818  3.465909   7.1818182      1
256      22     43 0.5813953 4.837209  3.581395  25.9767442      1
260      18     84 0.5833333 5.144578  4.048193  18.9756098      1
262       9     89 0.5842697 1.976744  3.813953   8.3975904      3
266      17     46 0.5869565 4.326087  3.108696   7.0869565      2
267      14     63 0.5873016 3.131148  3.983607  15.4745763      2
274      19     68 0.5882353 5.441176  3.411765  19.3823529      2
276      22     78 0.5897436 5.168831  4.038961  23.2857143      1
279      12     44 0.5909091 2.790698  3.325581  17.3488372      1
281      20     86 0.5930233 4.905882  4.188235  17.9024390      1
283      16     64 0.5937500 4.177419  4.258065  18.3442623      1
285      22     79 0.5949367 4.620253  3.113924  70.2531646      8
286      13     89 0.5955056 2.872093  3.755814  11.3095238      2
290      20     52 0.5961538 5.576923  3.288462  35.4038461      1
295       9     77 0.5974026 1.986842  3.960526  13.5466667      2
296      11     82 0.5975610 2.085366  3.243902  12.9629630      2
300      12     45 0.6000000 2.977273  3.590909  16.5454545      1
303      15     30 0.6000000 4.433333  4.000000   9.9333333      4
310      20     53 0.6037736 4.415094  3.150943  32.5471698      1
311      17     48 0.6041667 4.270833  4.104167  33.3636364      2
317      22     33 0.6060606 4.909091  3.515152  25.1818182      1
318      16     61 0.6065574 4.366667  4.333333   8.7666667      0
326      13     90 0.6111111 2.000000  3.454545  21.7500000      2
327      14     90 0.6111111 3.355556  3.244444  16.2500000      2
337      20     83 0.6144578 5.345679  3.172840  13.8250000      1
338      18     78 0.6153846 4.371795  3.397436  31.2133333      2
343      11     68 0.6176471 2.029851  3.910448  17.2424242      1
351      16     74 0.6216216 4.694444  3.486111   2.2361111      3
352      20     37 0.6216216 4.540541  3.243243  11.7027027      1
354      10     61 0.6229508 2.180328  4.229508   3.8947368      3
356      22     61 0.6229508 5.950820  3.393443  30.7868853      1
357       9     64 0.6250000 1.952381  4.063492  10.7000000      1
359      11     32 0.6250000 3.000000  3.161290  10.0000000      3
362      14     88 0.6250000 3.250000  3.488636  17.4022989      2
363      16     64 0.6250000 3.542373  3.711864  34.8035714      2
364      18     32 0.6250000 5.062500  3.625000   9.8437500      2
365      18     64 0.6250000 5.177419  4.258065   3.2419355      3
369      14     67 0.6268657 2.984615  3.846154  17.7692308      3
370      17     51 0.6274510 4.260000  4.220000   1.9000000      3
377      16     38 0.6315789 4.918919  3.162162   7.1351351      3
382      20     49 0.6326531 5.333333  4.111111  16.2444444      1
390      17     71 0.6338028 4.666667  3.130435  11.1014493      2
395       7     85 0.6352941 1.012048  3.843373  36.4634146      1
400      15     33 0.6363636 3.969697  3.303030  17.1212121      2
401      15     33 0.6363636 4.322581  3.258065   8.8387097      3
402      17     77 0.6363636 4.460526  3.157895  14.5921053      2
404      17     77 0.6363636 4.131579  3.986842  33.1052632      1
405      17     77 0.6363636 4.697368  3.473684  11.8815789      4
406      17     69 0.6376812 4.632353  3.764706   8.6470588      2
408      14     72 0.6388889 3.722222  4.013889  40.1944444      2
411       0     50 0.6400000 1.000000  3.640000 132.6200000      5
413      16     64 0.6406250 4.375000  3.750000  19.4062500      2
418      22     78 0.6410256 5.589744  3.487179  43.1428571      1
419      14     42 0.6428571 3.595238  3.619048   8.1750000      1
427       6     87 0.6436782 1.000000  3.710843          NA      2
429      22     59 0.6440678 4.762712  3.610169  32.5593220      1
434      11     48 0.6458333 2.000000  3.854167  12.3260870      3
435      20     48 0.6458333 5.520833  3.270833  20.7916667      2
436      21     48 0.6458333 4.787234  3.510638  50.5957447      1
438      10     51 0.6470588 1.980392  3.294118  21.2916667      2
440      11     68 0.6470588 1.984848  3.848485  25.5076923      2
445      16     88 0.6477273 3.545455  3.454545  29.4597701      2
446      12     37 0.6486486 2.972973  3.756757   4.0540541      1
447      16     37 0.6486486 3.891892  4.108108  23.4864865      2
448      18     37 0.6486486 3.864865  3.189189  62.5833333      3
450      22     77 0.6493506 5.842105  3.421053  22.3289474      1
458      19     46 0.6521739 5.173913  4.260870  31.5434783      2
459      15     75 0.6533333 3.890411  4.109589  20.3150685      1
463      13     81 0.6543210 2.654321  3.370370  29.5308642      2
466       8     32 0.6562500 2.000000  3.161290   5.2903226      3
467      17     32 0.6562500 4.687500  3.281250   5.0000000      3
482      20     50 0.6600000 4.224490  3.122449  47.2040816      2
488      11     68 0.6617647 2.015152  3.530303  20.8888889      1
489      13     68 0.6617647 3.298507  4.283582  12.1194030      2
495       9     48 0.6666667 1.937500  3.500000   8.6666667      1
497      10     90 0.6666667 1.640449  4.191011  34.5689655      1
498      10     69 0.6666667 1.637681  3.637681   5.0000000      2
501      11     90 0.6666667 2.011236  3.865169  16.2790698      2
503      12     72 0.6666667 2.985915  3.957746   7.8591549      2
504      12     84 0.6666667 2.940476  3.214286   4.2142857      3
505      13     39 0.6666667 3.179487  3.358974   8.8974359      1
518      16     82 0.6707317 3.670732  3.390244  23.1951220      3
519      17     76 0.6710526 4.333333  3.800000   9.0133333      1
520      12     70 0.6714286 2.955224  4.119403  14.3731343      3
522      20     67 0.6716418 5.378788  3.181818  17.6000000      2
531      11     49 0.6734694 3.042553  4.085106   5.2553191      1
532      18     49 0.6734694 4.326531  3.204082  31.0416667      3
535      11     46 0.6739130 2.021739  4.043478   9.0000000      4
544      12     40 0.6750000 2.925000  3.500000  20.0000000      3
545      20     77 0.6753247 4.960526  3.460526  31.1710526      3
553      20     68 0.6764706 4.537313  3.298507  43.1692308      1
561      11     84 0.6785714 2.011905  3.916667  15.4880952      2
562      14     84 0.6785714 3.000000  3.228916  31.0000000      2
564      19     53 0.6792453 4.792453  3.169811  10.9811321      2
568      20     72 0.6805556 5.549296  4.042254  53.9857143      1
584      13     73 0.6849315 2.972222  3.750000   5.4027778      7
590       9     32 0.6875000 1.875000  3.531250  29.9285714      3
592      17     64 0.6875000 4.921875  3.578125   8.0468750      1
593      12     61 0.6885246 2.918033  3.573770   7.0819672      3
596      12     45 0.6888889 2.840909  4.159091   8.3571429      1
597      18     45 0.6888889 3.711111  3.111111  20.7857143      3
598      18     90 0.6888889 4.333333  3.244444  30.2696629      3
610       9     49 0.6938776 2.041667  4.041667  11.2500000      1
614      12     36 0.6944444 2.944444  3.861111  16.2777778      1
615      18     72 0.6944444 4.416667  3.194444  31.8611111      2
628      19     86 0.6976744 5.302326  3.418605  30.9069767      2
629      22     63 0.6984127 5.709677  3.387097  53.7258065      1
638       7     84 0.7023810 1.011905  3.916667 -10.0000000      3
639       9     84 0.7023810 2.000000  3.202381  16.0120482      3
644      10     88 0.7045455 2.494253  3.275862  11.3493976      2
647       9     61 0.7049180 1.918033  3.573770  15.7719298      2
653      18     51 0.7058824 5.120000  3.320000  17.6000000      1
655      22     65 0.7076923 5.859375  3.453125  19.5714286      1
657      20     89 0.7078652 4.584270  3.662921  17.5056180      1
662      11     86 0.7093023 1.953488  3.267442  25.5185185      2
664      12     31 0.7096774 2.935484  3.774194   3.5806452      5
668      13     76 0.7105263 3.605263  3.723684   9.2368421      2
677      10     35 0.7142857 2.205882  4.235294   4.9705882      2
687      15     81 0.7160494 2.974359  3.474359  34.7435897      1
688      14     74 0.7162162 3.694444  3.486111  16.2898551      2
692      15     60 0.7166667 4.237288  3.288136  14.0000000      2
697       9     78 0.7179487 1.974359  3.602564  16.1710526      3
702       9     32 0.7187500 1.937500  3.781250  30.5333333      3
703      14     32 0.7187500 3.687500  3.281250  17.6666667      2
706      22     32 0.7187500 4.937500  3.531250  17.4516129      1
717      22     43 0.7209302 4.395349  3.162791  29.3953488      1
721      15     36 0.7222222 4.305556  3.111111  11.7777778      3
724      20     90 0.7222222 5.222222  3.188889  27.0804598      2
729      15     69 0.7246377 3.623188  3.782609  19.2424242      2
735       7     84 0.7261905 1.583333  3.273810  20.9000000      2
737      16     33 0.7272727 3.242424  3.727273  19.5151515      3
744      22     33 0.7272727 5.424242  3.787879  58.1818182      1
745      11     81 0.7283951 1.974359  3.474359  26.6081081      2
747      13     59 0.7288136 2.355932  3.406780  17.2280702      2
750       7     48 0.7291667 1.416667  3.229167  10.5312500      2
751      13     48 0.7291667 3.020833  3.770833  18.5319149      1
758      14     52 0.7307692 3.115385  3.230769   9.9038462      2
766      13     30 0.7333333 3.433333  4.000000  10.5666667      1
767      13     60 0.7333333 3.237288  3.288136  17.8771930      1
768      13     60 0.7333333 3.533333  3.966667  22.1333333      1
772      19     30 0.7333333 5.100000  3.866667  31.0666667      3
773      20     64 0.7343750 5.171875  3.437500  33.5781250      2
780      20     72 0.7361111 5.585714  3.800000  28.8857143      1
781      14     38 0.7368421 3.918919  3.162162  11.7500000      1
787      18     77 0.7402597 5.012987  3.480519  30.3733333      2
800      16     51 0.7450980 4.117647  3.294118  24.0196078      1
809      10     76 0.7500000 2.108108  4.270270   8.4561404      2
812      14     64 0.7500000 2.610169  3.661017  55.9298246      1
813      15     60 0.7500000 4.533333  3.966667  18.0833333      1
820      20     76 0.7500000 6.253333  3.853333  23.6301370      1
822      21     72 0.7500000 4.842857  3.885714  43.2463768      0
831      16     78 0.7564103 3.435897  3.538462  28.1710526      2
836       9     33 0.7575758 2.000000  3.212121  28.6666667      2
839      13     33 0.7575758 3.322581  3.258065  20.2903226      1
848       5     75 0.7600000 1.000000  3.306667          NA      1
851       8     71 0.7605634 1.750000  4.102941  27.4081633      2
854      14     88 0.7613636 3.602273  3.352273  37.6250000      3
857       7     38 0.7631579 1.026316  3.421053  21.7222222      3
872       6     81 0.7654321 1.000000  3.493827          NA      2
873       8     47 0.7659574 1.000000  3.425532          NA      2
877      20     30 0.7666667 4.766667  3.333333  44.0666667      1
891      11     61 0.7704918 2.016949  4.305085   8.3157895      1
893       8     48 0.7708333 1.434783  3.456522  32.3000000      2
894       9     70 0.7714286 1.955882  4.073529  19.8153846      2
895      16     70 0.7714286 4.200000  3.828571  15.8428571      3
900      11     88 0.7727273 1.952941  3.129412  35.3500000      1
906      12     84 0.7738095 2.626506  4.132530  25.0361446      2
912      13     71 0.7746479 3.183099  3.802817  27.6764706      2
913       6     80 0.7750000 1.000000  3.550000          NA      2
918       6     85 0.7764706 1.000000  3.892857          NA      2
922       9     45 0.7777778 1.977273  3.590909  22.9069767      2
926      17     77 0.7792208 4.526316  3.368421  28.7105263      2
942      14     83 0.7831325 2.924051  3.151899  27.4683544      2
947       7     56 0.7857143 1.017857  3.982143  -8.0000000      2
948      10     42 0.7857143 2.000000  3.190476  14.8809524      2
953       8     47 0.7872340 1.000000  3.340426          NA      4
956      11     33 0.7878788 3.000000  3.212121   3.8181818      2
961      21     71 0.7887324 5.571429  4.257143  50.3000000      1
962      22     71 0.7887324 4.436620  3.323944  43.1126761      1
975      16     77 0.7922078 3.831169  4.363636  53.6666667      2
977       7     87 0.7931034 1.000000  3.129412          NA      2
980      16     34 0.7941176 3.441176  3.764706  29.4848485      2
982       9     78 0.7948718 1.948718  3.243590  16.7432432      3
985       7     83 0.7951807 1.000000  3.506329          NA      1
988       6     88 0.7954545 1.125000  3.329545  12.6250000      2
998       6     50 0.8000000 1.021277  4.340426 -10.0000000      1
1001      7     30 0.8000000 1.000000  4.166667          NA      1
1002      7     40 0.8000000 1.100000  4.050000  -7.2500000      2
1003      7     35 0.8000000 1.205882  4.235294  20.6363636      2
1010     20     65 0.8000000 5.630769  3.215385  39.9218750      1
1013     11     76 0.8026316 2.605263  3.723684  20.9868421      2
1014     11     76 0.8026316 2.780822  3.876712  31.7826087      2
1023      9     36 0.8055556 1.944444  3.861111  21.6470588      2
1024      9     36 0.8055556 1.972222  3.666667  35.8285714      2
1025     13     36 0.8055556 3.305556  3.111111  15.3636364      1
1048     14     58 0.8103448 3.724138  3.810345  27.9285714      2
1051      7     90 0.8111111 1.078652  3.112360  78.2941177      3
1056      5     32 0.8125000 1.000000  3.375000          NA      1
1058      7     48 0.8125000 1.729167  3.333333   8.3428571      2
1062     19     48 0.8125000 4.562500  3.520833  56.8541667      2
1068      8     43 0.8139535 1.000000  3.790698          NA      2
1076      7     88 0.8181818 1.000000  3.795455          NA      3
1081      6     83 0.8192771 1.000000  3.337349          NA      2
1082      6    156 0.8205128 1.000000  3.847682          NA      2
1098     22     52 0.8269231 5.903846  3.653846  45.5098039      1
1099     22     64 0.8281250 5.843750  3.531250  56.0312500      0
1104     19     35 0.8285714 4.457143  3.742857  17.3428571      1
1105     22     35 0.8285714 5.823529  3.470588  26.7058823      1
1106      6     82 0.8292683 1.000000  3.237500          NA      4
1109     11     53 0.8301887 2.431373  3.431373  24.6200000      3
1110      7     71 0.8309859 1.000000  3.718310          NA      3
1113      6     42 0.8333333 1.000000  3.190476          NA      3
1129     10     68 0.8382353 1.955882  3.338235  37.5806452      1
1136      7     57 0.8421053 1.263158  4.245614  11.5384615      2
1143     14     64 0.8437500 3.921875  3.578125  17.7031250      2
1144     19     77 0.8441558 4.842105  4.381579  35.1447368      2
1147     20     71 0.8450704 5.802817  3.971831  33.3802817      1
1149      7     39 0.8461538 1.000000  3.605263          NA      1
1152      5     72 0.8472222 1.000000  3.750000          NA      3
1153      7     72 0.8472222 1.000000  3.647887          NA      1
1179      6     76 0.8552632 1.000000  3.263158          NA      4
1180      6     83 0.8554217 1.000000  3.939024          NA      2
1181      8     90 0.8555556 1.000000  3.438202          NA      4
1182     14     90 0.8555556 3.011236  3.865169  27.1797753      2
1196      6     51 0.8627451 1.000000  3.520000          NA      2
1205      9     37 0.8648649 1.972973  3.756757  23.2222222      2
1207      6     89 0.8651685 1.000000  3.425287          NA      2
1208     11     52 0.8653846 2.115385  3.230769  31.1176471      3
1211      8     82 0.8658537 1.000000  3.600000          NA      2
1213      5     60 0.8666667 1.000000  3.966667          NA      2
1214      7     45 0.8666667 1.044444  4.088889  -6.5000000      3
1226     17     53 0.8679245 4.849057  3.264151  32.3396226      1
1242      9     40 0.8750000 1.925000  3.500000  27.7837838      2
1245     15     48 0.8750000 4.020833  3.770833  20.3541667      1
1257     12     68 0.8823529 2.955882  3.338235  16.9852941      1
1268      6     72 0.8888889 1.000000  3.746479          NA      2
1273      7     74 0.8918919 1.000000  4.397260          NA      1
1274      9     37 0.8918919 1.000000  3.111111          NA      1
1283     22     58 0.8965517 6.017241  4.206897  41.1228070      1
1302      7     42 0.9047619 1.000000  3.857143          NA      1
1306      7     85 0.9058824 1.000000  3.130952          NA      1
1308     13     32 0.9062500 2.250000  3.781250  31.1562500      2
1309      8     65 0.9076923 1.969231  4.107692  17.9841270      1
1311     10     66 0.9090909 2.909091  4.090909  27.0156250      2
1331      6     62 0.9193548 1.000000  3.590164          NA      2
1363      5     69 0.9420290 1.000000  4.362319          NA      1
1370      5     59 0.9491525 1.000000  3.966102          NA      1
1387      6     39 0.9743590 1.000000  4.205128          NA      1
> corrplot::corrplot(flight.cor, method="number")
> jpeg(width=1024, height=640)
> corrplot::corrplot(flight.cor, method="number")
> dev.off()
null device 
          1 
> ## Following the caret vignette.
> ### weaves
> 
> ## Following the caret vignette.
> 
> ###################################################
> ### code chunk number 1: loadLibs
> ###################################################
> library(MASS)
> library(caret)
> library(mlbench)
> library(pROC)
> library(pls)
> 
> library(doMC)
> registerDoMC(cores = 4)
> 
> options(useFancyQuotes = FALSE) 
> 
> # Accounting info.
> getInfo <- function(what = "Suggests")
+ {
+   text <- packageDescription("caret")[what][[1]]
+   text <- gsub("\n", ", ", text, fixed = TRUE)
+   text <- gsub(">=", "$\\\\ge$", text, fixed = TRUE)
+   eachPkg <- strsplit(text, ", ", fixed = TRUE)[[1]]
+   eachPkg <- gsub(",", "", eachPkg, fixed = TRUE)
+   # out <- paste("\\\\pkg{", eachPkg[order(tolower(eachPkg))], "}", sep = "")
+   # paste(out, collapse = ", ")
+   length(eachPkg)
+ }
> 
> ### project-specific: begin
> ## Set-seed, load original CSV file and do some simple-cleaning
> ## Various datasets 
> 
> set.seed(101)                           # helpful for testing
> 
> flight <- read.csv("../bak/flight.csv")
> 
> # Backup
> flight.raw <- flight
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"
> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"
> 
> # And some deletions
> 
> t.cols <- colnames(flight)
> 
> t.drops <- t.cols[grep("^RANK*", t.cols)]
> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])
> t.drops <- c(t.drops, "D80THPCTL")
> 
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR
> flight$xHNGR <- flight$xDURN < 0
> 
> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+ }
> 
> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))
> 
> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE
> t.cols <- colnames(flight)
> 
> t.drops <- c("SARRHR", "xDURN")
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Backup
> 
> flight00 <- flight
> 
> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]
> 
> ## Take another copy - this is all we need as the training/prediction
> ## set.
> 
> flight1 <- flight
> 
> ## Data insights
> 
> ## Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> flight <- flight1
> 
> ## So something is defining the behaviour.
> 
> ## Try to simplify structure
> 
> head(model.matrix(LEGTYPE ~ ., data = flight))
   (Intercept) SDEPHR SKDDEPSTAALB SKDDEPSTAAMS SKDDEPSTAANC SKDDEPSTAATT
2            1     14            0            0            0            0
5            1     11            0            0            0            0
7            1     14            0            0            0            0
13           1     13            0            0            0            0
14           1     16            0            0            0            0
17           1     15            0            0            0            0
   SKDDEPSTAAUA SKDDEPSTAAUS SKDDEPSTABDA SKDDEPSTABDL SKDDEPSTABNA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTABOI SKDDEPSTABOS SKDDEPSTABRU SKDDEPSTABUF SKDDEPSTABWI
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTACCC SKDDEPSTACDG SKDDEPSTACHS SKDDEPSTACLE SKDDEPSTACMH
2             1            0            0            0            0
5             0            0            0            0            0
7             1            0            0            0            0
13            0            0            0            0            0
14            1            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTACUN SKDDEPSTADDD SKDDEPSTADEN SKDDEPSTADFW SKDDEPSTADSM
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            1            0            0            0
   SKDDEPSTADTW SKDDEPSTADUB SKDDEPSTAEWR SKDDEPSTAFCO SKDDEPSTAFLL
2             0            0            0            0            0
5             1            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAFRA SKDDEPSTAGCM SKDDEPSTAGDL SKDDEPSTAGEG SKDDEPSTAGIG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAHNL SKDDEPSTAIAH SKDDEPSTAILM SKDDEPSTAIND SKDDEPSTAJAX
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAJFK SKDDEPSTAKOA SKDDEPSTALAS SKDDEPSTALAX SKDDEPSTALGA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTALGB SKDDEPSTALGW SKDDEPSTALHR SKDDEPSTALIH SKDDEPSTAMAD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMAN SKDDEPSTAMBJ SKDDEPSTAMCI SKDDEPSTAMCO SKDDEPSTAMDT
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMEX SKDDEPSTAMHT SKDDEPSTAMIA SKDDEPSTAMKE SKDDEPSTAMSP
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMSY SKDDEPSTAMUC SKDDEPSTAMZT SKDDEPSTANAS SKDDEPSTAOAK
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAOGG SKDDEPSTAOMA SKDDEPSTAONT SKDDEPSTAORD SKDDEPSTAORF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAPBI SKDDEPSTAPDX SKDDEPSTAPIT SKDDEPSTAPLS SKDDEPSTAPPP
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            1
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAPUJ SKDDEPSTAPVD SKDDEPSTAPVR SKDDEPSTAPWM SKDDEPSTARDU
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTARIC SKDDEPSTARNO SKDDEPSTAROC SKDDEPSTARSW SKDDEPSTASAN
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASAT SKDDEPSTASEA SKDDEPSTASFO SKDDEPSTASJC SKDDEPSTASJD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASJO SKDDEPSTASJU SKDDEPSTASLC SKDDEPSTASMF SKDDEPSTASNA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASRQ SKDDEPSTASTL SKDDEPSTASTT SKDDEPSTASXM SKDDEPSTASYR
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTATLV SKDDEPSTATPA SKDDEPSTAXHP SKDDEPSTAYEG SKDDEPSTAYVR
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAYYC SKDDEPSTAZRH SKDARRSTAALB SKDARRSTAAMS SKDARRSTAANC
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAATT SKDARRSTAAUA SKDARRSTAAUS SKDARRSTABDA SKDARRSTABDL
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTABNA SKDARRSTABOI SKDARRSTABOS SKDARRSTABRU SKDARRSTABUF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            1            0            0
17            0            0            0            0            0
   SKDARRSTABWI SKDARRSTACCC SKDARRSTACDG SKDARRSTACHS SKDARRSTACLE
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            1            0            0            0
   SKDARRSTACMH SKDARRSTACUN SKDARRSTADDD SKDARRSTADEN SKDARRSTADFW
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTADSM SKDARRSTADTW SKDARRSTADUB SKDARRSTAEWR SKDARRSTAFCO
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAFLL SKDARRSTAFRA SKDARRSTAGCM SKDARRSTAGDL SKDARRSTAGEG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAGIG SKDARRSTAHNL SKDARRSTAIAH SKDARRSTAILM SKDARRSTAIND
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAJAX SKDARRSTAJFK SKDARRSTAKOA SKDARRSTALAS SKDARRSTALAX
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTALGA SKDARRSTALGB SKDARRSTALGW SKDARRSTALHR SKDARRSTALIH
2             0            0            0            0            0
5             0            0            0            0            0
7             1            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMAD SKDARRSTAMAN SKDARRSTAMBJ SKDARRSTAMCI SKDARRSTAMCO
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMDT SKDARRSTAMEX SKDARRSTAMHT SKDARRSTAMIA SKDARRSTAMKE
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMSP SKDARRSTAMSY SKDARRSTAMUC SKDARRSTAMZT SKDARRSTANAS
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAOAK SKDARRSTAOGG SKDARRSTAOMA SKDARRSTAONT SKDARRSTAORD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            1
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAORF SKDARRSTAPBI SKDARRSTAPDX SKDARRSTAPIT SKDARRSTAPLS
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAPPP SKDARRSTAPUJ SKDARRSTAPVD SKDARRSTAPVR SKDARRSTAPWM
2             1            0            0            0            0
5             1            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTARDU SKDARRSTARIC SKDARRSTARNO SKDARRSTAROC SKDARRSTARSW
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASAN SKDARRSTASAT SKDARRSTASEA SKDARRSTASFO SKDARRSTASJC
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASJD SKDARRSTASJO SKDARRSTASJU SKDARRSTASLC SKDARRSTASMF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASNA SKDARRSTASRQ SKDARRSTASTL SKDARRSTASTT SKDARRSTASXM
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASYR SKDARRSTATLV SKDARRSTATPA SKDARRSTAXHP SKDARRSTAYEG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAYVR SKDARRSTAYYC SKDARRSTAZRH SKDEQP319 SKDEQP320 SKDEQP321
2             0            0            0         0         0         0
5             0            0            0         0         0         0
7             0            0            0         0         0         1
13            0            0            0         0         0         0
14            0            0            0         0         0         1
17            0            0            0         0         0         0
   SKDEQP332 SKDEQP333 SKDEQP734 SKDEQP75E SKDEQP75H SKDEQP767 SKDEQPA01
2          0         0         1         0         0         0         0
5          0         0         0         0         0         0         0
7          0         0         0         0         0         0         0
13         0         0         1         0         0         0         0
14         0         0         0         0         0         0         0
17         0         0         0         0         0         0         0
   SKDEQPA05 SKDEQPA19 SKDEQPA21 SKDEQPE90 SKDEPS       D00    AVGSQ AVGLOFATC
2          0         0         0         0     32 0.2500000 3.258065  3.258065
5          0         0         0         1     72 0.2916667 2.986111  3.805556
7          0         0         0         0     88 0.3295455 2.551724  3.701149
13         0         0         0         0     32 0.3750000 3.000000  3.903226
14         0         0         0         0     72 0.3750000 3.295775  3.859155
17         0         0         0         0     84 0.3809524 3.939759  3.361446
   UPLINEATCIMPLow UPLINEATCIMPMed UPLINEATCIMPMedHigh UPLINEATCIMPMedLow
2                0               1                   0                  0
5                0               0                   0                  0
7                0               0                   0                  1
13               0               1                   0                  0
14               0               0                   0                  1
17               1               0                   0                  0
   DEPSTAATCIMPLow DOWNLINEATCIMPLow AVGSKDAVAIL AVAILBUCKETA05 AVAILBUCKETA10
2                0                 0   10.903226              0              1
5                1                 0    2.000000              0              0
7                0                 0    9.647059              1              0
13               0                 0   17.354839              0              0
14               0                 0   17.057143              0              0
17               0                 0   10.621951              0              1
   AVAILBUCKETA15 AVAILBUCKETA20 AVAILBUCKETA25 AVAILBUCKETA30 AVAILBUCKETA<0
2               0              0              0              0              0
5               0              0              0              0              0
7               0              0              0              0              0
13              1              0              0              0              0
14              1              0              0              0              0
17              0              0              0              0              0
   DEPBUCKETD2 DEPBUCKETD3 DEPBUCKETD4 DEPBUCKETD5 DEPBUCKETD6 DEPBUCKETD7
2            0           0           0           1           0           0
5            0           0           1           0           0           0
7            0           0           0           1           0           0
13           0           0           0           1           0           0
14           0           0           0           0           1           0
17           0           0           0           0           1           0
   DEPBUCKETD8 ARRBUCKETA2 ARRBUCKETA3 ARRBUCKETA4 ARRBUCKETA5 ARRBUCKETA6
2            0           0           0           0           0           1
5            0           0           0           0           1           0
7            0           0           0           0           0           1
13           0           0           0           0           0           1
14           0           0           0           0           0           0
17           0           0           0           0           0           1
   ARRBUCKETA7 ARRBUCKETA8 DEPRANKGRPLow DEPRANKGRPMed DEPRANKGRPMedHigh
2            0           0             1             0                 0
5            0           0             0             1                 0
7            0           0             1             0                 0
13           0           0             0             0                 0
14           1           0             1             0                 0
17           0           0             0             0                 0
   DEPRANKGRPMedLow TRNRANKGRPLow TRNRANKGRPMed TRNRANKGRPMedHigh
2                 0             1             0                 0
5                 0             1             0                 0
7                 0             1             0                 0
13                1             0             0                 0
14                0             1             0                 0
17                1             0             1                 0
   TRNRANKGRPMedLow ARRRANKGRPLow ARRRANKGRPMed ARRRANKGRPMedHigh
2                 0             0             0                 1
5                 0             0             0                 1
7                 0             0             1                 0
13                1             0             0                 0
14                0             0             0                 1
17                0             0             0                 1
   ARRRANKGRPMedLow DEPSPOKETRUE ARRSPOKETRUE xHNGRTRUE xDURN2
2                 0            0            0         0      2
5                 0            1            0         0      2
7                 0            0            1         0      2
13                1            0            1         0      2
14                0            0            1         0      2
17                0            0            0         0      2
> 
> dummies <- dummyVars(LEGTYPE ~ ., data = flight)
> flight.dum <- predict(dummies, newdata = flight)
> 
> ## It may be too big to use, but useful for inspection.
> 
> ### Numeric variables
> 
> ## Check some more correlations, I haven't scaled yet.
> 
> x1 <- as.data.frame(as.matrix(sapply(flight, class)))
> 
> flight.num <- flight[,names(x1[which(x1$V1 %in% c("numeric", "integer")),])]
> 
> flight.nzv <- nearZeroVar(flight.num, saveMetrics = TRUE)
> flight.nzv
            freqRatio percentUnique zeroVar   nzv
SDEPHR       1.038462        5.9375   FALSE FALSE
SKDEPS       1.000000       19.0625   FALSE FALSE
D00          1.166667       75.3125   FALSE FALSE
AVGSQ        6.333333       82.8125   FALSE FALSE
AVGLOFATC    1.000000       78.4375   FALSE FALSE
AVGSKDAVAIL  1.000000       87.5000   FALSE FALSE
xDURN2       1.428571        2.5000   FALSE FALSE
> 
> flight.cor <- cor(flight.num, use = "pairwise.complete.obs")
> 
> highlyCorDescr <- findCorrelation(flight.cor, cutoff = .75, verbose=TRUE)
Considering row	 1 column	 4 value	 0.956 
  Flagging column	 1 
Considering row	 4 column	 3 value	 0.414 
Considering row	 4 column	 6 value	 0.173 
Considering row	 4 column	 7 value	 0.201 
Considering row	 4 column	 5 value	 0.103 
Considering row	 4 column	 2 value	 0.082 
Considering row	 3 column	 6 value	 0.266 
Considering row	 3 column	 7 value	 0.071 
Considering row	 3 column	 5 value	 0.114 
Considering row	 3 column	 2 value	 0.006 
Considering row	 6 column	 7 value	 0.031 
Considering row	 6 column	 5 value	 0.094 
Considering row	 6 column	 2 value	 0.067 
Considering row	 7 column	 5 value	 0.137 
Considering row	 7 column	 2 value	 0.005 
Considering row	 5 column	 2 value	 0.041 
> 
> ## Which tells me that departure time is very highly correlated to AVGSQ.
> 
> ### Try and impute the AVG
> 
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))
> 
> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1
> 
> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]
> 
> preProcValues <- preProcess(flight.na, method = c("knnImpute"))
> flight.na1 <- predict(preProcValues, flight.na)
> 
> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL
> 
> ## And I'll leave the centered and scale values in for now.
> ## and delete the troublesome ones
> 
> flight$AVGSKDAVAIL <- NULL
> flight$xHNGR <- NULL
> flight$AVAILBUCKET <- NULL
> 
> # This should be deleted, leave it in and the results are ideal because it defines LEGTYPE.
> flight$D00 <- NULL
> 
> ## Keep the results.
> outcomes.flight <- flight$LEGTYPE
> 
> flight$LEGTYPE <- NULL
> 
> ## Try converting all the factors to numerics
> 
> flight[,names(x1[which(x1$V1 %in% c("factor")),])]
Error in `[.data.frame`(flight, , names(x1[which(x1$V1 %in% c("factor")),  : 
  undefined columns selected
> 
> ## If you know your factors are definitely factors, you don't need this
> ##  asNumeric <- function(x) as.numeric(as.character(x))
> 
> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))
> 
> flight.num0 <- factors.numeric(flight)
> 
> flight.scl0 <- scale(flight.num0)
> 
> ## Now split the results
> 
> inTrain <- createDataPartition(outcomes.flight, p = 0.75, list = FALSE)
> 
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> 
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> 
> prop.table(table(flight.scl0))
flight.scl0
    -2.99546983996958     -2.98604368384811     -2.82110052361751 
           0.00281250            0.00015625            0.00015625 
    -2.64037641778924     -2.37742331516569     -2.09431321436608 
           0.00015625            0.00015625            0.00031250 
    -2.02525208119049     -2.02364615961949     -1.96706162425765 
           0.00046875            0.00093750            0.00015625 
    -1.94787383036273     -1.91934227796699     -1.87162293167633 
           0.00125000            0.00015625            0.00015625 
    -1.80813803757891      -1.8064397520718     -1.76880294648328 
           0.00093750            0.00093750            0.00453125 
     -1.7104004231695     -1.67620690253875     -1.63572266525187 
           0.00312500            0.00015625            0.00078125 
    -1.60554554037119     -1.58829697245811     -1.58375887562806 
           0.00265625            0.00062500            0.00031250 
    -1.56068940274137     -1.55266802930898     -1.55257138616628 
           0.00593750            0.00015625            0.00015625 
    -1.54865734259279     -1.54635333101763     -1.54295794614133 
           0.00015625            0.00015625            0.00015625 
    -1.53179508600425     -1.53074294246617     -1.50769426210174 
           0.00203125            0.00015625            0.00015625 
    -1.49330986644838     -1.47983129638045     -1.47646498237513 
           0.00015625            0.00171875            0.00015625 
    -1.44796824755814     -1.43812707979848     -1.43616463590287 
           0.00015625            0.00031250            0.00015625 
     -1.4311495031078     -1.42786750675664     -1.42754311366228 
           0.00062500            0.00031250            0.00015625 
     -1.4230237164245     -1.42196682798086     -1.40691590144974 
           0.00015625            0.00015625            0.00750000 
    -1.40295304316347     -1.39839761187043     -1.38337483337197 
           0.00343750            0.00015625            0.00015625 
    -1.37828409873765     -1.37590371713284      -1.3753288895824 
           0.00031250            0.00078125            0.00015625 
    -1.37383369560894     -1.37045453151584     -1.35466334686085 
           0.00015625            0.00015625            0.00015625 
    -1.33716625322094     -1.33398496346823     -1.33080367371552 
           0.00015625            0.00015625            0.00015625 
    -1.32393992750903      -1.3160853172316     -1.31578091655701 
           0.00093750            0.00015625            0.00015625 
    -1.31443367614047      -1.3133256164209     -1.30151560934568 
           0.00015625            0.00015625            0.00015625 
    -1.30111163600234     -1.29600486257245     -1.28619597667342 
           0.00015625            0.00031250            0.00031250 
    -1.28367748081635     -1.28186181839242      -1.2799413346293 
           0.00031250            0.00015625            0.00015625 
    -1.27197613788523     -1.26773489691459      -1.2671778786613 
           0.00109375            0.00015625            0.00015625 
     -1.2615812276646     -1.25974760485758     -1.25283365916062 
           0.00031250            0.00078125            0.00015625 
    -1.25178454113998     -1.24659260411695     -1.24079645146543 
           0.00015625            0.00015625            0.00015625 
     -1.2302338686483     -1.23020377865797      -1.2268968080815 
           0.00015625            0.00687500            0.00031250 
    -1.22001234826142     -1.21809512250389     -1.21512040999215 
           0.00046875            0.00015625            0.00015625 
    -1.21024953572476     -1.20647153886774     -1.20560405725029 
           0.00015625            0.00015625            0.00015625 
    -1.20188627600106     -1.20036054595575     -1.20011285144544 
           0.00031250            0.00140625            0.00015625 
    -1.19042311450129     -1.18991798468508     -1.18966337127103 
           0.00015625            0.00015625            0.00062500 
    -1.16804855863761     -1.16764210792351     -1.16749679150174 
           0.00093750            0.00015625            0.00015625 
    -1.16258400593847     -1.16018257780086     -1.15839829359119 
           0.00015625            0.00640625            0.00015625 
    -1.14179763548495     -1.13992628855288     -1.13935994002253 
           0.00015625            0.00031250            0.00031250 
    -1.13310730700243     -1.13102279477938     -1.12993289335973 
           0.00015625            0.00015625            0.00015625 
    -1.12915754122589     -1.12753063368423     -1.12667091460446 
           0.00015625            0.00015625            0.00015625 
    -1.12622940836933     -1.12368140470519     -1.12361616254288 
           0.00031250            0.00015625            0.00062500 
    -1.12145428351456     -1.11910330109794     -1.11800948418703 
           0.00015625            0.00015625            0.00015625 
    -1.11608476901381     -1.11429923219746     -1.09261479989672 
           0.00062500            0.00015625            0.00015625 
    -1.09084552937417     -1.09012044993392      -1.0895833019642 
           0.00015625            0.00015625            0.00031250 
    -1.08549109658463     -1.06938028371369     -1.06604781193988 
           0.00031250            0.00015625            0.00015625 
    -1.06587003530766        -1.06412097939     -1.05534288054392 
           0.00015625            0.00046875            0.00015625 
    -1.04945721011816     -1.04845626690162     -1.04766888572427 
           0.00015625            0.00015625            0.00015625 
    -1.04755297964098     -1.04598728075964     -1.04536609890991 
           0.00031250            0.00031250            0.00031250 
    -1.02993885350447     -1.02151758080685     -1.01733580186582 
           0.00015625            0.00203125            0.02453125 
    -1.01577847702439      -1.0138904262493      -1.0121571897662 
           0.00015625            0.00015625            0.00062500 
    -1.00929178081963     -1.00745946934895     -1.00714202059705 
           0.00015625            0.00015625            0.00015625 
    -1.00664275166081     -1.00407661804032     -1.00110637205939 
           0.00046875            0.00015625            0.00015625 
   -0.997768048748026    -0.991929422812267    -0.989060788495757 
           0.00328125            0.00015625            0.00031250 
    -0.98572380365604    -0.979554261682366    -0.976324799963229 
           0.00015625            0.00031250            0.00875000 
   -0.973173077974651    -0.971118460177678     -0.96975725707502 
           0.01640625            0.00015625            0.00015625 
   -0.963461694934854    -0.961159884505833    -0.960193400142389 
           0.00015625            0.00015625            0.00046875 
   -0.958010282948452    -0.957720936633644    -0.955230663538487 
           0.00015625            0.00015625            0.00015625 
   -0.953451859649493    -0.952397629449069    -0.951677411170411 
           0.00031250            0.00015625            0.01765625 
   -0.947281520180146    -0.946066444247069    -0.942123167843126 
           0.00015625            0.00015625            0.00015625 
   -0.941185041055857    -0.939666457415937    -0.937914389255748 
           0.00015625            0.00031250            0.00015625 
   -0.937428692031181    -0.937143144639067    -0.929006249994557 
           0.00015625            0.00203125            0.00031250 
   -0.928956547037233    -0.927234345076844    -0.926325405165677 
           0.00015625            0.00015625            0.00015625 
   -0.926208874394783     -0.92432711582923    -0.923751900565718 
           0.00015625            0.00015625            0.00015625 
   -0.921447647976772    -0.920026610901552    -0.919775930100724 
           0.00015625            0.00015625            0.00031250 
   -0.919418999070816    -0.918979533540974    -0.918834367344145 
           0.00093750            0.00015625            0.00015625 
   -0.918602057207572    -0.918233359080158    -0.916620305783416 
           0.00015625            0.00015625            0.00031250 
   -0.908229610518583    -0.907879271266391    -0.907626204980156 
           0.00031250            0.00015625            0.00015625 
   -0.906631706666217    -0.905610577820333    -0.905104725277818 
           0.00015625            0.00015625            0.00015625 
   -0.904170844231002    -0.902563699445797    -0.902495470961171 
           0.00031250            0.00015625            0.00046875 
   -0.902207570970879    -0.900277820755885    -0.900269127160796 
           0.00015625            0.00609375            0.00015625 
   -0.900105713501894    -0.897103060359799    -0.896252308815885 
           0.00015625            0.00015625            0.00015625 
   -0.895759768448355    -0.895685333371447    -0.891948830933419 
           0.00015625            0.00015625            0.00015625 
   -0.891482707849845     -0.89086838304768    -0.889814536282523 
           0.00015625            0.02343750            0.00015625 
   -0.886894039811436    -0.885423108336021    -0.885386138492139 
           0.00093750            0.00015625            0.01593750 
   -0.884574764423174    -0.881181388644532    -0.881133728915611 
           0.00015625            0.00015625            0.00015625 
   -0.879323305434347    -0.878872666379052    -0.877901133624378 
           0.00015625            0.00015625            0.00015625 
   -0.876749332956921    -0.876685019263073    -0.875765771148607 
           0.00031250            0.00015625            0.00031250 
   -0.875473779114446     -0.87537693015952    -0.872246314823305 
           0.00015625            0.00015625            0.00015625 
   -0.871001261435858    -0.870353841103083    -0.869162583211394 
           0.00015625            0.00015625            0.00015625 
   -0.866780745576637    -0.866244907634358    -0.858819232798091 
           0.00015625            0.00015625            0.00015625 
   -0.856265820894777    -0.844253476212177    -0.844066341550782 
           0.00078125            0.00015625            0.00015625 
   -0.842025743633279    -0.831738843759029    -0.830837909586882 
           0.02921875            0.00015625            0.02515625 
   -0.829374923233683    -0.828920190368225    -0.827915178181078 
           0.00015625            0.00093750            0.00015625 
   -0.827728686266157    -0.826039032973297    -0.822416105203804 
           0.00015625            0.00015625            0.00015625 
   -0.821797313281808    -0.819285769008092    -0.816336564086851 
           0.00015625            0.00015625            0.00015625 
   -0.814051297945908    -0.811605617460827    -0.809148421270981 
           0.00015625            0.00015625            0.00015625 
   -0.804302031270971    -0.800154571238789    -0.795175551540305 
           0.00062500            0.00015625            0.00171875 
   -0.792845872277945    -0.790185643279993    -0.789212464897955 
           0.02015625            0.00859375            0.00046875 
   -0.787996109659257    -0.785742695872334    -0.783287556756109 
           0.00015625            0.00015625            0.00015625 
    -0.78222517242437    -0.777611190965241    -0.777259256743858 
           0.00015625            0.00015625            0.00015625 
   -0.775052088417874    -0.768725111385422      -0.7653899578722 
           0.00031250            0.00015625            0.00015625 
   -0.764328853007072    -0.759372004638613    -0.759121665238872 
           0.00015625            0.00015625            0.00015625 
   -0.758171518227594    -0.752387355098689    -0.752338241647165 
           0.00015625            0.00015625            0.00031250 
   -0.751716727129916    -0.750007134146443    -0.748171465050933 
           0.00015625            0.00562500            0.00015625 
   -0.743693425437366     -0.74226506946404    -0.738477819728135 
           0.00718750            0.00015625            0.00015625 
   -0.735940818773818    -0.734501921638923    -0.723911474638978 
           0.00015625            0.00015625            0.00015625 
   -0.720697236097384    -0.718445199078953    -0.715142805531928 
           0.00031250            0.00015625            0.00031250 
   -0.713461500253351    -0.710452171936934    -0.708684788599593 
           0.00015625            0.00015625            0.00015625 
   -0.708003561812545    -0.702080356630785     -0.70037445202336 
           0.00015625            0.00015625            0.00203125 
    -0.69602539257426     -0.69280361708918    -0.687853983052082 
           0.00015625            0.03375000            0.00015625 
    -0.68694861300278    -0.684622918007104    -0.682222958529648 
           0.00015625            0.00015625            0.00015625 
   -0.681188975020078    -0.673798181086569     -0.66884926915034 
           0.00187500            0.00015625            0.00015625 
     -0.6653122497357    -0.654779601264497    -0.648410662399554 
           0.00015625            0.00015625            0.00078125 
   -0.647068571912601    -0.646559789740211    -0.633905116384853 
           0.00015625            0.00015625            0.00015625 
   -0.633276439235621    -0.626480919280269    -0.624813955253419 
           0.00015625            0.00015625            0.00015625 
   -0.621563193776932    -0.615573756562581    -0.613123253862724 
           0.00015625            0.00015625            0.00171875 
   -0.604038319371604    -0.596446872775748    -0.596237216599971 
           0.00015625            0.00046875            0.00015625 
   -0.596137826610777    -0.592583054332584    -0.590968847296576 
           0.00015625            0.00359375            0.00015625 
   -0.581016668721787     -0.57842864719944    -0.577046832499099 
           0.00015625            0.00015625            0.00015625 
   -0.576399963736262    -0.567294133064953    -0.562646449882806 
           0.00187500            0.00015625            0.00031250 
   -0.559949234902497    -0.553868745195444    -0.551562209118441 
           0.00031250            0.00015625            0.00859375 
   -0.548486073402725    -0.545057532705371    -0.544483083151942 
           0.00015625            0.00046875            0.00093750 
   -0.543553164656681    -0.542887786706365    -0.542791834600063 
           0.00015625            0.00015625            0.03859375 
   -0.535816263171991    -0.529620965141671    -0.523583345339874 
           0.00031250            0.00015625            0.00015625 
   -0.522876883678594    -0.515144874010522    -0.511242837482551 
           0.00015625            0.00015625            0.00015625 
   -0.511062050911504    -0.509452501139644    -0.507981951223969 
           0.00500000            0.00015625            0.00015625 
   -0.506004946851197    -0.504251327555701    -0.503668338010739 
           0.00015625            0.00203125            0.00015625 
   -0.497665904683127    -0.492519293528136    -0.488304476973275 
           0.00015625            0.00062500            0.00015625 
   -0.486275884354524    -0.480531685495119    -0.479070530598709 
           0.00015625            0.00015625            0.00015625 
   -0.476991811548017    -0.475764665500524    -0.473473045518126 
           0.00078125            0.00015625            0.00015625 
   -0.472612890303562    -0.464757185992567    -0.456186401194196 
           0.00015625            0.00015625            0.00015625 
   -0.454553689487183    -0.453074332488957    -0.452195518537862 
           0.00015625            0.00015625            0.00015625 
   -0.450040882361118    -0.446015592229304    -0.443168278929009 
           0.00015625            0.00015625            0.00015625 
    -0.44055550390433    -0.439275967288811    -0.439064986884659 
           0.00093750            0.00015625            0.00031250 
   -0.436572045333686    -0.433356062339654     -0.43210269137514 
           0.00015625            0.00015625            0.00031250 
   -0.429159183376661     -0.42811270638386    -0.424489571114943 
           0.00015625            0.00015625            0.00015625 
   -0.424136094192972    -0.422368710855631    -0.422286506964679 
           0.00015625            0.00015625            0.00015625 
     -0.4217879739841     -0.42160028367728    -0.408926090390664 
           0.00015625            0.00015625            0.00062500 
   -0.406238662084726    -0.405337563546837    -0.402845924603104 
           0.00015625            0.00015625            0.00015625 
   -0.398392401687235    -0.392753100892855    -0.392721940787981 
           0.00015625            0.00015625            0.00015625 
   -0.389990557124863    -0.383778543291898    -0.381829344162238 
           0.00203125            0.00031250            0.00031250 
   -0.378610740922975    -0.377352421209284     -0.37278098800314 
           0.00015625            0.00015625            0.00015625 
   -0.368704530397105    -0.364033384865912    -0.363121805899083 
           0.00015625            0.00015625            0.00015625 
   -0.361905601371654    -0.360992312891898     -0.36077985218898 
           0.00015625            0.00015625            0.00015625 
    -0.35995405519458    -0.354602189779798    -0.354221703071568 
           0.00046875            0.00015625            0.00015625 
   -0.354125613590753     -0.35383985286255    -0.350820163721666 
           0.00015625            0.00015625            0.00015625 
   -0.347880750045415    -0.347682518083072    -0.344794514479224 
           0.00031250            0.00015625            0.00015625 
   -0.344246401931106    -0.340586009596143    -0.338241270869783 
           0.00015625            0.00015625            0.00031250 
   -0.336627924656718    -0.333999550987416    -0.331679860754818 
           0.00015625            0.00015625            0.00015625 
   -0.327473828580897    -0.325591270635287    -0.320604647133837 
           0.00015625            0.00015625            0.00015625 
   -0.320293393650012    -0.318998347766866    -0.313800886365509 
           0.00015625            0.00015625            0.00015625 
   -0.308729731711204     -0.30775968479621    -0.307488803472333 
           0.00015625            0.00062500            0.00015625 
   -0.305912488397539    -0.300040013990283    -0.299281804870489 
           0.00015625            0.00015625            0.00015625 
   -0.297576089117692    -0.294612153988498    -0.290886990303406 
           0.00015625            0.00015625            0.00015625 
   -0.289476667647491    -0.287805419014019    -0.284664135032912 
           0.00015625            0.00031250            0.00062500 
   -0.283279035792871    -0.278947445070673    -0.278430676385642 
           0.00015625            0.00015625            0.01140625 
   -0.277028655971768    -0.274352800845479    -0.269810489634915 
           0.00015625            0.00015625            0.00875000 
   -0.268327804913194    -0.264273008183568    -0.263991250766728 
           0.00015625            0.00015625            0.00015625 
   -0.263633329101249    -0.256569345435893    -0.255210887064625 
           0.00015625            0.00015625            0.00015625 
   -0.254264930167697    -0.253205544043426    -0.250717006205447 
           0.00015625            0.00015625            0.00015625 
   -0.250531752899298    -0.249985351299549    -0.247578088366761 
           0.00015625            0.00015625            0.00015625 
   -0.244437996150226    -0.243268618233703    -0.242824942853484 
           0.00015625            0.00015625            0.00015625 
   -0.233740722783471    -0.232700345409106    -0.232349973253986 
           0.00015625            0.00015625            0.00015625 
   -0.231815214890401    -0.231309362347886     -0.23037548130107 
           0.00015625            0.00015625            0.00015625 
   -0.228412208040947    -0.226589859802479    -0.224837647995068 
           0.00015625            0.01656250            0.00015625 
   -0.223464759128966     -0.22331717855311    -0.222588752387258 
           0.00015625            0.00015625            0.00015625 
   -0.222456945885953    -0.220222816737245    -0.217487288707678 
           0.00015625            0.00031250            0.00046875 
   -0.216388232760497    -0.213098676881504    -0.212807560710942 
           0.00015625            0.00093750            0.00015625 
   -0.205527942504415    -0.202889656333141    -0.199061273711729 
           0.00015625            0.00015625            0.00015625 
   -0.197285663071406    -0.196655198635886    -0.187398059917142 
           0.00015625            0.00015625            0.00328125 
    -0.18553936273967    -0.184426534107832      -0.1807365557853 
           0.00015625            0.00015625            0.00031250 
   -0.173455385110242    -0.170696066339926    -0.167983070845547 
           0.00953125            0.00062500            0.00015625 
    -0.16706735776498     -0.16549287956689    -0.163323851054559 
           0.00015625            0.00015625            0.00015625 
   -0.163005226779217    -0.155721964916119     -0.15557956030375 
           0.00015625            0.00015625            0.00015625 
   -0.145050220201077    -0.140627037006184    -0.136663205761249 
           0.00015625            0.00015625            0.00015625 
   -0.135547666352963    -0.135353058341049    -0.135168941442998 
           0.00015625            0.00015625            0.00015625 
    -0.13422823788067    -0.128983100398563    -0.128772766161494 
           0.00015625            0.00015625            0.00062500 
   -0.128276147190878    -0.124732071896041    -0.122750748897942 
           0.00015625            0.00015625            0.00015625 
   -0.121913567685457    -0.114572129500928    -0.113273027561381 
           0.00015625            0.00015625            0.00015625 
   -0.107405286684043    -0.105529863556612    -0.103356043915892 
           0.00015625            0.00953125            0.00015625 
  -0.0959919473132286   -0.0946576344451732   -0.0921610479659292 
           0.00015625            0.00031250            0.00015625 
  -0.0897276946329045    -0.082082912166815   -0.0820786945748793 
           0.00015625            0.00015625            0.00031250 
  -0.0807439358161152   -0.0768089765376881   -0.0759616047321375 
           0.00015625            0.00140625            0.00015625 
  -0.0741942213947964   -0.0733788467156504   -0.0726315828860554 
           0.00015625            0.00718750            0.00015625 
  -0.0685974846038955   -0.0532150311664168   -0.0498043335027671 
           0.00093750            0.00015625            0.00015625 
  -0.0497543467601004   -0.0473016251818649   -0.0451490777305966 
           0.00015625            0.00015625            0.00031250 
  -0.0446498361490209   -0.0392160026639466   -0.0373582346840002 
           0.00015625            0.00015625            0.00015625 
  -0.0352851923820555   -0.0345646240252186   -0.0326438116903773 
           0.00031250            0.00031250            0.00015625 
  -0.0248451869138821   -0.0188880173129063    -0.013807090586871 
           0.00109375            0.00015625            0.00015625 
  -0.0119657325121257   -0.0114810502208166  -0.00721676013122688 
           0.00015625            0.00015625            0.00015625 
 -0.00368424503602545 -0.000580656453063986   0.00425466589044258 
           0.00015625            0.00015625            0.00015625 
  0.00624696207963468   0.00661720265702806    0.0104887638020741 
           0.00015625            0.00015625            0.00015625 
   0.0151944372905789    0.0177528116242494    0.0194770878491831 
           0.00421875            0.00015625            0.00015625 
   0.0217087977522383    0.0235168212825711    0.0255537765734798 
           0.00015625            0.00015625            0.00015625 
   0.0264730080152699    0.0271186027099238    0.0361351573082595 
           0.00015625            0.00031250            0.00015625 
   0.0362911121323546    0.0368634437985054    0.0454309894047899 
           0.00015625            0.00015625            0.00015625 
   0.0533298995579193    0.0570581595639766    0.0585759323236618 
           0.00015625            0.00937500            0.00015625 
   0.0675339577108118    0.0702113818864803    0.0729377618887858 
           0.00046875            0.00015625            0.00062500 
   0.0788793134968683    0.0789059252411879    0.0790823923337298 
           0.00015625            0.02343750            0.00046875 
   0.0797510873183287    0.0806069942083428    0.0841639835120876 
           0.00015625            0.00015625            0.00015625 
   0.0899621750174284    0.0966606496804153    0.0972018193465008 
           0.00015625            0.00015625            0.00015625 
    0.101566818289489     0.108411810410797     0.109012079979066 
           0.00062500            0.00015625            0.00046875 
     0.11244290268093     0.119444894039026     0.131046181957536 
           0.00015625            0.00015625            0.00203125 
    0.134889340170799     0.135028927523559     0.136658265622521 
           0.00015625            0.00015625            0.00015625 
    0.144157938789208     0.146258849789861     0.147318188850963 
           0.00015625            0.00015625            0.02984375 
    0.151115033119933     0.152349655315244     0.154426066228552 
           0.00015625            0.00015625            0.00015625 
     0.15737266071083     0.162873929857665     0.162973153669365 
           0.00015625            0.00015625            0.00015625 
    0.164891939398059     0.165580765616732     0.173693095305534 
           0.00015625            0.00015625            0.00015625 
    0.183009971581342     0.186789363756051     0.187969991368742 
           0.00093750            0.00015625            0.00015625 
    0.192709893790261     0.194724832331223     0.194735738184732 
           0.00015625            0.00015625            0.00015625 
    0.195991364801127     0.206802781312992     0.210386154876613 
           0.00015625            0.00015625            0.00500000 
    0.217235034249908       0.2177869344983     0.234906769563277 
           0.00031250            0.00203125            0.00015625 
    0.234973761205148     0.238837237065174     0.241127733319099 
           0.00031250            0.00015625            0.00015625 
    0.250135635132824      0.25028785413495     0.253309352340188 
           0.00015625            0.00015625            0.00078125 
    0.254814769298151     0.260835355687548     0.264960519475955 
           0.00015625            0.00015625            0.00015625 
    0.266044692238248      0.27127954776092     0.273304013334367 
           0.00015625            0.00015625            0.00015625 
    0.273531307307048     0.274822103147971     0.280770740587068 
           0.00015625            0.00015625            0.00015625 
    0.284591080073122     0.285810915205503     0.286937550828954 
           0.00015625            0.00015625            0.00046875 
    0.289640625615739     0.301307082566931     0.302882181759369 
           0.00015625            0.00015625            0.00015625 
    0.304256560508303     0.309710068792923     0.311251030414092 
           0.00015625            0.00015625            0.00015625 
    0.311802268812853     0.318128929047187     0.318922298138204 
           0.00015625            0.00031250            0.00015625 
    0.320852365313198     0.322875645177539     0.334350357273903 
           0.00015625            0.00015625            0.00015625 
    0.337167536402539     0.338400625416362     0.338901340452759 
           0.00015625            0.00031250            0.00140625 
    0.346939027258188     0.348766831423466     0.358991725758732 
           0.00015625            0.00015625            0.00015625 
    0.364034892089946     0.365884194608935     0.368674799710984 
           0.00015625            0.00015625            0.00015625 
    0.369643258716518     0.373829702918903     0.379821273586168 
           0.00015625            0.00062500            0.00015625 
    0.382087226815338      0.38685609839469       0.3878539441829 
           0.00015625            0.00015625            0.00015625 
     0.38923354153609     0.390865130076565     0.393785793790202 
           0.00015625            0.00093750            0.00015625 
    0.402956322412276     0.404247945632944      0.40569298299336 
           0.00015625            0.00015625            0.00015625 
    0.406064629649282      0.40786256349758     0.408056423319527 
           0.00015625            0.00109375            0.00015625 
    0.412247177017014     0.414419483912049     0.416346031539166 
           0.00015625            0.00046875            0.00015625 
     0.41794166276908     0.419463447191946     0.420106603846799 
           0.00015625            0.01078125            0.00015625 
    0.420379431706021     0.420869449539072     0.431214346889845 
           0.00406250            0.00015625            0.00015625 
    0.433937840525743     0.440278644951702     0.441895424076257 
           0.00031250            0.00015625            0.00015625 
    0.442828919700371     0.443274873059508     0.446173888246631 
           0.00046875            0.00984375            0.00015625 
    0.450718587802467     0.456900610463576     0.459555681956315 
           0.00015625            0.00031250            0.00015625 
    0.460696686048428     0.467876105484108     0.472728746197005 
           0.00015625            0.00015625            0.00015625 
    0.474472217743954     0.474601080341499     0.474734089218203 
           0.00015625            0.00031250            0.00015625 
    0.477973490467994     0.484307789443022     0.484652344952628 
           0.00015625            0.00015625            0.00015625 
    0.494792709324177     0.498497691565453     0.500784787450151 
           0.00109375            0.00515625            0.00015625 
    0.504691880000581     0.508425703980646      0.50861676779181 
           0.00031250            0.00015625            0.00015625 
     0.50996114523361     0.514344382856681     0.516995457862692 
           0.00015625            0.00015625            0.00015625 
    0.518586102739047     0.521829770584971     0.523840570430114 
           0.00015625            0.00015625            0.00015625 
    0.524285913333902     0.525227742436545     0.527917885589494 
           0.00015625            0.00015625            0.00015625 
    0.531983533422768     0.539966728864973     0.541903897062432 
           0.00015625            0.00015625            0.00046875 
    0.543994005812287     0.545724786000498     0.546756498947983 
           0.00125000            0.00015625            0.00203125 
    0.548923619243861     0.549353970396232       0.5588553176537 
           0.00015625            0.00015625            0.00031250 
    0.564138483610525     0.566992546543754     0.569133261860447 
           0.00015625            0.00015625            0.00015625 
    0.574903744908869     0.577978215152712     0.578343495716271 
           0.00031250            0.00109375            0.00015625 
    0.580241024741447     0.581634314964003     0.583204933976379 
           0.00015625            0.00015625            0.00015625 
     0.58873859479558     0.595455758634415     0.597057916427158 
           0.00015625            0.00031250            0.00015625 
    0.598720288571789     0.599162991111384     0.599578938399305 
           0.00031250            0.00015625            0.00015625 
     0.60342049593258     0.604292419065582     0.607847397763963 
           0.00015625            0.00015625            0.00015625 
    0.611956869618315     0.612059726969641     0.612784292101807 
           0.00015625            0.00062500            0.00015625 
    0.613557486760981     0.620580331763515     0.622971928913742 
           0.00015625            0.00015625            0.00375000 
     0.63588348041021     0.641390081029809     0.643182929950686 
           0.00015625            0.00015625            0.00015625 
    0.648293425210027     0.650684078195595     0.657754904789885 
           0.00015625            0.00046875            0.00015625 
    0.664732625480728     0.665678528246394     0.665791697835918 
           0.00015625            0.00984375            0.00015625 
    0.666578602798705     0.678050028820375     0.678379635730825 
           0.00015625            0.00015625            0.00015625 
    0.679808655934455     0.680412565586961     0.680711498268701 
           0.00328125            0.00015625            0.00015625 
    0.684080216155581     0.684149053017272     0.685295140133807 
           0.00281250            0.00015625            0.00031250 
    0.686201169423553     0.690582799388141     0.692180702201577 
           0.00015625            0.00421875            0.00015625 
    0.696595449900374     0.697435597111395     0.698914306548046 
           0.00015625            0.00015625            0.00015625 
     0.70193206265865     0.702647867819401     0.707754986014002 
           0.00015625            0.00062500            0.00015625 
    0.711210346763156     0.712920206015224     0.713369947147153 
           0.00015625            0.00015625            0.00015625 
    0.715327471836729     0.722275487513834     0.722728216151602 
           0.00031250            0.00156250            0.00015625 
      0.7239248415172      0.72708089915877     0.729737150343281 
           0.00015625            0.00015625            0.00015625 
    0.735388003016973     0.740385327518889     0.741422651587756 
           0.00031250            0.00015625            0.00015625 
    0.741444754160499     0.747108762937508     0.748191169284348 
           0.00015625            0.00031250            0.00015625 
    0.751436430272142     0.752533256420978     0.752674676426801 
           0.00015625            0.00015625            0.00015625 
    0.754611657443207     0.754889027400603     0.756349639135923 
           0.00125000            0.00015625            0.00015625 
    0.763526062479594     0.768717423291569     0.770997182276433 
           0.00015625            0.00015625            0.00015625 
     0.77805655959217     0.780455501601279      0.79111659134251 
           0.00015625            0.00015625            0.00015625 
    0.794424123694395     0.794542595446869     0.797594367513394 
           0.00046875            0.00015625            0.00015625 
    0.806459604893308     0.806575447067013     0.815325824113437 
           0.00015625            0.00171875            0.00031250 
    0.820054212719794     0.821566079066492     0.822735985643791 
           0.00015625            0.00015625            0.00015625 
    0.824910396049865     0.825564426121463     0.827093295015157 
           0.00015625            0.00281250            0.00015625 
    0.830498441784675     0.839706577696515     0.854374875678462 
           0.00031250            0.00015625            0.00015625 
    0.857045424718981     0.857046899457354     0.858539236690819 
           0.00031250            0.00015625            0.00109375 
    0.861958482401254     0.864973903806387     0.868060666977836 
           0.00015625            0.00031250            0.00015625 
    0.871547517399078     0.877907606552374     0.878620392468042 
           0.00015625            0.00031250            0.00015625 
    0.882079910398028     0.886773165429333     0.895872264013794 
           0.00015625            0.00015625            0.00031250 
    0.902874892971196     0.909893594892982     0.910503026314625 
           0.00015625            0.00015625            0.00015625 
    0.918355472177732     0.923930998062757     0.928610132228083 
           0.00156250            0.00015625            0.00015625 
    0.930580294371997     0.932353440099381     0.933043163131344 
           0.00015625            0.00015625            0.00015625 
    0.935865275090846     0.938721396055517      0.94732667023698 
           0.00015625            0.00015625            0.00015625 
    0.952388332756409     0.953472399517577     0.960457391255192 
           0.00046875            0.00015625            0.00015625 
    0.962466815938431     0.974608403263273     0.977273131185975 
           0.00031250            0.00015625            0.00015625 
    0.979887858238853     0.981765099822977     0.982533764258785 
           0.02546875            0.00015625            0.00015625 
    0.986421193335086     0.991131333762411      0.99464772824313 
           0.00046875            0.00015625            0.00015625 
     1.00529335053186      1.01443060556224       1.0145402019372 
           0.00015625            0.00062500            0.00015625 
     1.02257036343242      1.02480443153783      1.02810330735672 
           0.00015625            0.00015625            0.00015625 
     1.02815692332918       1.0286099206142      1.03278708868866 
           0.00265625            0.00015625            0.00015625 
     1.03867605371823      1.04030809775545      1.05026762861212 
           0.00015625            0.00046875            0.00015625 
     1.05448691449244       1.0552263521649      1.05588258974527 
           0.00125000            0.00015625            0.00015625 
     1.06000513122926      1.06639439518604      1.07107601485988 
           0.00906250            0.00078125            0.00015625 
     1.07323792501438      1.07985999257921      1.08185178624946 
           0.00015625            0.00015625            0.00015625 
     1.08200577310599      1.08501442587133      1.08924264046828 
           0.00015625            0.00015625            0.00015625 
     1.09237983879524      1.09858922192811      1.09934822043348 
           0.00015625            0.00015625            0.00015625 
      1.1078948637414      1.11407400788163      1.11835818480985 
           0.00015625            0.00015625            0.00093750 
     1.11909298650692      1.12255263564979      1.13098492845703 
           0.00125000            0.00640625            0.00718750 
     1.13520899613199      1.13659865262031      1.14324263811607 
           0.00015625            0.00031250            0.00015625 
      1.1444495252129       1.1551673045972      1.15841602768456 
           0.00578125            0.00046875            0.00015625 
     1.17032197443365      1.17077944389967      1.17660425916148 
           0.00156250            0.01546875            0.00015625 
     1.17671971786951      1.18390085758965      1.19061835680715 
           0.00031250            0.02078125            0.00078125 
     1.19124162268748      1.19491419845781      1.20187158527135 
           0.00046875            0.01000000            0.00015625 
     1.20935820034015      1.21534749252995      1.21684078311872 
           0.00015625            0.00015625            0.00015625 
     1.22228576405746      1.22358524293339       1.2307494205369 
           0.00046875            0.00375000            0.00359375 
     1.23190824585799      1.23309624815214       1.2482497077686 
           0.00015625            0.00015625            0.00015625 
     1.24914605564843      1.25030062698194      1.25167385090479 
           0.00015625            0.00015625            0.00015625 
      1.2521388586462      1.25403638767138      1.25696184836792 
           0.00015625            0.00015625            0.00015625 
     1.25865710330342      1.26219503016375      1.26339025886804 
           0.00015625            0.00015625            0.00062500 
     1.27424955368127      1.27429889692881      1.27581391381442 
           0.00062500            0.01093750            0.00015625 
     1.28103448636196      1.28422435170195      1.28502302740832 
           0.00015625            0.00015625            0.00015625 
     1.28694332261892      1.28862136579613      1.29135133286724 
           0.00015625            0.00015625            0.00015625 
     1.29271693854318      1.29352984392642      1.29416501801516 
           0.00093750            0.00015625            0.00015625 
     1.32000923372796      1.32621334330507      1.32674979912185 
           0.00015625            0.00031250            0.00031250 
      1.3355388950486      1.33819762355126      1.34572143844383 
           0.00703125            0.00015625            0.00015625 
     1.34900429115538      1.35106912963136      1.35909050306374 
           0.00015625            0.00015625            0.00015625 
     1.36740896432616      1.37732504122682      1.37817713292888 
           0.00015625            0.00015625            0.00171875 
     1.38155034894393      1.38244688032714      1.38971756538262 
           0.00015625            0.00015625            0.00015625 
     1.39337346848199      1.39481552027921      1.39920925968592 
           0.00015625            0.00015625            0.00015625 
     1.40401019415033      1.40768753122916      1.42034462702771 
           0.00015625            0.00046875            0.00031250 
     1.42884838085788      1.43014092255268      1.43175470937195 
           0.00062500            0.00078125            0.00015625 
     1.43334191774463      1.43396654425843      1.43750664054499 
           0.00046875            0.00015625            0.00015625 
     1.43754219334743       1.4388998201083      1.44153927902681 
           0.00015625            0.01625000            0.01421875 
     1.44769121849116      1.44889234688456      1.45317034273597 
           0.00015625            0.00015625            0.00015625 
     1.45756717172523      1.46514717542552      1.48152004641465 
           0.00015625            0.01359375            0.00015625 
     1.48210471217649       1.4854271336131      1.49691410201524 
           0.00187500            0.00015625            0.00031250 
     1.50460499505036          1.5159104855      1.51944062018193 
           0.00015625            0.00062500            0.00015625 
     1.51951797036384      1.52322014302823      1.52914361888698 
           0.00015625            0.00015625            0.00015625 
     1.53094696259391      1.53185854523801      1.54534195968881 
           0.00015625            0.00015625            0.00015625 
     1.55198480359028      1.55950143190504      1.56497982317259 
           0.00031250            0.00015625            0.00015625 
     1.58262031982126      1.59616721426295      1.60437565730193 
           0.00062500            0.00015625            0.00015625 
     1.61266940307664      1.61805143272205      1.63593441495235 
           0.00015625            0.00015625            0.00390625 
     1.66020775786113      1.67542635415394      1.67673538939901 
           0.00046875            0.00015625            0.00437500 
     1.68035708519021      1.68346836697786      1.68837599513398 
           0.00015625            0.00015625            0.00015625 
     1.68938234802037      1.70189867028665      1.70300688645049 
           0.00015625            0.00015625            0.00015625 
     1.70487078400102      1.71353493899627      1.72834558905075 
           0.00015625            0.00015625            0.00015625 
     1.72915591888238      1.73426417234817      1.74021109248258 
           0.00015625            0.00015625            0.00015625 
     1.74232222740301      1.74349939634561       1.7580041756475 
           0.00015625            0.00015625            0.00015625 
     1.76113921780106      1.76617520172517      1.77211632108358 
           0.00015625            0.00015625            0.00015625 
     1.77514993495452      1.79958280830507      1.81629669477704 
           0.00015625            0.00015625            0.00031250 
     1.81990457312901      1.83656963213994      1.83724270780201 
           0.00015625            0.01140625            0.00015625 
     1.84610801109783      1.87127556838068      1.87941151145041 
           0.00015625            0.00031250            0.00015625 
     1.88207392317223      1.89017691499225      1.91733288828094 
           0.00031250            0.00015625            0.00015625 
     1.94867279430132      1.95578696468731      1.95652907096428 
           0.00687500            0.00015625            0.00015625 
     1.96029188648611      1.97337415011671      1.97682872944693 
           0.00015625            0.00015625            0.00015625 
     1.97898223695928      2.01790204562771      2.04143987127407 
           0.00015625            0.00015625            0.00171875 
     2.04788306887298      2.07547273185274      2.09309957494449 
           0.00062500            0.00031250            0.00015625 
     2.09950420993508      2.10052429104874      2.10697756530747 
           0.00031250            0.00015625            0.00015625 
     2.11999156344762      2.12917389303477      2.15933629269958 
           0.00015625            0.00015625            0.00015625 
     2.18306393167287      2.18323513022319      2.18704108088277 
           0.00187500            0.00015625            0.00015625 
     2.23887211958444      2.24380917557826      2.28051444339884 
           0.00015625            0.00015625            0.00562500 
     2.28417103037285      2.30954548348617      2.34561980157645 
           0.00015625            0.00125000            0.00015625 
     2.52385907644018      3.01185818638057      3.23514293488871 
           0.00015625            0.00015625            0.00031250 
     3.52347021972545      4.91171482734768      5.33930094132038 
           0.00015625            0.00015625            0.00015625 
     6.39137994453622      6.97999767626588 
           0.00015625            0.00015625 
> 
> prop.table(table(trainClass))
trainClass
  Strong     Weak 
0.746888 0.253112 
> 
> ncol(trainDescr)
[1] 20
> 
> ## Check Near-zero
> 
> nzv <- nearZeroVar(trainDescr, saveMetrics= TRUE)
> stopifnot( all(nzv$nzv == FALSE) )
> 
> # It's imputed and behaves well, no need for this.
> # descrCorr <- cor(scale(trainDescr), use = "pairwise.complete.obs")
> 
> descrCorr <- cor(scale(trainDescr))
> 
> highCorr <- findCorrelation(descrCorr, cutoff = .80, verbose = TRUE)
Considering row	 16 column	 17 value	 0.867 
  Flagging column	 16 
Considering row	 17 column	 10 value	 0.661 
Considering row	 17 column	 1 value	 0.267 
Considering row	 17 column	 11 value	 0.274 
Considering row	 17 column	 6 value	 0.212 
Considering row	 17 column	 12 value	 0.221 
Considering row	 17 column	 14 value	 0.22 
Considering row	 17 column	 8 value	 0.542 
Considering row	 17 column	 9 value	 0.573 
Considering row	 17 column	 2 value	 0.257 
Considering row	 17 column	 13 value	 0.192 
Considering row	 17 column	 19 value	 0.235 
Considering row	 17 column	 3 value	 0.272 
Considering row	 17 column	 18 value	 0.239 
Considering row	 17 column	 20 value	 0.131 
Considering row	 17 column	 15 value	 0.079 
Considering row	 17 column	 7 value	 0.103 
Considering row	 17 column	 5 value	 0.068 
Considering row	 17 column	 4 value	 0.073 
Considering row	 10 column	 1 value	 0.277 
Considering row	 10 column	 11 value	 0.284 
Considering row	 10 column	 6 value	 0.297 
Considering row	 10 column	 12 value	 0.259 
Considering row	 10 column	 14 value	 0.245 
Considering row	 10 column	 8 value	 0.412 
Considering row	 10 column	 9 value	 0.389 
Considering row	 10 column	 2 value	 0.277 
Considering row	 10 column	 13 value	 0.211 
Considering row	 10 column	 19 value	 0.183 
Considering row	 10 column	 3 value	 0.428 
Considering row	 10 column	 18 value	 0.176 
Considering row	 10 column	 20 value	 0.112 
Considering row	 10 column	 15 value	 0.332 
Considering row	 10 column	 7 value	 0.234 
Considering row	 10 column	 5 value	 0.082 
Considering row	 10 column	 4 value	 0.013 
Considering row	 1 column	 11 value	 0.987 
  Flagging column	 1 
Considering row	 11 column	 6 value	 0.944 
  Flagging column	 11 
Considering row	 6 column	 12 value	 0.876 
  Flagging column	 6 
Considering row	 12 column	 14 value	 0.125 
Considering row	 12 column	 8 value	 0.101 
Considering row	 12 column	 9 value	 0.122 
Considering row	 12 column	 2 value	 0.129 
Considering row	 12 column	 13 value	 0.099 
Considering row	 12 column	 19 value	 0.035 
Considering row	 12 column	 3 value	 0.076 
Considering row	 12 column	 18 value	 0.139 
Considering row	 12 column	 20 value	 0.092 
Considering row	 12 column	 15 value	 0.166 
Considering row	 12 column	 7 value	 0.114 
Considering row	 12 column	 5 value	 0.047 
Considering row	 12 column	 4 value	 0.023 
Considering row	 14 column	 8 value	 0.137 
Considering row	 14 column	 9 value	 0.146 
Considering row	 14 column	 2 value	 0.602 
Considering row	 14 column	 13 value	 0.712 
Considering row	 14 column	 19 value	 0.072 
Considering row	 14 column	 3 value	 0.137 
Considering row	 14 column	 18 value	 0.346 
Considering row	 14 column	 20 value	 0.154 
Considering row	 14 column	 15 value	 0.112 
Considering row	 14 column	 7 value	 0.179 
Considering row	 14 column	 5 value	 0.062 
Considering row	 14 column	 4 value	 0.237 
Considering row	 8 column	 9 value	 0.468 
Considering row	 8 column	 2 value	 0.197 
Considering row	 8 column	 13 value	 0.106 
Considering row	 8 column	 19 value	 0.289 
Considering row	 8 column	 3 value	 0.209 
Considering row	 8 column	 18 value	 0.147 
Considering row	 8 column	 20 value	 0.194 
Considering row	 8 column	 15 value	 0.073 
Considering row	 8 column	 7 value	 0.111 
Considering row	 8 column	 5 value	 0.025 
Considering row	 8 column	 4 value	 0.021 
Considering row	 9 column	 2 value	 0.383 
Considering row	 9 column	 13 value	 0.092 
Considering row	 9 column	 19 value	 0.247 
Considering row	 9 column	 3 value	 0.275 
Considering row	 9 column	 18 value	 0.046 
Considering row	 9 column	 20 value	 0.149 
Considering row	 9 column	 15 value	 0.078 
Considering row	 9 column	 7 value	 0.082 
Considering row	 9 column	 5 value	 0.09 
Considering row	 9 column	 4 value	 0.02 
Considering row	 2 column	 13 value	 0.586 
Considering row	 2 column	 19 value	 0.014 
Considering row	 2 column	 3 value	 0.289 
Considering row	 2 column	 18 value	 0.123 
Considering row	 2 column	 20 value	 0.11 
Considering row	 2 column	 15 value	 0.096 
Considering row	 2 column	 7 value	 0.009 
Considering row	 2 column	 5 value	 0.015 
Considering row	 2 column	 4 value	 0.221 
Considering row	 13 column	 19 value	 0.067 
Considering row	 13 column	 3 value	 0.201 
Considering row	 13 column	 18 value	 0.155 
Considering row	 13 column	 20 value	 0.132 
Considering row	 13 column	 15 value	 0.146 
Considering row	 13 column	 7 value	 0.121 
Considering row	 13 column	 5 value	 0.05 
Considering row	 13 column	 4 value	 0.23 
Considering row	 19 column	 3 value	 0.132 
Considering row	 19 column	 18 value	 0.12 
Considering row	 19 column	 20 value	 0.849 
  Flagging column	 19 
Considering row	 3 column	 18 value	 0.059 
Considering row	 3 column	 20 value	 0.03 
Considering row	 3 column	 15 value	 0.033 
Considering row	 3 column	 7 value	 0.151 
Considering row	 3 column	 5 value	 0.108 
Considering row	 3 column	 4 value	 0.107 
Considering row	 18 column	 20 value	 0.027 
Considering row	 18 column	 15 value	 0.12 
Considering row	 18 column	 7 value	 0.107 
Considering row	 18 column	 5 value	 0.001 
Considering row	 18 column	 4 value	 0.084 
Considering row	 20 column	 15 value	 0.037 
Considering row	 20 column	 7 value	 0.085 
Considering row	 20 column	 5 value	 0.129 
Considering row	 20 column	 4 value	 0.044 
Considering row	 15 column	 7 value	 0.016 
Considering row	 15 column	 5 value	 0.051 
Considering row	 15 column	 4 value	 0.022 
Considering row	 7 column	 5 value	 0.066 
Considering row	 7 column	 4 value	 0.041 
Considering row	 5 column	 4 value	 0.243 
> 
> # I've switched off the correlation remover and the results are better.
> if (sum(highCorr) > 0) {
+     warning("overfitting: correlations: ", paste(colnames(trainDescr)[highCorr], collapse = ", ") )
+     err.trainDescr <- trainDescr
+     trainDescr <- trainDescr[,-highCorr]
+ }
Warning message:
overfitting: correlations: DEPSPOKE, SDEPHR, DEPBUCKET, AVGSQ, xAVAILBUCKET 
> 
> descrCorr <- cor(trainDescr)
> summary(descrCorr[upper.tri(descrCorr)])
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
-0.57300 -0.12510 -0.01566  0.01494  0.12120  0.71240 
> 
> ## Dominant correlations
> ## At 0.9, there are some big ones that might need re-thinking.
> 
> table.descrCorr <- as.data.frame(as.table(descrCorr))
> table.descrCorr <- table.descrCorr[which(table.descrCorr$Var1 != table.descrCorr$Var2),]
> table.descrCorr[order(abs(table.descrCorr$Freq), decreasing = TRUE),]
              Var1           Var2          Freq
146     TRNRANKGRP     DEPRANKGRP  0.7123936016
160     DEPRANKGRP     TRNRANKGRP  0.7123936016
118       ARRSPOKE DOWNLINEATCIMP  0.6606389606
188 DOWNLINEATCIMP       ARRSPOKE  0.6606389606
11      TRNRANKGRP      SKDDEPSTA  0.6016994885
151      SKDDEPSTA     TRNRANKGRP  0.6016994885
10      DEPRANKGRP      SKDDEPSTA  0.5857295450
136      SKDDEPSTA     DEPRANKGRP  0.5857295450
103       ARRSPOKE   DEPSTAATCIMP -0.5729891892
187   DEPSTAATCIMP       ARRSPOKE -0.5729891892
88        ARRSPOKE   UPLINEATCIMP  0.5416679708
186   UPLINEATCIMP       ARRSPOKE  0.5416679708
82    DEPSTAATCIMP   UPLINEATCIMP -0.4683473008
96    UPLINEATCIMP   DEPSTAATCIMP -0.4683473008
23  DOWNLINEATCIMP      SKDARRSTA  0.4275176187
107      SKDARRSTA DOWNLINEATCIMP  0.4275176187
83  DOWNLINEATCIMP   UPLINEATCIMP  0.4124065350
111   UPLINEATCIMP DOWNLINEATCIMP  0.4124065350
98  DOWNLINEATCIMP   DEPSTAATCIMP -0.3886731631
112   DEPSTAATCIMP DOWNLINEATCIMP -0.3886731631
7     DEPSTAATCIMP      SKDDEPSTA  0.3832198201
91       SKDDEPSTA   DEPSTAATCIMP  0.3832198201
164         xDURN2     TRNRANKGRP  0.3462878006
206     TRNRANKGRP         xDURN2  0.3462878006
117     ARRRANKGRP DOWNLINEATCIMP -0.3321061029
173 DOWNLINEATCIMP     ARRRANKGRP -0.3321061029
2        SKDARRSTA      SKDDEPSTA -0.2893523493
16       SKDDEPSTA      SKDARRSTA -0.2893523493
8   DOWNLINEATCIMP      SKDDEPSTA -0.2770890658
106      SKDDEPSTA DOWNLINEATCIMP -0.2770890658
22    DEPSTAATCIMP      SKDARRSTA -0.2754764313
92       SKDARRSTA   DEPSTAATCIMP -0.2754764313
28        ARRSPOKE      SKDARRSTA  0.2719516846
182      SKDARRSTA       ARRSPOKE  0.2719516846
114      ARRBUCKET DOWNLINEATCIMP  0.2592870115
128 DOWNLINEATCIMP      ARRBUCKET  0.2592870115
13        ARRSPOKE      SKDDEPSTA -0.2565693570
181      SKDDEPSTA       ARRSPOKE -0.2565693570
116     TRNRANKGRP DOWNLINEATCIMP -0.2454705816
158 DOWNLINEATCIMP     TRNRANKGRP -0.2454705816
34          SKDEPS         SKDEQP  0.2429005770
48          SKDEQP         SKDEPS  0.2429005770
194         xDURN2       ARRSPOKE -0.2389499544
208       ARRSPOKE         xDURN2 -0.2389499544
41      TRNRANKGRP         SKDEQP  0.2365841507
153         SKDEQP     TRNRANKGRP  0.2365841507
68  DOWNLINEATCIMP      AVGLOFATC -0.2335839997
110      AVGLOFATC DOWNLINEATCIMP -0.2335839997
40      DEPRANKGRP         SKDEQP  0.2297970157
138         SKDEQP     DEPRANKGRP  0.2297970157
3           SKDEQP      SKDDEPSTA  0.2211561793
31       SKDDEPSTA         SKDEQP  0.2211561793
133       ARRSPOKE      ARRBUCKET  0.2210457979
189      ARRBUCKET       ARRSPOKE  0.2210457979
163       ARRSPOKE     TRNRANKGRP -0.2203007134
191     TRNRANKGRP       ARRSPOKE -0.2203007134
115     DEPRANKGRP DOWNLINEATCIMP -0.2105541478
143 DOWNLINEATCIMP     DEPRANKGRP -0.2105541478
21    UPLINEATCIMP      SKDARRSTA  0.2086590362
77       SKDARRSTA   UPLINEATCIMP  0.2086590362
25      DEPRANKGRP      SKDARRSTA -0.2012356887
137      SKDARRSTA     DEPRANKGRP -0.2012356887
6     UPLINEATCIMP      SKDDEPSTA -0.1974899930
76       SKDDEPSTA   UPLINEATCIMP -0.1974899930
90    xAVGSKDAVAIL   UPLINEATCIMP  0.1944125904
216   UPLINEATCIMP   xAVGSKDAVAIL  0.1944125904
148       ARRSPOKE     DEPRANKGRP -0.1918832166
190     DEPRANKGRP       ARRSPOKE -0.1918832166
71      TRNRANKGRP      AVGLOFATC  0.1785364320
155      AVGLOFATC     TRNRANKGRP  0.1785364320
119         xDURN2 DOWNLINEATCIMP -0.1757804944
203 DOWNLINEATCIMP         xDURN2 -0.1757804944
132     ARRRANKGRP      ARRBUCKET -0.1663215589
174      ARRBUCKET     ARRRANKGRP -0.1663215589
149         xDURN2     DEPRANKGRP  0.1546172935
205     DEPRANKGRP         xDURN2  0.1546172935
165   xAVGSKDAVAIL     TRNRANKGRP  0.1543973696
221     TRNRANKGRP   xAVGSKDAVAIL  0.1543973696
20       AVGLOFATC      SKDARRSTA -0.1513168864
62       SKDARRSTA      AVGLOFATC -0.1513168864
105   xAVGSKDAVAIL   DEPSTAATCIMP -0.1486910072
217   DEPSTAATCIMP   xAVGSKDAVAIL -0.1486910072
89          xDURN2   UPLINEATCIMP -0.1472964706
201   UPLINEATCIMP         xDURN2 -0.1472964706
101     TRNRANKGRP   DEPSTAATCIMP -0.1463023231
157   DEPSTAATCIMP     TRNRANKGRP -0.1463023231
147     ARRRANKGRP     DEPRANKGRP  0.1461231641
175     DEPRANKGRP     ARRRANKGRP  0.1461231641
134         xDURN2      ARRBUCKET -0.1387742725
204      ARRBUCKET         xDURN2 -0.1387742725
86      TRNRANKGRP   UPLINEATCIMP -0.1369384832
156   UPLINEATCIMP     TRNRANKGRP -0.1369384832
26      TRNRANKGRP      SKDARRSTA -0.1366878519
152      SKDARRSTA     TRNRANKGRP -0.1366878519
150   xAVGSKDAVAIL     DEPRANKGRP  0.1322388960
220     DEPRANKGRP   xAVGSKDAVAIL  0.1322388960
195   xAVGSKDAVAIL       ARRSPOKE  0.1312389745
223       ARRSPOKE   xAVGSKDAVAIL  0.1312389745
9        ARRBUCKET      SKDDEPSTA -0.1292069036
121      SKDDEPSTA      ARRBUCKET -0.1292069036
60    xAVGSKDAVAIL         SKDEPS  0.1290642104
214         SKDEPS   xAVGSKDAVAIL  0.1290642104
131     TRNRANKGRP      ARRBUCKET -0.1251244863
159      ARRBUCKET     TRNRANKGRP -0.1251244863
14          xDURN2      SKDDEPSTA  0.1225526684
196      SKDDEPSTA         xDURN2  0.1225526684
99       ARRBUCKET   DEPSTAATCIMP -0.1217839284
127   DEPSTAATCIMP      ARRBUCKET -0.1217839284
70      DEPRANKGRP      AVGLOFATC  0.1212460139
140      AVGLOFATC     DEPRANKGRP  0.1212460139
179         xDURN2     ARRRANKGRP  0.1197637732
207     ARRRANKGRP         xDURN2  0.1197637732
69       ARRBUCKET      AVGLOFATC -0.1142709272
125      AVGLOFATC      ARRBUCKET -0.1142709272
162     ARRRANKGRP     TRNRANKGRP  0.1124548664
176     TRNRANKGRP     ARRRANKGRP  0.1124548664
120   xAVGSKDAVAIL DOWNLINEATCIMP  0.1122021903
218 DOWNLINEATCIMP   xAVGSKDAVAIL  0.1122021903
66    UPLINEATCIMP      AVGLOFATC -0.1111026529
80       AVGLOFATC   UPLINEATCIMP -0.1111026529
15    xAVGSKDAVAIL      SKDDEPSTA  0.1103370848
211      SKDDEPSTA   xAVGSKDAVAIL  0.1103370848
19          SKDEPS      SKDARRSTA -0.1075315078
47       SKDARRSTA         SKDEPS -0.1075315078
74          xDURN2      AVGLOFATC -0.1071763905
200      AVGLOFATC         xDURN2 -0.1071763905
18          SKDEQP      SKDARRSTA  0.1069279831
32       SKDARRSTA         SKDEQP  0.1069279831
85      DEPRANKGRP   UPLINEATCIMP -0.1060427386
141   UPLINEATCIMP     DEPRANKGRP -0.1060427386
73        ARRSPOKE      AVGLOFATC -0.1031636516
185      AVGLOFATC       ARRSPOKE -0.1031636516
84       ARRBUCKET   UPLINEATCIMP  0.1005040141
126   UPLINEATCIMP      ARRBUCKET  0.1005040141
130     DEPRANKGRP      ARRBUCKET -0.0986950696
144      ARRBUCKET     DEPRANKGRP -0.0986950696
12      ARRRANKGRP      SKDDEPSTA  0.0957939692
166      SKDDEPSTA     ARRRANKGRP  0.0957939692
100     DEPRANKGRP   DEPSTAATCIMP  0.0917362584
142   DEPSTAATCIMP     DEPRANKGRP  0.0917362584
135   xAVGSKDAVAIL      ARRBUCKET -0.0916395464
219      ARRBUCKET   xAVGSKDAVAIL -0.0916395464
52    DEPSTAATCIMP         SKDEPS -0.0897016196
94          SKDEPS   DEPSTAATCIMP -0.0897016196
75    xAVGSKDAVAIL      AVGLOFATC -0.0851661321
215      AVGLOFATC   xAVGSKDAVAIL -0.0851661321
44          xDURN2         SKDEQP  0.0840845054
198         SKDEQP         xDURN2  0.0840845054
53  DOWNLINEATCIMP         SKDEPS -0.0824852879
109         SKDEPS DOWNLINEATCIMP -0.0824852879
67    DEPSTAATCIMP      AVGLOFATC -0.0820952353
95       AVGLOFATC   DEPSTAATCIMP -0.0820952353
178       ARRSPOKE     ARRRANKGRP -0.0786667163
192     ARRRANKGRP       ARRSPOKE -0.0786667163
102     ARRRANKGRP   DEPSTAATCIMP  0.0781721020
172   DEPSTAATCIMP     ARRRANKGRP  0.0781721020
24       ARRBUCKET      SKDARRSTA  0.0759279051
122      SKDARRSTA      ARRBUCKET  0.0759279051
43        ARRSPOKE         SKDEQP  0.0733208602
183         SKDEQP       ARRSPOKE  0.0733208602
87      ARRRANKGRP   UPLINEATCIMP -0.0726430815
171   UPLINEATCIMP     ARRRANKGRP -0.0726430815
58        ARRSPOKE         SKDEPS -0.0682301200
184         SKDEPS       ARRSPOKE -0.0682301200
50       AVGLOFATC         SKDEPS  0.0664222939
64          SKDEPS      AVGLOFATC  0.0664222939
56      TRNRANKGRP         SKDEPS  0.0618832558
154         SKDEPS     TRNRANKGRP  0.0618832558
29          xDURN2      SKDARRSTA  0.0591080250
197      SKDARRSTA         xDURN2  0.0591080250
57      ARRRANKGRP         SKDEPS  0.0512721484
169         SKDEPS     ARRRANKGRP  0.0512721484
55      DEPRANKGRP         SKDEPS  0.0500743992
139         SKDEPS     DEPRANKGRP  0.0500743992
54       ARRBUCKET         SKDEPS -0.0474518532
124         SKDEPS      ARRBUCKET -0.0474518532
104         xDURN2   DEPSTAATCIMP -0.0455009270
202   DEPSTAATCIMP         xDURN2 -0.0455009270
45    xAVGSKDAVAIL         SKDEQP  0.0443075653
213         SKDEQP   xAVGSKDAVAIL  0.0443075653
35       AVGLOFATC         SKDEQP  0.0409779020
63          SKDEQP      AVGLOFATC  0.0409779020
180   xAVGSKDAVAIL     ARRRANKGRP -0.0369486803
222     ARRRANKGRP   xAVGSKDAVAIL -0.0369486803
27      ARRRANKGRP      SKDARRSTA -0.0329029921
167      SKDARRSTA     ARRRANKGRP -0.0329029921
30    xAVGSKDAVAIL      SKDARRSTA  0.0295119094
212      SKDARRSTA   xAVGSKDAVAIL  0.0295119094
210   xAVGSKDAVAIL         xDURN2  0.0273117240
224         xDURN2   xAVGSKDAVAIL  0.0273117240
51    UPLINEATCIMP         SKDEPS -0.0247537375
79          SKDEPS   UPLINEATCIMP -0.0247537375
39       ARRBUCKET         SKDEQP -0.0227754634
123         SKDEQP      ARRBUCKET -0.0227754634
42      ARRRANKGRP         SKDEQP -0.0222304298
168         SKDEQP     ARRRANKGRP -0.0222304298
36    UPLINEATCIMP         SKDEQP -0.0213925713
78          SKDEQP   UPLINEATCIMP -0.0213925713
37    DEPSTAATCIMP         SKDEQP -0.0201791095
93          SKDEQP   DEPSTAATCIMP -0.0201791095
72      ARRRANKGRP      AVGLOFATC -0.0156582813
170      AVGLOFATC     ARRRANKGRP -0.0156582813
4           SKDEPS      SKDDEPSTA -0.0145908887
46       SKDDEPSTA         SKDEPS -0.0145908887
38  DOWNLINEATCIMP         SKDEQP -0.0131985370
108         SKDEQP DOWNLINEATCIMP -0.0131985370
5        AVGLOFATC      SKDDEPSTA -0.0093369555
61       SKDDEPSTA      AVGLOFATC -0.0093369555
59          xDURN2         SKDEPS -0.0009512376
199         SKDEPS         xDURN2 -0.0009512376
> 
> ### Models
> 
> ## Training controller
> 
> fitControl <- trainControl(## 10-fold CV
+     method = "repeatedcv",
+     number = 10,
+     ## repeated ten times
+     repeats = 10,
+     classProbs = 10,
+     summaryFunction = twoClassSummary)
> 
> ## Try many other parameters
> 
> colnames(trainDescr)
 [1] "SKDDEPSTA"      "SKDARRSTA"      "SKDEQP"         "SKDEPS"        
 [5] "AVGLOFATC"      "UPLINEATCIMP"   "DEPSTAATCIMP"   "DOWNLINEATCIMP"
 [9] "ARRBUCKET"      "DEPRANKGRP"     "TRNRANKGRP"     "ARRRANKGRP"    
[13] "ARRSPOKE"       "xDURN2"         "xAVGSKDAVAIL"  
> 
> gbmGrid <-  expand.grid(interaction.depth = c(1, 2, 3),
+                         n.trees = (1:30)*60,
+                         shrinkage = 0.1,
+                         n.minobsinnode = 20)
> 
> set.seed(107)
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "ROC",
+                  verbose = FALSE)
Loading required package: gbm
Loading required package: survival

Attaching package: 'survival'

The following object is masked from 'package:caret':

    cluster

Loading required package: splines
Loaded gbm 2.1.1
Loading required package: plyr
> gbmFit1
Stochastic Gradient Boosting 

241 samples
 15 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 216, 217, 217, 217, 217, 217, ... 

Resampling results across tuning parameters:

  interaction.depth  n.trees  ROC        Sens       Spec       ROC SD    
  1                    60     0.8101455  0.9183333  0.3409524  0.09986562
  1                   120     0.8082011  0.9061111  0.4354762  0.10312509
  1                   180     0.8016270  0.8961111  0.4597619  0.10527599
  1                   240     0.7977778  0.8933333  0.4619048  0.10662892
  1                   300     0.7977646  0.8850000  0.4835714  0.10331085
  1                   360     0.7943386  0.8866667  0.4838095  0.10053991
  1                   420     0.7933995  0.8788889  0.4769048  0.10232105
  1                   480     0.7914286  0.8750000  0.4733333  0.09833591
  1                   540     0.7898148  0.8700000  0.4783333  0.09587590
  1                   600     0.7873016  0.8666667  0.4680952  0.09587765
  1                   660     0.7815079  0.8672222  0.4721429  0.10348954
  1                   720     0.7805291  0.8650000  0.4619048  0.10297909
  1                   780     0.7816799  0.8638889  0.4588095  0.10328817
  1                   840     0.7818915  0.8555556  0.4650000  0.10250883
  1                   900     0.7796296  0.8561111  0.4604762  0.10115041
  1                   960     0.7808862  0.8561111  0.4626190  0.10125054
  1                  1020     0.7794974  0.8583333  0.4621429  0.10124602
  1                  1080     0.7797222  0.8572222  0.4523810  0.10103773
  1                  1140     0.7775661  0.8600000  0.4604762  0.10418471
  1                  1200     0.7790079  0.8533333  0.4685714  0.10431365
  1                  1260     0.7787566  0.8550000  0.4576190  0.10088826
  1                  1320     0.7764947  0.8533333  0.4592857  0.10071817
  1                  1380     0.7746693  0.8544444  0.4652381  0.10121091
  1                  1440     0.7730291  0.8522222  0.4623810  0.10159412
  1                  1500     0.7753968  0.8538889  0.4619048  0.10144840
  1                  1560     0.7735582  0.8522222  0.4635714  0.10130242
  1                  1620     0.7716005  0.8494444  0.4538095  0.10134487
  1                  1680     0.7730688  0.8488889  0.4685714  0.10265724
  1                  1740     0.7708333  0.8494444  0.4557143  0.10351550
  1                  1800     0.7696032  0.8488889  0.4607143  0.10265002
  2                    60     0.8117593  0.8994444  0.4340476  0.09461340
  2                   120     0.8035979  0.8872222  0.4709524  0.09828478
  2                   180     0.7958201  0.8777778  0.4673810  0.09865918
  2                   240     0.7952778  0.8755556  0.4711905  0.10113203
  2                   300     0.7960317  0.8727778  0.4511905  0.10055055
  2                   360     0.7933598  0.8722222  0.4726190  0.10187425
  2                   420     0.7909788  0.8666667  0.4769048  0.10192982
  2                   480     0.7879233  0.8677778  0.4609524  0.10306304
  2                   540     0.7896164  0.8633333  0.4569048  0.10081988
  2                   600     0.7905556  0.8650000  0.4645238  0.10163797
  2                   660     0.7867328  0.8627778  0.4497619  0.10381717
  2                   720     0.7871429  0.8661111  0.4566667  0.10214194
  2                   780     0.7861640  0.8616667  0.4500000  0.10105920
  2                   840     0.7886111  0.8605556  0.4480952  0.10209522
  2                   900     0.7888757  0.8605556  0.4545238  0.10075333
  2                   960     0.7863360  0.8588889  0.4416667  0.10363172
  2                  1020     0.7857407  0.8588889  0.4483333  0.10455594
  2                  1080     0.7853571  0.8555556  0.4545238  0.10360483
  2                  1140     0.7852513  0.8566667  0.4500000  0.10447704
  2                  1200     0.7846958  0.8561111  0.4435714  0.10422273
  2                  1260     0.7852381  0.8550000  0.4495238  0.10566977
  2                  1320     0.7865344  0.8544444  0.4464286  0.10572683
  2                  1380     0.7849868  0.8550000  0.4478571  0.10562843
  2                  1440     0.7853571  0.8538889  0.4497619  0.10824490
  2                  1500     0.7841931  0.8566667  0.4528571  0.10822947
  2                  1560     0.7846164  0.8544444  0.4497619  0.10472957
  2                  1620     0.7846958  0.8550000  0.4580952  0.10541966
  2                  1680     0.7845238  0.8544444  0.4547619  0.10407605
  2                  1740     0.7839550  0.8538889  0.4580952  0.10498560
  2                  1800     0.7839286  0.8522222  0.4547619  0.10482746
  3                    60     0.8018122  0.8966667  0.4211905  0.10048814
  3                   120     0.7958862  0.8883333  0.4488095  0.09869610
  3                   180     0.7911772  0.8805556  0.4426190  0.10178766
  3                   240     0.7894444  0.8738889  0.4442857  0.10220243
  3                   300     0.7840741  0.8688889  0.4502381  0.10275822
  3                   360     0.7871693  0.8666667  0.4473810  0.10018296
  3                   420     0.7860185  0.8661111  0.4538095  0.09688798
  3                   480     0.7856217  0.8638889  0.4400000  0.10359228
  3                   540     0.7870899  0.8633333  0.4469048  0.09864223
  3                   600     0.7896561  0.8616667  0.4533333  0.10042250
  3                   660     0.7884127  0.8633333  0.4576190  0.10118149
  3                   720     0.7855952  0.8661111  0.4497619  0.10429803
  3                   780     0.7847222  0.8638889  0.4514286  0.10405175
  3                   840     0.7864021  0.8622222  0.4528571  0.10215869
  3                   900     0.7851323  0.8616667  0.4530952  0.10454163
  3                   960     0.7854630  0.8600000  0.4530952  0.10394661
  3                  1020     0.7864683  0.8605556  0.4514286  0.10275085
  3                  1080     0.7851455  0.8616667  0.4530952  0.10701094
  3                  1140     0.7855423  0.8594444  0.4514286  0.10698375
  3                  1200     0.7854762  0.8611111  0.4547619  0.10754260
  3                  1260     0.7867857  0.8605556  0.4514286  0.10794731
  3                  1320     0.7872751  0.8577778  0.4564286  0.10488173
  3                  1380     0.7862169  0.8572222  0.4547619  0.10825860
  3                  1440     0.7859656  0.8544444  0.4597619  0.10812153
  3                  1500     0.7861508  0.8577778  0.4683333  0.10888552
  3                  1560     0.7865476  0.8550000  0.4614286  0.10956956
  3                  1620     0.7866534  0.8555556  0.4630952  0.10871207
  3                  1680     0.7869841  0.8577778  0.4611905  0.10834218
  3                  1740     0.7875397  0.8555556  0.4580952  0.10805811
  3                  1800     0.7868254  0.8533333  0.4661905  0.10787902
  Sens SD     Spec SD  
  0.06627974  0.2012888
  0.07394560  0.1954408
  0.07961397  0.2076685
  0.07883679  0.1998648
  0.08586865  0.1839208
  0.08428007  0.1892965
  0.08028662  0.2048859
  0.08444821  0.2054950
  0.08585595  0.1913489
  0.08898704  0.2033645
  0.08573785  0.1945234
  0.08623095  0.1945512
  0.08554856  0.1913417
  0.08757446  0.1915092
  0.08544646  0.1835632
  0.08689364  0.1975959
  0.08770785  0.1946422
  0.08907633  0.1938730
  0.08558681  0.1917412
  0.09090036  0.1989712
  0.08537346  0.1892572
  0.08486986  0.1947364
  0.08385731  0.1923733
  0.08512661  0.1895776
  0.08601376  0.1917347
  0.08475959  0.1946234
  0.08515407  0.1967992
  0.08652871  0.1929517
  0.08515407  0.2018326
  0.08507532  0.2000474
  0.07180663  0.2086907
  0.07953561  0.2091491
  0.07856742  0.2119523
  0.08095945  0.2160898
  0.08217299  0.2058039
  0.08187082  0.2005620
  0.08430966  0.1875208
  0.08459759  0.1914513
  0.08592854  0.1946011
  0.08477246  0.1910314
  0.08630323  0.1931598
  0.08471360  0.2019562
  0.08775050  0.1997358
  0.08631768  0.1894326
  0.08775050  0.1919166
  0.08629059  0.1902468
  0.08556496  0.1877527
  0.08757446  0.1937577
  0.08400589  0.1990754
  0.08617309  0.1912159
  0.08610070  0.1950591
  0.08678055  0.1890996
  0.08427082  0.1945716
  0.08418199  0.1979329
  0.08620383  0.1955195
  0.08713906  0.1950772
  0.08537346  0.1934626
  0.08642055  0.2012496
  0.08418199  0.1920068
  0.08729634  0.1916301
  0.08053475  0.1976086
  0.07756705  0.2177812
  0.08518336  0.2226108
  0.08572330  0.2101226
  0.08632671  0.2066569
  0.08319292  0.2052165
  0.08544646  0.2012302
  0.08627433  0.2116772
  0.08519982  0.2034387
  0.08559228  0.2019432
  0.08772385  0.2046377
  0.08508082  0.2072600
  0.08481658  0.2042551
  0.08262135  0.2063209
  0.08486068  0.2011914
  0.08774517  0.2093919
  0.08449250  0.2028768
  0.08486068  0.2025812
  0.08336326  0.1986844
  0.08148913  0.1994777
  0.08522726  0.2028768
  0.08697433  0.2087784
  0.08513943  0.2036537
  0.08459759  0.2016247
  0.08331275  0.2000096
  0.08537346  0.1956014
  0.08613871  0.1933814
  0.08065080  0.1976944
  0.08356683  0.2005832
  0.08560138  0.1950562

Tuning parameter 'shrinkage' was held constant at a value of 0.1

Tuning parameter 'n.minobsinnode' was held constant at a value of 20
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 60, interaction.depth =
 2, shrinkage = 0.1 and n.minobsinnode = 20. 
> 
> ## The acid test has failed. :-(
> 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
 Accuracy     Kappa 
0.7468354 0.0000000 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     59   20
    Weak        0    0
                                         
               Accuracy : 0.7468         
                 95% CI : (0.6364, 0.838)
    No Information Rate : 0.7468         
    P-Value [Acc > NIR] : 0.5597         
                                         
                  Kappa : 0              
 Mcnemar's Test P-Value : 2.152e-05      
                                         
            Sensitivity : 0.0000         
            Specificity : 1.0000         
         Pos Pred Value :    NaN         
         Neg Pred Value : 0.7468         
             Prevalence : 0.2532         
         Detection Rate : 0.0000         
   Detection Prevalence : 0.0000         
      Balanced Accuracy : 0.5000         
                                         
       'Positive' Class : Weak           
                                         
> 
> ## The training set is plausible - as one would hope.
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
 Accuracy     Kappa 
0.8506224 0.5674112 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    170   26
    Weak       10   35
                                          
               Accuracy : 0.8506          
                 95% CI : (0.7992, 0.8931)
    No Information Rate : 0.7469          
    P-Value [Acc > NIR] : 6.671e-05       
                                          
                  Kappa : 0.5674          
 Mcnemar's Test P-Value : 0.01242         
                                          
            Sensitivity : 0.5738          
            Specificity : 0.9444          
         Pos Pred Value : 0.7778          
         Neg Pred Value : 0.8673          
             Prevalence : 0.2531          
         Detection Rate : 0.1452          
   Detection Prevalence : 0.1867          
      Balanced Accuracy : 0.7591          
                                          
       'Positive' Class : Weak            
                                          
> trellis.par.set(caretTheme())
Warning message:
In trellis.par.set(caretTheme()) :
  Note: The default device has been opened to honour attempt to modify trellis settings
> plot(gbmFit1, metric = "ROC")
> quit()
Save workspace image? [y/n/c]: n

Process R finished at Sat May  7 01:24:19 2016


R version 3.2.5 (2016-04-14) -- "Very, Very Secure Dishes"
Copyright (C) 2016 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> > options(STERM='iESS', str.dendrogram.last="'", editor='emacsclient', show.error.locations=TRUE)
> 
+ . + + . + + . + 
> ### weaves
> 
> ## Following the caret vignette.
> 
> ###################################################
> ### code chunk number 1: loadLibs
> ###################################################
> library(MASS)

> library(caret)
Loading required package: lattice
Loading required package: ggplot2
Stackoverflow is a great place to get help:
http://stackoverflow.com/tags/ggplot2.

> library(mlbench)

> library(pROC)
Type 'citation("pROC")' for a citation.

Attaching package: 'pROC'

The following objects are masked from 'package:stats':

    cov, smooth, var


> library(pls)

Attaching package: 'pls'

The following object is masked from 'package:caret':

    R2

The following object is masked from 'package:stats':

    loadings


> library(doMC)
Loading required package: foreach
foreach: simple, scalable parallel programming from Revolution Analytics
Use Revolution R for scalability, fault tolerance and more.
http://www.revolutionanalytics.com
Loading required package: iterators
Loading required package: parallel

> registerDoMC(cores = 4)

> options(useFancyQuotes = FALSE) 

> # Accounting info.
> getInfo <- function(what = "Suggests")
+ {
+   text <- packageDescription("caret")[what][[1]]
+   text <- gsub("\n", ", ", text, fixed = TRUE)
+   text <- gsub(">=", "$\\\\ge$", text, fixed = TRUE)
+   eachPkg <- strsplit(text, ", ", fixed = TRUE)[[1]]
+   eachPkg <- gsub(",", .... [TRUNCATED] 

> ### project-specific: begin
> ## Set-seed, load original CSV file and do some simple-cleaning
> ## Various datasets 
> 
> set.seed(101)                           # helpful for testing

> flight <- read.csv("../bak/flight.csv")

> # Backup
> flight.raw <- flight

> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"

> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"

> # And some deletions
> 
> t.cols <- colnames(flight)

> t.drops <- t.cols[grep("^RANK*", t.cols)]

> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])

> t.drops <- c(t.drops, "D80THPCTL")

> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]

> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR

> flight$xHNGR <- flight$xDURN < 0

> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+  .... [TRUNCATED] 

> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))

> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE

> t.cols <- colnames(flight)

> t.drops <- c("SARRHR", "xDURN")

> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]

> ## Backup
> 
> flight00 <- flight

> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]

> ## Take another copy - this is all we need as the training/prediction
> ## set.
> 
> flight1 <- flight

> ## Data insights
> 
> ## Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> flight <- flight1

> ## So something is defining the behaviour.
> 
> ## Try to simplify structure
> 
> head(model.matrix(LEGTYPE ~ ., data = flight))
   (Intercept) SDEPHR SKDDEPSTAALB SKDDEPSTAAMS SKDDEPSTAANC SKDDEPSTAATT
2            1     14            0            0            0            0
5            1     11            0            0            0            0
7            1     14            0            0            0            0
13           1     13            0            0            0            0
14           1     16            0            0            0            0
17           1     15            0            0            0            0
   SKDDEPSTAAUA SKDDEPSTAAUS SKDDEPSTABDA SKDDEPSTABDL SKDDEPSTABNA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTABOI SKDDEPSTABOS SKDDEPSTABRU SKDDEPSTABUF SKDDEPSTABWI
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTACCC SKDDEPSTACDG SKDDEPSTACHS SKDDEPSTACLE SKDDEPSTACMH
2             1            0            0            0            0
5             0            0            0            0            0
7             1            0            0            0            0
13            0            0            0            0            0
14            1            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTACUN SKDDEPSTADDD SKDDEPSTADEN SKDDEPSTADFW SKDDEPSTADSM
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            1            0            0            0
   SKDDEPSTADTW SKDDEPSTADUB SKDDEPSTAEWR SKDDEPSTAFCO SKDDEPSTAFLL
2             0            0            0            0            0
5             1            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAFRA SKDDEPSTAGCM SKDDEPSTAGDL SKDDEPSTAGEG SKDDEPSTAGIG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAHNL SKDDEPSTAIAH SKDDEPSTAILM SKDDEPSTAIND SKDDEPSTAJAX
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAJFK SKDDEPSTAKOA SKDDEPSTALAS SKDDEPSTALAX SKDDEPSTALGA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTALGB SKDDEPSTALGW SKDDEPSTALHR SKDDEPSTALIH SKDDEPSTAMAD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMAN SKDDEPSTAMBJ SKDDEPSTAMCI SKDDEPSTAMCO SKDDEPSTAMDT
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMEX SKDDEPSTAMHT SKDDEPSTAMIA SKDDEPSTAMKE SKDDEPSTAMSP
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMSY SKDDEPSTAMUC SKDDEPSTAMZT SKDDEPSTANAS SKDDEPSTAOAK
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAOGG SKDDEPSTAOMA SKDDEPSTAONT SKDDEPSTAORD SKDDEPSTAORF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAPBI SKDDEPSTAPDX SKDDEPSTAPIT SKDDEPSTAPLS SKDDEPSTAPPP
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            1
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAPUJ SKDDEPSTAPVD SKDDEPSTAPVR SKDDEPSTAPWM SKDDEPSTARDU
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTARIC SKDDEPSTARNO SKDDEPSTAROC SKDDEPSTARSW SKDDEPSTASAN
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASAT SKDDEPSTASEA SKDDEPSTASFO SKDDEPSTASJC SKDDEPSTASJD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASJO SKDDEPSTASJU SKDDEPSTASLC SKDDEPSTASMF SKDDEPSTASNA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASRQ SKDDEPSTASTL SKDDEPSTASTT SKDDEPSTASXM SKDDEPSTASYR
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTATLV SKDDEPSTATPA SKDDEPSTAXHP SKDDEPSTAYEG SKDDEPSTAYVR
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAYYC SKDDEPSTAZRH SKDARRSTAALB SKDARRSTAAMS SKDARRSTAANC
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAATT SKDARRSTAAUA SKDARRSTAAUS SKDARRSTABDA SKDARRSTABDL
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTABNA SKDARRSTABOI SKDARRSTABOS SKDARRSTABRU SKDARRSTABUF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            1            0            0
17            0            0            0            0            0
   SKDARRSTABWI SKDARRSTACCC SKDARRSTACDG SKDARRSTACHS SKDARRSTACLE
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            1            0            0            0
   SKDARRSTACMH SKDARRSTACUN SKDARRSTADDD SKDARRSTADEN SKDARRSTADFW
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTADSM SKDARRSTADTW SKDARRSTADUB SKDARRSTAEWR SKDARRSTAFCO
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAFLL SKDARRSTAFRA SKDARRSTAGCM SKDARRSTAGDL SKDARRSTAGEG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAGIG SKDARRSTAHNL SKDARRSTAIAH SKDARRSTAILM SKDARRSTAIND
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAJAX SKDARRSTAJFK SKDARRSTAKOA SKDARRSTALAS SKDARRSTALAX
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTALGA SKDARRSTALGB SKDARRSTALGW SKDARRSTALHR SKDARRSTALIH
2             0            0            0            0            0
5             0            0            0            0            0
7             1            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMAD SKDARRSTAMAN SKDARRSTAMBJ SKDARRSTAMCI SKDARRSTAMCO
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMDT SKDARRSTAMEX SKDARRSTAMHT SKDARRSTAMIA SKDARRSTAMKE
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMSP SKDARRSTAMSY SKDARRSTAMUC SKDARRSTAMZT SKDARRSTANAS
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAOAK SKDARRSTAOGG SKDARRSTAOMA SKDARRSTAONT SKDARRSTAORD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            1
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAORF SKDARRSTAPBI SKDARRSTAPDX SKDARRSTAPIT SKDARRSTAPLS
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAPPP SKDARRSTAPUJ SKDARRSTAPVD SKDARRSTAPVR SKDARRSTAPWM
2             1            0            0            0            0
5             1            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTARDU SKDARRSTARIC SKDARRSTARNO SKDARRSTAROC SKDARRSTARSW
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASAN SKDARRSTASAT SKDARRSTASEA SKDARRSTASFO SKDARRSTASJC
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASJD SKDARRSTASJO SKDARRSTASJU SKDARRSTASLC SKDARRSTASMF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASNA SKDARRSTASRQ SKDARRSTASTL SKDARRSTASTT SKDARRSTASXM
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASYR SKDARRSTATLV SKDARRSTATPA SKDARRSTAXHP SKDARRSTAYEG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAYVR SKDARRSTAYYC SKDARRSTAZRH SKDEQP319 SKDEQP320 SKDEQP321
2             0            0            0         0         0         0
5             0            0            0         0         0         0
7             0            0            0         0         0         1
13            0            0            0         0         0         0
14            0            0            0         0         0         1
17            0            0            0         0         0         0
   SKDEQP332 SKDEQP333 SKDEQP734 SKDEQP75E SKDEQP75H SKDEQP767 SKDEQPA01
2          0         0         1         0         0         0         0
5          0         0         0         0         0         0         0
7          0         0         0         0         0         0         0
13         0         0         1         0         0         0         0
14         0         0         0         0         0         0         0
17         0         0         0         0         0         0         0
   SKDEQPA05 SKDEQPA19 SKDEQPA21 SKDEQPE90 SKDEPS       D00    AVGSQ AVGLOFATC
2          0         0         0         0     32 0.2500000 3.258065  3.258065
5          0         0         0         1     72 0.2916667 2.986111  3.805556
7          0         0         0         0     88 0.3295455 2.551724  3.701149
13         0         0         0         0     32 0.3750000 3.000000  3.903226
14         0         0         0         0     72 0.3750000 3.295775  3.859155
17         0         0         0         0     84 0.3809524 3.939759  3.361446
   UPLINEATCIMPLow UPLINEATCIMPMed UPLINEATCIMPMedHigh UPLINEATCIMPMedLow
2                0               1                   0                  0
5                0               0                   0                  0
7                0               0                   0                  1
13               0               1                   0                  0
14               0               0                   0                  1
17               1               0                   0                  0
   DEPSTAATCIMPLow DOWNLINEATCIMPLow AVGSKDAVAIL AVAILBUCKETA05 AVAILBUCKETA10
2                0                 0   10.903226              0              1
5                1                 0    2.000000              0              0
7                0                 0    9.647059              1              0
13               0                 0   17.354839              0              0
14               0                 0   17.057143              0              0
17               0                 0   10.621951              0              1
   AVAILBUCKETA15 AVAILBUCKETA20 AVAILBUCKETA25 AVAILBUCKETA30 AVAILBUCKETA<0
2               0              0              0              0              0
5               0              0              0              0              0
7               0              0              0              0              0
13              1              0              0              0              0
14              1              0              0              0              0
17              0              0              0              0              0
   DEPBUCKETD2 DEPBUCKETD3 DEPBUCKETD4 DEPBUCKETD5 DEPBUCKETD6 DEPBUCKETD7
2            0           0           0           1           0           0
5            0           0           1           0           0           0
7            0           0           0           1           0           0
13           0           0           0           1           0           0
14           0           0           0           0           1           0
17           0           0           0           0           1           0
   DEPBUCKETD8 ARRBUCKETA2 ARRBUCKETA3 ARRBUCKETA4 ARRBUCKETA5 ARRBUCKETA6
2            0           0           0           0           0           1
5            0           0           0           0           1           0
7            0           0           0           0           0           1
13           0           0           0           0           0           1
14           0           0           0           0           0           0
17           0           0           0           0           0           1
   ARRBUCKETA7 ARRBUCKETA8 DEPRANKGRPLow DEPRANKGRPMed DEPRANKGRPMedHigh
2            0           0             1             0                 0
5            0           0             0             1                 0
7            0           0             1             0                 0
13           0           0             0             0                 0
14           1           0             1             0                 0
17           0           0             0             0                 0
   DEPRANKGRPMedLow TRNRANKGRPLow TRNRANKGRPMed TRNRANKGRPMedHigh
2                 0             1             0                 0
5                 0             1             0                 0
7                 0             1             0                 0
13                1             0             0                 0
14                0             1             0                 0
17                1             0             1                 0
   TRNRANKGRPMedLow ARRRANKGRPLow ARRRANKGRPMed ARRRANKGRPMedHigh
2                 0             0             0                 1
5                 0             0             0                 1
7                 0             0             1                 0
13                1             0             0                 0
14                0             0             0                 1
17                0             0             0                 1
   ARRRANKGRPMedLow DEPSPOKETRUE ARRSPOKETRUE xHNGRTRUE xDURN2
2                 0            0            0         0      2
5                 0            1            0         0      2
7                 0            0            1         0      2
13                1            0            1         0      2
14                0            0            1         0      2
17                0            0            0         0      2

> dummies <- dummyVars(LEGTYPE ~ ., data = flight)

> flight.dum <- predict(dummies, newdata = flight)

> ## It may be too big to use, but useful for inspection.
> 
> ### Numeric variables
> 
> ## Check some more correlations, I haven't scaled yet.
> 
> x1 <- as.data.frame(as.matrix(sapply(flight, class)))

> flight.num <- flight[,names(x1[which(x1$V1 %in% c("numeric", "integer")),])]

> flight.nzv <- nearZeroVar(flight.num, saveMetrics = TRUE)

> flight.nzv
            freqRatio percentUnique zeroVar   nzv
SDEPHR       1.038462        5.9375   FALSE FALSE
SKDEPS       1.000000       19.0625   FALSE FALSE
D00          1.166667       75.3125   FALSE FALSE
AVGSQ        6.333333       82.8125   FALSE FALSE
AVGLOFATC    1.000000       78.4375   FALSE FALSE
AVGSKDAVAIL  1.000000       87.5000   FALSE FALSE
xDURN2       1.428571        2.5000   FALSE FALSE

> flight.cor <- cor(flight.num, use = "pairwise.complete.obs")

> highlyCorDescr <- findCorrelation(flight.cor, cutoff = .75, verbose=TRUE)
Considering row	 1 column	 4 value	 0.956 
  Flagging column	 1 
Considering row	 4 column	 3 value	 0.414 
Considering row	 4 column	 6 value	 0.173 
Considering row	 4 column	 7 value	 0.201 
Considering row	 4 column	 5 value	 0.103 
Considering row	 4 column	 2 value	 0.082 
Considering row	 3 column	 6 value	 0.266 
Considering row	 3 column	 7 value	 0.071 
Considering row	 3 column	 5 value	 0.114 
Considering row	 3 column	 2 value	 0.006 
Considering row	 6 column	 7 value	 0.031 
Considering row	 6 column	 5 value	 0.094 
Considering row	 6 column	 2 value	 0.067 
Considering row	 7 column	 5 value	 0.137 
Considering row	 7 column	 2 value	 0.005 
Considering row	 5 column	 2 value	 0.041 

> ## Which tells me that departure time is very highly correlated to AVGSQ.
> 
> ### Try and impute the AVG
> 
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))

> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1

> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]

> preProcValues <- preProcess(flight.na, method = c("knnImpute"))

> flight.na1 <- predict(preProcValues, flight.na)

> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL

> ## And I'll leave the centered and scale values in for now.
> ## and delete the troublesome ones
> 
> flight$AVGSKDAVAIL <- NULL

> flight$xHNGR <- NULL

> flight$AVAILBUCKET <- NULL

> # This should be deleted, leave it in and the results are ideal because it defines LEGTYPE.
> flight$D00 <- NULL

> ## Keep the results.
> outcomes.flight <- flight$LEGTYPE

> flight$LEGTYPE <- NULL

> ## Try converting all the factors to numerics
> 
> flight[,names(x1[which(x1$V1 %in% c("factor")),])]
Error in `[.data.frame`(flight, , names(x1[which(x1$V1 %in% c("factor")),  (from flight0.R!5049oZl#167) : 
  undefined columns selected
> options(useFancyQuotes = FALSE) 
> 
> # Accounting info.
> getInfo <- function(what = "Suggests")
+ {
+   text <- packageDescription("caret")[what][[1]]
+   text <- gsub("\n", ", ", text, fixed = TRUE)
+   text <- gsub(">=", "$\\\\ge$", text, fixed = TRUE)
+   eachPkg <- strsplit(text, ", ", fixed = TRUE)[[1]]
+   eachPkg <- gsub(",", "", eachPkg, fixed = TRUE)
+   # out <- paste("\\\\pkg{", eachPkg[order(tolower(eachPkg))], "}", sep = "")
+   # paste(out, collapse = ", ")
+   length(eachPkg)
+ }
> 
> ### project-specific: begin
> ## Set-seed, load original CSV file and do some simple-cleaning
> ## Various datasets 
> 
> set.seed(101)                           # helpful for testing
> 
> flight <- read.csv("../bak/flight.csv")
> 
> # Backup
> flight.raw <- flight
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"
> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"
> 
> # And some deletions
> 
> t.cols <- colnames(flight)
> 
> t.drops <- t.cols[grep("^RANK*", t.cols)]
> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])
> t.drops <- c(t.drops, "D80THPCTL")
> 
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR
> flight$xHNGR <- flight$xDURN < 0
> 
> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+ }
> 
> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))
> 
> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE
> t.cols <- colnames(flight)
> 
> t.drops <- c("SARRHR", "xDURN")
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Backup
> 
> flight00 <- flight
> 
> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]
> 
> ## Take another copy - this is all we need as the training/prediction
> ## set.
> 
> flight1 <- flight
> 
> ## Data insights
> 
> ## Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> flight <- flight1
> 
> ## So something is defining the behaviour.
> 
> ## Try to simplify structure
> 
> head(model.matrix(LEGTYPE ~ ., data = flight))
   (Intercept) SDEPHR SKDDEPSTAALB SKDDEPSTAAMS SKDDEPSTAANC SKDDEPSTAATT
2            1     14            0            0            0            0
5            1     11            0            0            0            0
7            1     14            0            0            0            0
13           1     13            0            0            0            0
14           1     16            0            0            0            0
17           1     15            0            0            0            0
   SKDDEPSTAAUA SKDDEPSTAAUS SKDDEPSTABDA SKDDEPSTABDL SKDDEPSTABNA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTABOI SKDDEPSTABOS SKDDEPSTABRU SKDDEPSTABUF SKDDEPSTABWI
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTACCC SKDDEPSTACDG SKDDEPSTACHS SKDDEPSTACLE SKDDEPSTACMH
2             1            0            0            0            0
5             0            0            0            0            0
7             1            0            0            0            0
13            0            0            0            0            0
14            1            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTACUN SKDDEPSTADDD SKDDEPSTADEN SKDDEPSTADFW SKDDEPSTADSM
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            1            0            0            0
   SKDDEPSTADTW SKDDEPSTADUB SKDDEPSTAEWR SKDDEPSTAFCO SKDDEPSTAFLL
2             0            0            0            0            0
5             1            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAFRA SKDDEPSTAGCM SKDDEPSTAGDL SKDDEPSTAGEG SKDDEPSTAGIG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAHNL SKDDEPSTAIAH SKDDEPSTAILM SKDDEPSTAIND SKDDEPSTAJAX
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAJFK SKDDEPSTAKOA SKDDEPSTALAS SKDDEPSTALAX SKDDEPSTALGA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTALGB SKDDEPSTALGW SKDDEPSTALHR SKDDEPSTALIH SKDDEPSTAMAD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMAN SKDDEPSTAMBJ SKDDEPSTAMCI SKDDEPSTAMCO SKDDEPSTAMDT
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMEX SKDDEPSTAMHT SKDDEPSTAMIA SKDDEPSTAMKE SKDDEPSTAMSP
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMSY SKDDEPSTAMUC SKDDEPSTAMZT SKDDEPSTANAS SKDDEPSTAOAK
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAOGG SKDDEPSTAOMA SKDDEPSTAONT SKDDEPSTAORD SKDDEPSTAORF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAPBI SKDDEPSTAPDX SKDDEPSTAPIT SKDDEPSTAPLS SKDDEPSTAPPP
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            1
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAPUJ SKDDEPSTAPVD SKDDEPSTAPVR SKDDEPSTAPWM SKDDEPSTARDU
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTARIC SKDDEPSTARNO SKDDEPSTAROC SKDDEPSTARSW SKDDEPSTASAN
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASAT SKDDEPSTASEA SKDDEPSTASFO SKDDEPSTASJC SKDDEPSTASJD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASJO SKDDEPSTASJU SKDDEPSTASLC SKDDEPSTASMF SKDDEPSTASNA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASRQ SKDDEPSTASTL SKDDEPSTASTT SKDDEPSTASXM SKDDEPSTASYR
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTATLV SKDDEPSTATPA SKDDEPSTAXHP SKDDEPSTAYEG SKDDEPSTAYVR
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAYYC SKDDEPSTAZRH SKDARRSTAALB SKDARRSTAAMS SKDARRSTAANC
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAATT SKDARRSTAAUA SKDARRSTAAUS SKDARRSTABDA SKDARRSTABDL
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTABNA SKDARRSTABOI SKDARRSTABOS SKDARRSTABRU SKDARRSTABUF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            1            0            0
17            0            0            0            0            0
   SKDARRSTABWI SKDARRSTACCC SKDARRSTACDG SKDARRSTACHS SKDARRSTACLE
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            1            0            0            0
   SKDARRSTACMH SKDARRSTACUN SKDARRSTADDD SKDARRSTADEN SKDARRSTADFW
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTADSM SKDARRSTADTW SKDARRSTADUB SKDARRSTAEWR SKDARRSTAFCO
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAFLL SKDARRSTAFRA SKDARRSTAGCM SKDARRSTAGDL SKDARRSTAGEG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAGIG SKDARRSTAHNL SKDARRSTAIAH SKDARRSTAILM SKDARRSTAIND
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAJAX SKDARRSTAJFK SKDARRSTAKOA SKDARRSTALAS SKDARRSTALAX
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTALGA SKDARRSTALGB SKDARRSTALGW SKDARRSTALHR SKDARRSTALIH
2             0            0            0            0            0
5             0            0            0            0            0
7             1            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMAD SKDARRSTAMAN SKDARRSTAMBJ SKDARRSTAMCI SKDARRSTAMCO
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMDT SKDARRSTAMEX SKDARRSTAMHT SKDARRSTAMIA SKDARRSTAMKE
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMSP SKDARRSTAMSY SKDARRSTAMUC SKDARRSTAMZT SKDARRSTANAS
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAOAK SKDARRSTAOGG SKDARRSTAOMA SKDARRSTAONT SKDARRSTAORD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            1
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAORF SKDARRSTAPBI SKDARRSTAPDX SKDARRSTAPIT SKDARRSTAPLS
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAPPP SKDARRSTAPUJ SKDARRSTAPVD SKDARRSTAPVR SKDARRSTAPWM
2             1            0            0            0            0
5             1            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTARDU SKDARRSTARIC SKDARRSTARNO SKDARRSTAROC SKDARRSTARSW
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASAN SKDARRSTASAT SKDARRSTASEA SKDARRSTASFO SKDARRSTASJC
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASJD SKDARRSTASJO SKDARRSTASJU SKDARRSTASLC SKDARRSTASMF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASNA SKDARRSTASRQ SKDARRSTASTL SKDARRSTASTT SKDARRSTASXM
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASYR SKDARRSTATLV SKDARRSTATPA SKDARRSTAXHP SKDARRSTAYEG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAYVR SKDARRSTAYYC SKDARRSTAZRH SKDEQP319 SKDEQP320 SKDEQP321
2             0            0            0         0         0         0
5             0            0            0         0         0         0
7             0            0            0         0         0         1
13            0            0            0         0         0         0
14            0            0            0         0         0         1
17            0            0            0         0         0         0
   SKDEQP332 SKDEQP333 SKDEQP734 SKDEQP75E SKDEQP75H SKDEQP767 SKDEQPA01
2          0         0         1         0         0         0         0
5          0         0         0         0         0         0         0
7          0         0         0         0         0         0         0
13         0         0         1         0         0         0         0
14         0         0         0         0         0         0         0
17         0         0         0         0         0         0         0
   SKDEQPA05 SKDEQPA19 SKDEQPA21 SKDEQPE90 SKDEPS       D00    AVGSQ AVGLOFATC
2          0         0         0         0     32 0.2500000 3.258065  3.258065
5          0         0         0         1     72 0.2916667 2.986111  3.805556
7          0         0         0         0     88 0.3295455 2.551724  3.701149
13         0         0         0         0     32 0.3750000 3.000000  3.903226
14         0         0         0         0     72 0.3750000 3.295775  3.859155
17         0         0         0         0     84 0.3809524 3.939759  3.361446
   UPLINEATCIMPLow UPLINEATCIMPMed UPLINEATCIMPMedHigh UPLINEATCIMPMedLow
2                0               1                   0                  0
5                0               0                   0                  0
7                0               0                   0                  1
13               0               1                   0                  0
14               0               0                   0                  1
17               1               0                   0                  0
   DEPSTAATCIMPLow DOWNLINEATCIMPLow AVGSKDAVAIL AVAILBUCKETA05 AVAILBUCKETA10
2                0                 0   10.903226              0              1
5                1                 0    2.000000              0              0
7                0                 0    9.647059              1              0
13               0                 0   17.354839              0              0
14               0                 0   17.057143              0              0
17               0                 0   10.621951              0              1
   AVAILBUCKETA15 AVAILBUCKETA20 AVAILBUCKETA25 AVAILBUCKETA30 AVAILBUCKETA<0
2               0              0              0              0              0
5               0              0              0              0              0
7               0              0              0              0              0
13              1              0              0              0              0
14              1              0              0              0              0
17              0              0              0              0              0
   DEPBUCKETD2 DEPBUCKETD3 DEPBUCKETD4 DEPBUCKETD5 DEPBUCKETD6 DEPBUCKETD7
2            0           0           0           1           0           0
5            0           0           1           0           0           0
7            0           0           0           1           0           0
13           0           0           0           1           0           0
14           0           0           0           0           1           0
17           0           0           0           0           1           0
   DEPBUCKETD8 ARRBUCKETA2 ARRBUCKETA3 ARRBUCKETA4 ARRBUCKETA5 ARRBUCKETA6
2            0           0           0           0           0           1
5            0           0           0           0           1           0
7            0           0           0           0           0           1
13           0           0           0           0           0           1
14           0           0           0           0           0           0
17           0           0           0           0           0           1
   ARRBUCKETA7 ARRBUCKETA8 DEPRANKGRPLow DEPRANKGRPMed DEPRANKGRPMedHigh
2            0           0             1             0                 0
5            0           0             0             1                 0
7            0           0             1             0                 0
13           0           0             0             0                 0
14           1           0             1             0                 0
17           0           0             0             0                 0
   DEPRANKGRPMedLow TRNRANKGRPLow TRNRANKGRPMed TRNRANKGRPMedHigh
2                 0             1             0                 0
5                 0             1             0                 0
7                 0             1             0                 0
13                1             0             0                 0
14                0             1             0                 0
17                1             0             1                 0
   TRNRANKGRPMedLow ARRRANKGRPLow ARRRANKGRPMed ARRRANKGRPMedHigh
2                 0             0             0                 1
5                 0             0             0                 1
7                 0             0             1                 0
13                1             0             0                 0
14                0             0             0                 1
17                0             0             0                 1
   ARRRANKGRPMedLow DEPSPOKETRUE ARRSPOKETRUE xHNGRTRUE xDURN2
2                 0            0            0         0      2
5                 0            1            0         0      2
7                 0            0            1         0      2
13                1            0            1         0      2
14                0            0            1         0      2
17                0            0            0         0      2
> 
> dummies <- dummyVars(LEGTYPE ~ ., data = flight)
> flight.dum <- predict(dummies, newdata = flight)
> 
> ## It may be too big to use, but useful for inspection.
> 
> ### Numeric variables
> 
> ## Check some more correlations, I haven't scaled yet.
> 
> x1 <- as.data.frame(as.matrix(sapply(flight, class)))
> 
> flight.num <- flight[,names(x1[which(x1$V1 %in% c("numeric", "integer")),])]
> 
> flight.nzv <- nearZeroVar(flight.num, saveMetrics = TRUE)
> flight.nzv
            freqRatio percentUnique zeroVar   nzv
SDEPHR       1.038462        5.9375   FALSE FALSE
SKDEPS       1.000000       19.0625   FALSE FALSE
D00          1.166667       75.3125   FALSE FALSE
AVGSQ        6.333333       82.8125   FALSE FALSE
AVGLOFATC    1.000000       78.4375   FALSE FALSE
AVGSKDAVAIL  1.000000       87.5000   FALSE FALSE
xDURN2       1.428571        2.5000   FALSE FALSE
> 
> flight.cor <- cor(flight.num, use = "pairwise.complete.obs")
> 
> highlyCorDescr <- findCorrelation(flight.cor, cutoff = .75, verbose=TRUE)
Considering row	 1 column	 4 value	 0.956 
  Flagging column	 1 
Considering row	 4 column	 3 value	 0.414 
Considering row	 4 column	 6 value	 0.173 
Considering row	 4 column	 7 value	 0.201 
Considering row	 4 column	 5 value	 0.103 
Considering row	 4 column	 2 value	 0.082 
Considering row	 3 column	 6 value	 0.266 
Considering row	 3 column	 7 value	 0.071 
Considering row	 3 column	 5 value	 0.114 
Considering row	 3 column	 2 value	 0.006 
Considering row	 6 column	 7 value	 0.031 
Considering row	 6 column	 5 value	 0.094 
Considering row	 6 column	 2 value	 0.067 
Considering row	 7 column	 5 value	 0.137 
Considering row	 7 column	 2 value	 0.005 
Considering row	 5 column	 2 value	 0.041 
> 
> ## Which tells me that departure time is very highly correlated to AVGSQ.
> 
> ### Try and impute the AVG
> 
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))
> 
> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1
> 
> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]
> 
> preProcValues <- preProcess(flight.na, method = c("knnImpute"))
> flight.na1 <- predict(preProcValues, flight.na)
> 
> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL
> 
> ## And I'll leave the centered and scale values in for now.
> ## and delete the troublesome ones
> 
> flight$AVGSKDAVAIL <- NULL
> flight$xHNGR <- NULL
> flight$AVAILBUCKET <- NULL
> 
> # This should be deleted, leave it in and the results are ideal because it defines LEGTYPE.
> flight$D00 <- NULL
> 
> ## Keep the results.
> outcomes.flight <- flight$LEGTYPE
> 
> flight$LEGTYPE <- NULL
> 
> ## Try converting all the factors to numerics
> 
> ## If you know your factors are definitely factors, you don't need this
> ##  asNumeric <- function(x) as.numeric(as.character(x))
> 
> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))
> 
> flight.num0 <- factors.numeric(flight)
> 
> flight.scl0 <- scale(flight.num0)
> 
> ## Now split the results
> 
> inTrain <- createDataPartition(outcomes.flight, p = 0.75, list = FALSE)
> 
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> 
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> 
> prop.table(table(flight.scl0))
flight.scl0
    -2.99546983996958     -2.98604368384811     -2.82110052361751 
           0.00281250            0.00015625            0.00015625 
    -2.64037641778924     -2.37742331516569     -2.09431321436608 
           0.00015625            0.00015625            0.00031250 
    -2.02525208119049     -2.02364615961949     -1.96706162425765 
           0.00046875            0.00093750            0.00015625 
    -1.94787383036273     -1.91934227796699     -1.87162293167633 
           0.00125000            0.00015625            0.00015625 
    -1.80813803757891      -1.8064397520718     -1.76880294648328 
           0.00093750            0.00093750            0.00453125 
     -1.7104004231695     -1.67620690253875     -1.63572266525187 
           0.00312500            0.00015625            0.00078125 
    -1.60554554037119     -1.58829697245811     -1.58375887562806 
           0.00265625            0.00062500            0.00031250 
    -1.56068940274137     -1.55266802930898     -1.55257138616628 
           0.00593750            0.00015625            0.00015625 
    -1.54865734259279     -1.54635333101763     -1.54295794614133 
           0.00015625            0.00015625            0.00015625 
    -1.53179508600425     -1.53074294246617     -1.50769426210174 
           0.00203125            0.00015625            0.00015625 
    -1.49330986644838     -1.47983129638045     -1.47646498237513 
           0.00015625            0.00171875            0.00015625 
    -1.44796824755814     -1.43812707979848     -1.43616463590287 
           0.00015625            0.00031250            0.00015625 
     -1.4311495031078     -1.42786750675664     -1.42754311366228 
           0.00062500            0.00031250            0.00015625 
     -1.4230237164245     -1.42196682798086     -1.40691590144974 
           0.00015625            0.00015625            0.00750000 
    -1.40295304316347     -1.39839761187043     -1.38337483337197 
           0.00343750            0.00015625            0.00015625 
    -1.37828409873765     -1.37590371713284      -1.3753288895824 
           0.00031250            0.00078125            0.00015625 
    -1.37383369560894     -1.37045453151584     -1.35466334686085 
           0.00015625            0.00015625            0.00015625 
    -1.33716625322094     -1.33398496346823     -1.33080367371552 
           0.00015625            0.00015625            0.00015625 
    -1.32393992750903      -1.3160853172316     -1.31578091655701 
           0.00093750            0.00015625            0.00015625 
    -1.31443367614047      -1.3133256164209     -1.30151560934568 
           0.00015625            0.00015625            0.00015625 
    -1.30111163600234     -1.29600486257245     -1.28619597667342 
           0.00015625            0.00031250            0.00031250 
    -1.28367748081635     -1.28186181839242      -1.2799413346293 
           0.00031250            0.00015625            0.00015625 
    -1.27197613788523     -1.26773489691459      -1.2671778786613 
           0.00109375            0.00015625            0.00015625 
     -1.2615812276646     -1.25974760485758     -1.25283365916062 
           0.00031250            0.00078125            0.00015625 
    -1.25178454113998     -1.24659260411695     -1.24079645146543 
           0.00015625            0.00015625            0.00015625 
     -1.2302338686483     -1.23020377865797      -1.2268968080815 
           0.00015625            0.00687500            0.00031250 
    -1.22001234826142     -1.21809512250389     -1.21512040999215 
           0.00046875            0.00015625            0.00015625 
    -1.21024953572476     -1.20647153886774     -1.20560405725029 
           0.00015625            0.00015625            0.00015625 
    -1.20188627600106     -1.20036054595575     -1.20011285144544 
           0.00031250            0.00140625            0.00015625 
    -1.19042311450129     -1.18991798468508     -1.18966337127103 
           0.00015625            0.00015625            0.00062500 
    -1.16804855863761     -1.16764210792351     -1.16749679150174 
           0.00093750            0.00015625            0.00015625 
    -1.16258400593847     -1.16018257780086     -1.15839829359119 
           0.00015625            0.00640625            0.00015625 
    -1.14179763548495     -1.13992628855288     -1.13935994002253 
           0.00015625            0.00031250            0.00031250 
    -1.13310730700243     -1.13102279477938     -1.12993289335973 
           0.00015625            0.00015625            0.00015625 
    -1.12915754122589     -1.12753063368423     -1.12667091460446 
           0.00015625            0.00015625            0.00015625 
    -1.12622940836933     -1.12368140470519     -1.12361616254288 
           0.00031250            0.00015625            0.00062500 
    -1.12145428351456     -1.11910330109794     -1.11800948418703 
           0.00015625            0.00015625            0.00015625 
    -1.11608476901381     -1.11429923219746     -1.09261479989672 
           0.00062500            0.00015625            0.00015625 
    -1.09084552937417     -1.09012044993392      -1.0895833019642 
           0.00015625            0.00015625            0.00031250 
    -1.08549109658463     -1.06938028371369     -1.06604781193988 
           0.00031250            0.00015625            0.00015625 
    -1.06587003530766        -1.06412097939     -1.05534288054392 
           0.00015625            0.00046875            0.00015625 
    -1.04945721011816     -1.04845626690162     -1.04766888572427 
           0.00015625            0.00015625            0.00015625 
    -1.04755297964098     -1.04598728075964     -1.04536609890991 
           0.00031250            0.00031250            0.00031250 
    -1.02993885350447     -1.02151758080685     -1.01733580186582 
           0.00015625            0.00203125            0.02453125 
    -1.01577847702439      -1.0138904262493      -1.0121571897662 
           0.00015625            0.00015625            0.00062500 
    -1.00929178081963     -1.00745946934895     -1.00714202059705 
           0.00015625            0.00015625            0.00015625 
    -1.00664275166081     -1.00407661804032     -1.00110637205939 
           0.00046875            0.00015625            0.00015625 
   -0.997768048748026    -0.991929422812267    -0.989060788495757 
           0.00328125            0.00015625            0.00031250 
    -0.98572380365604    -0.979554261682366    -0.976324799963229 
           0.00015625            0.00031250            0.00875000 
   -0.973173077974651    -0.971118460177678     -0.96975725707502 
           0.01640625            0.00015625            0.00015625 
   -0.963461694934854    -0.961159884505833    -0.960193400142389 
           0.00015625            0.00015625            0.00046875 
   -0.958010282948452    -0.957720936633644    -0.955230663538487 
           0.00015625            0.00015625            0.00015625 
   -0.953451859649493    -0.952397629449069    -0.951677411170411 
           0.00031250            0.00015625            0.01765625 
   -0.947281520180146    -0.946066444247069    -0.942123167843126 
           0.00015625            0.00015625            0.00015625 
   -0.941185041055857    -0.939666457415937    -0.937914389255748 
           0.00015625            0.00031250            0.00015625 
   -0.937428692031181    -0.937143144639067    -0.929006249994557 
           0.00015625            0.00203125            0.00031250 
   -0.928956547037233    -0.927234345076844    -0.926325405165677 
           0.00015625            0.00015625            0.00015625 
   -0.926208874394783     -0.92432711582923    -0.923751900565718 
           0.00015625            0.00015625            0.00015625 
   -0.921447647976772    -0.920026610901552    -0.919775930100724 
           0.00015625            0.00015625            0.00031250 
   -0.919418999070816    -0.918979533540974    -0.918834367344145 
           0.00093750            0.00015625            0.00015625 
   -0.918602057207572    -0.918233359080158    -0.916620305783416 
           0.00015625            0.00015625            0.00031250 
   -0.908229610518583    -0.907879271266391    -0.907626204980156 
           0.00031250            0.00015625            0.00015625 
   -0.906631706666217    -0.905610577820333    -0.905104725277818 
           0.00015625            0.00015625            0.00015625 
   -0.904170844231002    -0.902563699445797    -0.902495470961171 
           0.00031250            0.00015625            0.00046875 
   -0.902207570970879    -0.900277820755885    -0.900269127160796 
           0.00015625            0.00609375            0.00015625 
   -0.900105713501894    -0.897103060359799    -0.896252308815885 
           0.00015625            0.00015625            0.00015625 
   -0.895759768448355    -0.895685333371447    -0.891948830933419 
           0.00015625            0.00015625            0.00015625 
   -0.891482707849845     -0.89086838304768    -0.889814536282523 
           0.00015625            0.02343750            0.00015625 
   -0.886894039811436    -0.885423108336021    -0.885386138492139 
           0.00093750            0.00015625            0.01593750 
   -0.884574764423174    -0.881181388644532    -0.881133728915611 
           0.00015625            0.00015625            0.00015625 
   -0.879323305434347    -0.878872666379052    -0.877901133624378 
           0.00015625            0.00015625            0.00015625 
   -0.876749332956921    -0.876685019263073    -0.875765771148607 
           0.00031250            0.00015625            0.00031250 
   -0.875473779114446     -0.87537693015952    -0.872246314823305 
           0.00015625            0.00015625            0.00015625 
   -0.871001261435858    -0.870353841103083    -0.869162583211394 
           0.00015625            0.00015625            0.00015625 
   -0.866780745576637    -0.866244907634358    -0.858819232798091 
           0.00015625            0.00015625            0.00015625 
   -0.856265820894777    -0.844253476212177    -0.844066341550782 
           0.00078125            0.00015625            0.00015625 
   -0.842025743633279    -0.831738843759029    -0.830837909586882 
           0.02921875            0.00015625            0.02515625 
   -0.829374923233683    -0.828920190368225    -0.827915178181078 
           0.00015625            0.00093750            0.00015625 
   -0.827728686266157    -0.826039032973297    -0.822416105203804 
           0.00015625            0.00015625            0.00015625 
   -0.821797313281808    -0.819285769008092    -0.816336564086851 
           0.00015625            0.00015625            0.00015625 
   -0.814051297945908    -0.811605617460827    -0.809148421270981 
           0.00015625            0.00015625            0.00015625 
   -0.804302031270971    -0.800154571238789    -0.795175551540305 
           0.00062500            0.00015625            0.00171875 
   -0.792845872277945    -0.790185643279993    -0.789212464897955 
           0.02015625            0.00859375            0.00046875 
   -0.787996109659257    -0.785742695872334    -0.783287556756109 
           0.00015625            0.00015625            0.00015625 
    -0.78222517242437    -0.777611190965241    -0.777259256743858 
           0.00015625            0.00015625            0.00015625 
   -0.775052088417874    -0.768725111385422      -0.7653899578722 
           0.00031250            0.00015625            0.00015625 
   -0.764328853007072    -0.759372004638613    -0.759121665238872 
           0.00015625            0.00015625            0.00015625 
   -0.758171518227594    -0.752387355098689    -0.752338241647165 
           0.00015625            0.00015625            0.00031250 
   -0.751716727129916    -0.750007134146443    -0.748171465050933 
           0.00015625            0.00562500            0.00015625 
   -0.743693425437366     -0.74226506946404    -0.738477819728135 
           0.00718750            0.00015625            0.00015625 
   -0.735940818773818    -0.734501921638923    -0.723911474638978 
           0.00015625            0.00015625            0.00015625 
   -0.720697236097384    -0.718445199078953    -0.715142805531928 
           0.00031250            0.00015625            0.00031250 
   -0.713461500253351    -0.710452171936934    -0.708684788599593 
           0.00015625            0.00015625            0.00015625 
   -0.708003561812545    -0.702080356630785     -0.70037445202336 
           0.00015625            0.00015625            0.00203125 
    -0.69602539257426     -0.69280361708918    -0.687853983052082 
           0.00015625            0.03375000            0.00015625 
    -0.68694861300278    -0.684622918007104    -0.682222958529648 
           0.00015625            0.00015625            0.00015625 
   -0.681188975020078    -0.673798181086569     -0.66884926915034 
           0.00187500            0.00015625            0.00015625 
     -0.6653122497357    -0.654779601264497    -0.648410662399554 
           0.00015625            0.00015625            0.00078125 
   -0.647068571912601    -0.646559789740211    -0.633905116384853 
           0.00015625            0.00015625            0.00015625 
   -0.633276439235621    -0.626480919280269    -0.624813955253419 
           0.00015625            0.00015625            0.00015625 
   -0.621563193776932    -0.615573756562581    -0.613123253862724 
           0.00015625            0.00015625            0.00171875 
   -0.604038319371604    -0.596446872775748    -0.596237216599971 
           0.00015625            0.00046875            0.00015625 
   -0.596137826610777    -0.592583054332584    -0.590968847296576 
           0.00015625            0.00359375            0.00015625 
   -0.581016668721787     -0.57842864719944    -0.577046832499099 
           0.00015625            0.00015625            0.00015625 
   -0.576399963736262    -0.567294133064953    -0.562646449882806 
           0.00187500            0.00015625            0.00031250 
   -0.559949234902497    -0.553868745195444    -0.551562209118441 
           0.00031250            0.00015625            0.00859375 
   -0.548486073402725    -0.545057532705371    -0.544483083151942 
           0.00015625            0.00046875            0.00093750 
   -0.543553164656681    -0.542887786706365    -0.542791834600063 
           0.00015625            0.00015625            0.03859375 
   -0.535816263171991    -0.529620965141671    -0.523583345339874 
           0.00031250            0.00015625            0.00015625 
   -0.522876883678594    -0.515144874010522    -0.511242837482551 
           0.00015625            0.00015625            0.00015625 
   -0.511062050911504    -0.509452501139644    -0.507981951223969 
           0.00500000            0.00015625            0.00015625 
   -0.506004946851197    -0.504251327555701    -0.503668338010739 
           0.00015625            0.00203125            0.00015625 
   -0.497665904683127    -0.492519293528136    -0.488304476973275 
           0.00015625            0.00062500            0.00015625 
   -0.486275884354524    -0.480531685495119    -0.479070530598709 
           0.00015625            0.00015625            0.00015625 
   -0.476991811548017    -0.475764665500524    -0.473473045518126 
           0.00078125            0.00015625            0.00015625 
   -0.472612890303562    -0.464757185992567    -0.456186401194196 
           0.00015625            0.00015625            0.00015625 
   -0.454553689487183    -0.453074332488957    -0.452195518537862 
           0.00015625            0.00015625            0.00015625 
   -0.450040882361118    -0.446015592229304    -0.443168278929009 
           0.00015625            0.00015625            0.00015625 
    -0.44055550390433    -0.439275967288811    -0.439064986884659 
           0.00093750            0.00015625            0.00031250 
   -0.436572045333686    -0.433356062339654     -0.43210269137514 
           0.00015625            0.00015625            0.00031250 
   -0.429159183376661     -0.42811270638386    -0.424489571114943 
           0.00015625            0.00015625            0.00015625 
   -0.424136094192972    -0.422368710855631    -0.422286506964679 
           0.00015625            0.00015625            0.00015625 
     -0.4217879739841     -0.42160028367728    -0.408926090390664 
           0.00015625            0.00015625            0.00062500 
   -0.406238662084726    -0.405337563546837    -0.402845924603104 
           0.00015625            0.00015625            0.00015625 
   -0.398392401687235    -0.392753100892855    -0.392721940787981 
           0.00015625            0.00015625            0.00015625 
   -0.389990557124863    -0.383778543291898    -0.381829344162238 
           0.00203125            0.00031250            0.00031250 
   -0.378610740922975    -0.377352421209284     -0.37278098800314 
           0.00015625            0.00015625            0.00015625 
   -0.368704530397105    -0.364033384865912    -0.363121805899083 
           0.00015625            0.00015625            0.00015625 
   -0.361905601371654    -0.360992312891898     -0.36077985218898 
           0.00015625            0.00015625            0.00015625 
    -0.35995405519458    -0.354602189779798    -0.354221703071568 
           0.00046875            0.00015625            0.00015625 
   -0.354125613590753     -0.35383985286255    -0.350820163721666 
           0.00015625            0.00015625            0.00015625 
   -0.347880750045415    -0.347682518083072    -0.344794514479224 
           0.00031250            0.00015625            0.00015625 
   -0.344246401931106    -0.340586009596143    -0.338241270869783 
           0.00015625            0.00015625            0.00031250 
   -0.336627924656718    -0.333999550987416    -0.331679860754818 
           0.00015625            0.00015625            0.00015625 
   -0.327473828580897    -0.325591270635287    -0.320604647133837 
           0.00015625            0.00015625            0.00015625 
   -0.320293393650012    -0.318998347766866    -0.313800886365509 
           0.00015625            0.00015625            0.00015625 
   -0.308729731711204     -0.30775968479621    -0.307488803472333 
           0.00015625            0.00062500            0.00015625 
   -0.305912488397539    -0.300040013990283    -0.299281804870489 
           0.00015625            0.00015625            0.00015625 
   -0.297576089117692    -0.294612153988498    -0.290886990303406 
           0.00015625            0.00015625            0.00015625 
   -0.289476667647491    -0.287805419014019    -0.284664135032912 
           0.00015625            0.00031250            0.00062500 
   -0.283279035792871    -0.278947445070673    -0.278430676385642 
           0.00015625            0.00015625            0.01140625 
   -0.277028655971768    -0.274352800845479    -0.269810489634915 
           0.00015625            0.00015625            0.00875000 
   -0.268327804913194    -0.264273008183568    -0.263991250766728 
           0.00015625            0.00015625            0.00015625 
   -0.263633329101249    -0.256569345435893    -0.255210887064625 
           0.00015625            0.00015625            0.00015625 
   -0.254264930167697    -0.253205544043426    -0.250717006205447 
           0.00015625            0.00015625            0.00015625 
   -0.250531752899298    -0.249985351299549    -0.247578088366761 
           0.00015625            0.00015625            0.00015625 
   -0.244437996150226    -0.243268618233703    -0.242824942853484 
           0.00015625            0.00015625            0.00015625 
   -0.233740722783471    -0.232700345409106    -0.232349973253986 
           0.00015625            0.00015625            0.00015625 
   -0.231815214890401    -0.231309362347886     -0.23037548130107 
           0.00015625            0.00015625            0.00015625 
   -0.228412208040947    -0.226589859802479    -0.224837647995068 
           0.00015625            0.01656250            0.00015625 
   -0.223464759128966     -0.22331717855311    -0.222588752387258 
           0.00015625            0.00015625            0.00015625 
   -0.222456945885953    -0.220222816737245    -0.217487288707678 
           0.00015625            0.00031250            0.00046875 
   -0.216388232760497    -0.213098676881504    -0.212807560710942 
           0.00015625            0.00093750            0.00015625 
   -0.205527942504415    -0.202889656333141    -0.199061273711729 
           0.00015625            0.00015625            0.00015625 
   -0.197285663071406    -0.196655198635886    -0.187398059917142 
           0.00015625            0.00015625            0.00328125 
    -0.18553936273967    -0.184426534107832      -0.1807365557853 
           0.00015625            0.00015625            0.00031250 
   -0.173455385110242    -0.170696066339926    -0.167983070845547 
           0.00953125            0.00062500            0.00015625 
    -0.16706735776498     -0.16549287956689    -0.163323851054559 
           0.00015625            0.00015625            0.00015625 
   -0.163005226779217    -0.155721964916119     -0.15557956030375 
           0.00015625            0.00015625            0.00015625 
   -0.145050220201077    -0.140627037006184    -0.136663205761249 
           0.00015625            0.00015625            0.00015625 
   -0.135547666352963    -0.135353058341049    -0.135168941442998 
           0.00015625            0.00015625            0.00015625 
    -0.13422823788067    -0.128983100398563    -0.128772766161494 
           0.00015625            0.00015625            0.00062500 
   -0.128276147190878    -0.124732071896041    -0.122750748897942 
           0.00015625            0.00015625            0.00015625 
   -0.121913567685457    -0.114572129500928    -0.113273027561381 
           0.00015625            0.00015625            0.00015625 
   -0.107405286684043    -0.105529863556612    -0.103356043915892 
           0.00015625            0.00953125            0.00015625 
  -0.0959919473132286   -0.0946576344451732   -0.0921610479659292 
           0.00015625            0.00031250            0.00015625 
  -0.0897276946329045    -0.082082912166815   -0.0820786945748793 
           0.00015625            0.00015625            0.00031250 
  -0.0807439358161152   -0.0768089765376881   -0.0759616047321375 
           0.00015625            0.00140625            0.00015625 
  -0.0741942213947964   -0.0733788467156504   -0.0726315828860554 
           0.00015625            0.00718750            0.00015625 
  -0.0685974846038955   -0.0532150311664168   -0.0498043335027671 
           0.00093750            0.00015625            0.00015625 
  -0.0497543467601004   -0.0473016251818649   -0.0451490777305966 
           0.00015625            0.00015625            0.00031250 
  -0.0446498361490209   -0.0392160026639466   -0.0373582346840002 
           0.00015625            0.00015625            0.00015625 
  -0.0352851923820555   -0.0345646240252186   -0.0326438116903773 
           0.00031250            0.00031250            0.00015625 
  -0.0248451869138821   -0.0188880173129063    -0.013807090586871 
           0.00109375            0.00015625            0.00015625 
  -0.0119657325121257   -0.0114810502208166  -0.00721676013122688 
           0.00015625            0.00015625            0.00015625 
 -0.00368424503602545 -0.000580656453063986   0.00425466589044258 
           0.00015625            0.00015625            0.00015625 
  0.00624696207963468   0.00661720265702806    0.0104887638020741 
           0.00015625            0.00015625            0.00015625 
   0.0151944372905789    0.0177528116242494    0.0194770878491831 
           0.00421875            0.00015625            0.00015625 
   0.0217087977522383    0.0235168212825711    0.0255537765734798 
           0.00015625            0.00015625            0.00015625 
   0.0264730080152699    0.0271186027099238    0.0361351573082595 
           0.00015625            0.00031250            0.00015625 
   0.0362911121323546    0.0368634437985054    0.0454309894047899 
           0.00015625            0.00015625            0.00015625 
   0.0533298995579193    0.0570581595639766    0.0585759323236618 
           0.00015625            0.00937500            0.00015625 
   0.0675339577108118    0.0702113818864803    0.0729377618887858 
           0.00046875            0.00015625            0.00062500 
   0.0788793134968683    0.0789059252411879    0.0790823923337298 
           0.00015625            0.02343750            0.00046875 
   0.0797510873183287    0.0806069942083428    0.0841639835120876 
           0.00015625            0.00015625            0.00015625 
   0.0899621750174284    0.0966606496804153    0.0972018193465008 
           0.00015625            0.00015625            0.00015625 
    0.101566818289489     0.108411810410797     0.109012079979066 
           0.00062500            0.00015625            0.00046875 
     0.11244290268093     0.119444894039026     0.131046181957536 
           0.00015625            0.00015625            0.00203125 
    0.134889340170799     0.135028927523559     0.136658265622521 
           0.00015625            0.00015625            0.00015625 
    0.144157938789208     0.146258849789861     0.147318188850963 
           0.00015625            0.00015625            0.02984375 
    0.151115033119933     0.152349655315244     0.154426066228552 
           0.00015625            0.00015625            0.00015625 
     0.15737266071083     0.162873929857665     0.162973153669365 
           0.00015625            0.00015625            0.00015625 
    0.164891939398059     0.165580765616732     0.173693095305534 
           0.00015625            0.00015625            0.00015625 
    0.183009971581342     0.186789363756051     0.187969991368742 
           0.00093750            0.00015625            0.00015625 
    0.192709893790261     0.194724832331223     0.194735738184732 
           0.00015625            0.00015625            0.00015625 
    0.195991364801127     0.206802781312992     0.210386154876613 
           0.00015625            0.00015625            0.00500000 
    0.217235034249908       0.2177869344983     0.234906769563277 
           0.00031250            0.00203125            0.00015625 
    0.234973761205148     0.238837237065174     0.241127733319099 
           0.00031250            0.00015625            0.00015625 
    0.250135635132824      0.25028785413495     0.253309352340188 
           0.00015625            0.00015625            0.00078125 
    0.254814769298151     0.260835355687548     0.264960519475955 
           0.00015625            0.00015625            0.00015625 
    0.266044692238248      0.27127954776092     0.273304013334367 
           0.00015625            0.00015625            0.00015625 
    0.273531307307048     0.274822103147971     0.280770740587068 
           0.00015625            0.00015625            0.00015625 
    0.284591080073122     0.285810915205503     0.286937550828954 
           0.00015625            0.00015625            0.00046875 
    0.289640625615739     0.301307082566931     0.302882181759369 
           0.00015625            0.00015625            0.00015625 
    0.304256560508303     0.309710068792923     0.311251030414092 
           0.00015625            0.00015625            0.00015625 
    0.311802268812853     0.318128929047187     0.318922298138204 
           0.00015625            0.00031250            0.00015625 
    0.320852365313198     0.322875645177539     0.334350357273903 
           0.00015625            0.00015625            0.00015625 
    0.337167536402539     0.338400625416362     0.338901340452759 
           0.00015625            0.00031250            0.00140625 
    0.346939027258188     0.348766831423466     0.358991725758732 
           0.00015625            0.00015625            0.00015625 
    0.364034892089946     0.365884194608935     0.368674799710984 
           0.00015625            0.00015625            0.00015625 
    0.369643258716518     0.373829702918903     0.379821273586168 
           0.00015625            0.00062500            0.00015625 
    0.382087226815338      0.38685609839469       0.3878539441829 
           0.00015625            0.00015625            0.00015625 
     0.38923354153609     0.390865130076565     0.393785793790202 
           0.00015625            0.00093750            0.00015625 
    0.402956322412276     0.404247945632944      0.40569298299336 
           0.00015625            0.00015625            0.00015625 
    0.406064629649282      0.40786256349758     0.408056423319527 
           0.00015625            0.00109375            0.00015625 
    0.412247177017014     0.414419483912049     0.416346031539166 
           0.00015625            0.00046875            0.00015625 
     0.41794166276908     0.419463447191946     0.420106603846799 
           0.00015625            0.01078125            0.00015625 
    0.420379431706021     0.420869449539072     0.431214346889845 
           0.00406250            0.00015625            0.00015625 
    0.433937840525743     0.440278644951702     0.441895424076257 
           0.00031250            0.00015625            0.00015625 
    0.442828919700371     0.443274873059508     0.446173888246631 
           0.00046875            0.00984375            0.00015625 
    0.450718587802467     0.456900610463576     0.459555681956315 
           0.00015625            0.00031250            0.00015625 
    0.460696686048428     0.467876105484108     0.472728746197005 
           0.00015625            0.00015625            0.00015625 
    0.474472217743954     0.474601080341499     0.474734089218203 
           0.00015625            0.00031250            0.00015625 
    0.477973490467994     0.484307789443022     0.484652344952628 
           0.00015625            0.00015625            0.00015625 
    0.494792709324177     0.498497691565453     0.500784787450151 
           0.00109375            0.00515625            0.00015625 
    0.504691880000581     0.508425703980646      0.50861676779181 
           0.00031250            0.00015625            0.00015625 
     0.50996114523361     0.514344382856681     0.516995457862692 
           0.00015625            0.00015625            0.00015625 
    0.518586102739047     0.521829770584971     0.523840570430114 
           0.00015625            0.00015625            0.00015625 
    0.524285913333902     0.525227742436545     0.527917885589494 
           0.00015625            0.00015625            0.00015625 
    0.531983533422768     0.539966728864973     0.541903897062432 
           0.00015625            0.00015625            0.00046875 
    0.543994005812287     0.545724786000498     0.546756498947983 
           0.00125000            0.00015625            0.00203125 
    0.548923619243861     0.549353970396232       0.5588553176537 
           0.00015625            0.00015625            0.00031250 
    0.564138483610525     0.566992546543754     0.569133261860447 
           0.00015625            0.00015625            0.00015625 
    0.574903744908869     0.577978215152712     0.578343495716271 
           0.00031250            0.00109375            0.00015625 
    0.580241024741447     0.581634314964003     0.583204933976379 
           0.00015625            0.00015625            0.00015625 
     0.58873859479558     0.595455758634415     0.597057916427158 
           0.00015625            0.00031250            0.00015625 
    0.598720288571789     0.599162991111384     0.599578938399305 
           0.00031250            0.00015625            0.00015625 
     0.60342049593258     0.604292419065582     0.607847397763963 
           0.00015625            0.00015625            0.00015625 
    0.611956869618315     0.612059726969641     0.612784292101807 
           0.00015625            0.00062500            0.00015625 
    0.613557486760981     0.620580331763515     0.622971928913742 
           0.00015625            0.00015625            0.00375000 
     0.63588348041021     0.641390081029809     0.643182929950686 
           0.00015625            0.00015625            0.00015625 
    0.648293425210027     0.650684078195595     0.657754904789885 
           0.00015625            0.00046875            0.00015625 
    0.664732625480728     0.665678528246394     0.665791697835918 
           0.00015625            0.00984375            0.00015625 
    0.666578602798705     0.678050028820375     0.678379635730825 
           0.00015625            0.00015625            0.00015625 
    0.679808655934455     0.680412565586961     0.680711498268701 
           0.00328125            0.00015625            0.00015625 
    0.684080216155581     0.684149053017272     0.685295140133807 
           0.00281250            0.00015625            0.00031250 
    0.686201169423553     0.690582799388141     0.692180702201577 
           0.00015625            0.00421875            0.00015625 
    0.696595449900374     0.697435597111395     0.698914306548046 
           0.00015625            0.00015625            0.00015625 
     0.70193206265865     0.702647867819401     0.707754986014002 
           0.00015625            0.00062500            0.00015625 
    0.711210346763156     0.712920206015224     0.713369947147153 
           0.00015625            0.00015625            0.00015625 
    0.715327471836729     0.722275487513834     0.722728216151602 
           0.00031250            0.00156250            0.00015625 
      0.7239248415172      0.72708089915877     0.729737150343281 
           0.00015625            0.00015625            0.00015625 
    0.735388003016973     0.740385327518889     0.741422651587756 
           0.00031250            0.00015625            0.00015625 
    0.741444754160499     0.747108762937508     0.748191169284348 
           0.00015625            0.00031250            0.00015625 
    0.751436430272142     0.752533256420978     0.752674676426801 
           0.00015625            0.00015625            0.00015625 
    0.754611657443207     0.754889027400603     0.756349639135923 
           0.00125000            0.00015625            0.00015625 
    0.763526062479594     0.768717423291569     0.770997182276433 
           0.00015625            0.00015625            0.00015625 
     0.77805655959217     0.780455501601279      0.79111659134251 
           0.00015625            0.00015625            0.00015625 
    0.794424123694395     0.794542595446869     0.797594367513394 
           0.00046875            0.00015625            0.00015625 
    0.806459604893308     0.806575447067013     0.815325824113437 
           0.00015625            0.00171875            0.00031250 
    0.820054212719794     0.821566079066492     0.822735985643791 
           0.00015625            0.00015625            0.00015625 
    0.824910396049865     0.825564426121463     0.827093295015157 
           0.00015625            0.00281250            0.00015625 
    0.830498441784675     0.839706577696515     0.854374875678462 
           0.00031250            0.00015625            0.00015625 
    0.857045424718981     0.857046899457354     0.858539236690819 
           0.00031250            0.00015625            0.00109375 
    0.861958482401254     0.864973903806387     0.868060666977836 
           0.00015625            0.00031250            0.00015625 
    0.871547517399078     0.877907606552374     0.878620392468042 
           0.00015625            0.00031250            0.00015625 
    0.882079910398028     0.886773165429333     0.895872264013794 
           0.00015625            0.00015625            0.00031250 
    0.902874892971196     0.909893594892982     0.910503026314625 
           0.00015625            0.00015625            0.00015625 
    0.918355472177732     0.923930998062757     0.928610132228083 
           0.00156250            0.00015625            0.00015625 
    0.930580294371997     0.932353440099381     0.933043163131344 
           0.00015625            0.00015625            0.00015625 
    0.935865275090846     0.938721396055517      0.94732667023698 
           0.00015625            0.00015625            0.00015625 
    0.952388332756409     0.953472399517577     0.960457391255192 
           0.00046875            0.00015625            0.00015625 
    0.962466815938431     0.974608403263273     0.977273131185975 
           0.00031250            0.00015625            0.00015625 
    0.979887858238853     0.981765099822977     0.982533764258785 
           0.02546875            0.00015625            0.00015625 
    0.986421193335086     0.991131333762411      0.99464772824313 
           0.00046875            0.00015625            0.00015625 
     1.00529335053186      1.01443060556224       1.0145402019372 
           0.00015625            0.00062500            0.00015625 
     1.02257036343242      1.02480443153783      1.02810330735672 
           0.00015625            0.00015625            0.00015625 
     1.02815692332918       1.0286099206142      1.03278708868866 
           0.00265625            0.00015625            0.00015625 
     1.03867605371823      1.04030809775545      1.05026762861212 
           0.00015625            0.00046875            0.00015625 
     1.05448691449244       1.0552263521649      1.05588258974527 
           0.00125000            0.00015625            0.00015625 
     1.06000513122926      1.06639439518604      1.07107601485988 
           0.00906250            0.00078125            0.00015625 
     1.07323792501438      1.07985999257921      1.08185178624946 
           0.00015625            0.00015625            0.00015625 
     1.08200577310599      1.08501442587133      1.08924264046828 
           0.00015625            0.00015625            0.00015625 
     1.09237983879524      1.09858922192811      1.09934822043348 
           0.00015625            0.00015625            0.00015625 
      1.1078948637414      1.11407400788163      1.11835818480985 
           0.00015625            0.00015625            0.00093750 
     1.11909298650692      1.12255263564979      1.13098492845703 
           0.00125000            0.00640625            0.00718750 
     1.13520899613199      1.13659865262031      1.14324263811607 
           0.00015625            0.00031250            0.00015625 
      1.1444495252129       1.1551673045972      1.15841602768456 
           0.00578125            0.00046875            0.00015625 
     1.17032197443365      1.17077944389967      1.17660425916148 
           0.00156250            0.01546875            0.00015625 
     1.17671971786951      1.18390085758965      1.19061835680715 
           0.00031250            0.02078125            0.00078125 
     1.19124162268748      1.19491419845781      1.20187158527135 
           0.00046875            0.01000000            0.00015625 
     1.20935820034015      1.21534749252995      1.21684078311872 
           0.00015625            0.00015625            0.00015625 
     1.22228576405746      1.22358524293339       1.2307494205369 
           0.00046875            0.00375000            0.00359375 
     1.23190824585799      1.23309624815214       1.2482497077686 
           0.00015625            0.00015625            0.00015625 
     1.24914605564843      1.25030062698194      1.25167385090479 
           0.00015625            0.00015625            0.00015625 
      1.2521388586462      1.25403638767138      1.25696184836792 
           0.00015625            0.00015625            0.00015625 
     1.25865710330342      1.26219503016375      1.26339025886804 
           0.00015625            0.00015625            0.00062500 
     1.27424955368127      1.27429889692881      1.27581391381442 
           0.00062500            0.01093750            0.00015625 
     1.28103448636196      1.28422435170195      1.28502302740832 
           0.00015625            0.00015625            0.00015625 
     1.28694332261892      1.28862136579613      1.29135133286724 
           0.00015625            0.00015625            0.00015625 
     1.29271693854318      1.29352984392642      1.29416501801516 
           0.00093750            0.00015625            0.00015625 
     1.32000923372796      1.32621334330507      1.32674979912185 
           0.00015625            0.00031250            0.00031250 
      1.3355388950486      1.33819762355126      1.34572143844383 
           0.00703125            0.00015625            0.00015625 
     1.34900429115538      1.35106912963136      1.35909050306374 
           0.00015625            0.00015625            0.00015625 
     1.36740896432616      1.37732504122682      1.37817713292888 
           0.00015625            0.00015625            0.00171875 
     1.38155034894393      1.38244688032714      1.38971756538262 
           0.00015625            0.00015625            0.00015625 
     1.39337346848199      1.39481552027921      1.39920925968592 
           0.00015625            0.00015625            0.00015625 
     1.40401019415033      1.40768753122916      1.42034462702771 
           0.00015625            0.00046875            0.00031250 
     1.42884838085788      1.43014092255268      1.43175470937195 
           0.00062500            0.00078125            0.00015625 
     1.43334191774463      1.43396654425843      1.43750664054499 
           0.00046875            0.00015625            0.00015625 
     1.43754219334743       1.4388998201083      1.44153927902681 
           0.00015625            0.01625000            0.01421875 
     1.44769121849116      1.44889234688456      1.45317034273597 
           0.00015625            0.00015625            0.00015625 
     1.45756717172523      1.46514717542552      1.48152004641465 
           0.00015625            0.01359375            0.00015625 
     1.48210471217649       1.4854271336131      1.49691410201524 
           0.00187500            0.00015625            0.00031250 
     1.50460499505036          1.5159104855      1.51944062018193 
           0.00015625            0.00062500            0.00015625 
     1.51951797036384      1.52322014302823      1.52914361888698 
           0.00015625            0.00015625            0.00015625 
     1.53094696259391      1.53185854523801      1.54534195968881 
           0.00015625            0.00015625            0.00015625 
     1.55198480359028      1.55950143190504      1.56497982317259 
           0.00031250            0.00015625            0.00015625 
     1.58262031982126      1.59616721426295      1.60437565730193 
           0.00062500            0.00015625            0.00015625 
     1.61266940307664      1.61805143272205      1.63593441495235 
           0.00015625            0.00015625            0.00390625 
     1.66020775786113      1.67542635415394      1.67673538939901 
           0.00046875            0.00015625            0.00437500 
     1.68035708519021      1.68346836697786      1.68837599513398 
           0.00015625            0.00015625            0.00015625 
     1.68938234802037      1.70189867028665      1.70300688645049 
           0.00015625            0.00015625            0.00015625 
     1.70487078400102      1.71353493899627      1.72834558905075 
           0.00015625            0.00015625            0.00015625 
     1.72915591888238      1.73426417234817      1.74021109248258 
           0.00015625            0.00015625            0.00015625 
     1.74232222740301      1.74349939634561       1.7580041756475 
           0.00015625            0.00015625            0.00015625 
     1.76113921780106      1.76617520172517      1.77211632108358 
           0.00015625            0.00015625            0.00015625 
     1.77514993495452      1.79958280830507      1.81629669477704 
           0.00015625            0.00015625            0.00031250 
     1.81990457312901      1.83656963213994      1.83724270780201 
           0.00015625            0.01140625            0.00015625 
     1.84610801109783      1.87127556838068      1.87941151145041 
           0.00015625            0.00031250            0.00015625 
     1.88207392317223      1.89017691499225      1.91733288828094 
           0.00031250            0.00015625            0.00015625 
     1.94867279430132      1.95578696468731      1.95652907096428 
           0.00687500            0.00015625            0.00015625 
     1.96029188648611      1.97337415011671      1.97682872944693 
           0.00015625            0.00015625            0.00015625 
     1.97898223695928      2.01790204562771      2.04143987127407 
           0.00015625            0.00015625            0.00171875 
     2.04788306887298      2.07547273185274      2.09309957494449 
           0.00062500            0.00031250            0.00015625 
     2.09950420993508      2.10052429104874      2.10697756530747 
           0.00031250            0.00015625            0.00015625 
     2.11999156344762      2.12917389303477      2.15933629269958 
           0.00015625            0.00015625            0.00015625 
     2.18306393167287      2.18323513022319      2.18704108088277 
           0.00187500            0.00015625            0.00015625 
     2.23887211958444      2.24380917557826      2.28051444339884 
           0.00015625            0.00015625            0.00562500 
     2.28417103037285      2.30954548348617      2.34561980157645 
           0.00015625            0.00125000            0.00015625 
     2.52385907644018      3.01185818638057      3.23514293488871 
           0.00015625            0.00015625            0.00031250 
     3.52347021972545      4.91171482734768      5.33930094132038 
           0.00015625            0.00015625            0.00015625 
     6.39137994453622      6.97999767626588 
           0.00015625            0.00015625 
> 
> prop.table(table(trainClass))
trainClass
  Strong     Weak 
0.746888 0.253112 
> 
> ncol(trainDescr)
[1] 20
> 
> ## Check Near-zero
> 
> nzv <- nearZeroVar(trainDescr, saveMetrics= TRUE)
> stopifnot( all(nzv$nzv == FALSE) )
> 
> # It's imputed and behaves well, no need for this.
> # descrCorr <- cor(scale(trainDescr), use = "pairwise.complete.obs")
> 
> descrCorr <- cor(scale(trainDescr))
> 
> highCorr <- findCorrelation(descrCorr, cutoff = .80, verbose = TRUE)
Considering row	 16 column	 17 value	 0.867 
  Flagging column	 16 
Considering row	 17 column	 10 value	 0.661 
Considering row	 17 column	 1 value	 0.267 
Considering row	 17 column	 11 value	 0.274 
Considering row	 17 column	 6 value	 0.212 
Considering row	 17 column	 12 value	 0.221 
Considering row	 17 column	 14 value	 0.22 
Considering row	 17 column	 8 value	 0.542 
Considering row	 17 column	 9 value	 0.573 
Considering row	 17 column	 2 value	 0.257 
Considering row	 17 column	 13 value	 0.192 
Considering row	 17 column	 19 value	 0.235 
Considering row	 17 column	 3 value	 0.272 
Considering row	 17 column	 18 value	 0.239 
Considering row	 17 column	 20 value	 0.131 
Considering row	 17 column	 15 value	 0.079 
Considering row	 17 column	 7 value	 0.103 
Considering row	 17 column	 5 value	 0.068 
Considering row	 17 column	 4 value	 0.073 
Considering row	 10 column	 1 value	 0.277 
Considering row	 10 column	 11 value	 0.284 
Considering row	 10 column	 6 value	 0.297 
Considering row	 10 column	 12 value	 0.259 
Considering row	 10 column	 14 value	 0.245 
Considering row	 10 column	 8 value	 0.412 
Considering row	 10 column	 9 value	 0.389 
Considering row	 10 column	 2 value	 0.277 
Considering row	 10 column	 13 value	 0.211 
Considering row	 10 column	 19 value	 0.183 
Considering row	 10 column	 3 value	 0.428 
Considering row	 10 column	 18 value	 0.176 
Considering row	 10 column	 20 value	 0.112 
Considering row	 10 column	 15 value	 0.332 
Considering row	 10 column	 7 value	 0.234 
Considering row	 10 column	 5 value	 0.082 
Considering row	 10 column	 4 value	 0.013 
Considering row	 1 column	 11 value	 0.987 
  Flagging column	 1 
Considering row	 11 column	 6 value	 0.944 
  Flagging column	 11 
Considering row	 6 column	 12 value	 0.876 
  Flagging column	 6 
Considering row	 12 column	 14 value	 0.125 
Considering row	 12 column	 8 value	 0.101 
Considering row	 12 column	 9 value	 0.122 
Considering row	 12 column	 2 value	 0.129 
Considering row	 12 column	 13 value	 0.099 
Considering row	 12 column	 19 value	 0.035 
Considering row	 12 column	 3 value	 0.076 
Considering row	 12 column	 18 value	 0.139 
Considering row	 12 column	 20 value	 0.092 
Considering row	 12 column	 15 value	 0.166 
Considering row	 12 column	 7 value	 0.114 
Considering row	 12 column	 5 value	 0.047 
Considering row	 12 column	 4 value	 0.023 
Considering row	 14 column	 8 value	 0.137 
Considering row	 14 column	 9 value	 0.146 
Considering row	 14 column	 2 value	 0.602 
Considering row	 14 column	 13 value	 0.712 
Considering row	 14 column	 19 value	 0.072 
Considering row	 14 column	 3 value	 0.137 
Considering row	 14 column	 18 value	 0.346 
Considering row	 14 column	 20 value	 0.154 
Considering row	 14 column	 15 value	 0.112 
Considering row	 14 column	 7 value	 0.179 
Considering row	 14 column	 5 value	 0.062 
Considering row	 14 column	 4 value	 0.237 
Considering row	 8 column	 9 value	 0.468 
Considering row	 8 column	 2 value	 0.197 
Considering row	 8 column	 13 value	 0.106 
Considering row	 8 column	 19 value	 0.289 
Considering row	 8 column	 3 value	 0.209 
Considering row	 8 column	 18 value	 0.147 
Considering row	 8 column	 20 value	 0.194 
Considering row	 8 column	 15 value	 0.073 
Considering row	 8 column	 7 value	 0.111 
Considering row	 8 column	 5 value	 0.025 
Considering row	 8 column	 4 value	 0.021 
Considering row	 9 column	 2 value	 0.383 
Considering row	 9 column	 13 value	 0.092 
Considering row	 9 column	 19 value	 0.247 
Considering row	 9 column	 3 value	 0.275 
Considering row	 9 column	 18 value	 0.046 
Considering row	 9 column	 20 value	 0.149 
Considering row	 9 column	 15 value	 0.078 
Considering row	 9 column	 7 value	 0.082 
Considering row	 9 column	 5 value	 0.09 
Considering row	 9 column	 4 value	 0.02 
Considering row	 2 column	 13 value	 0.586 
Considering row	 2 column	 19 value	 0.014 
Considering row	 2 column	 3 value	 0.289 
Considering row	 2 column	 18 value	 0.123 
Considering row	 2 column	 20 value	 0.11 
Considering row	 2 column	 15 value	 0.096 
Considering row	 2 column	 7 value	 0.009 
Considering row	 2 column	 5 value	 0.015 
Considering row	 2 column	 4 value	 0.221 
Considering row	 13 column	 19 value	 0.067 
Considering row	 13 column	 3 value	 0.201 
Considering row	 13 column	 18 value	 0.155 
Considering row	 13 column	 20 value	 0.132 
Considering row	 13 column	 15 value	 0.146 
Considering row	 13 column	 7 value	 0.121 
Considering row	 13 column	 5 value	 0.05 
Considering row	 13 column	 4 value	 0.23 
Considering row	 19 column	 3 value	 0.132 
Considering row	 19 column	 18 value	 0.12 
Considering row	 19 column	 20 value	 0.849 
  Flagging column	 19 
Considering row	 3 column	 18 value	 0.059 
Considering row	 3 column	 20 value	 0.03 
Considering row	 3 column	 15 value	 0.033 
Considering row	 3 column	 7 value	 0.151 
Considering row	 3 column	 5 value	 0.108 
Considering row	 3 column	 4 value	 0.107 
Considering row	 18 column	 20 value	 0.027 
Considering row	 18 column	 15 value	 0.12 
Considering row	 18 column	 7 value	 0.107 
Considering row	 18 column	 5 value	 0.001 
Considering row	 18 column	 4 value	 0.084 
Considering row	 20 column	 15 value	 0.037 
Considering row	 20 column	 7 value	 0.085 
Considering row	 20 column	 5 value	 0.129 
Considering row	 20 column	 4 value	 0.044 
Considering row	 15 column	 7 value	 0.016 
Considering row	 15 column	 5 value	 0.051 
Considering row	 15 column	 4 value	 0.022 
Considering row	 7 column	 5 value	 0.066 
Considering row	 7 column	 4 value	 0.041 
Considering row	 5 column	 4 value	 0.243 
> 
> # I've switched off the correlation remover and the results are better.
> if (sum(highCorr) > 0) {
+     warning("overfitting: correlations: ", paste(colnames(trainDescr)[highCorr], collapse = ", ") )
+     err.trainDescr <- trainDescr
+     trainDescr <- trainDescr[,-highCorr]
+ }
Warning message:
overfitting: correlations: DEPSPOKE, SDEPHR, DEPBUCKET, AVGSQ, xAVAILBUCKET 
> 
> descrCorr <- cor(trainDescr)
> summary(descrCorr[upper.tri(descrCorr)])
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
-0.57300 -0.12510 -0.01566  0.01494  0.12120  0.71240 
> 
> ## Dominant correlations
> ## At 0.9, there are some big ones that might need re-thinking.
> 
> table.descrCorr <- as.data.frame(as.table(descrCorr))
> table.descrCorr <- table.descrCorr[which(table.descrCorr$Var1 != table.descrCorr$Var2),]
> table.descrCorr[order(abs(table.descrCorr$Freq), decreasing = TRUE),]
              Var1           Var2          Freq
146     TRNRANKGRP     DEPRANKGRP  0.7123936016
160     DEPRANKGRP     TRNRANKGRP  0.7123936016
118       ARRSPOKE DOWNLINEATCIMP  0.6606389606
188 DOWNLINEATCIMP       ARRSPOKE  0.6606389606
11      TRNRANKGRP      SKDDEPSTA  0.6016994885
151      SKDDEPSTA     TRNRANKGRP  0.6016994885
10      DEPRANKGRP      SKDDEPSTA  0.5857295450
136      SKDDEPSTA     DEPRANKGRP  0.5857295450
103       ARRSPOKE   DEPSTAATCIMP -0.5729891892
187   DEPSTAATCIMP       ARRSPOKE -0.5729891892
88        ARRSPOKE   UPLINEATCIMP  0.5416679708
186   UPLINEATCIMP       ARRSPOKE  0.5416679708
82    DEPSTAATCIMP   UPLINEATCIMP -0.4683473008
96    UPLINEATCIMP   DEPSTAATCIMP -0.4683473008
23  DOWNLINEATCIMP      SKDARRSTA  0.4275176187
107      SKDARRSTA DOWNLINEATCIMP  0.4275176187
83  DOWNLINEATCIMP   UPLINEATCIMP  0.4124065350
111   UPLINEATCIMP DOWNLINEATCIMP  0.4124065350
98  DOWNLINEATCIMP   DEPSTAATCIMP -0.3886731631
112   DEPSTAATCIMP DOWNLINEATCIMP -0.3886731631
7     DEPSTAATCIMP      SKDDEPSTA  0.3832198201
91       SKDDEPSTA   DEPSTAATCIMP  0.3832198201
164         xDURN2     TRNRANKGRP  0.3462878006
206     TRNRANKGRP         xDURN2  0.3462878006
117     ARRRANKGRP DOWNLINEATCIMP -0.3321061029
173 DOWNLINEATCIMP     ARRRANKGRP -0.3321061029
2        SKDARRSTA      SKDDEPSTA -0.2893523493
16       SKDDEPSTA      SKDARRSTA -0.2893523493
8   DOWNLINEATCIMP      SKDDEPSTA -0.2770890658
106      SKDDEPSTA DOWNLINEATCIMP -0.2770890658
22    DEPSTAATCIMP      SKDARRSTA -0.2754764313
92       SKDARRSTA   DEPSTAATCIMP -0.2754764313
28        ARRSPOKE      SKDARRSTA  0.2719516846
182      SKDARRSTA       ARRSPOKE  0.2719516846
114      ARRBUCKET DOWNLINEATCIMP  0.2592870115
128 DOWNLINEATCIMP      ARRBUCKET  0.2592870115
13        ARRSPOKE      SKDDEPSTA -0.2565693570
181      SKDDEPSTA       ARRSPOKE -0.2565693570
116     TRNRANKGRP DOWNLINEATCIMP -0.2454705816
158 DOWNLINEATCIMP     TRNRANKGRP -0.2454705816
34          SKDEPS         SKDEQP  0.2429005770
48          SKDEQP         SKDEPS  0.2429005770
194         xDURN2       ARRSPOKE -0.2389499544
208       ARRSPOKE         xDURN2 -0.2389499544
41      TRNRANKGRP         SKDEQP  0.2365841507
153         SKDEQP     TRNRANKGRP  0.2365841507
68  DOWNLINEATCIMP      AVGLOFATC -0.2335839997
110      AVGLOFATC DOWNLINEATCIMP -0.2335839997
40      DEPRANKGRP         SKDEQP  0.2297970157
138         SKDEQP     DEPRANKGRP  0.2297970157
3           SKDEQP      SKDDEPSTA  0.2211561793
31       SKDDEPSTA         SKDEQP  0.2211561793
133       ARRSPOKE      ARRBUCKET  0.2210457979
189      ARRBUCKET       ARRSPOKE  0.2210457979
163       ARRSPOKE     TRNRANKGRP -0.2203007134
191     TRNRANKGRP       ARRSPOKE -0.2203007134
115     DEPRANKGRP DOWNLINEATCIMP -0.2105541478
143 DOWNLINEATCIMP     DEPRANKGRP -0.2105541478
21    UPLINEATCIMP      SKDARRSTA  0.2086590362
77       SKDARRSTA   UPLINEATCIMP  0.2086590362
25      DEPRANKGRP      SKDARRSTA -0.2012356887
137      SKDARRSTA     DEPRANKGRP -0.2012356887
6     UPLINEATCIMP      SKDDEPSTA -0.1974899930
76       SKDDEPSTA   UPLINEATCIMP -0.1974899930
90    xAVGSKDAVAIL   UPLINEATCIMP  0.1944125904
216   UPLINEATCIMP   xAVGSKDAVAIL  0.1944125904
148       ARRSPOKE     DEPRANKGRP -0.1918832166
190     DEPRANKGRP       ARRSPOKE -0.1918832166
71      TRNRANKGRP      AVGLOFATC  0.1785364320
155      AVGLOFATC     TRNRANKGRP  0.1785364320
119         xDURN2 DOWNLINEATCIMP -0.1757804944
203 DOWNLINEATCIMP         xDURN2 -0.1757804944
132     ARRRANKGRP      ARRBUCKET -0.1663215589
174      ARRBUCKET     ARRRANKGRP -0.1663215589
149         xDURN2     DEPRANKGRP  0.1546172935
205     DEPRANKGRP         xDURN2  0.1546172935
165   xAVGSKDAVAIL     TRNRANKGRP  0.1543973696
221     TRNRANKGRP   xAVGSKDAVAIL  0.1543973696
20       AVGLOFATC      SKDARRSTA -0.1513168864
62       SKDARRSTA      AVGLOFATC -0.1513168864
105   xAVGSKDAVAIL   DEPSTAATCIMP -0.1486910072
217   DEPSTAATCIMP   xAVGSKDAVAIL -0.1486910072
89          xDURN2   UPLINEATCIMP -0.1472964706
201   UPLINEATCIMP         xDURN2 -0.1472964706
101     TRNRANKGRP   DEPSTAATCIMP -0.1463023231
157   DEPSTAATCIMP     TRNRANKGRP -0.1463023231
147     ARRRANKGRP     DEPRANKGRP  0.1461231641
175     DEPRANKGRP     ARRRANKGRP  0.1461231641
134         xDURN2      ARRBUCKET -0.1387742725
204      ARRBUCKET         xDURN2 -0.1387742725
86      TRNRANKGRP   UPLINEATCIMP -0.1369384832
156   UPLINEATCIMP     TRNRANKGRP -0.1369384832
26      TRNRANKGRP      SKDARRSTA -0.1366878519
152      SKDARRSTA     TRNRANKGRP -0.1366878519
150   xAVGSKDAVAIL     DEPRANKGRP  0.1322388960
220     DEPRANKGRP   xAVGSKDAVAIL  0.1322388960
195   xAVGSKDAVAIL       ARRSPOKE  0.1312389745
223       ARRSPOKE   xAVGSKDAVAIL  0.1312389745
9        ARRBUCKET      SKDDEPSTA -0.1292069036
121      SKDDEPSTA      ARRBUCKET -0.1292069036
60    xAVGSKDAVAIL         SKDEPS  0.1290642104
214         SKDEPS   xAVGSKDAVAIL  0.1290642104
131     TRNRANKGRP      ARRBUCKET -0.1251244863
159      ARRBUCKET     TRNRANKGRP -0.1251244863
14          xDURN2      SKDDEPSTA  0.1225526684
196      SKDDEPSTA         xDURN2  0.1225526684
99       ARRBUCKET   DEPSTAATCIMP -0.1217839284
127   DEPSTAATCIMP      ARRBUCKET -0.1217839284
70      DEPRANKGRP      AVGLOFATC  0.1212460139
140      AVGLOFATC     DEPRANKGRP  0.1212460139
179         xDURN2     ARRRANKGRP  0.1197637732
207     ARRRANKGRP         xDURN2  0.1197637732
69       ARRBUCKET      AVGLOFATC -0.1142709272
125      AVGLOFATC      ARRBUCKET -0.1142709272
162     ARRRANKGRP     TRNRANKGRP  0.1124548664
176     TRNRANKGRP     ARRRANKGRP  0.1124548664
120   xAVGSKDAVAIL DOWNLINEATCIMP  0.1122021903
218 DOWNLINEATCIMP   xAVGSKDAVAIL  0.1122021903
66    UPLINEATCIMP      AVGLOFATC -0.1111026529
80       AVGLOFATC   UPLINEATCIMP -0.1111026529
15    xAVGSKDAVAIL      SKDDEPSTA  0.1103370848
211      SKDDEPSTA   xAVGSKDAVAIL  0.1103370848
19          SKDEPS      SKDARRSTA -0.1075315078
47       SKDARRSTA         SKDEPS -0.1075315078
74          xDURN2      AVGLOFATC -0.1071763905
200      AVGLOFATC         xDURN2 -0.1071763905
18          SKDEQP      SKDARRSTA  0.1069279831
32       SKDARRSTA         SKDEQP  0.1069279831
85      DEPRANKGRP   UPLINEATCIMP -0.1060427386
141   UPLINEATCIMP     DEPRANKGRP -0.1060427386
73        ARRSPOKE      AVGLOFATC -0.1031636516
185      AVGLOFATC       ARRSPOKE -0.1031636516
84       ARRBUCKET   UPLINEATCIMP  0.1005040141
126   UPLINEATCIMP      ARRBUCKET  0.1005040141
130     DEPRANKGRP      ARRBUCKET -0.0986950696
144      ARRBUCKET     DEPRANKGRP -0.0986950696
12      ARRRANKGRP      SKDDEPSTA  0.0957939692
166      SKDDEPSTA     ARRRANKGRP  0.0957939692
100     DEPRANKGRP   DEPSTAATCIMP  0.0917362584
142   DEPSTAATCIMP     DEPRANKGRP  0.0917362584
135   xAVGSKDAVAIL      ARRBUCKET -0.0916395464
219      ARRBUCKET   xAVGSKDAVAIL -0.0916395464
52    DEPSTAATCIMP         SKDEPS -0.0897016196
94          SKDEPS   DEPSTAATCIMP -0.0897016196
75    xAVGSKDAVAIL      AVGLOFATC -0.0851661321
215      AVGLOFATC   xAVGSKDAVAIL -0.0851661321
44          xDURN2         SKDEQP  0.0840845054
198         SKDEQP         xDURN2  0.0840845054
53  DOWNLINEATCIMP         SKDEPS -0.0824852879
109         SKDEPS DOWNLINEATCIMP -0.0824852879
67    DEPSTAATCIMP      AVGLOFATC -0.0820952353
95       AVGLOFATC   DEPSTAATCIMP -0.0820952353
178       ARRSPOKE     ARRRANKGRP -0.0786667163
192     ARRRANKGRP       ARRSPOKE -0.0786667163
102     ARRRANKGRP   DEPSTAATCIMP  0.0781721020
172   DEPSTAATCIMP     ARRRANKGRP  0.0781721020
24       ARRBUCKET      SKDARRSTA  0.0759279051
122      SKDARRSTA      ARRBUCKET  0.0759279051
43        ARRSPOKE         SKDEQP  0.0733208602
183         SKDEQP       ARRSPOKE  0.0733208602
87      ARRRANKGRP   UPLINEATCIMP -0.0726430815
171   UPLINEATCIMP     ARRRANKGRP -0.0726430815
58        ARRSPOKE         SKDEPS -0.0682301200
184         SKDEPS       ARRSPOKE -0.0682301200
50       AVGLOFATC         SKDEPS  0.0664222939
64          SKDEPS      AVGLOFATC  0.0664222939
56      TRNRANKGRP         SKDEPS  0.0618832558
154         SKDEPS     TRNRANKGRP  0.0618832558
29          xDURN2      SKDARRSTA  0.0591080250
197      SKDARRSTA         xDURN2  0.0591080250
57      ARRRANKGRP         SKDEPS  0.0512721484
169         SKDEPS     ARRRANKGRP  0.0512721484
55      DEPRANKGRP         SKDEPS  0.0500743992
139         SKDEPS     DEPRANKGRP  0.0500743992
54       ARRBUCKET         SKDEPS -0.0474518532
124         SKDEPS      ARRBUCKET -0.0474518532
104         xDURN2   DEPSTAATCIMP -0.0455009270
202   DEPSTAATCIMP         xDURN2 -0.0455009270
45    xAVGSKDAVAIL         SKDEQP  0.0443075653
213         SKDEQP   xAVGSKDAVAIL  0.0443075653
35       AVGLOFATC         SKDEQP  0.0409779020
63          SKDEQP      AVGLOFATC  0.0409779020
180   xAVGSKDAVAIL     ARRRANKGRP -0.0369486803
222     ARRRANKGRP   xAVGSKDAVAIL -0.0369486803
27      ARRRANKGRP      SKDARRSTA -0.0329029921
167      SKDARRSTA     ARRRANKGRP -0.0329029921
30    xAVGSKDAVAIL      SKDARRSTA  0.0295119094
212      SKDARRSTA   xAVGSKDAVAIL  0.0295119094
210   xAVGSKDAVAIL         xDURN2  0.0273117240
224         xDURN2   xAVGSKDAVAIL  0.0273117240
51    UPLINEATCIMP         SKDEPS -0.0247537375
79          SKDEPS   UPLINEATCIMP -0.0247537375
39       ARRBUCKET         SKDEQP -0.0227754634
123         SKDEQP      ARRBUCKET -0.0227754634
42      ARRRANKGRP         SKDEQP -0.0222304298
168         SKDEQP     ARRRANKGRP -0.0222304298
36    UPLINEATCIMP         SKDEQP -0.0213925713
78          SKDEQP   UPLINEATCIMP -0.0213925713
37    DEPSTAATCIMP         SKDEQP -0.0201791095
93          SKDEQP   DEPSTAATCIMP -0.0201791095
72      ARRRANKGRP      AVGLOFATC -0.0156582813
170      AVGLOFATC     ARRRANKGRP -0.0156582813
4           SKDEPS      SKDDEPSTA -0.0145908887
46       SKDDEPSTA         SKDEPS -0.0145908887
38  DOWNLINEATCIMP         SKDEQP -0.0131985370
108         SKDEQP DOWNLINEATCIMP -0.0131985370
5        AVGLOFATC      SKDDEPSTA -0.0093369555
61       SKDDEPSTA      AVGLOFATC -0.0093369555
59          xDURN2         SKDEPS -0.0009512376
199         SKDEPS         xDURN2 -0.0009512376
> 
> ### Models
> 
> ## Training controller
> 
> fitControl <- trainControl(## 10-fold CV
+     method = "repeatedcv",
+     number = 10,
+     ## repeated ten times
+     repeats = 10,
+     classProbs = 10,
+     summaryFunction = twoClassSummary)
> 
> ## Try many other parameters
> 
> colnames(trainDescr)
 [1] "SKDDEPSTA"      "SKDARRSTA"      "SKDEQP"         "SKDEPS"        
 [5] "AVGLOFATC"      "UPLINEATCIMP"   "DEPSTAATCIMP"   "DOWNLINEATCIMP"
 [9] "ARRBUCKET"      "DEPRANKGRP"     "TRNRANKGRP"     "ARRRANKGRP"    
[13] "ARRSPOKE"       "xDURN2"         "xAVGSKDAVAIL"  
> 
> gbmGrid <-  expand.grid(interaction.depth = c(1, 2, 3),
+                         n.trees = (1:30)*60,
+                         shrinkage = 0.1,
+                         n.minobsinnode = 20)
> 
> set.seed(107)
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "ROC",
+                  verbose = FALSE)
Loading required package: gbm
Loading required package: survival

Attaching package: 'survival'

The following object is masked from 'package:caret':

    cluster

Loading required package: splines
Loaded gbm 2.1.1
Loading required package: plyr
> gbmFit1
Stochastic Gradient Boosting 

241 samples
 15 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 216, 217, 217, 217, 217, 217, ... 

Resampling results across tuning parameters:

  interaction.depth  n.trees  ROC        Sens       Spec       ROC SD    
  1                    60     0.8118981  0.9166667  0.3566667  0.09490395
  1                   120     0.8063690  0.8988889  0.4314286  0.10224243
  1                   180     0.8022090  0.8933333  0.4652381  0.09655809
  1                   240     0.8016534  0.8883333  0.4690476  0.10259388
  1                   300     0.7955159  0.8822222  0.4673810  0.10021217
  1                   360     0.7913624  0.8800000  0.4771429  0.10759016
  1                   420     0.7919577  0.8794444  0.4809524  0.10398458
  1                   480     0.7910053  0.8766667  0.4847619  0.10252040
  1                   540     0.7890212  0.8738889  0.4735714  0.09903500
  1                   600     0.7867857  0.8694444  0.4788095  0.10294338
  1                   660     0.7865741  0.8661111  0.4880952  0.10497858
  1                   720     0.7850926  0.8600000  0.4783333  0.10043579
  1                   780     0.7850265  0.8600000  0.4740476  0.10136901
  1                   840     0.7819444  0.8605556  0.4657143  0.10274141
  1                   900     0.7797487  0.8594444  0.4776190  0.09887319
  1                   960     0.7789153  0.8544444  0.4747619  0.10363301
  1                  1020     0.7820238  0.8533333  0.4619048  0.10078708
  1                  1080     0.7800529  0.8561111  0.4604762  0.09962458
  1                  1140     0.7783201  0.8505556  0.4702381  0.10024127
  1                  1200     0.7788889  0.8583333  0.4569048  0.10034464
  1                  1260     0.7751323  0.8538889  0.4554762  0.09973219
  1                  1320     0.7758333  0.8516667  0.4550000  0.10004119
  1                  1380     0.7760053  0.8544444  0.4535714  0.10261762
  1                  1440     0.7743254  0.8522222  0.4652381  0.10264874
  1                  1500     0.7735714  0.8511111  0.4602381  0.10387631
  1                  1560     0.7737302  0.8477778  0.4702381  0.10390531
  1                  1620     0.7732407  0.8477778  0.4523810  0.10184782
  1                  1680     0.7724868  0.8444444  0.4478571  0.10301895
  1                  1740     0.7703307  0.8455556  0.4607143  0.10452325
  1                  1800     0.7705556  0.8477778  0.4590476  0.10514395
  2                    60     0.8057275  0.9027778  0.4164286  0.10279373
  2                   120     0.7996296  0.8894444  0.4690476  0.09661830
  2                   180     0.7954365  0.8811111  0.4828571  0.09685651
  2                   240     0.7881217  0.8805556  0.4578571  0.10389809
  2                   300     0.7894974  0.8755556  0.4600000  0.10487645
  2                   360     0.7826852  0.8722222  0.4585714  0.10415868
  2                   420     0.7854497  0.8700000  0.4619048  0.10366438
  2                   480     0.7813360  0.8672222  0.4769048  0.10400355
  2                   540     0.7819312  0.8638889  0.4685714  0.10308344
  2                   600     0.7843651  0.8650000  0.4714286  0.10467538
  2                   660     0.7812566  0.8661111  0.4642857  0.10519406
  2                   720     0.7842063  0.8661111  0.4626190  0.10097028
  2                   780     0.7834788  0.8661111  0.4690476  0.10359031
  2                   840     0.7846429  0.8633333  0.4642857  0.10165266
  2                   900     0.7849735  0.8666667  0.4723810  0.10449952
  2                   960     0.7844180  0.8650000  0.4764286  0.10472483
  2                  1020     0.7830423  0.8622222  0.4714286  0.10433529
  2                  1080     0.7844048  0.8616667  0.4761905  0.10584207
  2                  1140     0.7844048  0.8594444  0.4647619  0.10195348
  2                  1200     0.7823942  0.8600000  0.4626190  0.10813425
  2                  1260     0.7836111  0.8588889  0.4626190  0.10785139
  2                  1320     0.7827249  0.8577778  0.4645238  0.10662151
  2                  1380     0.7805820  0.8588889  0.4611905  0.10890714
  2                  1440     0.7814418  0.8544444  0.4626190  0.10734183
  2                  1500     0.7827778  0.8572222  0.4659524  0.10745467
  2                  1560     0.7827381  0.8566667  0.4657143  0.10879512
  2                  1620     0.7831349  0.8572222  0.4657143  0.10741483
  2                  1680     0.7825000  0.8555556  0.4671429  0.10801565
  2                  1740     0.7827910  0.8538889  0.4526190  0.11008092
  2                  1800     0.7821296  0.8538889  0.4540476  0.10793202
  3                    60     0.8034921  0.8977778  0.4219048  0.09401575
  3                   120     0.7979233  0.8861111  0.4388095  0.09618993
  3                   180     0.7924603  0.8822222  0.4783333  0.09696486
  3                   240     0.7918783  0.8772222  0.4880952  0.09854782
  3                   300     0.7902513  0.8722222  0.4761905  0.10723499
  3                   360     0.7893254  0.8694444  0.4695238  0.10021795
  3                   420     0.7864683  0.8666667  0.4630952  0.10316711
  3                   480     0.7871164  0.8700000  0.4726190  0.10273116
  3                   540     0.7875265  0.8622222  0.4659524  0.10355959
  3                   600     0.7883333  0.8605556  0.4647619  0.10442655
  3                   660     0.7889286  0.8594444  0.4583333  0.09919009
  3                   720     0.7847090  0.8605556  0.4561905  0.10463470
  3                   780     0.7858862  0.8550000  0.4616667  0.09988724
  3                   840     0.7840344  0.8533333  0.4557143  0.10116226
  3                   900     0.7850397  0.8544444  0.4652381  0.10193337
  3                   960     0.7856614  0.8566667  0.4559524  0.10205786
  3                  1020     0.7842460  0.8583333  0.4559524  0.10354563
  3                  1080     0.7852778  0.8588889  0.4571429  0.10267648
  3                  1140     0.7857011  0.8583333  0.4576190  0.10431826
  3                  1200     0.7844709  0.8577778  0.4607143  0.10282935
  3                  1260     0.7858333  0.8572222  0.4604762  0.10124037
  3                  1320     0.7858730  0.8561111  0.4654762  0.09983302
  3                  1380     0.7847354  0.8561111  0.4654762  0.10665267
  3                  1440     0.7838228  0.8583333  0.4669048  0.10656342
  3                  1500     0.7859524  0.8583333  0.4623810  0.10365796
  3                  1560     0.7864815  0.8555556  0.4609524  0.10235826
  3                  1620     0.7869974  0.8566667  0.4576190  0.10206142
  3                  1680     0.7873413  0.8583333  0.4642857  0.10359613
  3                  1740     0.7849339  0.8572222  0.4671429  0.10305584
  3                  1800     0.7841138  0.8555556  0.4623810  0.10443320
  Sens SD     Spec SD  
  0.06996160  0.1883595
  0.07548323  0.2151333
  0.07844034  0.1947106
  0.07955129  0.1855267
  0.08102104  0.1933897
  0.08383500  0.1790372
  0.08358734  0.1829940
  0.08151973  0.1844750
  0.08351271  0.1964519
  0.08481658  0.1815771
  0.08725169  0.1770619
  0.08485517  0.1883933
  0.08738914  0.1786586
  0.08375129  0.1819685
  0.08738022  0.1868590
  0.08890993  0.1856909
  0.08775938  0.1849858
  0.08544646  0.1827504
  0.08456626  0.1853685
  0.08518336  0.1827026
  0.08381083  0.1846963
  0.08794923  0.1768158
  0.08605905  0.1708362
  0.08475959  0.1818772
  0.08753173  0.1737173
  0.09161776  0.1696589
  0.08743907  0.1835564
  0.08430966  0.1771652
  0.08813513  0.1828492
  0.08779490  0.1817090
  0.07253236  0.1981815
  0.07994223  0.2078010
  0.07857536  0.1957273
  0.07911115  0.2136797
  0.07781785  0.1942531
  0.07756906  0.2027271
  0.08475959  0.2074838
  0.08164011  0.2058896
  0.08295838  0.1975560
  0.08440390  0.1856039
  0.08581054  0.2058352
  0.08508082  0.1911441
  0.08653412  0.1944776
  0.08446482  0.1918093
  0.08467863  0.1906180
  0.08403372  0.1817851
  0.08374571  0.1879035
  0.08110373  0.1896628
  0.08447774  0.1926725
  0.08485517  0.1954982
  0.08807852  0.1958786
  0.08331275  0.1859582
  0.08335017  0.1867926
  0.08311044  0.1915331
  0.08477246  0.1979144
  0.08288506  0.1939120
  0.08659174  0.1967847
  0.08356683  0.2005164
  0.08381083  0.1936808
  0.08491944  0.1961415
  0.07395614  0.2176682
  0.07589307  0.1984345
  0.08102104  0.2035861
  0.08179272  0.1984993
  0.08072035  0.1995781
  0.07871608  0.2049592
  0.08393906  0.2138812
  0.08214453  0.2137473
  0.08411715  0.1984922
  0.08375129  0.2007647
  0.08373640  0.1998469
  0.08337821  0.2063414
  0.08390006  0.1970340
  0.08486986  0.2045101
  0.08459759  0.1998195
  0.08288506  0.1986687
  0.08295838  0.1986687
  0.08259871  0.1914059
  0.08144130  0.2011380
  0.08218248  0.2038469
  0.08101142  0.2034771
  0.08017587  0.2009328
  0.08397434  0.2029743
  0.08444821  0.2018290
  0.07911115  0.2024603
  0.08393906  0.2018184
  0.08363395  0.2042736
  0.08182320  0.2069173
  0.08062567  0.2120367
  0.08430966  0.2038415

Tuning parameter 'shrinkage' was held constant at a value of 0.1

Tuning parameter 'n.minobsinnode' was held constant at a value of 20
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 60, interaction.depth =
 1, shrinkage = 0.1 and n.minobsinnode = 20. 
> 
> ## The acid test has failed. :-(
> 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
 Accuracy     Kappa 
0.7468354 0.0000000 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     59   20
    Weak        0    0
                                         
               Accuracy : 0.7468         
                 95% CI : (0.6364, 0.838)
    No Information Rate : 0.7468         
    P-Value [Acc > NIR] : 0.5597         
                                         
                  Kappa : 0              
 Mcnemar's Test P-Value : 2.152e-05      
                                         
            Sensitivity : 0.0000         
            Specificity : 1.0000         
         Pos Pred Value :    NaN         
         Neg Pred Value : 0.7468         
             Prevalence : 0.2532         
         Detection Rate : 0.0000         
   Detection Prevalence : 0.0000         
      Balanced Accuracy : 0.5000         
                                         
       'Positive' Class : Weak           
                                         
> 
> ## The training set is plausible - as one would hope.
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
 Accuracy     Kappa 
0.8132780 0.4358321 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    169   34
    Weak       11   27
                                          
               Accuracy : 0.8133          
                 95% CI : (0.7582, 0.8604)
    No Information Rate : 0.7469          
    P-Value [Acc > NIR] : 0.009206        
                                          
                  Kappa : 0.4358          
 Mcnemar's Test P-Value : 0.001040        
                                          
            Sensitivity : 0.4426          
            Specificity : 0.9389          
         Pos Pred Value : 0.7105          
         Neg Pred Value : 0.8325          
             Prevalence : 0.2531          
         Detection Rate : 0.1120          
   Detection Prevalence : 0.1577          
      Balanced Accuracy : 0.6908          
                                          
       'Positive' Class : Weak            
                                          
> library(doMC)
> registerDoMC(cores = 4)
> 
> options(useFancyQuotes = FALSE) 
> 
> # Accounting info.
> getInfo <- function(what = "Suggests")
+ {
+   text <- packageDescription("caret")[what][[1]]
+   text <- gsub("\n", ", ", text, fixed = TRUE)
+   text <- gsub(">=", "$\\\\ge$", text, fixed = TRUE)
+   eachPkg <- strsplit(text, ", ", fixed = TRUE)[[1]]
+   eachPkg <- gsub(",", "", eachPkg, fixed = TRUE)
+   # out <- paste("\\\\pkg{", eachPkg[order(tolower(eachPkg))], "}", sep = "")
+   # paste(out, collapse = ", ")
+   length(eachPkg)
+ }
> 
> ### project-specific: begin
> ## Set-seed, load original CSV file and do some simple-cleaning
> ## Various datasets 
> 
> set.seed(101)                           # helpful for testing
> 
> flight <- read.csv("../bak/flight.csv")
> 
> # Backup
> flight.raw <- flight
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"
> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"
> 
> # And some deletions
> 
> t.cols <- colnames(flight)
> 
> t.drops <- t.cols[grep("^RANK*", t.cols)]
> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])
> t.drops <- c(t.drops, "D80THPCTL")
> 
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR
> flight$xHNGR <- flight$xDURN < 0
> 
> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+ }
> 
> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))
> 
> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE
> t.cols <- colnames(flight)
> 
> t.drops <- c("SARRHR", "xDURN")
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Backup
> 
> flight00 <- flight
> 
> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]
> 
> ## Take another copy - this is all we need as the training/prediction
> ## set.
> 
> flight1 <- flight
> 
> ## Data insights
> 
> ## Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> flight <- flight1
> 
> ## So something is defining the behaviour.
> 
> ## Try to simplify structure
> 
> head(model.matrix(LEGTYPE ~ ., data = flight))
   (Intercept) SDEPHR SKDDEPSTAALB SKDDEPSTAAMS SKDDEPSTAANC SKDDEPSTAATT
2            1     14            0            0            0            0
5            1     11            0            0            0            0
7            1     14            0            0            0            0
13           1     13            0            0            0            0
14           1     16            0            0            0            0
17           1     15            0            0            0            0
   SKDDEPSTAAUA SKDDEPSTAAUS SKDDEPSTABDA SKDDEPSTABDL SKDDEPSTABNA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTABOI SKDDEPSTABOS SKDDEPSTABRU SKDDEPSTABUF SKDDEPSTABWI
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTACCC SKDDEPSTACDG SKDDEPSTACHS SKDDEPSTACLE SKDDEPSTACMH
2             1            0            0            0            0
5             0            0            0            0            0
7             1            0            0            0            0
13            0            0            0            0            0
14            1            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTACUN SKDDEPSTADDD SKDDEPSTADEN SKDDEPSTADFW SKDDEPSTADSM
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            1            0            0            0
   SKDDEPSTADTW SKDDEPSTADUB SKDDEPSTAEWR SKDDEPSTAFCO SKDDEPSTAFLL
2             0            0            0            0            0
5             1            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAFRA SKDDEPSTAGCM SKDDEPSTAGDL SKDDEPSTAGEG SKDDEPSTAGIG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAHNL SKDDEPSTAIAH SKDDEPSTAILM SKDDEPSTAIND SKDDEPSTAJAX
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAJFK SKDDEPSTAKOA SKDDEPSTALAS SKDDEPSTALAX SKDDEPSTALGA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTALGB SKDDEPSTALGW SKDDEPSTALHR SKDDEPSTALIH SKDDEPSTAMAD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMAN SKDDEPSTAMBJ SKDDEPSTAMCI SKDDEPSTAMCO SKDDEPSTAMDT
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMEX SKDDEPSTAMHT SKDDEPSTAMIA SKDDEPSTAMKE SKDDEPSTAMSP
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMSY SKDDEPSTAMUC SKDDEPSTAMZT SKDDEPSTANAS SKDDEPSTAOAK
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAOGG SKDDEPSTAOMA SKDDEPSTAONT SKDDEPSTAORD SKDDEPSTAORF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAPBI SKDDEPSTAPDX SKDDEPSTAPIT SKDDEPSTAPLS SKDDEPSTAPPP
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            1
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAPUJ SKDDEPSTAPVD SKDDEPSTAPVR SKDDEPSTAPWM SKDDEPSTARDU
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTARIC SKDDEPSTARNO SKDDEPSTAROC SKDDEPSTARSW SKDDEPSTASAN
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASAT SKDDEPSTASEA SKDDEPSTASFO SKDDEPSTASJC SKDDEPSTASJD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASJO SKDDEPSTASJU SKDDEPSTASLC SKDDEPSTASMF SKDDEPSTASNA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASRQ SKDDEPSTASTL SKDDEPSTASTT SKDDEPSTASXM SKDDEPSTASYR
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTATLV SKDDEPSTATPA SKDDEPSTAXHP SKDDEPSTAYEG SKDDEPSTAYVR
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAYYC SKDDEPSTAZRH SKDARRSTAALB SKDARRSTAAMS SKDARRSTAANC
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAATT SKDARRSTAAUA SKDARRSTAAUS SKDARRSTABDA SKDARRSTABDL
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTABNA SKDARRSTABOI SKDARRSTABOS SKDARRSTABRU SKDARRSTABUF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            1            0            0
17            0            0            0            0            0
   SKDARRSTABWI SKDARRSTACCC SKDARRSTACDG SKDARRSTACHS SKDARRSTACLE
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            1            0            0            0
   SKDARRSTACMH SKDARRSTACUN SKDARRSTADDD SKDARRSTADEN SKDARRSTADFW
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTADSM SKDARRSTADTW SKDARRSTADUB SKDARRSTAEWR SKDARRSTAFCO
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAFLL SKDARRSTAFRA SKDARRSTAGCM SKDARRSTAGDL SKDARRSTAGEG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAGIG SKDARRSTAHNL SKDARRSTAIAH SKDARRSTAILM SKDARRSTAIND
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAJAX SKDARRSTAJFK SKDARRSTAKOA SKDARRSTALAS SKDARRSTALAX
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTALGA SKDARRSTALGB SKDARRSTALGW SKDARRSTALHR SKDARRSTALIH
2             0            0            0            0            0
5             0            0            0            0            0
7             1            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMAD SKDARRSTAMAN SKDARRSTAMBJ SKDARRSTAMCI SKDARRSTAMCO
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMDT SKDARRSTAMEX SKDARRSTAMHT SKDARRSTAMIA SKDARRSTAMKE
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMSP SKDARRSTAMSY SKDARRSTAMUC SKDARRSTAMZT SKDARRSTANAS
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAOAK SKDARRSTAOGG SKDARRSTAOMA SKDARRSTAONT SKDARRSTAORD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            1
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAORF SKDARRSTAPBI SKDARRSTAPDX SKDARRSTAPIT SKDARRSTAPLS
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAPPP SKDARRSTAPUJ SKDARRSTAPVD SKDARRSTAPVR SKDARRSTAPWM
2             1            0            0            0            0
5             1            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTARDU SKDARRSTARIC SKDARRSTARNO SKDARRSTAROC SKDARRSTARSW
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASAN SKDARRSTASAT SKDARRSTASEA SKDARRSTASFO SKDARRSTASJC
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASJD SKDARRSTASJO SKDARRSTASJU SKDARRSTASLC SKDARRSTASMF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASNA SKDARRSTASRQ SKDARRSTASTL SKDARRSTASTT SKDARRSTASXM
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASYR SKDARRSTATLV SKDARRSTATPA SKDARRSTAXHP SKDARRSTAYEG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAYVR SKDARRSTAYYC SKDARRSTAZRH SKDEQP319 SKDEQP320 SKDEQP321
2             0            0            0         0         0         0
5             0            0            0         0         0         0
7             0            0            0         0         0         1
13            0            0            0         0         0         0
14            0            0            0         0         0         1
17            0            0            0         0         0         0
   SKDEQP332 SKDEQP333 SKDEQP734 SKDEQP75E SKDEQP75H SKDEQP767 SKDEQPA01
2          0         0         1         0         0         0         0
5          0         0         0         0         0         0         0
7          0         0         0         0         0         0         0
13         0         0         1         0         0         0         0
14         0         0         0         0         0         0         0
17         0         0         0         0         0         0         0
   SKDEQPA05 SKDEQPA19 SKDEQPA21 SKDEQPE90 SKDEPS       D00    AVGSQ AVGLOFATC
2          0         0         0         0     32 0.2500000 3.258065  3.258065
5          0         0         0         1     72 0.2916667 2.986111  3.805556
7          0         0         0         0     88 0.3295455 2.551724  3.701149
13         0         0         0         0     32 0.3750000 3.000000  3.903226
14         0         0         0         0     72 0.3750000 3.295775  3.859155
17         0         0         0         0     84 0.3809524 3.939759  3.361446
   UPLINEATCIMPLow UPLINEATCIMPMed UPLINEATCIMPMedHigh UPLINEATCIMPMedLow
2                0               1                   0                  0
5                0               0                   0                  0
7                0               0                   0                  1
13               0               1                   0                  0
14               0               0                   0                  1
17               1               0                   0                  0
   DEPSTAATCIMPLow DOWNLINEATCIMPLow AVGSKDAVAIL AVAILBUCKETA05 AVAILBUCKETA10
2                0                 0   10.903226              0              1
5                1                 0    2.000000              0              0
7                0                 0    9.647059              1              0
13               0                 0   17.354839              0              0
14               0                 0   17.057143              0              0
17               0                 0   10.621951              0              1
   AVAILBUCKETA15 AVAILBUCKETA20 AVAILBUCKETA25 AVAILBUCKETA30 AVAILBUCKETA<0
2               0              0              0              0              0
5               0              0              0              0              0
7               0              0              0              0              0
13              1              0              0              0              0
14              1              0              0              0              0
17              0              0              0              0              0
   DEPBUCKETD2 DEPBUCKETD3 DEPBUCKETD4 DEPBUCKETD5 DEPBUCKETD6 DEPBUCKETD7
2            0           0           0           1           0           0
5            0           0           1           0           0           0
7            0           0           0           1           0           0
13           0           0           0           1           0           0
14           0           0           0           0           1           0
17           0           0           0           0           1           0
   DEPBUCKETD8 ARRBUCKETA2 ARRBUCKETA3 ARRBUCKETA4 ARRBUCKETA5 ARRBUCKETA6
2            0           0           0           0           0           1
5            0           0           0           0           1           0
7            0           0           0           0           0           1
13           0           0           0           0           0           1
14           0           0           0           0           0           0
17           0           0           0           0           0           1
   ARRBUCKETA7 ARRBUCKETA8 DEPRANKGRPLow DEPRANKGRPMed DEPRANKGRPMedHigh
2            0           0             1             0                 0
5            0           0             0             1                 0
7            0           0             1             0                 0
13           0           0             0             0                 0
14           1           0             1             0                 0
17           0           0             0             0                 0
   DEPRANKGRPMedLow TRNRANKGRPLow TRNRANKGRPMed TRNRANKGRPMedHigh
2                 0             1             0                 0
5                 0             1             0                 0
7                 0             1             0                 0
13                1             0             0                 0
14                0             1             0                 0
17                1             0             1                 0
   TRNRANKGRPMedLow ARRRANKGRPLow ARRRANKGRPMed ARRRANKGRPMedHigh
2                 0             0             0                 1
5                 0             0             0                 1
7                 0             0             1                 0
13                1             0             0                 0
14                0             0             0                 1
17                0             0             0                 1
   ARRRANKGRPMedLow DEPSPOKETRUE ARRSPOKETRUE xHNGRTRUE xDURN2
2                 0            0            0         0      2
5                 0            1            0         0      2
7                 0            0            1         0      2
13                1            0            1         0      2
14                0            0            1         0      2
17                0            0            0         0      2
> 
> dummies <- dummyVars(LEGTYPE ~ ., data = flight)
> flight.dum <- predict(dummies, newdata = flight)
> 
> ## It may be too big to use, but useful for inspection.
> 
> ### Numeric variables
> 
> ## Check some more correlations, I haven't scaled yet.
> 
> x1 <- as.data.frame(as.matrix(sapply(flight, class)))
> 
> flight.num <- flight[,names(x1[which(x1$V1 %in% c("numeric", "integer")),])]
> 
> flight.nzv <- nearZeroVar(flight.num, saveMetrics = TRUE)
> flight.nzv
            freqRatio percentUnique zeroVar   nzv
SDEPHR       1.038462        5.9375   FALSE FALSE
SKDEPS       1.000000       19.0625   FALSE FALSE
D00          1.166667       75.3125   FALSE FALSE
AVGSQ        6.333333       82.8125   FALSE FALSE
AVGLOFATC    1.000000       78.4375   FALSE FALSE
AVGSKDAVAIL  1.000000       87.5000   FALSE FALSE
xDURN2       1.428571        2.5000   FALSE FALSE
> 
> flight.cor <- cor(flight.num, use = "pairwise.complete.obs")
> 
> highlyCorDescr <- findCorrelation(flight.cor, cutoff = .75, verbose=TRUE)
Considering row	 1 column	 4 value	 0.956 
  Flagging column	 1 
Considering row	 4 column	 3 value	 0.414 
Considering row	 4 column	 6 value	 0.173 
Considering row	 4 column	 7 value	 0.201 
Considering row	 4 column	 5 value	 0.103 
Considering row	 4 column	 2 value	 0.082 
Considering row	 3 column	 6 value	 0.266 
Considering row	 3 column	 7 value	 0.071 
Considering row	 3 column	 5 value	 0.114 
Considering row	 3 column	 2 value	 0.006 
Considering row	 6 column	 7 value	 0.031 
Considering row	 6 column	 5 value	 0.094 
Considering row	 6 column	 2 value	 0.067 
Considering row	 7 column	 5 value	 0.137 
Considering row	 7 column	 2 value	 0.005 
Considering row	 5 column	 2 value	 0.041 
> 
> ## Which tells me that departure time is very highly correlated to AVGSQ.
> 
> ### Try and impute the AVG
> 
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))
> 
> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1
> 
> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]
> 
> preProcValues <- preProcess(flight.na, method = c("knnImpute"))
> flight.na1 <- predict(preProcValues, flight.na)
> 
> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL
> 
> ## And I'll leave the centered and scale values in for now.
> ## and delete the troublesome ones
> 
> flight$AVGSKDAVAIL <- NULL
> flight$xHNGR <- NULL
> flight$AVAILBUCKET <- NULL
> 
> # This should be deleted, leave it in and the results are ideal because it defines LEGTYPE.
> flight$D00 <- NULL
> 
> ## Keep the results.
> outcomes.flight <- flight$LEGTYPE
> 
> flight$LEGTYPE <- NULL
> 
> ## Try converting all the factors to numerics
> 
> ## If you know your factors are definitely factors, you don't need this
> ##  asNumeric <- function(x) as.numeric(as.character(x))
> 
> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))
> 
> flight.num0 <- factors.numeric(flight)
> 
> flight.scl0 <- scale(flight.num0)
> 
> ## Now split the results
> 
> inTrain <- createDataPartition(outcomes.flight, p = 0.75, list = FALSE)
> 
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> 
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> 
> prop.table(table(flight.scl0))
flight.scl0
    -2.99546983996958     -2.98604368384811     -2.82110052361751 
           0.00281250            0.00015625            0.00015625 
    -2.64037641778924     -2.37742331516569     -2.09431321436608 
           0.00015625            0.00015625            0.00031250 
    -2.02525208119049     -2.02364615961949     -1.96706162425765 
           0.00046875            0.00093750            0.00015625 
    -1.94787383036273     -1.91934227796699     -1.87162293167633 
           0.00125000            0.00015625            0.00015625 
    -1.80813803757891      -1.8064397520718     -1.76880294648328 
           0.00093750            0.00093750            0.00453125 
     -1.7104004231695     -1.67620690253875     -1.63572266525187 
           0.00312500            0.00015625            0.00078125 
    -1.60554554037119     -1.58829697245811     -1.58375887562806 
           0.00265625            0.00062500            0.00031250 
    -1.56068940274137     -1.55266802930898     -1.55257138616628 
           0.00593750            0.00015625            0.00015625 
    -1.54865734259279     -1.54635333101763     -1.54295794614133 
           0.00015625            0.00015625            0.00015625 
    -1.53179508600425     -1.53074294246617     -1.50769426210174 
           0.00203125            0.00015625            0.00015625 
    -1.49330986644838     -1.47983129638045     -1.47646498237513 
           0.00015625            0.00171875            0.00015625 
    -1.44796824755814     -1.43812707979848     -1.43616463590287 
           0.00015625            0.00031250            0.00015625 
     -1.4311495031078     -1.42786750675664     -1.42754311366228 
           0.00062500            0.00031250            0.00015625 
     -1.4230237164245     -1.42196682798086     -1.40691590144974 
           0.00015625            0.00015625            0.00750000 
    -1.40295304316347     -1.39839761187043     -1.38337483337197 
           0.00343750            0.00015625            0.00015625 
    -1.37828409873765     -1.37590371713284      -1.3753288895824 
           0.00031250            0.00078125            0.00015625 
    -1.37383369560894     -1.37045453151584     -1.35466334686085 
           0.00015625            0.00015625            0.00015625 
    -1.33716625322094     -1.33398496346823     -1.33080367371552 
           0.00015625            0.00015625            0.00015625 
    -1.32393992750903      -1.3160853172316     -1.31578091655701 
           0.00093750            0.00015625            0.00015625 
    -1.31443367614047      -1.3133256164209     -1.30151560934568 
           0.00015625            0.00015625            0.00015625 
    -1.30111163600234     -1.29600486257245     -1.28619597667342 
           0.00015625            0.00031250            0.00031250 
    -1.28367748081635     -1.28186181839242      -1.2799413346293 
           0.00031250            0.00015625            0.00015625 
    -1.27197613788523     -1.26773489691459      -1.2671778786613 
           0.00109375            0.00015625            0.00015625 
     -1.2615812276646     -1.25974760485758     -1.25283365916062 
           0.00031250            0.00078125            0.00015625 
    -1.25178454113998     -1.24659260411695     -1.24079645146543 
           0.00015625            0.00015625            0.00015625 
     -1.2302338686483     -1.23020377865797      -1.2268968080815 
           0.00015625            0.00687500            0.00031250 
    -1.22001234826142     -1.21809512250389     -1.21512040999215 
           0.00046875            0.00015625            0.00015625 
    -1.21024953572476     -1.20647153886774     -1.20560405725029 
           0.00015625            0.00015625            0.00015625 
    -1.20188627600106     -1.20036054595575     -1.20011285144544 
           0.00031250            0.00140625            0.00015625 
    -1.19042311450129     -1.18991798468508     -1.18966337127103 
           0.00015625            0.00015625            0.00062500 
    -1.16804855863761     -1.16764210792351     -1.16749679150174 
           0.00093750            0.00015625            0.00015625 
    -1.16258400593847     -1.16018257780086     -1.15839829359119 
           0.00015625            0.00640625            0.00015625 
    -1.14179763548495     -1.13992628855288     -1.13935994002253 
           0.00015625            0.00031250            0.00031250 
    -1.13310730700243     -1.13102279477938     -1.12993289335973 
           0.00015625            0.00015625            0.00015625 
    -1.12915754122589     -1.12753063368423     -1.12667091460446 
           0.00015625            0.00015625            0.00015625 
    -1.12622940836933     -1.12368140470519     -1.12361616254288 
           0.00031250            0.00015625            0.00062500 
    -1.12145428351456     -1.11910330109794     -1.11800948418703 
           0.00015625            0.00015625            0.00015625 
    -1.11608476901381     -1.11429923219746     -1.09261479989672 
           0.00062500            0.00015625            0.00015625 
    -1.09084552937417     -1.09012044993392      -1.0895833019642 
           0.00015625            0.00015625            0.00031250 
    -1.08549109658463     -1.06938028371369     -1.06604781193988 
           0.00031250            0.00015625            0.00015625 
    -1.06587003530766        -1.06412097939     -1.05534288054392 
           0.00015625            0.00046875            0.00015625 
    -1.04945721011816     -1.04845626690162     -1.04766888572427 
           0.00015625            0.00015625            0.00015625 
    -1.04755297964098     -1.04598728075964     -1.04536609890991 
           0.00031250            0.00031250            0.00031250 
    -1.02993885350447     -1.02151758080685     -1.01733580186582 
           0.00015625            0.00203125            0.02453125 
    -1.01577847702439      -1.0138904262493      -1.0121571897662 
           0.00015625            0.00015625            0.00062500 
    -1.00929178081963     -1.00745946934895     -1.00714202059705 
           0.00015625            0.00015625            0.00015625 
    -1.00664275166081     -1.00407661804032     -1.00110637205939 
           0.00046875            0.00015625            0.00015625 
   -0.997768048748026    -0.991929422812267    -0.989060788495757 
           0.00328125            0.00015625            0.00031250 
    -0.98572380365604    -0.979554261682366    -0.976324799963229 
           0.00015625            0.00031250            0.00875000 
   -0.973173077974651    -0.971118460177678     -0.96975725707502 
           0.01640625            0.00015625            0.00015625 
   -0.963461694934854    -0.961159884505833    -0.960193400142389 
           0.00015625            0.00015625            0.00046875 
   -0.958010282948452    -0.957720936633644    -0.955230663538487 
           0.00015625            0.00015625            0.00015625 
   -0.953451859649493    -0.952397629449069    -0.951677411170411 
           0.00031250            0.00015625            0.01765625 
   -0.947281520180146    -0.946066444247069    -0.942123167843126 
           0.00015625            0.00015625            0.00015625 
   -0.941185041055857    -0.939666457415937    -0.937914389255748 
           0.00015625            0.00031250            0.00015625 
   -0.937428692031181    -0.937143144639067    -0.929006249994557 
           0.00015625            0.00203125            0.00031250 
   -0.928956547037233    -0.927234345076844    -0.926325405165677 
           0.00015625            0.00015625            0.00015625 
   -0.926208874394783     -0.92432711582923    -0.923751900565718 
           0.00015625            0.00015625            0.00015625 
   -0.921447647976772    -0.920026610901552    -0.919775930100724 
           0.00015625            0.00015625            0.00031250 
   -0.919418999070816    -0.918979533540974    -0.918834367344145 
           0.00093750            0.00015625            0.00015625 
   -0.918602057207572    -0.918233359080158    -0.916620305783416 
           0.00015625            0.00015625            0.00031250 
   -0.908229610518583    -0.907879271266391    -0.907626204980156 
           0.00031250            0.00015625            0.00015625 
   -0.906631706666217    -0.905610577820333    -0.905104725277818 
           0.00015625            0.00015625            0.00015625 
   -0.904170844231002    -0.902563699445797    -0.902495470961171 
           0.00031250            0.00015625            0.00046875 
   -0.902207570970879    -0.900277820755885    -0.900269127160796 
           0.00015625            0.00609375            0.00015625 
   -0.900105713501894    -0.897103060359799    -0.896252308815885 
           0.00015625            0.00015625            0.00015625 
   -0.895759768448355    -0.895685333371447    -0.891948830933419 
           0.00015625            0.00015625            0.00015625 
   -0.891482707849845     -0.89086838304768    -0.889814536282523 
           0.00015625            0.02343750            0.00015625 
   -0.886894039811436    -0.885423108336021    -0.885386138492139 
           0.00093750            0.00015625            0.01593750 
   -0.884574764423174    -0.881181388644532    -0.881133728915611 
           0.00015625            0.00015625            0.00015625 
   -0.879323305434347    -0.878872666379052    -0.877901133624378 
           0.00015625            0.00015625            0.00015625 
   -0.876749332956921    -0.876685019263073    -0.875765771148607 
           0.00031250            0.00015625            0.00031250 
   -0.875473779114446     -0.87537693015952    -0.872246314823305 
           0.00015625            0.00015625            0.00015625 
   -0.871001261435858    -0.870353841103083    -0.869162583211394 
           0.00015625            0.00015625            0.00015625 
   -0.866780745576637    -0.866244907634358    -0.858819232798091 
           0.00015625            0.00015625            0.00015625 
   -0.856265820894777    -0.844253476212177    -0.844066341550782 
           0.00078125            0.00015625            0.00015625 
   -0.842025743633279    -0.831738843759029    -0.830837909586882 
           0.02921875            0.00015625            0.02515625 
   -0.829374923233683    -0.828920190368225    -0.827915178181078 
           0.00015625            0.00093750            0.00015625 
   -0.827728686266157    -0.826039032973297    -0.822416105203804 
           0.00015625            0.00015625            0.00015625 
   -0.821797313281808    -0.819285769008092    -0.816336564086851 
           0.00015625            0.00015625            0.00015625 
   -0.814051297945908    -0.811605617460827    -0.809148421270981 
           0.00015625            0.00015625            0.00015625 
   -0.804302031270971    -0.800154571238789    -0.795175551540305 
           0.00062500            0.00015625            0.00171875 
   -0.792845872277945    -0.790185643279993    -0.789212464897955 
           0.02015625            0.00859375            0.00046875 
   -0.787996109659257    -0.785742695872334    -0.783287556756109 
           0.00015625            0.00015625            0.00015625 
    -0.78222517242437    -0.777611190965241    -0.777259256743858 
           0.00015625            0.00015625            0.00015625 
   -0.775052088417874    -0.768725111385422      -0.7653899578722 
           0.00031250            0.00015625            0.00015625 
   -0.764328853007072    -0.759372004638613    -0.759121665238872 
           0.00015625            0.00015625            0.00015625 
   -0.758171518227594    -0.752387355098689    -0.752338241647165 
           0.00015625            0.00015625            0.00031250 
   -0.751716727129916    -0.750007134146443    -0.748171465050933 
           0.00015625            0.00562500            0.00015625 
   -0.743693425437366     -0.74226506946404    -0.738477819728135 
           0.00718750            0.00015625            0.00015625 
   -0.735940818773818    -0.734501921638923    -0.723911474638978 
           0.00015625            0.00015625            0.00015625 
   -0.720697236097384    -0.718445199078953    -0.715142805531928 
           0.00031250            0.00015625            0.00031250 
   -0.713461500253351    -0.710452171936934    -0.708684788599593 
           0.00015625            0.00015625            0.00015625 
   -0.708003561812545    -0.702080356630785     -0.70037445202336 
           0.00015625            0.00015625            0.00203125 
    -0.69602539257426     -0.69280361708918    -0.687853983052082 
           0.00015625            0.03375000            0.00015625 
    -0.68694861300278    -0.684622918007104    -0.682222958529648 
           0.00015625            0.00015625            0.00015625 
   -0.681188975020078    -0.673798181086569     -0.66884926915034 
           0.00187500            0.00015625            0.00015625 
     -0.6653122497357    -0.654779601264497    -0.648410662399554 
           0.00015625            0.00015625            0.00078125 
   -0.647068571912601    -0.646559789740211    -0.633905116384853 
           0.00015625            0.00015625            0.00015625 
   -0.633276439235621    -0.626480919280269    -0.624813955253419 
           0.00015625            0.00015625            0.00015625 
   -0.621563193776932    -0.615573756562581    -0.613123253862724 
           0.00015625            0.00015625            0.00171875 
   -0.604038319371604    -0.596446872775748    -0.596237216599971 
           0.00015625            0.00046875            0.00015625 
   -0.596137826610777    -0.592583054332584    -0.590968847296576 
           0.00015625            0.00359375            0.00015625 
   -0.581016668721787     -0.57842864719944    -0.577046832499099 
           0.00015625            0.00015625            0.00015625 
   -0.576399963736262    -0.567294133064953    -0.562646449882806 
           0.00187500            0.00015625            0.00031250 
   -0.559949234902497    -0.553868745195444    -0.551562209118441 
           0.00031250            0.00015625            0.00859375 
   -0.548486073402725    -0.545057532705371    -0.544483083151942 
           0.00015625            0.00046875            0.00093750 
   -0.543553164656681    -0.542887786706365    -0.542791834600063 
           0.00015625            0.00015625            0.03859375 
   -0.535816263171991    -0.529620965141671    -0.523583345339874 
           0.00031250            0.00015625            0.00015625 
   -0.522876883678594    -0.515144874010522    -0.511242837482551 
           0.00015625            0.00015625            0.00015625 
   -0.511062050911504    -0.509452501139644    -0.507981951223969 
           0.00500000            0.00015625            0.00015625 
   -0.506004946851197    -0.504251327555701    -0.503668338010739 
           0.00015625            0.00203125            0.00015625 
   -0.497665904683127    -0.492519293528136    -0.488304476973275 
           0.00015625            0.00062500            0.00015625 
   -0.486275884354524    -0.480531685495119    -0.479070530598709 
           0.00015625            0.00015625            0.00015625 
   -0.476991811548017    -0.475764665500524    -0.473473045518126 
           0.00078125            0.00015625            0.00015625 
   -0.472612890303562    -0.464757185992567    -0.456186401194196 
           0.00015625            0.00015625            0.00015625 
   -0.454553689487183    -0.453074332488957    -0.452195518537862 
           0.00015625            0.00015625            0.00015625 
   -0.450040882361118    -0.446015592229304    -0.443168278929009 
           0.00015625            0.00015625            0.00015625 
    -0.44055550390433    -0.439275967288811    -0.439064986884659 
           0.00093750            0.00015625            0.00031250 
   -0.436572045333686    -0.433356062339654     -0.43210269137514 
           0.00015625            0.00015625            0.00031250 
   -0.429159183376661     -0.42811270638386    -0.424489571114943 
           0.00015625            0.00015625            0.00015625 
   -0.424136094192972    -0.422368710855631    -0.422286506964679 
           0.00015625            0.00015625            0.00015625 
     -0.4217879739841     -0.42160028367728    -0.408926090390664 
           0.00015625            0.00015625            0.00062500 
   -0.406238662084726    -0.405337563546837    -0.402845924603104 
           0.00015625            0.00015625            0.00015625 
   -0.398392401687235    -0.392753100892855    -0.392721940787981 
           0.00015625            0.00015625            0.00015625 
   -0.389990557124863    -0.383778543291898    -0.381829344162238 
           0.00203125            0.00031250            0.00031250 
   -0.378610740922975    -0.377352421209284     -0.37278098800314 
           0.00015625            0.00015625            0.00015625 
   -0.368704530397105    -0.364033384865912    -0.363121805899083 
           0.00015625            0.00015625            0.00015625 
   -0.361905601371654    -0.360992312891898     -0.36077985218898 
           0.00015625            0.00015625            0.00015625 
    -0.35995405519458    -0.354602189779798    -0.354221703071568 
           0.00046875            0.00015625            0.00015625 
   -0.354125613590753     -0.35383985286255    -0.350820163721666 
           0.00015625            0.00015625            0.00015625 
   -0.347880750045415    -0.347682518083072    -0.344794514479224 
           0.00031250            0.00015625            0.00015625 
   -0.344246401931106    -0.340586009596143    -0.338241270869783 
           0.00015625            0.00015625            0.00031250 
   -0.336627924656718    -0.333999550987416    -0.331679860754818 
           0.00015625            0.00015625            0.00015625 
   -0.327473828580897    -0.325591270635287    -0.320604647133837 
           0.00015625            0.00015625            0.00015625 
   -0.320293393650012    -0.318998347766866    -0.313800886365509 
           0.00015625            0.00015625            0.00015625 
   -0.308729731711204     -0.30775968479621    -0.307488803472333 
           0.00015625            0.00062500            0.00015625 
   -0.305912488397539    -0.300040013990283    -0.299281804870489 
           0.00015625            0.00015625            0.00015625 
   -0.297576089117692    -0.294612153988498    -0.290886990303406 
           0.00015625            0.00015625            0.00015625 
   -0.289476667647491    -0.287805419014019    -0.284664135032912 
           0.00015625            0.00031250            0.00062500 
   -0.283279035792871    -0.278947445070673    -0.278430676385642 
           0.00015625            0.00015625            0.01140625 
   -0.277028655971768    -0.274352800845479    -0.269810489634915 
           0.00015625            0.00015625            0.00875000 
   -0.268327804913194    -0.264273008183568    -0.263991250766728 
           0.00015625            0.00015625            0.00015625 
   -0.263633329101249    -0.256569345435893    -0.255210887064625 
           0.00015625            0.00015625            0.00015625 
   -0.254264930167697    -0.253205544043426    -0.250717006205447 
           0.00015625            0.00015625            0.00015625 
   -0.250531752899298    -0.249985351299549    -0.247578088366761 
           0.00015625            0.00015625            0.00015625 
   -0.244437996150226    -0.243268618233703    -0.242824942853484 
           0.00015625            0.00015625            0.00015625 
   -0.233740722783471    -0.232700345409106    -0.232349973253986 
           0.00015625            0.00015625            0.00015625 
   -0.231815214890401    -0.231309362347886     -0.23037548130107 
           0.00015625            0.00015625            0.00015625 
   -0.228412208040947    -0.226589859802479    -0.224837647995068 
           0.00015625            0.01656250            0.00015625 
   -0.223464759128966     -0.22331717855311    -0.222588752387258 
           0.00015625            0.00015625            0.00015625 
   -0.222456945885953    -0.220222816737245    -0.217487288707678 
           0.00015625            0.00031250            0.00046875 
   -0.216388232760497    -0.213098676881504    -0.212807560710942 
           0.00015625            0.00093750            0.00015625 
   -0.205527942504415    -0.202889656333141    -0.199061273711729 
           0.00015625            0.00015625            0.00015625 
   -0.197285663071406    -0.196655198635886    -0.187398059917142 
           0.00015625            0.00015625            0.00328125 
    -0.18553936273967    -0.184426534107832      -0.1807365557853 
           0.00015625            0.00015625            0.00031250 
   -0.173455385110242    -0.170696066339926    -0.167983070845547 
           0.00953125            0.00062500            0.00015625 
    -0.16706735776498     -0.16549287956689    -0.163323851054559 
           0.00015625            0.00015625            0.00015625 
   -0.163005226779217    -0.155721964916119     -0.15557956030375 
           0.00015625            0.00015625            0.00015625 
   -0.145050220201077    -0.140627037006184    -0.136663205761249 
           0.00015625            0.00015625            0.00015625 
   -0.135547666352963    -0.135353058341049    -0.135168941442998 
           0.00015625            0.00015625            0.00015625 
    -0.13422823788067    -0.128983100398563    -0.128772766161494 
           0.00015625            0.00015625            0.00062500 
   -0.128276147190878    -0.124732071896041    -0.122750748897942 
           0.00015625            0.00015625            0.00015625 
   -0.121913567685457    -0.114572129500928    -0.113273027561381 
           0.00015625            0.00015625            0.00015625 
   -0.107405286684043    -0.105529863556612    -0.103356043915892 
           0.00015625            0.00953125            0.00015625 
  -0.0959919473132286   -0.0946576344451732   -0.0921610479659292 
           0.00015625            0.00031250            0.00015625 
  -0.0897276946329045    -0.082082912166815   -0.0820786945748793 
           0.00015625            0.00015625            0.00031250 
  -0.0807439358161152   -0.0768089765376881   -0.0759616047321375 
           0.00015625            0.00140625            0.00015625 
  -0.0741942213947964   -0.0733788467156504   -0.0726315828860554 
           0.00015625            0.00718750            0.00015625 
  -0.0685974846038955   -0.0532150311664168   -0.0498043335027671 
           0.00093750            0.00015625            0.00015625 
  -0.0497543467601004   -0.0473016251818649   -0.0451490777305966 
           0.00015625            0.00015625            0.00031250 
  -0.0446498361490209   -0.0392160026639466   -0.0373582346840002 
           0.00015625            0.00015625            0.00015625 
  -0.0352851923820555   -0.0345646240252186   -0.0326438116903773 
           0.00031250            0.00031250            0.00015625 
  -0.0248451869138821   -0.0188880173129063    -0.013807090586871 
           0.00109375            0.00015625            0.00015625 
  -0.0119657325121257   -0.0114810502208166  -0.00721676013122688 
           0.00015625            0.00015625            0.00015625 
 -0.00368424503602545 -0.000580656453063986   0.00425466589044258 
           0.00015625            0.00015625            0.00015625 
  0.00624696207963468   0.00661720265702806    0.0104887638020741 
           0.00015625            0.00015625            0.00015625 
   0.0151944372905789    0.0177528116242494    0.0194770878491831 
           0.00421875            0.00015625            0.00015625 
   0.0217087977522383    0.0235168212825711    0.0255537765734798 
           0.00015625            0.00015625            0.00015625 
   0.0264730080152699    0.0271186027099238    0.0361351573082595 
           0.00015625            0.00031250            0.00015625 
   0.0362911121323546    0.0368634437985054    0.0454309894047899 
           0.00015625            0.00015625            0.00015625 
   0.0533298995579193    0.0570581595639766    0.0585759323236618 
           0.00015625            0.00937500            0.00015625 
   0.0675339577108118    0.0702113818864803    0.0729377618887858 
           0.00046875            0.00015625            0.00062500 
   0.0788793134968683    0.0789059252411879    0.0790823923337298 
           0.00015625            0.02343750            0.00046875 
   0.0797510873183287    0.0806069942083428    0.0841639835120876 
           0.00015625            0.00015625            0.00015625 
   0.0899621750174284    0.0966606496804153    0.0972018193465008 
           0.00015625            0.00015625            0.00015625 
    0.101566818289489     0.108411810410797     0.109012079979066 
           0.00062500            0.00015625            0.00046875 
     0.11244290268093     0.119444894039026     0.131046181957536 
           0.00015625            0.00015625            0.00203125 
    0.134889340170799     0.135028927523559     0.136658265622521 
           0.00015625            0.00015625            0.00015625 
    0.144157938789208     0.146258849789861     0.147318188850963 
           0.00015625            0.00015625            0.02984375 
    0.151115033119933     0.152349655315244     0.154426066228552 
           0.00015625            0.00015625            0.00015625 
     0.15737266071083     0.162873929857665     0.162973153669365 
           0.00015625            0.00015625            0.00015625 
    0.164891939398059     0.165580765616732     0.173693095305534 
           0.00015625            0.00015625            0.00015625 
    0.183009971581342     0.186789363756051     0.187969991368742 
           0.00093750            0.00015625            0.00015625 
    0.192709893790261     0.194724832331223     0.194735738184732 
           0.00015625            0.00015625            0.00015625 
    0.195991364801127     0.206802781312992     0.210386154876613 
           0.00015625            0.00015625            0.00500000 
    0.217235034249908       0.2177869344983     0.234906769563277 
           0.00031250            0.00203125            0.00015625 
    0.234973761205148     0.238837237065174     0.241127733319099 
           0.00031250            0.00015625            0.00015625 
    0.250135635132824      0.25028785413495     0.253309352340188 
           0.00015625            0.00015625            0.00078125 
    0.254814769298151     0.260835355687548     0.264960519475955 
           0.00015625            0.00015625            0.00015625 
    0.266044692238248      0.27127954776092     0.273304013334367 
           0.00015625            0.00015625            0.00015625 
    0.273531307307048     0.274822103147971     0.280770740587068 
           0.00015625            0.00015625            0.00015625 
    0.284591080073122     0.285810915205503     0.286937550828954 
           0.00015625            0.00015625            0.00046875 
    0.289640625615739     0.301307082566931     0.302882181759369 
           0.00015625            0.00015625            0.00015625 
    0.304256560508303     0.309710068792923     0.311251030414092 
           0.00015625            0.00015625            0.00015625 
    0.311802268812853     0.318128929047187     0.318922298138204 
           0.00015625            0.00031250            0.00015625 
    0.320852365313198     0.322875645177539     0.334350357273903 
           0.00015625            0.00015625            0.00015625 
    0.337167536402539     0.338400625416362     0.338901340452759 
           0.00015625            0.00031250            0.00140625 
    0.346939027258188     0.348766831423466     0.358991725758732 
           0.00015625            0.00015625            0.00015625 
    0.364034892089946     0.365884194608935     0.368674799710984 
           0.00015625            0.00015625            0.00015625 
    0.369643258716518     0.373829702918903     0.379821273586168 
           0.00015625            0.00062500            0.00015625 
    0.382087226815338      0.38685609839469       0.3878539441829 
           0.00015625            0.00015625            0.00015625 
     0.38923354153609     0.390865130076565     0.393785793790202 
           0.00015625            0.00093750            0.00015625 
    0.402956322412276     0.404247945632944      0.40569298299336 
           0.00015625            0.00015625            0.00015625 
    0.406064629649282      0.40786256349758     0.408056423319527 
           0.00015625            0.00109375            0.00015625 
    0.412247177017014     0.414419483912049     0.416346031539166 
           0.00015625            0.00046875            0.00015625 
     0.41794166276908     0.419463447191946     0.420106603846799 
           0.00015625            0.01078125            0.00015625 
    0.420379431706021     0.420869449539072     0.431214346889845 
           0.00406250            0.00015625            0.00015625 
    0.433937840525743     0.440278644951702     0.441895424076257 
           0.00031250            0.00015625            0.00015625 
    0.442828919700371     0.443274873059508     0.446173888246631 
           0.00046875            0.00984375            0.00015625 
    0.450718587802467     0.456900610463576     0.459555681956315 
           0.00015625            0.00031250            0.00015625 
    0.460696686048428     0.467876105484108     0.472728746197005 
           0.00015625            0.00015625            0.00015625 
    0.474472217743954     0.474601080341499     0.474734089218203 
           0.00015625            0.00031250            0.00015625 
    0.477973490467994     0.484307789443022     0.484652344952628 
           0.00015625            0.00015625            0.00015625 
    0.494792709324177     0.498497691565453     0.500784787450151 
           0.00109375            0.00515625            0.00015625 
    0.504691880000581     0.508425703980646      0.50861676779181 
           0.00031250            0.00015625            0.00015625 
     0.50996114523361     0.514344382856681     0.516995457862692 
           0.00015625            0.00015625            0.00015625 
    0.518586102739047     0.521829770584971     0.523840570430114 
           0.00015625            0.00015625            0.00015625 
    0.524285913333902     0.525227742436545     0.527917885589494 
           0.00015625            0.00015625            0.00015625 
    0.531983533422768     0.539966728864973     0.541903897062432 
           0.00015625            0.00015625            0.00046875 
    0.543994005812287     0.545724786000498     0.546756498947983 
           0.00125000            0.00015625            0.00203125 
    0.548923619243861     0.549353970396232       0.5588553176537 
           0.00015625            0.00015625            0.00031250 
    0.564138483610525     0.566992546543754     0.569133261860447 
           0.00015625            0.00015625            0.00015625 
    0.574903744908869     0.577978215152712     0.578343495716271 
           0.00031250            0.00109375            0.00015625 
    0.580241024741447     0.581634314964003     0.583204933976379 
           0.00015625            0.00015625            0.00015625 
     0.58873859479558     0.595455758634415     0.597057916427158 
           0.00015625            0.00031250            0.00015625 
    0.598720288571789     0.599162991111384     0.599578938399305 
           0.00031250            0.00015625            0.00015625 
     0.60342049593258     0.604292419065582     0.607847397763963 
           0.00015625            0.00015625            0.00015625 
    0.611956869618315     0.612059726969641     0.612784292101807 
           0.00015625            0.00062500            0.00015625 
    0.613557486760981     0.620580331763515     0.622971928913742 
           0.00015625            0.00015625            0.00375000 
     0.63588348041021     0.641390081029809     0.643182929950686 
           0.00015625            0.00015625            0.00015625 
    0.648293425210027     0.650684078195595     0.657754904789885 
           0.00015625            0.00046875            0.00015625 
    0.664732625480728     0.665678528246394     0.665791697835918 
           0.00015625            0.00984375            0.00015625 
    0.666578602798705     0.678050028820375     0.678379635730825 
           0.00015625            0.00015625            0.00015625 
    0.679808655934455     0.680412565586961     0.680711498268701 
           0.00328125            0.00015625            0.00015625 
    0.684080216155581     0.684149053017272     0.685295140133807 
           0.00281250            0.00015625            0.00031250 
    0.686201169423553     0.690582799388141     0.692180702201577 
           0.00015625            0.00421875            0.00015625 
    0.696595449900374     0.697435597111395     0.698914306548046 
           0.00015625            0.00015625            0.00015625 
     0.70193206265865     0.702647867819401     0.707754986014002 
           0.00015625            0.00062500            0.00015625 
    0.711210346763156     0.712920206015224     0.713369947147153 
           0.00015625            0.00015625            0.00015625 
    0.715327471836729     0.722275487513834     0.722728216151602 
           0.00031250            0.00156250            0.00015625 
      0.7239248415172      0.72708089915877     0.729737150343281 
           0.00015625            0.00015625            0.00015625 
    0.735388003016973     0.740385327518889     0.741422651587756 
           0.00031250            0.00015625            0.00015625 
    0.741444754160499     0.747108762937508     0.748191169284348 
           0.00015625            0.00031250            0.00015625 
    0.751436430272142     0.752533256420978     0.752674676426801 
           0.00015625            0.00015625            0.00015625 
    0.754611657443207     0.754889027400603     0.756349639135923 
           0.00125000            0.00015625            0.00015625 
    0.763526062479594     0.768717423291569     0.770997182276433 
           0.00015625            0.00015625            0.00015625 
     0.77805655959217     0.780455501601279      0.79111659134251 
           0.00015625            0.00015625            0.00015625 
    0.794424123694395     0.794542595446869     0.797594367513394 
           0.00046875            0.00015625            0.00015625 
    0.806459604893308     0.806575447067013     0.815325824113437 
           0.00015625            0.00171875            0.00031250 
    0.820054212719794     0.821566079066492     0.822735985643791 
           0.00015625            0.00015625            0.00015625 
    0.824910396049865     0.825564426121463     0.827093295015157 
           0.00015625            0.00281250            0.00015625 
    0.830498441784675     0.839706577696515     0.854374875678462 
           0.00031250            0.00015625            0.00015625 
    0.857045424718981     0.857046899457354     0.858539236690819 
           0.00031250            0.00015625            0.00109375 
    0.861958482401254     0.864973903806387     0.868060666977836 
           0.00015625            0.00031250            0.00015625 
    0.871547517399078     0.877907606552374     0.878620392468042 
           0.00015625            0.00031250            0.00015625 
    0.882079910398028     0.886773165429333     0.895872264013794 
           0.00015625            0.00015625            0.00031250 
    0.902874892971196     0.909893594892982     0.910503026314625 
           0.00015625            0.00015625            0.00015625 
    0.918355472177732     0.923930998062757     0.928610132228083 
           0.00156250            0.00015625            0.00015625 
    0.930580294371997     0.932353440099381     0.933043163131344 
           0.00015625            0.00015625            0.00015625 
    0.935865275090846     0.938721396055517      0.94732667023698 
           0.00015625            0.00015625            0.00015625 
    0.952388332756409     0.953472399517577     0.960457391255192 
           0.00046875            0.00015625            0.00015625 
    0.962466815938431     0.974608403263273     0.977273131185975 
           0.00031250            0.00015625            0.00015625 
    0.979887858238853     0.981765099822977     0.982533764258785 
           0.02546875            0.00015625            0.00015625 
    0.986421193335086     0.991131333762411      0.99464772824313 
           0.00046875            0.00015625            0.00015625 
     1.00529335053186      1.01443060556224       1.0145402019372 
           0.00015625            0.00062500            0.00015625 
     1.02257036343242      1.02480443153783      1.02810330735672 
           0.00015625            0.00015625            0.00015625 
     1.02815692332918       1.0286099206142      1.03278708868866 
           0.00265625            0.00015625            0.00015625 
     1.03867605371823      1.04030809775545      1.05026762861212 
           0.00015625            0.00046875            0.00015625 
     1.05448691449244       1.0552263521649      1.05588258974527 
           0.00125000            0.00015625            0.00015625 
     1.06000513122926      1.06639439518604      1.07107601485988 
           0.00906250            0.00078125            0.00015625 
     1.07323792501438      1.07985999257921      1.08185178624946 
           0.00015625            0.00015625            0.00015625 
     1.08200577310599      1.08501442587133      1.08924264046828 
           0.00015625            0.00015625            0.00015625 
     1.09237983879524      1.09858922192811      1.09934822043348 
           0.00015625            0.00015625            0.00015625 
      1.1078948637414      1.11407400788163      1.11835818480985 
           0.00015625            0.00015625            0.00093750 
     1.11909298650692      1.12255263564979      1.13098492845703 
           0.00125000            0.00640625            0.00718750 
     1.13520899613199      1.13659865262031      1.14324263811607 
           0.00015625            0.00031250            0.00015625 
      1.1444495252129       1.1551673045972      1.15841602768456 
           0.00578125            0.00046875            0.00015625 
     1.17032197443365      1.17077944389967      1.17660425916148 
           0.00156250            0.01546875            0.00015625 
     1.17671971786951      1.18390085758965      1.19061835680715 
           0.00031250            0.02078125            0.00078125 
     1.19124162268748      1.19491419845781      1.20187158527135 
           0.00046875            0.01000000            0.00015625 
     1.20935820034015      1.21534749252995      1.21684078311872 
           0.00015625            0.00015625            0.00015625 
     1.22228576405746      1.22358524293339       1.2307494205369 
           0.00046875            0.00375000            0.00359375 
     1.23190824585799      1.23309624815214       1.2482497077686 
           0.00015625            0.00015625            0.00015625 
     1.24914605564843      1.25030062698194      1.25167385090479 
           0.00015625            0.00015625            0.00015625 
      1.2521388586462      1.25403638767138      1.25696184836792 
           0.00015625            0.00015625            0.00015625 
     1.25865710330342      1.26219503016375      1.26339025886804 
           0.00015625            0.00015625            0.00062500 
     1.27424955368127      1.27429889692881      1.27581391381442 
           0.00062500            0.01093750            0.00015625 
     1.28103448636196      1.28422435170195      1.28502302740832 
           0.00015625            0.00015625            0.00015625 
     1.28694332261892      1.28862136579613      1.29135133286724 
           0.00015625            0.00015625            0.00015625 
     1.29271693854318      1.29352984392642      1.29416501801516 
           0.00093750            0.00015625            0.00015625 
     1.32000923372796      1.32621334330507      1.32674979912185 
           0.00015625            0.00031250            0.00031250 
      1.3355388950486      1.33819762355126      1.34572143844383 
           0.00703125            0.00015625            0.00015625 
     1.34900429115538      1.35106912963136      1.35909050306374 
           0.00015625            0.00015625            0.00015625 
     1.36740896432616      1.37732504122682      1.37817713292888 
           0.00015625            0.00015625            0.00171875 
     1.38155034894393      1.38244688032714      1.38971756538262 
           0.00015625            0.00015625            0.00015625 
     1.39337346848199      1.39481552027921      1.39920925968592 
           0.00015625            0.00015625            0.00015625 
     1.40401019415033      1.40768753122916      1.42034462702771 
           0.00015625            0.00046875            0.00031250 
     1.42884838085788      1.43014092255268      1.43175470937195 
           0.00062500            0.00078125            0.00015625 
     1.43334191774463      1.43396654425843      1.43750664054499 
           0.00046875            0.00015625            0.00015625 
     1.43754219334743       1.4388998201083      1.44153927902681 
           0.00015625            0.01625000            0.01421875 
     1.44769121849116      1.44889234688456      1.45317034273597 
           0.00015625            0.00015625            0.00015625 
     1.45756717172523      1.46514717542552      1.48152004641465 
           0.00015625            0.01359375            0.00015625 
     1.48210471217649       1.4854271336131      1.49691410201524 
           0.00187500            0.00015625            0.00031250 
     1.50460499505036          1.5159104855      1.51944062018193 
           0.00015625            0.00062500            0.00015625 
     1.51951797036384      1.52322014302823      1.52914361888698 
           0.00015625            0.00015625            0.00015625 
     1.53094696259391      1.53185854523801      1.54534195968881 
           0.00015625            0.00015625            0.00015625 
     1.55198480359028      1.55950143190504      1.56497982317259 
           0.00031250            0.00015625            0.00015625 
     1.58262031982126      1.59616721426295      1.60437565730193 
           0.00062500            0.00015625            0.00015625 
     1.61266940307664      1.61805143272205      1.63593441495235 
           0.00015625            0.00015625            0.00390625 
     1.66020775786113      1.67542635415394      1.67673538939901 
           0.00046875            0.00015625            0.00437500 
     1.68035708519021      1.68346836697786      1.68837599513398 
           0.00015625            0.00015625            0.00015625 
     1.68938234802037      1.70189867028665      1.70300688645049 
           0.00015625            0.00015625            0.00015625 
     1.70487078400102      1.71353493899627      1.72834558905075 
           0.00015625            0.00015625            0.00015625 
     1.72915591888238      1.73426417234817      1.74021109248258 
           0.00015625            0.00015625            0.00015625 
     1.74232222740301      1.74349939634561       1.7580041756475 
           0.00015625            0.00015625            0.00015625 
     1.76113921780106      1.76617520172517      1.77211632108358 
           0.00015625            0.00015625            0.00015625 
     1.77514993495452      1.79958280830507      1.81629669477704 
           0.00015625            0.00015625            0.00031250 
     1.81990457312901      1.83656963213994      1.83724270780201 
           0.00015625            0.01140625            0.00015625 
     1.84610801109783      1.87127556838068      1.87941151145041 
           0.00015625            0.00031250            0.00015625 
     1.88207392317223      1.89017691499225      1.91733288828094 
           0.00031250            0.00015625            0.00015625 
     1.94867279430132      1.95578696468731      1.95652907096428 
           0.00687500            0.00015625            0.00015625 
     1.96029188648611      1.97337415011671      1.97682872944693 
           0.00015625            0.00015625            0.00015625 
     1.97898223695928      2.01790204562771      2.04143987127407 
           0.00015625            0.00015625            0.00171875 
     2.04788306887298      2.07547273185274      2.09309957494449 
           0.00062500            0.00031250            0.00015625 
     2.09950420993508      2.10052429104874      2.10697756530747 
           0.00031250            0.00015625            0.00015625 
     2.11999156344762      2.12917389303477      2.15933629269958 
           0.00015625            0.00015625            0.00015625 
     2.18306393167287      2.18323513022319      2.18704108088277 
           0.00187500            0.00015625            0.00015625 
     2.23887211958444      2.24380917557826      2.28051444339884 
           0.00015625            0.00015625            0.00562500 
     2.28417103037285      2.30954548348617      2.34561980157645 
           0.00015625            0.00125000            0.00015625 
     2.52385907644018      3.01185818638057      3.23514293488871 
           0.00015625            0.00015625            0.00031250 
     3.52347021972545      4.91171482734768      5.33930094132038 
           0.00015625            0.00015625            0.00015625 
     6.39137994453622      6.97999767626588 
           0.00015625            0.00015625 
> 
> prop.table(table(trainClass))
trainClass
  Strong     Weak 
0.746888 0.253112 
> 
> ncol(trainDescr)
[1] 20
> 
> ## Check Near-zero
> 
> nzv <- nearZeroVar(trainDescr, saveMetrics= TRUE)
> stopifnot( all(nzv$nzv == FALSE) )
> 
> # It's imputed and behaves well, no need for this.
> # descrCorr <- cor(scale(trainDescr), use = "pairwise.complete.obs")
> 
> descrCorr <- cor(scale(trainDescr))
> 
> highCorr <- findCorrelation(descrCorr, cutoff = .95, verbose = TRUE)
Considering row	 16 column	 17 value	 0.867 
Considering row	 16 column	 10 value	 0.57 
Considering row	 16 column	 1 value	 0.271 
Considering row	 16 column	 11 value	 0.276 
Considering row	 16 column	 6 value	 0.226 
Considering row	 16 column	 12 value	 0.231 
Considering row	 16 column	 14 value	 0.245 
Considering row	 16 column	 8 value	 0.626 
Considering row	 16 column	 9 value	 0.641 
Considering row	 16 column	 2 value	 0.293 
Considering row	 16 column	 13 value	 0.166 
Considering row	 16 column	 19 value	 0.254 
Considering row	 16 column	 3 value	 0.242 
Considering row	 16 column	 18 value	 0.254 
Considering row	 16 column	 20 value	 0.179 
Considering row	 16 column	 15 value	 0.097 
Considering row	 16 column	 7 value	 0.1 
Considering row	 16 column	 5 value	 0.086 
Considering row	 16 column	 4 value	 0.008 
Considering row	 17 column	 10 value	 0.661 
Considering row	 17 column	 1 value	 0.267 
Considering row	 17 column	 11 value	 0.274 
Considering row	 17 column	 6 value	 0.212 
Considering row	 17 column	 12 value	 0.221 
Considering row	 17 column	 14 value	 0.22 
Considering row	 17 column	 8 value	 0.542 
Considering row	 17 column	 9 value	 0.573 
Considering row	 17 column	 2 value	 0.257 
Considering row	 17 column	 13 value	 0.192 
Considering row	 17 column	 19 value	 0.235 
Considering row	 17 column	 3 value	 0.272 
Considering row	 17 column	 18 value	 0.239 
Considering row	 17 column	 20 value	 0.131 
Considering row	 17 column	 15 value	 0.079 
Considering row	 17 column	 7 value	 0.103 
Considering row	 17 column	 5 value	 0.068 
Considering row	 17 column	 4 value	 0.073 
Considering row	 10 column	 1 value	 0.277 
Considering row	 10 column	 11 value	 0.284 
Considering row	 10 column	 6 value	 0.297 
Considering row	 10 column	 12 value	 0.259 
Considering row	 10 column	 14 value	 0.245 
Considering row	 10 column	 8 value	 0.412 
Considering row	 10 column	 9 value	 0.389 
Considering row	 10 column	 2 value	 0.277 
Considering row	 10 column	 13 value	 0.211 
Considering row	 10 column	 19 value	 0.183 
Considering row	 10 column	 3 value	 0.428 
Considering row	 10 column	 18 value	 0.176 
Considering row	 10 column	 20 value	 0.112 
Considering row	 10 column	 15 value	 0.332 
Considering row	 10 column	 7 value	 0.234 
Considering row	 10 column	 5 value	 0.082 
Considering row	 10 column	 4 value	 0.013 
Considering row	 1 column	 11 value	 0.987 
  Flagging column	 1 
Considering row	 11 column	 6 value	 0.944 
Considering row	 11 column	 12 value	 0.882 
Considering row	 11 column	 14 value	 0.19 
Considering row	 11 column	 8 value	 0.169 
Considering row	 11 column	 9 value	 0.128 
Considering row	 11 column	 2 value	 0.157 
Considering row	 11 column	 13 value	 0.124 
Considering row	 11 column	 19 value	 0.056 
Considering row	 11 column	 3 value	 0.069 
Considering row	 11 column	 18 value	 0.202 
Considering row	 11 column	 20 value	 0.015 
Considering row	 11 column	 15 value	 0.181 
Considering row	 11 column	 7 value	 0.143 
Considering row	 11 column	 5 value	 0.088 
Considering row	 11 column	 4 value	 0 
Considering row	 6 column	 12 value	 0.876 
Considering row	 6 column	 14 value	 0.226 
Considering row	 6 column	 8 value	 0.095 
Considering row	 6 column	 9 value	 0.019 
Considering row	 6 column	 2 value	 0.152 
Considering row	 6 column	 13 value	 0.143 
Considering row	 6 column	 19 value	 0.028 
Considering row	 6 column	 3 value	 0.067 
Considering row	 6 column	 18 value	 0.21 
Considering row	 6 column	 20 value	 0.039 
Considering row	 6 column	 15 value	 0.199 
Considering row	 6 column	 7 value	 0.112 
Considering row	 6 column	 5 value	 0.085 
Considering row	 6 column	 4 value	 0.018 
Considering row	 12 column	 14 value	 0.125 
Considering row	 12 column	 8 value	 0.101 
Considering row	 12 column	 9 value	 0.122 
Considering row	 12 column	 2 value	 0.129 
Considering row	 12 column	 13 value	 0.099 
Considering row	 12 column	 19 value	 0.035 
Considering row	 12 column	 3 value	 0.076 
Considering row	 12 column	 18 value	 0.139 
Considering row	 12 column	 20 value	 0.092 
Considering row	 12 column	 15 value	 0.166 
Considering row	 12 column	 7 value	 0.114 
Considering row	 12 column	 5 value	 0.047 
Considering row	 12 column	 4 value	 0.023 
Considering row	 14 column	 8 value	 0.137 
Considering row	 14 column	 9 value	 0.146 
Considering row	 14 column	 2 value	 0.602 
Considering row	 14 column	 13 value	 0.712 
Considering row	 14 column	 19 value	 0.072 
Considering row	 14 column	 3 value	 0.137 
Considering row	 14 column	 18 value	 0.346 
Considering row	 14 column	 20 value	 0.154 
Considering row	 14 column	 15 value	 0.112 
Considering row	 14 column	 7 value	 0.179 
Considering row	 14 column	 5 value	 0.062 
Considering row	 14 column	 4 value	 0.237 
Considering row	 8 column	 9 value	 0.468 
Considering row	 8 column	 2 value	 0.197 
Considering row	 8 column	 13 value	 0.106 
Considering row	 8 column	 19 value	 0.289 
Considering row	 8 column	 3 value	 0.209 
Considering row	 8 column	 18 value	 0.147 
Considering row	 8 column	 20 value	 0.194 
Considering row	 8 column	 15 value	 0.073 
Considering row	 8 column	 7 value	 0.111 
Considering row	 8 column	 5 value	 0.025 
Considering row	 8 column	 4 value	 0.021 
Considering row	 9 column	 2 value	 0.383 
Considering row	 9 column	 13 value	 0.092 
Considering row	 9 column	 19 value	 0.247 
Considering row	 9 column	 3 value	 0.275 
Considering row	 9 column	 18 value	 0.046 
Considering row	 9 column	 20 value	 0.149 
Considering row	 9 column	 15 value	 0.078 
Considering row	 9 column	 7 value	 0.082 
Considering row	 9 column	 5 value	 0.09 
Considering row	 9 column	 4 value	 0.02 
Considering row	 2 column	 13 value	 0.586 
Considering row	 2 column	 19 value	 0.014 
Considering row	 2 column	 3 value	 0.289 
Considering row	 2 column	 18 value	 0.123 
Considering row	 2 column	 20 value	 0.11 
Considering row	 2 column	 15 value	 0.096 
Considering row	 2 column	 7 value	 0.009 
Considering row	 2 column	 5 value	 0.015 
Considering row	 2 column	 4 value	 0.221 
Considering row	 13 column	 19 value	 0.067 
Considering row	 13 column	 3 value	 0.201 
Considering row	 13 column	 18 value	 0.155 
Considering row	 13 column	 20 value	 0.132 
Considering row	 13 column	 15 value	 0.146 
Considering row	 13 column	 7 value	 0.121 
Considering row	 13 column	 5 value	 0.05 
Considering row	 13 column	 4 value	 0.23 
Considering row	 19 column	 3 value	 0.132 
Considering row	 19 column	 18 value	 0.12 
Considering row	 19 column	 20 value	 0.849 
Considering row	 19 column	 15 value	 0.098 
Considering row	 19 column	 7 value	 0.078 
Considering row	 19 column	 5 value	 0.159 
Considering row	 19 column	 4 value	 0.049 
Considering row	 3 column	 18 value	 0.059 
Considering row	 3 column	 20 value	 0.03 
Considering row	 3 column	 15 value	 0.033 
Considering row	 3 column	 7 value	 0.151 
Considering row	 3 column	 5 value	 0.108 
Considering row	 3 column	 4 value	 0.107 
Considering row	 18 column	 20 value	 0.027 
Considering row	 18 column	 15 value	 0.12 
Considering row	 18 column	 7 value	 0.107 
Considering row	 18 column	 5 value	 0.001 
Considering row	 18 column	 4 value	 0.084 
Considering row	 20 column	 15 value	 0.037 
Considering row	 20 column	 7 value	 0.085 
Considering row	 20 column	 5 value	 0.129 
Considering row	 20 column	 4 value	 0.044 
Considering row	 15 column	 7 value	 0.016 
Considering row	 15 column	 5 value	 0.051 
Considering row	 15 column	 4 value	 0.022 
Considering row	 7 column	 5 value	 0.066 
Considering row	 7 column	 4 value	 0.041 
Considering row	 5 column	 4 value	 0.243 
> 
> # I've switched off the correlation remover and the results are better.
> if (sum(highCorr) > 0) {
+     warning("overfitting: correlations: ", paste(colnames(trainDescr)[highCorr], collapse = ", ") )
+     err.trainDescr <- trainDescr
+     trainDescr <- trainDescr[,-highCorr]
+ }
Warning message:
overfitting: correlations: SDEPHR 
> 
> descrCorr <- cor(trainDescr)
> summary(descrCorr[upper.tri(descrCorr)])
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
-0.86700 -0.13790 -0.01566  0.01904  0.13020  0.94360 
> 
> ## Dominant correlations
> ## At 0.9, there are some big ones that might need re-thinking.
> 
> table.descrCorr <- as.data.frame(as.table(descrCorr))
> table.descrCorr <- table.descrCorr[which(table.descrCorr$Var1 != table.descrCorr$Var2),]
> table.descrCorr[order(abs(table.descrCorr$Freq), decreasing = TRUE),]
              Var1           Var2          Freq
86       DEPBUCKET          AVGSQ  0.9436172014
176          AVGSQ      DEPBUCKET  0.9436172014
182      ARRBUCKET      DEPBUCKET  0.8824389879
200      DEPBUCKET      ARRBUCKET  0.8824389879
87       ARRBUCKET          AVGSQ  0.8759944089
195          AVGSQ      ARRBUCKET  0.8759944089
282       ARRSPOKE       DEPSPOKE -0.8669785554
300       DEPSPOKE       ARRSPOKE -0.8669785554
342   xAVGSKDAVAIL   xAVAILBUCKET  0.8494561477
360   xAVAILBUCKET   xAVGSKDAVAIL  0.8494561477
222     TRNRANKGRP     DEPRANKGRP  0.7123936016
240     DEPRANKGRP     TRNRANKGRP  0.7123936016
168       ARRSPOKE DOWNLINEATCIMP  0.6606389606
294 DOWNLINEATCIMP       ARRSPOKE  0.6606389606
148       DEPSPOKE   DEPSTAATCIMP  0.6410854714
274   DEPSTAATCIMP       DEPSPOKE  0.6410854714
129       DEPSPOKE   UPLINEATCIMP -0.6263003047
273   UPLINEATCIMP       DEPSPOKE -0.6263003047
13      TRNRANKGRP      SKDDEPSTA  0.6016994885
229      SKDDEPSTA     TRNRANKGRP  0.6016994885
12      DEPRANKGRP      SKDDEPSTA  0.5857295450
210      SKDDEPSTA     DEPRANKGRP  0.5857295450
149       ARRSPOKE   DEPSTAATCIMP -0.5729891892
293   DEPSTAATCIMP       ARRSPOKE -0.5729891892
167       DEPSPOKE DOWNLINEATCIMP -0.5701530610
275 DOWNLINEATCIMP       DEPSPOKE -0.5701530610
130       ARRSPOKE   UPLINEATCIMP  0.5416679708
292   UPLINEATCIMP       ARRSPOKE  0.5416679708
122   DEPSTAATCIMP   UPLINEATCIMP -0.4683473008
140   UPLINEATCIMP   DEPSTAATCIMP -0.4683473008
28  DOWNLINEATCIMP      SKDARRSTA  0.4275176187
154      SKDARRSTA DOWNLINEATCIMP  0.4275176187
123 DOWNLINEATCIMP   UPLINEATCIMP  0.4124065350
159   UPLINEATCIMP DOWNLINEATCIMP  0.4124065350
142 DOWNLINEATCIMP   DEPSTAATCIMP -0.3886731631
160   DEPSTAATCIMP DOWNLINEATCIMP -0.3886731631
8     DEPSTAATCIMP      SKDDEPSTA  0.3832198201
134      SKDDEPSTA   DEPSTAATCIMP  0.3832198201
245         xDURN2     TRNRANKGRP  0.3462878006
317     TRNRANKGRP         xDURN2  0.3462878006
166     ARRRANKGRP DOWNLINEATCIMP -0.3321061029
256 DOWNLINEATCIMP     ARRRANKGRP -0.3321061029
85  DOWNLINEATCIMP          AVGSQ  0.2966710969
157          AVGSQ DOWNLINEATCIMP  0.2966710969
15        DEPSPOKE      SKDDEPSTA  0.2930450627
267      SKDDEPSTA       DEPSPOKE  0.2930450627
2        SKDARRSTA      SKDDEPSTA -0.2893523493
20       SKDDEPSTA      SKDARRSTA -0.2893523493
132   xAVAILBUCKET   UPLINEATCIMP  0.2887036833
330   UPLINEATCIMP   xAVAILBUCKET  0.2887036833
162      DEPBUCKET DOWNLINEATCIMP  0.2842392037
180 DOWNLINEATCIMP      DEPBUCKET  0.2842392037
9   DOWNLINEATCIMP      SKDDEPSTA -0.2770890658
153      SKDDEPSTA DOWNLINEATCIMP -0.2770890658
186       DEPSPOKE      DEPBUCKET -0.2756199156
276      DEPBUCKET       DEPSPOKE -0.2756199156
27    DEPSTAATCIMP      SKDARRSTA -0.2754764313
135      SKDARRSTA   DEPSTAATCIMP -0.2754764313
187       ARRSPOKE      DEPBUCKET  0.2742731187
295      DEPBUCKET       ARRSPOKE  0.2742731187
35        ARRSPOKE      SKDARRSTA  0.2719516846
287      SKDARRSTA       ARRSPOKE  0.2719516846
163      ARRBUCKET DOWNLINEATCIMP  0.2592870115
199 DOWNLINEATCIMP      ARRBUCKET  0.2592870115
16        ARRSPOKE      SKDDEPSTA -0.2565693570
286      SKDDEPSTA       ARRSPOKE -0.2565693570
283         xDURN2       DEPSPOKE  0.2542373360
319       DEPSPOKE         xDURN2  0.2542373360
284   xAVAILBUCKET       DEPSPOKE -0.2541780798
338       DEPSPOKE   xAVAILBUCKET -0.2541780798
151   xAVAILBUCKET   DEPSTAATCIMP -0.2467982341
331   DEPSTAATCIMP   xAVAILBUCKET -0.2467982341
165     TRNRANKGRP DOWNLINEATCIMP -0.2454705816
237 DOWNLINEATCIMP     TRNRANKGRP -0.2454705816
243       DEPSPOKE     TRNRANKGRP  0.2448609283
279     TRNRANKGRP       DEPSPOKE  0.2448609283
42          SKDEPS         SKDEQP  0.2429005770
60          SKDEQP         SKDEPS  0.2429005770
34        DEPSPOKE      SKDARRSTA -0.2423443099
268      SKDARRSTA       DEPSPOKE -0.2423443099
302         xDURN2       ARRSPOKE -0.2389499544
320       ARRSPOKE         xDURN2 -0.2389499544
51      TRNRANKGRP         SKDEQP  0.2365841507
231         SKDEQP     TRNRANKGRP  0.2365841507
303   xAVAILBUCKET       ARRSPOKE  0.2346329905
339       ARRSPOKE   xAVAILBUCKET  0.2346329905
104 DOWNLINEATCIMP      AVGLOFATC -0.2335839997
158      AVGLOFATC DOWNLINEATCIMP -0.2335839997
205       DEPSPOKE      ARRBUCKET -0.2310858796
277      ARRBUCKET       DEPSPOKE -0.2310858796
50      DEPRANKGRP         SKDEQP  0.2297970157
212         SKDEQP     DEPRANKGRP  0.2297970157
91        DEPSPOKE          AVGSQ -0.2259049427
271          AVGSQ       DEPSPOKE -0.2259049427
89      TRNRANKGRP          AVGSQ -0.2259001592
233          AVGSQ     TRNRANKGRP -0.2259001592
3           SKDEQP      SKDDEPSTA  0.2211561793
39       SKDDEPSTA         SKDEQP  0.2211561793
206       ARRSPOKE      ARRBUCKET  0.2210457979
296      ARRBUCKET       ARRSPOKE  0.2210457979
244       ARRSPOKE     TRNRANKGRP -0.2203007134
298     TRNRANKGRP       ARRSPOKE -0.2203007134
92        ARRSPOKE          AVGSQ  0.2115736905
290          AVGSQ       ARRSPOKE  0.2115736905
164     DEPRANKGRP DOWNLINEATCIMP -0.2105541478
218 DOWNLINEATCIMP     DEPRANKGRP -0.2105541478
93          xDURN2          AVGSQ -0.2095275966
309          AVGSQ         xDURN2 -0.2095275966
26    UPLINEATCIMP      SKDARRSTA  0.2086590362
116      SKDARRSTA   UPLINEATCIMP  0.2086590362
188         xDURN2      DEPBUCKET -0.2016725747
314      DEPBUCKET         xDURN2 -0.2016725747
31      DEPRANKGRP      SKDARRSTA -0.2012356887
211      SKDARRSTA     DEPRANKGRP -0.2012356887
90      ARRRANKGRP          AVGSQ -0.1988873393
252          AVGSQ     ARRRANKGRP -0.1988873393
7     UPLINEATCIMP      SKDDEPSTA -0.1974899930
115      SKDDEPSTA   UPLINEATCIMP -0.1974899930
133   xAVGSKDAVAIL   UPLINEATCIMP  0.1944125904
349   UPLINEATCIMP   xAVGSKDAVAIL  0.1944125904
225       ARRSPOKE     DEPRANKGRP -0.1918832166
297     DEPRANKGRP       ARRSPOKE -0.1918832166
184     TRNRANKGRP      DEPBUCKET -0.1902527343
238      DEPBUCKET     TRNRANKGRP -0.1902527343
170   xAVAILBUCKET DOWNLINEATCIMP  0.1825083698
332 DOWNLINEATCIMP   xAVAILBUCKET  0.1825083698
185     ARRRANKGRP      DEPBUCKET -0.1807949563
257      DEPBUCKET     ARRRANKGRP -0.1807949563
285   xAVGSKDAVAIL       DEPSPOKE -0.1791641744
357       DEPSPOKE   xAVGSKDAVAIL -0.1791641744
108     TRNRANKGRP      AVGLOFATC  0.1785364320
234      AVGLOFATC     TRNRANKGRP  0.1785364320
169         xDURN2 DOWNLINEATCIMP -0.1757804944
313 DOWNLINEATCIMP         xDURN2 -0.1757804944
124      DEPBUCKET   UPLINEATCIMP  0.1694114316
178   UPLINEATCIMP      DEPBUCKET  0.1694114316
204     ARRRANKGRP      ARRBUCKET -0.1663215589
258      ARRBUCKET     ARRRANKGRP -0.1663215589
224       DEPSPOKE     DEPRANKGRP  0.1661897526
278     DEPRANKGRP       DEPSPOKE  0.1661897526
75    xAVAILBUCKET         SKDEPS  0.1592575409
327         SKDEPS   xAVAILBUCKET  0.1592575409
10       DEPBUCKET      SKDDEPSTA -0.1573888323
172      SKDDEPSTA      DEPBUCKET -0.1573888323
226         xDURN2     DEPRANKGRP  0.1546172935
316     DEPRANKGRP         xDURN2  0.1546172935
247   xAVGSKDAVAIL     TRNRANKGRP  0.1543973696
355     TRNRANKGRP   xAVGSKDAVAIL  0.1543973696
5            AVGSQ      SKDDEPSTA -0.1519958619
77       SKDDEPSTA          AVGSQ -0.1519958619
25       AVGLOFATC      SKDARRSTA -0.1513168864
97       SKDARRSTA      AVGLOFATC -0.1513168864
152   xAVGSKDAVAIL   DEPSTAATCIMP -0.1486910072
350   DEPSTAATCIMP   xAVGSKDAVAIL -0.1486910072
131         xDURN2   UPLINEATCIMP -0.1472964706
311   UPLINEATCIMP         xDURN2 -0.1472964706
146     TRNRANKGRP   DEPSTAATCIMP -0.1463023231
236   DEPSTAATCIMP     TRNRANKGRP -0.1463023231
223     ARRRANKGRP     DEPRANKGRP  0.1461231641
259     DEPRANKGRP     ARRRANKGRP  0.1461231641
105      DEPBUCKET      AVGLOFATC -0.1427717222
177      AVGLOFATC      DEPBUCKET -0.1427717222
88      DEPRANKGRP          AVGSQ -0.1427427690
214          AVGSQ     DEPRANKGRP -0.1427427690
207         xDURN2      ARRBUCKET -0.1387742725
315      ARRBUCKET         xDURN2 -0.1387742725
127     TRNRANKGRP   UPLINEATCIMP -0.1369384832
235   UPLINEATCIMP     TRNRANKGRP -0.1369384832
32      TRNRANKGRP      SKDARRSTA -0.1366878519
230      SKDARRSTA     TRNRANKGRP -0.1366878519
228   xAVGSKDAVAIL     DEPRANKGRP  0.1322388960
354     DEPRANKGRP   xAVGSKDAVAIL  0.1322388960
37    xAVAILBUCKET      SKDARRSTA  0.1320598063
325      SKDARRSTA   xAVAILBUCKET  0.1320598063
304   xAVGSKDAVAIL       ARRSPOKE  0.1312389745
358       ARRSPOKE   xAVGSKDAVAIL  0.1312389745
11       ARRBUCKET      SKDDEPSTA -0.1292069036
191      SKDDEPSTA      ARRBUCKET -0.1292069036
76    xAVGSKDAVAIL         SKDEPS  0.1290642104
346         SKDEPS   xAVGSKDAVAIL  0.1290642104
143      DEPBUCKET   DEPSTAATCIMP -0.1284415703
179   DEPSTAATCIMP      DEPBUCKET -0.1284415703
203     TRNRANKGRP      ARRBUCKET -0.1251244863
239      ARRBUCKET     TRNRANKGRP -0.1251244863
183     DEPRANKGRP      DEPBUCKET -0.1239882754
219      DEPBUCKET     DEPRANKGRP -0.1239882754
17          xDURN2      SKDDEPSTA  0.1225526684
305      SKDDEPSTA         xDURN2  0.1225526684
144      ARRBUCKET   DEPSTAATCIMP -0.1217839284
198   DEPSTAATCIMP      ARRBUCKET -0.1217839284
107     DEPRANKGRP      AVGLOFATC  0.1212460139
215      AVGLOFATC     DEPRANKGRP  0.1212460139
264         xDURN2     ARRRANKGRP  0.1197637732
318     ARRRANKGRP         xDURN2  0.1197637732
322   xAVAILBUCKET         xDURN2 -0.1196105635
340         xDURN2   xAVAILBUCKET -0.1196105635
106      ARRBUCKET      AVGLOFATC -0.1142709272
196      AVGLOFATC      ARRBUCKET -0.1142709272
242     ARRRANKGRP     TRNRANKGRP  0.1124548664
260     TRNRANKGRP     ARRRANKGRP  0.1124548664
171   xAVGSKDAVAIL DOWNLINEATCIMP  0.1122021903
351 DOWNLINEATCIMP   xAVGSKDAVAIL  0.1122021903
82       AVGLOFATC          AVGSQ -0.1117245790
100          AVGSQ      AVGLOFATC -0.1117245790
102   UPLINEATCIMP      AVGLOFATC -0.1111026529
120      AVGLOFATC   UPLINEATCIMP -0.1111026529
19    xAVGSKDAVAIL      SKDDEPSTA  0.1103370848
343      SKDDEPSTA   xAVGSKDAVAIL  0.1103370848
23          SKDEPS      SKDARRSTA -0.1075315078
59       SKDARRSTA         SKDEPS -0.1075315078
112         xDURN2      AVGLOFATC -0.1071763905
310      AVGLOFATC         xDURN2 -0.1071763905
22          SKDEQP      SKDARRSTA  0.1069279831
40       SKDARRSTA         SKDEQP  0.1069279831
126     DEPRANKGRP   UPLINEATCIMP -0.1060427386
216   UPLINEATCIMP     DEPRANKGRP -0.1060427386
111       ARRSPOKE      AVGLOFATC -0.1031636516
291      AVGLOFATC       ARRSPOKE -0.1031636516
125      ARRBUCKET   UPLINEATCIMP  0.1005040141
197   UPLINEATCIMP      ARRBUCKET  0.1005040141
110       DEPSPOKE      AVGLOFATC  0.1003783131
272      AVGLOFATC       DEPSPOKE  0.1003783131
202     DEPRANKGRP      ARRBUCKET -0.0986950696
220      ARRBUCKET     DEPRANKGRP -0.0986950696
265   xAVAILBUCKET     ARRRANKGRP -0.0984458532
337     ARRRANKGRP   xAVAILBUCKET -0.0984458532
262       DEPSPOKE     ARRRANKGRP  0.0971101492
280     ARRRANKGRP       DEPSPOKE  0.0971101492
14      ARRRANKGRP      SKDDEPSTA  0.0957939692
248      SKDDEPSTA     ARRRANKGRP  0.0957939692
83    UPLINEATCIMP          AVGSQ  0.0948326996
119          AVGSQ   UPLINEATCIMP  0.0948326996
145     DEPRANKGRP   DEPSTAATCIMP  0.0917362584
217   DEPSTAATCIMP     DEPRANKGRP  0.0917362584
209   xAVGSKDAVAIL      ARRBUCKET -0.0916395464
353      ARRBUCKET   xAVGSKDAVAIL -0.0916395464
65    DEPSTAATCIMP         SKDEPS -0.0897016196
137         SKDEPS   DEPSTAATCIMP -0.0897016196
67       DEPBUCKET         SKDEPS -0.0882188049
175         SKDEPS      DEPBUCKET -0.0882188049
72        DEPSPOKE         SKDEPS  0.0864184227
270         SKDEPS       DEPSPOKE  0.0864184227
114   xAVGSKDAVAIL      AVGLOFATC -0.0851661321
348      AVGLOFATC   xAVGSKDAVAIL -0.0851661321
62           AVGSQ         SKDEPS -0.0849060910
80          SKDEPS          AVGSQ -0.0849060910
55          xDURN2         SKDEQP  0.0840845054
307         SKDEQP         xDURN2  0.0840845054
66  DOWNLINEATCIMP         SKDEPS -0.0824852879
156         SKDEPS DOWNLINEATCIMP -0.0824852879
103   DEPSTAATCIMP      AVGLOFATC -0.0820952353
139      AVGLOFATC   DEPSTAATCIMP -0.0820952353
263       ARRSPOKE     ARRRANKGRP -0.0786667163
299     ARRRANKGRP       ARRSPOKE -0.0786667163
147     ARRRANKGRP   DEPSTAATCIMP  0.0781721020
255   DEPSTAATCIMP     ARRRANKGRP  0.0781721020
113   xAVAILBUCKET      AVGLOFATC -0.0776637909
329      AVGLOFATC   xAVAILBUCKET -0.0776637909
30       ARRBUCKET      SKDARRSTA  0.0759279051
192      SKDARRSTA      ARRBUCKET  0.0759279051
54        ARRSPOKE         SKDEQP  0.0733208602
288         SKDEQP       ARRSPOKE  0.0733208602
128     ARRRANKGRP   UPLINEATCIMP -0.0726430815
254   UPLINEATCIMP     ARRRANKGRP -0.0726430815
246   xAVAILBUCKET     TRNRANKGRP  0.0715839202
336     TRNRANKGRP   xAVAILBUCKET  0.0715839202
29       DEPBUCKET      SKDARRSTA  0.0685198783
173      SKDARRSTA      DEPBUCKET  0.0685198783
73        ARRSPOKE         SKDEPS -0.0682301200
289         SKDEPS       ARRSPOKE -0.0682301200
24           AVGSQ      SKDARRSTA  0.0673656454
78       SKDARRSTA          AVGSQ  0.0673656454
227   xAVAILBUCKET     DEPRANKGRP  0.0666761197
335     DEPRANKGRP   xAVAILBUCKET  0.0666761197
63       AVGLOFATC         SKDEPS  0.0664222939
99          SKDEPS      AVGLOFATC  0.0664222939
70      TRNRANKGRP         SKDEPS  0.0618832558
232         SKDEPS     TRNRANKGRP  0.0618832558
36          xDURN2      SKDARRSTA  0.0591080250
306      SKDARRSTA         xDURN2  0.0591080250
189   xAVAILBUCKET      DEPBUCKET  0.0563810925
333      DEPBUCKET   xAVAILBUCKET  0.0563810925
71      ARRRANKGRP         SKDEPS  0.0512721484
251         SKDEPS     ARRRANKGRP  0.0512721484
69      DEPRANKGRP         SKDEPS  0.0500743992
213         SKDEPS     DEPRANKGRP  0.0500743992
56    xAVAILBUCKET         SKDEQP  0.0488400944
326         SKDEQP   xAVAILBUCKET  0.0488400944
68       ARRBUCKET         SKDEPS -0.0474518532
194         SKDEPS      ARRBUCKET -0.0474518532
150         xDURN2   DEPSTAATCIMP -0.0455009270
312   DEPSTAATCIMP         xDURN2 -0.0455009270
57    xAVGSKDAVAIL         SKDEQP  0.0443075653
345         SKDEQP   xAVGSKDAVAIL  0.0443075653
44       AVGLOFATC         SKDEQP  0.0409779020
98          SKDEQP      AVGLOFATC  0.0409779020
95    xAVGSKDAVAIL          AVGSQ -0.0392581085
347          AVGSQ   xAVGSKDAVAIL -0.0392581085
266   xAVGSKDAVAIL     ARRRANKGRP -0.0369486803
356     ARRRANKGRP   xAVGSKDAVAIL -0.0369486803
208   xAVAILBUCKET      ARRBUCKET -0.0350128170
334      ARRBUCKET   xAVAILBUCKET -0.0350128170
33      ARRRANKGRP      SKDARRSTA -0.0329029921
249      SKDARRSTA     ARRRANKGRP -0.0329029921
38    xAVGSKDAVAIL      SKDARRSTA  0.0295119094
344      SKDARRSTA   xAVGSKDAVAIL  0.0295119094
94    xAVAILBUCKET          AVGSQ -0.0284070072
328          AVGSQ   xAVAILBUCKET -0.0284070072
323   xAVGSKDAVAIL         xDURN2  0.0273117240
359         xDURN2   xAVGSKDAVAIL  0.0273117240
64    UPLINEATCIMP         SKDEPS -0.0247537375
118         SKDEPS   UPLINEATCIMP -0.0247537375
49       ARRBUCKET         SKDEQP -0.0227754634
193         SKDEQP      ARRBUCKET -0.0227754634
52      ARRRANKGRP         SKDEQP -0.0222304298
250         SKDEQP     ARRRANKGRP -0.0222304298
45    UPLINEATCIMP         SKDEQP -0.0213925713
117         SKDEQP   UPLINEATCIMP -0.0213925713
46    DEPSTAATCIMP         SKDEQP -0.0201791095
136         SKDEQP   DEPSTAATCIMP -0.0201791095
84    DEPSTAATCIMP          AVGSQ -0.0194885380
138          AVGSQ   DEPSTAATCIMP -0.0194885380
43           AVGSQ         SKDEQP -0.0181745537
79          SKDEQP          AVGSQ -0.0181745537
109     ARRRANKGRP      AVGLOFATC -0.0156582813
253      AVGLOFATC     ARRRANKGRP -0.0156582813
190   xAVGSKDAVAIL      DEPBUCKET  0.0154766338
352      DEPBUCKET   xAVGSKDAVAIL  0.0154766338
4           SKDEPS      SKDDEPSTA -0.0145908887
58       SKDDEPSTA         SKDEPS -0.0145908887
18    xAVAILBUCKET      SKDDEPSTA  0.0140078712
324      SKDDEPSTA   xAVAILBUCKET  0.0140078712
47  DOWNLINEATCIMP         SKDEQP -0.0131985370
155         SKDEQP DOWNLINEATCIMP -0.0131985370
6        AVGLOFATC      SKDDEPSTA -0.0093369555
96       SKDDEPSTA      AVGLOFATC -0.0093369555
53        DEPSPOKE         SKDEQP  0.0079226438
269         SKDEQP       DEPSPOKE  0.0079226438
74          xDURN2         SKDEPS -0.0009512376
308         SKDEPS         xDURN2 -0.0009512376
48       DEPBUCKET         SKDEQP  0.0003729706
174         SKDEQP      DEPBUCKET  0.0003729706
> 
> ### Models
> 
> ## Training controller
> 
> fitControl <- trainControl(## 10-fold CV
+     method = "repeatedcv",
+     number = 10,
+     ## repeated ten times
+     repeats = 10,
+     classProbs = 10,
+     summaryFunction = twoClassSummary)
> 
> ## Try many other parameters
> 
> colnames(trainDescr)
 [1] "SKDDEPSTA"      "SKDARRSTA"      "SKDEQP"         "SKDEPS"        
 [5] "AVGSQ"          "AVGLOFATC"      "UPLINEATCIMP"   "DEPSTAATCIMP"  
 [9] "DOWNLINEATCIMP" "DEPBUCKET"      "ARRBUCKET"      "DEPRANKGRP"    
[13] "TRNRANKGRP"     "ARRRANKGRP"     "DEPSPOKE"       "ARRSPOKE"      
[17] "xDURN2"         "xAVAILBUCKET"   "xAVGSKDAVAIL"  
> 
> gbmGrid <-  expand.grid(interaction.depth = c(1, 2, 3),
+                         n.trees = (1:30)*60,
+                         shrinkage = 0.1,
+                         n.minobsinnode = 20)
> 
> set.seed(107)
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "ROC",
+                  verbose = FALSE)
> gbmFit1
Stochastic Gradient Boosting 

241 samples
 19 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 216, 217, 217, 217, 217, 217, ... 

Resampling results across tuning parameters:

  interaction.depth  n.trees  ROC        Sens       Spec       ROC SD    
  1                    60     0.8082606  0.9122222  0.3857143  0.10095711
  1                   120     0.8127315  0.9011111  0.4652381  0.10031370
  1                   180     0.8171958  0.8955556  0.4909524  0.09858059
  1                   240     0.8181878  0.8933333  0.5183333  0.09836187
  1                   300     0.8132804  0.8888889  0.5214286  0.10548667
  1                   360     0.8189153  0.8888889  0.5264286  0.10575787
  1                   420     0.8162963  0.8894444  0.5350000  0.10328628
  1                   480     0.8143519  0.8844444  0.5250000  0.10815025
  1                   540     0.8145370  0.8838889  0.5154762  0.10721109
  1                   600     0.8148810  0.8850000  0.5219048  0.10943878
  1                   660     0.8141931  0.8811111  0.5254762  0.10849028
  1                   720     0.8122884  0.8755556  0.5154762  0.10889494
  1                   780     0.8120106  0.8777778  0.5235714  0.10835724
  1                   840     0.8140476  0.8755556  0.5257143  0.10757543
  1                   900     0.8130556  0.8727778  0.5288095  0.10891960
  1                   960     0.8120635  0.8716667  0.5188095  0.10927674
  1                  1020     0.8114683  0.8733333  0.5376190  0.10922218
  1                  1080     0.8106085  0.8750000  0.5328571  0.11004030
  1                  1140     0.8075397  0.8672222  0.5247619  0.11015349
  1                  1200     0.8094974  0.8711111  0.5197619  0.10911655
  1                  1260     0.8095635  0.8727778  0.5361905  0.10864493
  1                  1320     0.8100794  0.8716667  0.5311905  0.11054615
  1                  1380     0.8099868  0.8711111  0.5309524  0.11096362
  1                  1440     0.8089286  0.8661111  0.5316667  0.11096076
  1                  1500     0.8075132  0.8683333  0.5297619  0.11054572
  1                  1560     0.8083333  0.8716667  0.5261905  0.10913899
  1                  1620     0.8089021  0.8705556  0.5311905  0.11026766
  1                  1680     0.8078175  0.8705556  0.5395238  0.10973245
  1                  1740     0.8077646  0.8661111  0.5295238  0.11220264
  1                  1800     0.8095503  0.8661111  0.5311905  0.10958719
  2                    60     0.8128042  0.8950000  0.4519048  0.10234018
  2                   120     0.8132937  0.8966667  0.4959524  0.10213739
  2                   180     0.8136376  0.8961111  0.5183333  0.10096256
  2                   240     0.8106217  0.8916667  0.5200000  0.10198755
  2                   300     0.8084127  0.8916667  0.5252381  0.10953069
  2                   360     0.8074735  0.8888889  0.5283333  0.10440173
  2                   420     0.8078571  0.8911111  0.5245238  0.10565373
  2                   480     0.8086376  0.8900000  0.5088095  0.10268371
  2                   540     0.8102116  0.8877778  0.5216667  0.10545178
  2                   600     0.8100529  0.8822222  0.5285714  0.10333755
  2                   660     0.8102381  0.8838889  0.5216667  0.10128109
  2                   720     0.8100000  0.8827778  0.5311905  0.10026302
  2                   780     0.8082011  0.8783333  0.5245238  0.10452061
  2                   840     0.8082672  0.8783333  0.5266667  0.10395420
  2                   900     0.8064947  0.8788889  0.5233333  0.10474193
  2                   960     0.8039550  0.8788889  0.5230952  0.11236858
  2                  1020     0.8047619  0.8777778  0.5328571  0.10938606
  2                  1080     0.8066534  0.8783333  0.5261905  0.10582963
  2                  1140     0.8034788  0.8761111  0.5211905  0.11166711
  2                  1200     0.8046032  0.8750000  0.5211905  0.11122098
  2                  1260     0.8052646  0.8755556  0.5328571  0.10769552
  2                  1320     0.8047354  0.8783333  0.5264286  0.10803095
  2                  1380     0.8050397  0.8755556  0.5278571  0.11226088
  2                  1440     0.8034392  0.8750000  0.5278571  0.11118267
  2                  1500     0.8039021  0.8755556  0.5211905  0.11276926
  2                  1560     0.8031878  0.8733333  0.5211905  0.11186715
  2                  1620     0.8040079  0.8733333  0.5276190  0.11220075
  2                  1680     0.8037037  0.8727778  0.5164286  0.11074658
  2                  1740     0.8041799  0.8722222  0.5180952  0.11110394
  2                  1800     0.8036905  0.8716667  0.5211905  0.11115009
  3                    60     0.8069444  0.8933333  0.4514286  0.10058330
  3                   120     0.8057672  0.8933333  0.5038095  0.10516383
  3                   180     0.8073677  0.8922222  0.4938095  0.10662550
  3                   240     0.8063889  0.8922222  0.5119048  0.11350709
  3                   300     0.8097090  0.8938889  0.5240476  0.10616793
  3                   360     0.8090741  0.8894444  0.5207143  0.10134577
  3                   420     0.8082011  0.8905556  0.5204762  0.10643593
  3                   480     0.8073942  0.8877778  0.5092857  0.10610780
  3                   540     0.8080159  0.8838889  0.5192857  0.10586887
  3                   600     0.8081217  0.8850000  0.5176190  0.09953188
  3                   660     0.8091270  0.8833333  0.5161905  0.10070396
  3                   720     0.8073545  0.8811111  0.5109524  0.10671345
  3                   780     0.8091931  0.8805556  0.5176190  0.10172439
  3                   840     0.8116799  0.8794444  0.5259524  0.10201070
  3                   900     0.8102381  0.8794444  0.5211905  0.10333591
  3                   960     0.8090741  0.8794444  0.5173810  0.10058152
  3                  1020     0.8097487  0.8794444  0.5178571  0.10022451
  3                  1080     0.8087434  0.8800000  0.5242857  0.10153740
  3                  1140     0.8095238  0.8766667  0.5228571  0.10048848
  3                  1200     0.8095635  0.8772222  0.5178571  0.09787519
  3                  1260     0.8105026  0.8777778  0.5276190  0.09830261
  3                  1320     0.8109921  0.8783333  0.5304762  0.09827281
  3                  1380     0.8113095  0.8772222  0.5240476  0.09975316
  3                  1440     0.8111111  0.8811111  0.5257143  0.10060765
  3                  1500     0.8109127  0.8772222  0.5261905  0.10185894
  3                  1560     0.8108069  0.8744444  0.5276190  0.10246323
  3                  1620     0.8099206  0.8766667  0.5290476  0.10355239
  3                  1680     0.8119444  0.8766667  0.5261905  0.10050537
  3                  1740     0.8112037  0.8766667  0.5228571  0.10072105
  3                  1800     0.8113095  0.8750000  0.5214286  0.10117877
  Sens SD     Spec SD  
  0.06892002  0.2121776
  0.07840058  0.2162785
  0.08024778  0.1930081
  0.07844034  0.2019697
  0.07856742  0.2067512
  0.08206099  0.1928928
  0.08186891  0.2018733
  0.07923125  0.2005905
  0.08056378  0.2046879
  0.07945718  0.2034056
  0.08468599  0.2005300
  0.08937856  0.2063319
  0.08863600  0.2055567
  0.08508998  0.2053389
  0.08367681  0.2022089
  0.08852866  0.2033947
  0.08795809  0.2171705
  0.08841590  0.2090998
  0.08789249  0.2058191
  0.08536798  0.2097362
  0.08838769  0.2030900
  0.08566510  0.2052556
  0.08463444  0.2066127
  0.08971800  0.2000096
  0.08637545  0.1950032
  0.08638989  0.1918988
  0.08935589  0.2100265
  0.08970410  0.2142248
  0.08831711  0.2051837
  0.08689364  0.2056179
  0.07189341  0.2129045
  0.07450213  0.2239946
  0.08192982  0.2189476
  0.07871608  0.2174745
  0.08028468  0.2036627
  0.07856742  0.2110600
  0.07404040  0.2180723
  0.07490277  0.2078052
  0.07448539  0.2091905
  0.07985834  0.1979938
  0.07780783  0.2023730
  0.08125734  0.2045290
  0.08232461  0.1942111
  0.08307855  0.2009871
  0.07911312  0.2000074
  0.07792194  0.1910901
  0.08129762  0.1958063
  0.08002018  0.1996498
  0.08276273  0.1938404
  0.08182320  0.1981353
  0.08018559  0.1958063
  0.07962963  0.1865853
  0.07979585  0.1958728
  0.08105759  0.1973001
  0.08057345  0.1967141
  0.08247028  0.1967141
  0.08322290  0.1912179
  0.08330340  0.1993397
  0.08412456  0.1927510
  0.08270244  0.1891456
  0.07601826  0.2229148
  0.07435972  0.2221892
  0.07849596  0.2108951
  0.07648436  0.2035131
  0.07577796  0.2031187
  0.07635177  0.2007126
  0.08031573  0.2079255
  0.08090552  0.2039739
  0.08094983  0.1976666
  0.08513943  0.1883789
  0.08375315  0.1918505
  0.08650709  0.1986411
  0.08105759  0.1921112
  0.08506616  0.1892425
  0.08321353  0.1902324
  0.08615862  0.1946058
  0.08543186  0.1916562
  0.08675899  0.1887239
  0.08848815  0.1903836
  0.08803426  0.1931147
  0.08613871  0.1897449
  0.08566510  0.1832779
  0.08767941  0.1880100
  0.08686673  0.1851306
  0.08803426  0.1903409
  0.08779490  0.1890495
  0.09057740  0.1858376
  0.08778069  0.1858659
  0.08919001  0.1805976
  0.08981525  0.1853723

Tuning parameter 'shrinkage' was held constant at a value of 0.1

Tuning parameter 'n.minobsinnode' was held constant at a value of 20
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 360, interaction.depth =
 1, shrinkage = 0.1 and n.minobsinnode = 20. 
> 
> ## The acid test has failed. :-(
> 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
  Accuracy      Kappa 
0.59493671 0.02544333 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     40   13
    Weak       19    7
                                         
               Accuracy : 0.5949         
                 95% CI : (0.4785, 0.704)
    No Information Rate : 0.7468         
    P-Value [Acc > NIR] : 0.9990         
                                         
                  Kappa : 0.0254         
 Mcnemar's Test P-Value : 0.3768         
                                         
            Sensitivity : 0.35000        
            Specificity : 0.67797        
         Pos Pred Value : 0.26923        
         Neg Pred Value : 0.75472        
             Prevalence : 0.25316        
         Detection Rate : 0.08861        
   Detection Prevalence : 0.32911        
      Balanced Accuracy : 0.51398        
                                         
       'Positive' Class : Weak           
                                         
> 
> ## The training set is plausible - as one would hope.
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
 Accuracy     Kappa 
0.9128631 0.7604487 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    173   14
    Weak        7   47
                                          
               Accuracy : 0.9129          
                 95% CI : (0.8699, 0.9453)
    No Information Rate : 0.7469          
    P-Value [Acc > NIR] : 4.465e-11       
                                          
                  Kappa : 0.7604          
 Mcnemar's Test P-Value : 0.1904          
                                          
            Sensitivity : 0.7705          
            Specificity : 0.9611          
         Pos Pred Value : 0.8704          
         Neg Pred Value : 0.9251          
             Prevalence : 0.2531          
         Detection Rate : 0.1950          
   Detection Prevalence : 0.2241          
      Balanced Accuracy : 0.8658          
                                          
       'Positive' Class : Weak            
                                          
> jpeg(width=1024, height=640)
> trellis.par.set(caretTheme())
> plot(gbmFit1, metric = "ROC")
> dev.off()
null device 
          1 
> quit()
Save workspace image? [y/n/c]: n

Process R finished at Sat May  7 01:31:12 2016


R version 3.2.5 (2016-04-14) -- "Very, Very Secure Dishes"
Copyright (C) 2016 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> > options(STERM='iESS', str.dendrogram.last="'", editor='emacsclient', show.error.locations=TRUE)
> 
+ . + 
> ### weaves
> 
> ## Processing for flights data.
> 
> ## Following the caret vignette.
> 
> ###################################################
> ### code chunk number 1: loadLibs
> ###################################################
> library(MASS)

> library(caret)
Loading required package: lattice
Loading required package: ggplot2

> library(mlbench)

> library(pROC)
Type 'citation("pROC")' for a citation.

Attaching package: 'pROC'

The following objects are masked from 'package:stats':

    cov, smooth, var


> library(pls)

Attaching package: 'pls'

The following object is masked from 'package:caret':

    R2

The following object is masked from 'package:stats':

    loadings


> library(doMC)
Loading required package: foreach
foreach: simple, scalable parallel programming from Revolution Analytics
Use Revolution R for scalability, fault tolerance and more.
http://www.revolutionanalytics.com
Loading required package: iterators
Loading required package: parallel

> registerDoMC(cores = 4)

> options(useFancyQuotes = FALSE) 

> # Accounting info.
> getInfo <- function(what = "Suggests")
+ {
+   text <- packageDescription("caret")[what][[1]]
+   text <- gsub("\n", ", ", text, fixed = TRUE)
+   text <- gsub(">=", "$\\\\ge$", text, fixed = TRUE)
+   eachPkg <- strsplit(text, ", ", fixed = TRUE)[[1]]
+   eachPkg <- gsub(",", .... [TRUNCATED] 

> ### project-specific: begin
> ## Set-seed, load original CSV file, order it
> ## and do some simple-cleaning
> ## Various datasets 
> 
> seed.mine = 107

> set.seed(seed.mine)                     # helpful for testing

> flight <- read.csv("../bak/flight.csv")

> flight <- flight[order(flight$D00),]

> # Backup
> flight.raw <- flight

> # Check warnings
> src.adjust <- TRUE

> source(file = "flight1.R")

> # To check adjustment, there is test code in flight-nb.R
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"

> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"

> # And some deletions
> 
> t.cols <- colnames(flight)

> t.drops <- t.cols[grep("^RANK*", t.cols)]

> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])

> t.drops <- c(t.drops, "D80THPCTL")

> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]

> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR

> flight$xHNGR <- flight$xDURN < 0

> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+  .... [TRUNCATED] 

> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))

> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE

> t.cols <- colnames(flight)

> t.drops <- c("SARRHR", "xDURN")

> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]

> ## Backup
> 
> flight00 <- flight

> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]

> paste("samples in use: ", dim(flight)[1])
[1] "samples in use:  320"

> ## Take another copy - this is all we need as the training/prediction
> ## set.
> 
> flight1 <- flight

> ## Data insights
> 
> ## *Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> flight <- flight1

> ## So something is defining the behaviour.
> 
> ## Try to simplify structure
> 
> head(model.matrix(LEGTYPE ~ ., data = flight))
   (Intercept) SDEPHR SKDDEPSTAALB SKDDEPSTAAMS SKDDEPSTAANC SKDDEPSTAATT
2            1     14            0            0            0            0
5            1     11            0            0            0            0
7            1     14            0            0            0            0
13           1     13            0            0            0            0
14           1     16            0            0            0            0
17           1     15            0            0            0            0
   SKDDEPSTAAUA SKDDEPSTAAUS SKDDEPSTABDA SKDDEPSTABDL SKDDEPSTABNA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTABOI SKDDEPSTABOS SKDDEPSTABRU SKDDEPSTABUF SKDDEPSTABWI
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTACCC SKDDEPSTACDG SKDDEPSTACHS SKDDEPSTACLE SKDDEPSTACMH
2             1            0            0            0            0
5             0            0            0            0            0
7             1            0            0            0            0
13            0            0            0            0            0
14            1            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTACUN SKDDEPSTADDD SKDDEPSTADEN SKDDEPSTADFW SKDDEPSTADSM
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            1            0            0            0
   SKDDEPSTADTW SKDDEPSTADUB SKDDEPSTAEWR SKDDEPSTAFCO SKDDEPSTAFLL
2             0            0            0            0            0
5             1            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAFRA SKDDEPSTAGCM SKDDEPSTAGDL SKDDEPSTAGEG SKDDEPSTAGIG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAHNL SKDDEPSTAIAH SKDDEPSTAILM SKDDEPSTAIND SKDDEPSTAJAX
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAJFK SKDDEPSTAKOA SKDDEPSTALAS SKDDEPSTALAX SKDDEPSTALGA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTALGB SKDDEPSTALGW SKDDEPSTALHR SKDDEPSTALIH SKDDEPSTAMAD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMAN SKDDEPSTAMBJ SKDDEPSTAMCI SKDDEPSTAMCO SKDDEPSTAMDT
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMEX SKDDEPSTAMHT SKDDEPSTAMIA SKDDEPSTAMKE SKDDEPSTAMSP
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMSY SKDDEPSTAMUC SKDDEPSTAMZT SKDDEPSTANAS SKDDEPSTAOAK
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAOGG SKDDEPSTAOMA SKDDEPSTAONT SKDDEPSTAORD SKDDEPSTAORF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAPBI SKDDEPSTAPDX SKDDEPSTAPIT SKDDEPSTAPLS SKDDEPSTAPPP
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            1
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAPUJ SKDDEPSTAPVD SKDDEPSTAPVR SKDDEPSTAPWM SKDDEPSTARDU
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTARIC SKDDEPSTARNO SKDDEPSTAROC SKDDEPSTARSW SKDDEPSTASAN
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASAT SKDDEPSTASEA SKDDEPSTASFO SKDDEPSTASJC SKDDEPSTASJD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASJO SKDDEPSTASJU SKDDEPSTASLC SKDDEPSTASMF SKDDEPSTASNA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASRQ SKDDEPSTASTL SKDDEPSTASTT SKDDEPSTASXM SKDDEPSTASYR
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTATLV SKDDEPSTATPA SKDDEPSTAXHP SKDDEPSTAYEG SKDDEPSTAYVR
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAYYC SKDDEPSTAZRH SKDARRSTAALB SKDARRSTAAMS SKDARRSTAANC
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAATT SKDARRSTAAUA SKDARRSTAAUS SKDARRSTABDA SKDARRSTABDL
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTABNA SKDARRSTABOI SKDARRSTABOS SKDARRSTABRU SKDARRSTABUF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            1            0            0
17            0            0            0            0            0
   SKDARRSTABWI SKDARRSTACCC SKDARRSTACDG SKDARRSTACHS SKDARRSTACLE
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            1            0            0            0
   SKDARRSTACMH SKDARRSTACUN SKDARRSTADDD SKDARRSTADEN SKDARRSTADFW
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTADSM SKDARRSTADTW SKDARRSTADUB SKDARRSTAEWR SKDARRSTAFCO
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAFLL SKDARRSTAFRA SKDARRSTAGCM SKDARRSTAGDL SKDARRSTAGEG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAGIG SKDARRSTAHNL SKDARRSTAIAH SKDARRSTAILM SKDARRSTAIND
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAJAX SKDARRSTAJFK SKDARRSTAKOA SKDARRSTALAS SKDARRSTALAX
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTALGA SKDARRSTALGB SKDARRSTALGW SKDARRSTALHR SKDARRSTALIH
2             0            0            0            0            0
5             0            0            0            0            0
7             1            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMAD SKDARRSTAMAN SKDARRSTAMBJ SKDARRSTAMCI SKDARRSTAMCO
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMDT SKDARRSTAMEX SKDARRSTAMHT SKDARRSTAMIA SKDARRSTAMKE
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMSP SKDARRSTAMSY SKDARRSTAMUC SKDARRSTAMZT SKDARRSTANAS
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAOAK SKDARRSTAOGG SKDARRSTAOMA SKDARRSTAONT SKDARRSTAORD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            1
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAORF SKDARRSTAPBI SKDARRSTAPDX SKDARRSTAPIT SKDARRSTAPLS
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAPPP SKDARRSTAPUJ SKDARRSTAPVD SKDARRSTAPVR SKDARRSTAPWM
2             1            0            0            0            0
5             1            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTARDU SKDARRSTARIC SKDARRSTARNO SKDARRSTAROC SKDARRSTARSW
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASAN SKDARRSTASAT SKDARRSTASEA SKDARRSTASFO SKDARRSTASJC
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASJD SKDARRSTASJO SKDARRSTASJU SKDARRSTASLC SKDARRSTASMF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASNA SKDARRSTASRQ SKDARRSTASTL SKDARRSTASTT SKDARRSTASXM
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASYR SKDARRSTATLV SKDARRSTATPA SKDARRSTAXHP SKDARRSTAYEG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAYVR SKDARRSTAYYC SKDARRSTAZRH SKDEQP319 SKDEQP320 SKDEQP321
2             0            0            0         0         0         0
5             0            0            0         0         0         0
7             0            0            0         0         0         1
13            0            0            0         0         0         0
14            0            0            0         0         0         1
17            0            0            0         0         0         0
   SKDEQP332 SKDEQP333 SKDEQP734 SKDEQP75E SKDEQP75H SKDEQP767 SKDEQPA01
2          0         0         1         0         0         0         0
5          0         0         0         0         0         0         0
7          0         0         0         0         0         0         0
13         0         0         1         0         0         0         0
14         0         0         0         0         0         0         0
17         0         0         0         0         0         0         0
   SKDEQPA05 SKDEQPA19 SKDEQPA21 SKDEQPE90 SKDEPS       D00    AVGSQ AVGLOFATC
2          0         0         0         0     32 0.2500000 3.258065  3.258065
5          0         0         0         1     72 0.2916667 2.986111  3.805556
7          0         0         0         0     88 0.3295455 2.551724  3.701149
13         0         0         0         0     32 0.3750000 3.000000  3.903226
14         0         0         0         0     72 0.3750000 3.295775  3.859155
17         0         0         0         0     84 0.3809524 3.939759  3.361446
   UPLINEATCIMPLow UPLINEATCIMPMed UPLINEATCIMPMedHigh UPLINEATCIMPMedLow
2                0               1                   0                  0
5                0               0                   0                  0
7                0               0                   0                  1
13               0               1                   0                  0
14               0               0                   0                  1
17               1               0                   0                  0
   DEPSTAATCIMPLow DOWNLINEATCIMPLow AVGSKDAVAIL AVAILBUCKETA05 AVAILBUCKETA10
2                0                 0   10.903226              0              1
5                1                 0    2.000000              0              0
7                0                 0    9.647059              1              0
13               0                 0   17.354839              0              0
14               0                 0   17.057143              0              0
17               0                 0   10.621951              0              1
   AVAILBUCKETA15 AVAILBUCKETA20 AVAILBUCKETA25 AVAILBUCKETA30 AVAILBUCKETA<0
2               0              0              0              0              0
5               0              0              0              0              0
7               0              0              0              0              0
13              1              0              0              0              0
14              1              0              0              0              0
17              0              0              0              0              0
   DEPBUCKETD2 DEPBUCKETD3 DEPBUCKETD4 DEPBUCKETD5 DEPBUCKETD6 DEPBUCKETD7
2            0           0           0           1           0           0
5            0           0           1           0           0           0
7            0           0           0           1           0           0
13           0           0           0           1           0           0
14           0           0           0           0           1           0
17           0           0           0           0           1           0
   DEPBUCKETD8 ARRBUCKETA2 ARRBUCKETA3 ARRBUCKETA4 ARRBUCKETA5 ARRBUCKETA6
2            0           0           0           0           0           1
5            0           0           0           0           1           0
7            0           0           0           0           0           1
13           0           0           0           0           0           1
14           0           0           0           0           0           0
17           0           0           0           0           0           1
   ARRBUCKETA7 ARRBUCKETA8 DEPRANKGRPLow DEPRANKGRPMed DEPRANKGRPMedHigh
2            0           0             1             0                 0
5            0           0             0             1                 0
7            0           0             1             0                 0
13           0           0             0             0                 0
14           1           0             1             0                 0
17           0           0             0             0                 0
   DEPRANKGRPMedLow TRNRANKGRPLow TRNRANKGRPMed TRNRANKGRPMedHigh
2                 0             1             0                 0
5                 0             1             0                 0
7                 0             1             0                 0
13                1             0             0                 0
14                0             1             0                 0
17                1             0             1                 0
   TRNRANKGRPMedLow ARRRANKGRPLow ARRRANKGRPMed ARRRANKGRPMedHigh
2                 0             0             0                 1
5                 0             0             0                 1
7                 0             0             1                 0
13                1             0             0                 0
14                0             0             0                 1
17                0             0             0                 1
   ARRRANKGRPMedLow DEPSPOKETRUE ARRSPOKETRUE xHNGRTRUE xDURN2
2                 0            0            0         0      2
5                 0            1            0         0      2
7                 0            0            1         0      2
13                1            0            1         0      2
14                0            0            1         0      2
17                0            0            0         0      2

> dummies <- dummyVars(LEGTYPE ~ ., data = flight)

> flight.dum <- predict(dummies, newdata = flight)

> ## It may be too big to use, but useful for inspection.
> 
> ### Numeric variables
> 
> ## Check some more numeric correlations, I haven't scaled yet.
> ## I'd cut correlations above 0.75 because of overfitting.
> 
> x1 <- as.data.frame(as.matrix(sapply(flight, class)))

> flight.num <- flight[,names(x1[which(x1$V1 %in% c("numeric", "integer")),])]

> flight.nzv <- nearZeroVar(flight.num, saveMetrics = TRUE)

> flight.nzv
            freqRatio percentUnique zeroVar   nzv
SDEPHR       1.038462        5.9375   FALSE FALSE
SKDEPS       1.000000       19.0625   FALSE FALSE
D00          1.166667       75.3125   FALSE FALSE
AVGSQ        6.333333       82.8125   FALSE FALSE
AVGLOFATC    1.000000       78.4375   FALSE FALSE
AVGSKDAVAIL  1.000000       87.5000   FALSE FALSE
xDURN2       1.428571        2.5000   FALSE FALSE

> # annoying NA
> flight.cor <- cor(flight.num, use = "pairwise.complete.obs")

> descrCorr <- findCorrelation(flight.cor, cutoff = .65, verbose=TRUE)
Considering row	 1 column	 4 value	 0.956 
  Flagging column	 1 
Considering row	 4 column	 3 value	 0.414 
Considering row	 4 column	 6 value	 0.173 
Considering row	 4 column	 7 value	 0.201 
Considering row	 4 column	 5 value	 0.103 
Considering row	 4 column	 2 value	 0.082 
Considering row	 3 column	 6 value	 0.266 
Considering row	 3 column	 7 value	 0.071 
Considering row	 3 column	 5 value	 0.114 
Considering row	 3 column	 2 value	 0.006 
Considering row	 6 column	 7 value	 0.031 
Considering row	 6 column	 5 value	 0.094 
Considering row	 6 column	 2 value	 0.067 
Considering row	 7 column	 5 value	 0.137 
Considering row	 7 column	 2 value	 0.005 
Considering row	 5 column	 2 value	 0.041 

> colnames(flight.num)[descrCorr]
[1] "SDEPHR"

> ## Which tells me that departure time is very highly correlated to AVGSQ.
> ## AVGSQ is average stand queue?
> 
> ### Try and impute the AVG, it might have more information than the
> ### bucket.
> 
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))

> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1

> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]

> preProcValues <- preProcess(flight.na, method = c("knnImpute"))

> flight.na1 <- predict(preProcValues, flight.na)

> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL

> ## And I'll leave the centered and scale values in for now.
> ## and delete the troublesome ones
> 
> flight$AVGSKDAVAIL <- NULL

> flight$xHNGR <- NULL

> flight$AVAILBUCKET <- NULL

> # This should be deleted, leave it in and the results are ideal because it defines LEGTYPE.
> flight$D00 <- NULL

> ## Keep the results but don't change the order.
> outcomes.flight <- flight$LEGTYPE

> flight$LEGTYPE <- NULL

> ## If you know your factors are definitely factors, you don't need this
> ##  asNumeric <- function(x) as.numeric(as.character(x))
> 
> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))

> flight.num0 <- factors.numeric(flight)

> flight.scl0 <- scale(flight.num0)

> ## Now split the results
> 
> set.seed(seed.mine)

> inTrain <- createDataPartition(outcomes.flight, p = 0.65, list = FALSE)

> trainDescr <- flight.scl0[inTrain,]

> testDescr <- flight.scl0[-inTrain,]

> trainClass <- outcomes.flight[inTrain]

> testClass <- outcomes.flight[-inTrain]

> prop.table(table(flight.scl0))
flight.scl0
    -2.99546983996958     -2.98604368384811     -2.82110052361751 
           0.00281250            0.00015625            0.00015625 
    -2.64037641778924     -2.37742331516569     -2.09431321436608 
           0.00015625            0.00015625            0.00031250 
    -2.02525208119049     -2.02364615961949     -1.96706162425765 
           0.00046875            0.00093750            0.00015625 
    -1.94787383036273     -1.91934227796699     -1.87162293167633 
           0.00125000            0.00015625            0.00015625 
    -1.80813803757891      -1.8064397520718     -1.76880294648328 
           0.00093750            0.00093750            0.00453125 
     -1.7104004231695     -1.67620690253875     -1.63572266525187 
           0.00312500            0.00015625            0.00078125 
    -1.60554554037119     -1.58829697245811     -1.58375887562806 
           0.00265625            0.00062500            0.00031250 
    -1.56068940274137     -1.55266802930898     -1.55257138616628 
           0.00593750            0.00015625            0.00015625 
    -1.54865734259279     -1.54635333101763     -1.54295794614133 
           0.00015625            0.00015625            0.00015625 
    -1.53179508600425     -1.53074294246617     -1.50769426210174 
           0.00203125            0.00015625            0.00015625 
    -1.49330986644838     -1.47983129638045     -1.47646498237513 
           0.00015625            0.00171875            0.00015625 
    -1.44796824755814     -1.43812707979848     -1.43616463590287 
           0.00015625            0.00031250            0.00015625 
     -1.4311495031078     -1.42786750675664     -1.42754311366228 
           0.00062500            0.00031250            0.00015625 
     -1.4230237164245     -1.42196682798086     -1.40691590144974 
           0.00015625            0.00015625            0.00750000 
    -1.40295304316347     -1.39839761187043     -1.38337483337197 
           0.00343750            0.00015625            0.00015625 
    -1.37828409873765     -1.37590371713284      -1.3753288895824 
           0.00031250            0.00078125            0.00015625 
    -1.37383369560894     -1.37045453151584     -1.35466334686085 
           0.00015625            0.00015625            0.00015625 
    -1.33716625322094     -1.33398496346823     -1.33080367371552 
           0.00015625            0.00015625            0.00015625 
    -1.32393992750903      -1.3160853172316     -1.31578091655701 
           0.00093750            0.00015625            0.00015625 
    -1.31443367614047      -1.3133256164209     -1.30151560934568 
           0.00015625            0.00015625            0.00015625 
    -1.30111163600234     -1.29600486257245     -1.28619597667342 
           0.00015625            0.00031250            0.00031250 
    -1.28367748081635     -1.28186181839242      -1.2799413346293 
           0.00031250            0.00015625            0.00015625 
    -1.27197613788523     -1.26773489691459      -1.2671778786613 
           0.00109375            0.00015625            0.00015625 
     -1.2615812276646     -1.25974760485758     -1.25283365916062 
           0.00031250            0.00078125            0.00015625 
    -1.25178454113998     -1.24659260411695     -1.24079645146543 
           0.00015625            0.00015625            0.00015625 
     -1.2302338686483     -1.23020377865797      -1.2268968080815 
           0.00015625            0.00687500            0.00031250 
    -1.22001234826142     -1.21809512250389     -1.21512040999215 
           0.00046875            0.00015625            0.00015625 
    -1.21024953572476     -1.20647153886774     -1.20560405725029 
           0.00015625            0.00015625            0.00015625 
    -1.20188627600106     -1.20036054595575     -1.20011285144544 
           0.00031250            0.00140625            0.00015625 
    -1.19042311450129     -1.18991798468508     -1.18966337127103 
           0.00015625            0.00015625            0.00062500 
    -1.16804855863761     -1.16764210792351     -1.16749679150174 
           0.00093750            0.00015625            0.00015625 
    -1.16258400593847     -1.16018257780086     -1.15839829359119 
           0.00015625            0.00640625            0.00015625 
    -1.14179763548495     -1.13992628855288     -1.13935994002253 
           0.00015625            0.00031250            0.00031250 
    -1.13310730700243     -1.13102279477938     -1.12993289335973 
           0.00015625            0.00015625            0.00015625 
    -1.12915754122589     -1.12753063368423     -1.12667091460446 
           0.00015625            0.00015625            0.00015625 
    -1.12622940836933     -1.12368140470519     -1.12361616254288 
           0.00031250            0.00015625            0.00062500 
    -1.12145428351456     -1.11910330109794     -1.11800948418703 
           0.00015625            0.00015625            0.00015625 
    -1.11608476901381     -1.11429923219746     -1.09261479989672 
           0.00062500            0.00015625            0.00015625 
    -1.09084552937417     -1.09012044993392      -1.0895833019642 
           0.00015625            0.00015625            0.00031250 
    -1.08549109658463     -1.06938028371369     -1.06604781193988 
           0.00031250            0.00015625            0.00015625 
    -1.06587003530766        -1.06412097939     -1.05534288054392 
           0.00015625            0.00046875            0.00015625 
    -1.04945721011816     -1.04845626690162     -1.04766888572427 
           0.00015625            0.00015625            0.00015625 
    -1.04755297964098     -1.04598728075964     -1.04536609890991 
           0.00031250            0.00031250            0.00031250 
    -1.02993885350447     -1.02151758080685     -1.01733580186582 
           0.00015625            0.00203125            0.02453125 
    -1.01577847702439      -1.0138904262493      -1.0121571897662 
           0.00015625            0.00015625            0.00062500 
    -1.00929178081963     -1.00745946934895     -1.00714202059705 
           0.00015625            0.00015625            0.00015625 
    -1.00664275166081     -1.00407661804032     -1.00110637205939 
           0.00046875            0.00015625            0.00015625 
   -0.997768048748026    -0.991929422812267    -0.989060788495757 
           0.00328125            0.00015625            0.00031250 
    -0.98572380365604    -0.979554261682366    -0.976324799963229 
           0.00015625            0.00031250            0.00875000 
   -0.973173077974651    -0.971118460177678     -0.96975725707502 
           0.01640625            0.00015625            0.00015625 
   -0.963461694934854    -0.961159884505833    -0.960193400142389 
           0.00015625            0.00015625            0.00046875 
   -0.958010282948452    -0.957720936633644    -0.955230663538487 
           0.00015625            0.00015625            0.00015625 
   -0.953451859649493    -0.952397629449069    -0.951677411170411 
           0.00031250            0.00015625            0.01765625 
   -0.947281520180146    -0.946066444247069    -0.942123167843126 
           0.00015625            0.00015625            0.00015625 
   -0.941185041055857    -0.939666457415937    -0.937914389255748 
           0.00015625            0.00031250            0.00015625 
   -0.937428692031181    -0.937143144639067    -0.929006249994557 
           0.00015625            0.00203125            0.00031250 
   -0.928956547037233    -0.927234345076844    -0.926325405165677 
           0.00015625            0.00015625            0.00015625 
   -0.926208874394783     -0.92432711582923    -0.923751900565718 
           0.00015625            0.00015625            0.00015625 
   -0.921447647976772    -0.920026610901552    -0.919775930100724 
           0.00015625            0.00015625            0.00031250 
   -0.919418999070816    -0.918979533540974    -0.918834367344145 
           0.00093750            0.00015625            0.00015625 
   -0.918602057207572    -0.918233359080158    -0.916620305783416 
           0.00015625            0.00015625            0.00031250 
   -0.908229610518583    -0.907879271266391    -0.907626204980156 
           0.00031250            0.00015625            0.00015625 
   -0.906631706666217    -0.905610577820333    -0.905104725277818 
           0.00015625            0.00015625            0.00015625 
   -0.904170844231002    -0.902563699445797    -0.902495470961171 
           0.00031250            0.00015625            0.00046875 
   -0.902207570970879    -0.900277820755885    -0.900269127160796 
           0.00015625            0.00609375            0.00015625 
   -0.900105713501894    -0.897103060359799    -0.896252308815885 
           0.00015625            0.00015625            0.00015625 
   -0.895759768448355    -0.895685333371447    -0.891948830933419 
           0.00015625            0.00015625            0.00015625 
   -0.891482707849845     -0.89086838304768    -0.889814536282523 
           0.00015625            0.02343750            0.00015625 
   -0.886894039811436    -0.885423108336021    -0.885386138492139 
           0.00093750            0.00015625            0.01593750 
   -0.884574764423174    -0.881181388644532    -0.881133728915611 
           0.00015625            0.00015625            0.00015625 
   -0.879323305434347    -0.878872666379052    -0.877901133624378 
           0.00015625            0.00015625            0.00015625 
   -0.876749332956921    -0.876685019263073    -0.875765771148607 
           0.00031250            0.00015625            0.00031250 
   -0.875473779114446     -0.87537693015952    -0.872246314823305 
           0.00015625            0.00015625            0.00015625 
   -0.871001261435858    -0.870353841103083    -0.869162583211394 
           0.00015625            0.00015625            0.00015625 
   -0.866780745576637    -0.866244907634358    -0.858819232798091 
           0.00015625            0.00015625            0.00015625 
   -0.856265820894777    -0.844253476212177    -0.844066341550782 
           0.00078125            0.00015625            0.00015625 
   -0.842025743633279    -0.831738843759029    -0.830837909586882 
           0.02921875            0.00015625            0.02515625 
   -0.829374923233683    -0.828920190368225    -0.827915178181078 
           0.00015625            0.00093750            0.00015625 
   -0.827728686266157    -0.826039032973297    -0.822416105203804 
           0.00015625            0.00015625            0.00015625 
   -0.821797313281808    -0.819285769008092    -0.816336564086851 
           0.00015625            0.00015625            0.00015625 
   -0.814051297945908    -0.811605617460827    -0.809148421270981 
           0.00015625            0.00015625            0.00015625 
   -0.804302031270971    -0.800154571238789    -0.795175551540305 
           0.00062500            0.00015625            0.00171875 
   -0.792845872277945    -0.790185643279993    -0.789212464897955 
           0.02015625            0.00859375            0.00046875 
   -0.787996109659257    -0.785742695872334    -0.783287556756109 
           0.00015625            0.00015625            0.00015625 
    -0.78222517242437    -0.777611190965241    -0.777259256743858 
           0.00015625            0.00015625            0.00015625 
   -0.775052088417874    -0.768725111385422      -0.7653899578722 
           0.00031250            0.00015625            0.00015625 
   -0.764328853007072    -0.759372004638613    -0.759121665238872 
           0.00015625            0.00015625            0.00015625 
   -0.758171518227594    -0.752387355098689    -0.752338241647165 
           0.00015625            0.00015625            0.00031250 
   -0.751716727129916    -0.750007134146443    -0.748171465050933 
           0.00015625            0.00562500            0.00015625 
   -0.743693425437366     -0.74226506946404    -0.738477819728135 
           0.00718750            0.00015625            0.00015625 
   -0.735940818773818    -0.734501921638923    -0.723911474638978 
           0.00015625            0.00015625            0.00015625 
   -0.720697236097384    -0.718445199078953    -0.715142805531928 
           0.00031250            0.00015625            0.00031250 
   -0.713461500253351    -0.710452171936934    -0.708684788599593 
           0.00015625            0.00015625            0.00015625 
   -0.708003561812545    -0.702080356630785     -0.70037445202336 
           0.00015625            0.00015625            0.00203125 
    -0.69602539257426     -0.69280361708918    -0.687853983052082 
           0.00015625            0.03375000            0.00015625 
    -0.68694861300278    -0.684622918007104    -0.682222958529648 
           0.00015625            0.00015625            0.00015625 
   -0.681188975020078    -0.673798181086569     -0.66884926915034 
           0.00187500            0.00015625            0.00015625 
     -0.6653122497357    -0.654779601264497    -0.648410662399554 
           0.00015625            0.00015625            0.00078125 
   -0.647068571912601    -0.646559789740211    -0.633905116384853 
           0.00015625            0.00015625            0.00015625 
   -0.633276439235621    -0.626480919280269    -0.624813955253419 
           0.00015625            0.00015625            0.00015625 
   -0.621563193776932    -0.615573756562581    -0.613123253862724 
           0.00015625            0.00015625            0.00171875 
   -0.604038319371604    -0.596446872775748    -0.596237216599971 
           0.00015625            0.00046875            0.00015625 
   -0.596137826610777    -0.592583054332584    -0.590968847296576 
           0.00015625            0.00359375            0.00015625 
   -0.581016668721787     -0.57842864719944    -0.577046832499099 
           0.00015625            0.00015625            0.00015625 
   -0.576399963736262    -0.567294133064953    -0.562646449882806 
           0.00187500            0.00015625            0.00031250 
   -0.559949234902497    -0.553868745195444    -0.551562209118441 
           0.00031250            0.00015625            0.00859375 
   -0.548486073402725    -0.545057532705371    -0.544483083151942 
           0.00015625            0.00046875            0.00093750 
   -0.543553164656681    -0.542887786706365    -0.542791834600063 
           0.00015625            0.00015625            0.03859375 
   -0.535816263171991    -0.529620965141671    -0.523583345339874 
           0.00031250            0.00015625            0.00015625 
   -0.522876883678594    -0.515144874010522    -0.511242837482551 
           0.00015625            0.00015625            0.00015625 
   -0.511062050911504    -0.509452501139644    -0.507981951223969 
           0.00500000            0.00015625            0.00015625 
   -0.506004946851197    -0.504251327555701    -0.503668338010739 
           0.00015625            0.00203125            0.00015625 
   -0.497665904683127    -0.492519293528136    -0.488304476973275 
           0.00015625            0.00062500            0.00015625 
   -0.486275884354524    -0.480531685495119    -0.479070530598709 
           0.00015625            0.00015625            0.00015625 
   -0.476991811548017    -0.475764665500524    -0.473473045518126 
           0.00078125            0.00015625            0.00015625 
   -0.472612890303562    -0.464757185992567    -0.456186401194196 
           0.00015625            0.00015625            0.00015625 
   -0.454553689487183    -0.453074332488957    -0.452195518537862 
           0.00015625            0.00015625            0.00015625 
   -0.450040882361118    -0.446015592229304    -0.443168278929009 
           0.00015625            0.00015625            0.00015625 
    -0.44055550390433    -0.439275967288811    -0.439064986884659 
           0.00093750            0.00015625            0.00031250 
   -0.436572045333686    -0.433356062339654     -0.43210269137514 
           0.00015625            0.00015625            0.00031250 
   -0.429159183376661     -0.42811270638386    -0.424489571114943 
           0.00015625            0.00015625            0.00015625 
   -0.424136094192972    -0.422368710855631    -0.422286506964679 
           0.00015625            0.00015625            0.00015625 
     -0.4217879739841     -0.42160028367728    -0.408926090390664 
           0.00015625            0.00015625            0.00062500 
   -0.406238662084726    -0.405337563546837    -0.402845924603104 
           0.00015625            0.00015625            0.00015625 
   -0.398392401687235    -0.392753100892855    -0.392721940787981 
           0.00015625            0.00015625            0.00015625 
   -0.389990557124863    -0.383778543291898    -0.381829344162238 
           0.00203125            0.00031250            0.00031250 
   -0.378610740922975    -0.377352421209284     -0.37278098800314 
           0.00015625            0.00015625            0.00015625 
   -0.368704530397105    -0.364033384865912    -0.363121805899083 
           0.00015625            0.00015625            0.00015625 
   -0.361905601371654    -0.360992312891898     -0.36077985218898 
           0.00015625            0.00015625            0.00015625 
    -0.35995405519458    -0.354602189779798    -0.354221703071568 
           0.00046875            0.00015625            0.00015625 
   -0.354125613590753     -0.35383985286255    -0.350820163721666 
           0.00015625            0.00015625            0.00015625 
   -0.347880750045415    -0.347682518083072    -0.344794514479224 
           0.00031250            0.00015625            0.00015625 
   -0.344246401931106    -0.340586009596143    -0.338241270869783 
           0.00015625            0.00015625            0.00031250 
   -0.336627924656718    -0.333999550987416    -0.331679860754818 
           0.00015625            0.00015625            0.00015625 
   -0.327473828580897    -0.325591270635287    -0.320604647133837 
           0.00015625            0.00015625            0.00015625 
   -0.320293393650012    -0.318998347766866    -0.313800886365509 
           0.00015625            0.00015625            0.00015625 
   -0.308729731711204     -0.30775968479621    -0.307488803472333 
           0.00015625            0.00062500            0.00015625 
   -0.305912488397539    -0.300040013990283    -0.299281804870489 
           0.00015625            0.00015625            0.00015625 
   -0.297576089117692    -0.294612153988498    -0.290886990303406 
           0.00015625            0.00015625            0.00015625 
   -0.289476667647491    -0.287805419014019    -0.284664135032912 
           0.00015625            0.00031250            0.00062500 
   -0.283279035792871    -0.278947445070673    -0.278430676385642 
           0.00015625            0.00015625            0.01140625 
   -0.277028655971768    -0.274352800845479    -0.269810489634915 
           0.00015625            0.00015625            0.00875000 
   -0.268327804913194    -0.264273008183568    -0.263991250766728 
           0.00015625            0.00015625            0.00015625 
   -0.263633329101249    -0.256569345435893    -0.255210887064625 
           0.00015625            0.00015625            0.00015625 
   -0.254264930167697    -0.253205544043426    -0.250717006205447 
           0.00015625            0.00015625            0.00015625 
   -0.250531752899298    -0.249985351299549    -0.247578088366761 
           0.00015625            0.00015625            0.00015625 
   -0.244437996150226    -0.243268618233703    -0.242824942853484 
           0.00015625            0.00015625            0.00015625 
   -0.233740722783471    -0.232700345409106    -0.232349973253986 
           0.00015625            0.00015625            0.00015625 
   -0.231815214890401    -0.231309362347886     -0.23037548130107 
           0.00015625            0.00015625            0.00015625 
   -0.228412208040947    -0.226589859802479    -0.224837647995068 
           0.00015625            0.01656250            0.00015625 
   -0.223464759128966     -0.22331717855311    -0.222588752387258 
           0.00015625            0.00015625            0.00015625 
   -0.222456945885953    -0.220222816737245    -0.217487288707678 
           0.00015625            0.00031250            0.00046875 
   -0.216388232760497    -0.213098676881504    -0.212807560710942 
           0.00015625            0.00093750            0.00015625 
   -0.205527942504415    -0.202889656333141    -0.199061273711729 
           0.00015625            0.00015625            0.00015625 
   -0.197285663071406    -0.196655198635886    -0.187398059917142 
           0.00015625            0.00015625            0.00328125 
    -0.18553936273967    -0.184426534107832      -0.1807365557853 
           0.00015625            0.00015625            0.00031250 
   -0.173455385110242    -0.170696066339926    -0.167983070845547 
           0.00953125            0.00062500            0.00015625 
    -0.16706735776498     -0.16549287956689    -0.163323851054559 
           0.00015625            0.00015625            0.00015625 
   -0.163005226779217    -0.155721964916119     -0.15557956030375 
           0.00015625            0.00015625            0.00015625 
   -0.145050220201077    -0.140627037006184    -0.136663205761249 
           0.00015625            0.00015625            0.00015625 
   -0.135547666352963    -0.135353058341049    -0.135168941442998 
           0.00015625            0.00015625            0.00015625 
    -0.13422823788067    -0.128983100398563    -0.128772766161494 
           0.00015625            0.00015625            0.00062500 
   -0.128276147190878    -0.124732071896041    -0.122750748897942 
           0.00015625            0.00015625            0.00015625 
   -0.121913567685457    -0.114572129500928    -0.113273027561381 
           0.00015625            0.00015625            0.00015625 
   -0.107405286684043    -0.105529863556612    -0.103356043915892 
           0.00015625            0.00953125            0.00015625 
  -0.0959919473132286   -0.0946576344451732   -0.0921610479659292 
           0.00015625            0.00031250            0.00015625 
  -0.0897276946329045    -0.082082912166815   -0.0820786945748793 
           0.00015625            0.00015625            0.00031250 
  -0.0807439358161152   -0.0768089765376881   -0.0759616047321375 
           0.00015625            0.00140625            0.00015625 
  -0.0741942213947964   -0.0733788467156504   -0.0726315828860554 
           0.00015625            0.00718750            0.00015625 
  -0.0685974846038955   -0.0532150311664168   -0.0498043335027671 
           0.00093750            0.00015625            0.00015625 
  -0.0497543467601004   -0.0473016251818649   -0.0451490777305966 
           0.00015625            0.00015625            0.00031250 
  -0.0446498361490209   -0.0392160026639466   -0.0373582346840002 
           0.00015625            0.00015625            0.00015625 
  -0.0352851923820555   -0.0345646240252186   -0.0326438116903773 
           0.00031250            0.00031250            0.00015625 
  -0.0248451869138821   -0.0188880173129063    -0.013807090586871 
           0.00109375            0.00015625            0.00015625 
  -0.0119657325121257   -0.0114810502208166  -0.00721676013122688 
           0.00015625            0.00015625            0.00015625 
 -0.00368424503602545 -0.000580656453063986   0.00425466589044258 
           0.00015625            0.00015625            0.00015625 
  0.00624696207963468   0.00661720265702806    0.0104887638020741 
           0.00015625            0.00015625            0.00015625 
   0.0151944372905789    0.0177528116242494    0.0194770878491831 
           0.00421875            0.00015625            0.00015625 
   0.0217087977522383    0.0235168212825711    0.0255537765734798 
           0.00015625            0.00015625            0.00015625 
   0.0264730080152699    0.0271186027099238    0.0361351573082595 
           0.00015625            0.00031250            0.00015625 
   0.0362911121323546    0.0368634437985054    0.0454309894047899 
           0.00015625            0.00015625            0.00015625 
   0.0533298995579193    0.0570581595639766    0.0585759323236618 
           0.00015625            0.00937500            0.00015625 
   0.0675339577108118    0.0702113818864803    0.0729377618887858 
           0.00046875            0.00015625            0.00062500 
   0.0788793134968683    0.0789059252411879    0.0790823923337298 
           0.00015625            0.02343750            0.00046875 
   0.0797510873183287    0.0806069942083428    0.0841639835120876 
           0.00015625            0.00015625            0.00015625 
   0.0899621750174284    0.0966606496804153    0.0972018193465008 
           0.00015625            0.00015625            0.00015625 
    0.101566818289489     0.108411810410797     0.109012079979066 
           0.00062500            0.00015625            0.00046875 
     0.11244290268093     0.119444894039026     0.131046181957536 
           0.00015625            0.00015625            0.00203125 
    0.134889340170799     0.135028927523559     0.136658265622521 
           0.00015625            0.00015625            0.00015625 
    0.144157938789208     0.146258849789861     0.147318188850963 
           0.00015625            0.00015625            0.02984375 
    0.151115033119933     0.152349655315244     0.154426066228552 
           0.00015625            0.00015625            0.00015625 
     0.15737266071083     0.162873929857665     0.162973153669365 
           0.00015625            0.00015625            0.00015625 
    0.164891939398059     0.165580765616732     0.173693095305534 
           0.00015625            0.00015625            0.00015625 
    0.183009971581342     0.186789363756051     0.187969991368742 
           0.00093750            0.00015625            0.00015625 
    0.192709893790261     0.194724832331223     0.194735738184732 
           0.00015625            0.00015625            0.00015625 
    0.195991364801127     0.206802781312992     0.210386154876613 
           0.00015625            0.00015625            0.00500000 
    0.217235034249908       0.2177869344983     0.234906769563277 
           0.00031250            0.00203125            0.00015625 
    0.234973761205148     0.238837237065174     0.241127733319099 
           0.00031250            0.00015625            0.00015625 
    0.250135635132824      0.25028785413495     0.253309352340188 
           0.00015625            0.00015625            0.00078125 
    0.254814769298151     0.260835355687548     0.264960519475955 
           0.00015625            0.00015625            0.00015625 
    0.266044692238248      0.27127954776092     0.273304013334367 
           0.00015625            0.00015625            0.00015625 
    0.273531307307048     0.274822103147971     0.280770740587068 
           0.00015625            0.00015625            0.00015625 
    0.284591080073122     0.285810915205503     0.286937550828954 
           0.00015625            0.00015625            0.00046875 
    0.289640625615739     0.301307082566931     0.302882181759369 
           0.00015625            0.00015625            0.00015625 
    0.304256560508303     0.309710068792923     0.311251030414092 
           0.00015625            0.00015625            0.00015625 
    0.311802268812853     0.318128929047187     0.318922298138204 
           0.00015625            0.00031250            0.00015625 
    0.320852365313198     0.322875645177539     0.334350357273903 
           0.00015625            0.00015625            0.00015625 
    0.337167536402539     0.338400625416362     0.338901340452759 
           0.00015625            0.00031250            0.00140625 
    0.346939027258188     0.348766831423466     0.358991725758732 
           0.00015625            0.00015625            0.00015625 
    0.364034892089946     0.365884194608935     0.368674799710984 
           0.00015625            0.00015625            0.00015625 
    0.369643258716518     0.373829702918903     0.379821273586168 
           0.00015625            0.00062500            0.00015625 
    0.382087226815338      0.38685609839469       0.3878539441829 
           0.00015625            0.00015625            0.00015625 
     0.38923354153609     0.390865130076565     0.393785793790202 
           0.00015625            0.00093750            0.00015625 
    0.402956322412276     0.404247945632944      0.40569298299336 
           0.00015625            0.00015625            0.00015625 
    0.406064629649282      0.40786256349758     0.408056423319527 
           0.00015625            0.00109375            0.00015625 
    0.412247177017014     0.414419483912049     0.416346031539166 
           0.00015625            0.00046875            0.00015625 
     0.41794166276908     0.419463447191946     0.420106603846799 
           0.00015625            0.01078125            0.00015625 
    0.420379431706021     0.420869449539072     0.431214346889845 
           0.00406250            0.00015625            0.00015625 
    0.433937840525743     0.440278644951702     0.441895424076257 
           0.00031250            0.00015625            0.00015625 
    0.442828919700371     0.443274873059508     0.446173888246631 
           0.00046875            0.00984375            0.00015625 
    0.450718587802467     0.456900610463576     0.459555681956315 
           0.00015625            0.00031250            0.00015625 
    0.460696686048428     0.467876105484108     0.472728746197005 
           0.00015625            0.00015625            0.00015625 
    0.474472217743954     0.474601080341499     0.474734089218203 
           0.00015625            0.00031250            0.00015625 
    0.477973490467994     0.484307789443022     0.484652344952628 
           0.00015625            0.00015625            0.00015625 
    0.494792709324177     0.498497691565453     0.500784787450151 
           0.00109375            0.00515625            0.00015625 
    0.504691880000581     0.508425703980646      0.50861676779181 
           0.00031250            0.00015625            0.00015625 
     0.50996114523361     0.514344382856681     0.516995457862692 
           0.00015625            0.00015625            0.00015625 
    0.518586102739047     0.521829770584971     0.523840570430114 
           0.00015625            0.00015625            0.00015625 
    0.524285913333902     0.525227742436545     0.527917885589494 
           0.00015625            0.00015625            0.00015625 
    0.531983533422768     0.539966728864973     0.541903897062432 
           0.00015625            0.00015625            0.00046875 
    0.543994005812287     0.545724786000498     0.546756498947983 
           0.00125000            0.00015625            0.00203125 
    0.548923619243861     0.549353970396232       0.5588553176537 
           0.00015625            0.00015625            0.00031250 
    0.564138483610525     0.566992546543754     0.569133261860447 
           0.00015625            0.00015625            0.00015625 
    0.574903744908869     0.577978215152712     0.578343495716271 
           0.00031250            0.00109375            0.00015625 
    0.580241024741447     0.581634314964003     0.583204933976379 
           0.00015625            0.00015625            0.00015625 
     0.58873859479558     0.595455758634415     0.597057916427158 
           0.00015625            0.00031250            0.00015625 
    0.598720288571789     0.599162991111384     0.599578938399305 
           0.00031250            0.00015625            0.00015625 
     0.60342049593258     0.604292419065582     0.607847397763963 
           0.00015625            0.00015625            0.00015625 
    0.611956869618315     0.612059726969641     0.612784292101807 
           0.00015625            0.00062500            0.00015625 
    0.613557486760981     0.620580331763515     0.622971928913742 
           0.00015625            0.00015625            0.00375000 
     0.63588348041021     0.641390081029809     0.643182929950686 
           0.00015625            0.00015625            0.00015625 
    0.648293425210027     0.650684078195595     0.657754904789885 
           0.00015625            0.00046875            0.00015625 
    0.664732625480728     0.665678528246394     0.665791697835918 
           0.00015625            0.00984375            0.00015625 
    0.666578602798705     0.678050028820375     0.678379635730825 
           0.00015625            0.00015625            0.00015625 
    0.679808655934455     0.680412565586961     0.680711498268701 
           0.00328125            0.00015625            0.00015625 
    0.684080216155581     0.684149053017272     0.685295140133807 
           0.00281250            0.00015625            0.00031250 
    0.686201169423553     0.690582799388141     0.692180702201577 
           0.00015625            0.00421875            0.00015625 
    0.696595449900374     0.697435597111395     0.698914306548046 
           0.00015625            0.00015625            0.00015625 
     0.70193206265865     0.702647867819401     0.707754986014002 
           0.00015625            0.00062500            0.00015625 
    0.711210346763156     0.712920206015224     0.713369947147153 
           0.00015625            0.00015625            0.00015625 
    0.715327471836729     0.722275487513834     0.722728216151602 
           0.00031250            0.00156250            0.00015625 
      0.7239248415172      0.72708089915877     0.729737150343281 
           0.00015625            0.00015625            0.00015625 
    0.735388003016973     0.740385327518889     0.741422651587756 
           0.00031250            0.00015625            0.00015625 
    0.741444754160499     0.747108762937508     0.748191169284348 
           0.00015625            0.00031250            0.00015625 
    0.751436430272142     0.752533256420978     0.752674676426801 
           0.00015625            0.00015625            0.00015625 
    0.754611657443207     0.754889027400603     0.756349639135923 
           0.00125000            0.00015625            0.00015625 
    0.763526062479594     0.768717423291569     0.770997182276433 
           0.00015625            0.00015625            0.00015625 
     0.77805655959217     0.780455501601279      0.79111659134251 
           0.00015625            0.00015625            0.00015625 
    0.794424123694395     0.794542595446869     0.797594367513394 
           0.00046875            0.00015625            0.00015625 
    0.806459604893308     0.806575447067013     0.815325824113437 
           0.00015625            0.00171875            0.00031250 
    0.820054212719794     0.821566079066492     0.822735985643791 
           0.00015625            0.00015625            0.00015625 
    0.824910396049865     0.825564426121463     0.827093295015157 
           0.00015625            0.00281250            0.00015625 
    0.830498441784675     0.839706577696515     0.854374875678462 
           0.00031250            0.00015625            0.00015625 
    0.857045424718981     0.857046899457354     0.858539236690819 
           0.00031250            0.00015625            0.00109375 
    0.861958482401254     0.864973903806387     0.868060666977836 
           0.00015625            0.00031250            0.00015625 
    0.871547517399078     0.877907606552374     0.878620392468042 
           0.00015625            0.00031250            0.00015625 
    0.882079910398028     0.886773165429333     0.895872264013794 
           0.00015625            0.00015625            0.00031250 
    0.902874892971196     0.909893594892982     0.910503026314625 
           0.00015625            0.00015625            0.00015625 
    0.918355472177732     0.923930998062757     0.928610132228083 
           0.00156250            0.00015625            0.00015625 
    0.930580294371997     0.932353440099381     0.933043163131344 
           0.00015625            0.00015625            0.00015625 
    0.935865275090846     0.938721396055517      0.94732667023698 
           0.00015625            0.00015625            0.00015625 
    0.952388332756409     0.953472399517577     0.960457391255192 
           0.00046875            0.00015625            0.00015625 
    0.962466815938431     0.974608403263273     0.977273131185975 
           0.00031250            0.00015625            0.00015625 
    0.979887858238853     0.981765099822977     0.982533764258785 
           0.02546875            0.00015625            0.00015625 
    0.986421193335086     0.991131333762411      0.99464772824313 
           0.00046875            0.00015625            0.00015625 
     1.00529335053186      1.01443060556224       1.0145402019372 
           0.00015625            0.00062500            0.00015625 
     1.02257036343242      1.02480443153783      1.02810330735672 
           0.00015625            0.00015625            0.00015625 
     1.02815692332918       1.0286099206142      1.03278708868866 
           0.00265625            0.00015625            0.00015625 
     1.03867605371823      1.04030809775545      1.05026762861212 
           0.00015625            0.00046875            0.00015625 
     1.05448691449244       1.0552263521649      1.05588258974527 
           0.00125000            0.00015625            0.00015625 
     1.06000513122926      1.06639439518604      1.07107601485988 
           0.00906250            0.00078125            0.00015625 
     1.07323792501438      1.07985999257921      1.08185178624946 
           0.00015625            0.00015625            0.00015625 
     1.08200577310599      1.08501442587133      1.08924264046828 
           0.00015625            0.00015625            0.00015625 
     1.09237983879524      1.09858922192811      1.09934822043348 
           0.00015625            0.00015625            0.00015625 
      1.1078948637414      1.11407400788163      1.11835818480985 
           0.00015625            0.00015625            0.00093750 
     1.11909298650692      1.12255263564979      1.13098492845703 
           0.00125000            0.00640625            0.00718750 
     1.13520899613199      1.13659865262031      1.14324263811607 
           0.00015625            0.00031250            0.00015625 
      1.1444495252129       1.1551673045972      1.15841602768456 
           0.00578125            0.00046875            0.00015625 
     1.17032197443365      1.17077944389967      1.17660425916148 
           0.00156250            0.01546875            0.00015625 
     1.17671971786951      1.18390085758965      1.19061835680715 
           0.00031250            0.02078125            0.00078125 
     1.19124162268748      1.19491419845781      1.20187158527135 
           0.00046875            0.01000000            0.00015625 
     1.20935820034015      1.21534749252995      1.21684078311872 
           0.00015625            0.00015625            0.00015625 
     1.22228576405746      1.22358524293339       1.2307494205369 
           0.00046875            0.00375000            0.00359375 
     1.23190824585799      1.23309624815214       1.2482497077686 
           0.00015625            0.00015625            0.00015625 
     1.24914605564843      1.25030062698194      1.25167385090479 
           0.00015625            0.00015625            0.00015625 
      1.2521388586462      1.25403638767138      1.25696184836792 
           0.00015625            0.00015625            0.00015625 
     1.25865710330342      1.26219503016375      1.26339025886804 
           0.00015625            0.00015625            0.00062500 
     1.27424955368127      1.27429889692881      1.27581391381442 
           0.00062500            0.01093750            0.00015625 
     1.28103448636196      1.28422435170195      1.28502302740832 
           0.00015625            0.00015625            0.00015625 
     1.28694332261892      1.28862136579613      1.29135133286724 
           0.00015625            0.00015625            0.00015625 
     1.29271693854318      1.29352984392642      1.29416501801516 
           0.00093750            0.00015625            0.00015625 
     1.32000923372796      1.32621334330507      1.32674979912185 
           0.00015625            0.00031250            0.00031250 
      1.3355388950486      1.33819762355126      1.34572143844383 
           0.00703125            0.00015625            0.00015625 
     1.34900429115538      1.35106912963136      1.35909050306374 
           0.00015625            0.00015625            0.00015625 
     1.36740896432616      1.37732504122682      1.37817713292888 
           0.00015625            0.00015625            0.00171875 
     1.38155034894393      1.38244688032714      1.38971756538262 
           0.00015625            0.00015625            0.00015625 
     1.39337346848199      1.39481552027921      1.39920925968592 
           0.00015625            0.00015625            0.00015625 
     1.40401019415033      1.40768753122916      1.42034462702771 
           0.00015625            0.00046875            0.00031250 
     1.42884838085788      1.43014092255268      1.43175470937195 
           0.00062500            0.00078125            0.00015625 
     1.43334191774463      1.43396654425843      1.43750664054499 
           0.00046875            0.00015625            0.00015625 
     1.43754219334743       1.4388998201083      1.44153927902681 
           0.00015625            0.01625000            0.01421875 
     1.44769121849116      1.44889234688456      1.45317034273597 
           0.00015625            0.00015625            0.00015625 
     1.45756717172523      1.46514717542552      1.48152004641465 
           0.00015625            0.01359375            0.00015625 
     1.48210471217649       1.4854271336131      1.49691410201524 
           0.00187500            0.00015625            0.00031250 
     1.50460499505036          1.5159104855      1.51944062018193 
           0.00015625            0.00062500            0.00015625 
     1.51951797036384      1.52322014302823      1.52914361888698 
           0.00015625            0.00015625            0.00015625 
     1.53094696259391      1.53185854523801      1.54534195968881 
           0.00015625            0.00015625            0.00015625 
     1.55198480359028      1.55950143190504      1.56497982317259 
           0.00031250            0.00015625            0.00015625 
     1.58262031982126      1.59616721426295      1.60437565730193 
           0.00062500            0.00015625            0.00015625 
     1.61266940307664      1.61805143272205      1.63593441495235 
           0.00015625            0.00015625            0.00390625 
     1.66020775786113      1.67542635415394      1.67673538939901 
           0.00046875            0.00015625            0.00437500 
     1.68035708519021      1.68346836697786      1.68837599513398 
           0.00015625            0.00015625            0.00015625 
     1.68938234802037      1.70189867028665      1.70300688645049 
           0.00015625            0.00015625            0.00015625 
     1.70487078400102      1.71353493899627      1.72834558905075 
           0.00015625            0.00015625            0.00015625 
     1.72915591888238      1.73426417234817      1.74021109248258 
           0.00015625            0.00015625            0.00015625 
     1.74232222740301      1.74349939634561       1.7580041756475 
           0.00015625            0.00015625            0.00015625 
     1.76113921780106      1.76617520172517      1.77211632108358 
           0.00015625            0.00015625            0.00015625 
     1.77514993495452      1.79958280830507      1.81629669477704 
           0.00015625            0.00015625            0.00031250 
     1.81990457312901      1.83656963213994      1.83724270780201 
           0.00015625            0.01140625            0.00015625 
     1.84610801109783      1.87127556838068      1.87941151145041 
           0.00015625            0.00031250            0.00015625 
     1.88207392317223      1.89017691499225      1.91733288828094 
           0.00031250            0.00015625            0.00015625 
     1.94867279430132      1.95578696468731      1.95652907096428 
           0.00687500            0.00015625            0.00015625 
     1.96029188648611      1.97337415011671      1.97682872944693 
           0.00015625            0.00015625            0.00015625 
     1.97898223695928      2.01790204562771      2.04143987127407 
           0.00015625            0.00015625            0.00171875 
     2.04788306887298      2.07547273185274      2.09309957494449 
           0.00062500            0.00031250            0.00015625 
     2.09950420993508      2.10052429104874      2.10697756530747 
           0.00031250            0.00015625            0.00015625 
     2.11999156344762      2.12917389303477      2.15933629269958 
           0.00015625            0.00015625            0.00015625 
     2.18306393167287      2.18323513022319      2.18704108088277 
           0.00187500            0.00015625            0.00015625 
     2.23887211958444      2.24380917557826      2.28051444339884 
           0.00015625            0.00015625            0.00562500 
     2.28417103037285      2.30954548348617      2.34561980157645 
           0.00015625            0.00125000            0.00015625 
     2.52385907644018      3.01185818638057      3.23514293488871 
           0.00015625            0.00015625            0.00031250 
     3.52347021972545      4.91171482734768      5.33930094132038 
           0.00015625            0.00015625            0.00015625 
     6.39137994453622      6.97999767626588 
           0.00015625            0.00015625 

> prop.table(table(trainClass))
trainClass
   Strong      Weak 
0.3492823 0.6507177 

> dim(trainDescr)
[1] 209  20

> dim(testDescr)
[1] 111  20

> ## Check Near-zero variance
> 
> nzv <- nearZeroVar(trainDescr, saveMetrics= TRUE)

> stopifnot( all(nzv$nzv == FALSE) )

> # It's imputed and behaves well, no need for this.
> # descrCorr <- cor(scale(trainDescr), use = "pairwise.complete.obs")
> 
> descrCorr <- cor(scale(trainDescr))

> ## This cut-off should be under src.adjust control.
> ## I'm under Git, so I can tinker with it.
> highCorr <- findCorrelation(descrCorr, cutoff = .65, verbose = TRUE)
Considering row	 10 column	 16 value	 0.55 
Considering row	 10 column	 17 value	 0.647 
Considering row	 10 column	 11 value	 0.297 
Considering row	 10 column	 1 value	 0.286 
Considering row	 10 column	 6 value	 0.307 
Considering row	 10 column	 12 value	 0.26 
Considering row	 10 column	 14 value	 0.272 
Considering row	 10 column	 2 value	 0.293 
Considering row	 10 column	 9 value	 0.365 
Considering row	 10 column	 8 value	 0.363 
Considering row	 10 column	 13 value	 0.231 
Considering row	 10 column	 18 value	 0.191 
Considering row	 10 column	 19 value	 0.166 
Considering row	 10 column	 3 value	 0.423 
Considering row	 10 column	 20 value	 0.091 
Considering row	 10 column	 4 value	 0.078 
Considering row	 10 column	 5 value	 0.164 
Considering row	 10 column	 15 value	 0.168 
Considering row	 10 column	 7 value	 0.144 
Considering row	 16 column	 17 value	 0.855 
  Flagging column	 16 
Considering row	 17 column	 11 value	 0.252 
Considering row	 17 column	 1 value	 0.245 
Considering row	 17 column	 6 value	 0.183 
Considering row	 17 column	 12 value	 0.195 
Considering row	 17 column	 14 value	 0.217 
Considering row	 17 column	 2 value	 0.232 
Considering row	 17 column	 9 value	 0.547 
Considering row	 17 column	 8 value	 0.503 
Considering row	 17 column	 13 value	 0.19 
Considering row	 17 column	 18 value	 0.241 
Considering row	 17 column	 19 value	 0.214 
Considering row	 17 column	 3 value	 0.259 
Considering row	 17 column	 20 value	 0.101 
Considering row	 17 column	 4 value	 0.042 
Considering row	 17 column	 5 value	 0.076 
Considering row	 17 column	 15 value	 0.047 
Considering row	 17 column	 7 value	 0.019 
Considering row	 11 column	 1 value	 0.988 
  Flagging column	 11 
Considering row	 1 column	 6 value	 0.955 
  Flagging column	 1 
Considering row	 6 column	 12 value	 0.87 
  Flagging column	 6 
Considering row	 12 column	 14 value	 0.07 
Considering row	 12 column	 2 value	 0.077 
Considering row	 12 column	 9 value	 0.092 
Considering row	 12 column	 8 value	 0.112 
Considering row	 12 column	 13 value	 0.013 
Considering row	 12 column	 18 value	 0.158 
Considering row	 12 column	 19 value	 0.037 
Considering row	 12 column	 3 value	 0.061 
Considering row	 12 column	 20 value	 0.101 
Considering row	 12 column	 4 value	 0.032 
Considering row	 12 column	 5 value	 0.032 
Considering row	 12 column	 15 value	 0.122 
Considering row	 12 column	 7 value	 0.047 
Considering row	 14 column	 2 value	 0.602 
Considering row	 14 column	 9 value	 0.16 
Considering row	 14 column	 8 value	 0.113 
Considering row	 14 column	 13 value	 0.692 
  Flagging column	 14 
Considering row	 2 column	 9 value	 0.371 
Considering row	 2 column	 8 value	 0.147 
Considering row	 2 column	 13 value	 0.602 
Considering row	 2 column	 18 value	 0.156 
Considering row	 2 column	 19 value	 0.043 
Considering row	 2 column	 3 value	 0.261 
Considering row	 2 column	 20 value	 0.136 
Considering row	 2 column	 4 value	 0.224 
Considering row	 2 column	 5 value	 0.009 
Considering row	 2 column	 15 value	 0.107 
Considering row	 2 column	 7 value	 0.044 
Considering row	 9 column	 8 value	 0.416 
Considering row	 9 column	 13 value	 0.113 
Considering row	 9 column	 18 value	 0.059 
Considering row	 9 column	 19 value	 0.222 
Considering row	 9 column	 3 value	 0.274 
Considering row	 9 column	 20 value	 0.112 
Considering row	 9 column	 4 value	 0.033 
Considering row	 9 column	 5 value	 0.072 
Considering row	 9 column	 15 value	 0.011 
Considering row	 9 column	 7 value	 0.165 
Considering row	 8 column	 13 value	 0.108 
Considering row	 8 column	 18 value	 0.127 
Considering row	 8 column	 19 value	 0.221 
Considering row	 8 column	 3 value	 0.16 
Considering row	 8 column	 20 value	 0.155 
Considering row	 8 column	 4 value	 0.037 
Considering row	 8 column	 5 value	 0.022 
Considering row	 8 column	 15 value	 0.03 
Considering row	 8 column	 7 value	 0.108 
Considering row	 13 column	 18 value	 0.186 
Considering row	 13 column	 19 value	 0.084 
Considering row	 13 column	 3 value	 0.179 
Considering row	 13 column	 20 value	 0.142 
Considering row	 13 column	 4 value	 0.229 
Considering row	 13 column	 5 value	 0.063 
Considering row	 13 column	 15 value	 0.182 
Considering row	 13 column	 7 value	 0.094 
Considering row	 18 column	 19 value	 0.086 
Considering row	 18 column	 3 value	 0.073 
Considering row	 18 column	 20 value	 0.075 
Considering row	 18 column	 4 value	 0.123 
Considering row	 18 column	 5 value	 0.019 
Considering row	 18 column	 15 value	 0.086 
Considering row	 18 column	 7 value	 0.151 
Considering row	 19 column	 3 value	 0.093 
Considering row	 19 column	 20 value	 0.846 
  Flagging column	 19 
Considering row	 3 column	 20 value	 0.012 
Considering row	 3 column	 4 value	 0.056 
Considering row	 3 column	 5 value	 0.164 
Considering row	 3 column	 15 value	 0.061 
Considering row	 3 column	 7 value	 0.079 
Considering row	 20 column	 4 value	 0.085 
Considering row	 20 column	 5 value	 0.101 
Considering row	 20 column	 15 value	 0.032 
Considering row	 20 column	 7 value	 0.1 
Considering row	 4 column	 5 value	 0.255 
Considering row	 4 column	 15 value	 0.003 
Considering row	 4 column	 7 value	 0.039 
Considering row	 5 column	 15 value	 0.035 
Considering row	 5 column	 7 value	 0.012 
Considering row	 15 column	 7 value	 0.033 

> colnames(trainDescr)[highCorr]
[1] "DEPSPOKE"     "DEPBUCKET"    "SDEPHR"       "AVGSQ"        "TRNRANKGRP"  
[6] "xAVAILBUCKET"

> descr.ncol0 <- ncol(trainDescr)

> # I've switched off the correlation remover and the results are better.
> if (sum(highCorr) > 0) {
+     warning("overfitting: correlations: err.trainDescr: ", paste(colnames(trainDescr)[highCorr], collapse = ", ") )
+     err.trainDescr <- trainDescr
+     trainDescr <- trainDescr[,-highCorr]
+ }

> descr.ncol1 <- ncol(trainDescr)

> paste("Dropped: ", as.character(descr.ncol0 - descr.ncol1))
[1] "Dropped:  6"

> descrCorr <- cor(trainDescr)

> summary(descrCorr[upper.tri(descrCorr)])
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
-0.54690 -0.11030 -0.01327  0.00736  0.10400  0.64730 

> ## Dominant correlations
> ## At 0.9, there are some big ones that might need re-thinking.
> 
> table.descrCorr <- as.data.frame(as.table(descrCorr))

> table.descrCorr <- table.descrCorr[which(table.descrCorr$Var1 != table.descrCorr$Var2),]

> table.descrCorr[order(abs(table.descrCorr$Freq), decreasing = TRUE),]
              Var1           Var2         Freq
110       ARRSPOKE DOWNLINEATCIMP  0.647266036
162 DOWNLINEATCIMP       ARRSPOKE  0.647266036
10      DEPRANKGRP      SKDDEPSTA  0.602444444
127      SKDDEPSTA     DEPRANKGRP  0.602444444
96        ARRSPOKE   DEPSTAATCIMP -0.546894213
161   DEPSTAATCIMP       ARRSPOKE -0.546894213
82        ARRSPOKE   UPLINEATCIMP  0.503083376
160   UPLINEATCIMP       ARRSPOKE  0.503083376
22  DOWNLINEATCIMP      SKDARRSTA  0.423085302
100      SKDARRSTA DOWNLINEATCIMP  0.423085302
77    DEPSTAATCIMP   UPLINEATCIMP -0.415657487
90    UPLINEATCIMP   DEPSTAATCIMP -0.415657487
7     DEPSTAATCIMP      SKDDEPSTA  0.371415190
85       SKDDEPSTA   DEPSTAATCIMP  0.371415190
92  DOWNLINEATCIMP   DEPSTAATCIMP -0.365064678
105   DEPSTAATCIMP DOWNLINEATCIMP -0.365064678
78  DOWNLINEATCIMP   UPLINEATCIMP  0.362606504
104   UPLINEATCIMP DOWNLINEATCIMP  0.362606504
8   DOWNLINEATCIMP      SKDDEPSTA -0.292861955
99       SKDDEPSTA DOWNLINEATCIMP -0.292861955
21    DEPSTAATCIMP      SKDARRSTA -0.273653815
86       SKDARRSTA   DEPSTAATCIMP -0.273653815
2        SKDARRSTA      SKDDEPSTA -0.261225264
15       SKDDEPSTA      SKDARRSTA -0.261225264
107      ARRBUCKET DOWNLINEATCIMP  0.260336603
120 DOWNLINEATCIMP      ARRBUCKET  0.260336603
26        ARRSPOKE      SKDARRSTA  0.259207810
156      SKDARRSTA       ARRSPOKE  0.259207810
32          SKDEPS         SKDEQP  0.254961381
45          SKDEQP         SKDEPS  0.254961381
167         xDURN2       ARRSPOKE -0.240925782
180       ARRSPOKE         xDURN2 -0.240925782
12        ARRSPOKE      SKDDEPSTA -0.231962447
155      SKDDEPSTA       ARRSPOKE -0.231962447
108     DEPRANKGRP DOWNLINEATCIMP -0.230708862
134 DOWNLINEATCIMP     DEPRANKGRP -0.230708862
38      DEPRANKGRP         SKDEQP  0.229386430
129         SKDEQP     DEPRANKGRP  0.229386430
3           SKDEQP      SKDDEPSTA  0.224186605
29       SKDDEPSTA         SKDEQP  0.224186605
124       ARRSPOKE      ARRBUCKET  0.194637431
163      ARRBUCKET       ARRSPOKE  0.194637431
111         xDURN2 DOWNLINEATCIMP -0.190870792
176 DOWNLINEATCIMP         xDURN2 -0.190870792
138       ARRSPOKE     DEPRANKGRP -0.190129997
164     DEPRANKGRP       ARRSPOKE -0.190129997
139         xDURN2     DEPRANKGRP  0.185783873
178     DEPRANKGRP         xDURN2  0.185783873
137     ARRRANKGRP     DEPRANKGRP  0.182490249
150     DEPRANKGRP     ARRRANKGRP  0.182490249
24      DEPRANKGRP      SKDARRSTA -0.178745408
128      SKDARRSTA     DEPRANKGRP -0.178745408
109     ARRRANKGRP DOWNLINEATCIMP -0.168270397
148 DOWNLINEATCIMP     ARRRANKGRP -0.168270397
63    DEPSTAATCIMP      AVGLOFATC -0.165076256
89       AVGLOFATC   DEPSTAATCIMP -0.165076256
18          SKDEPS      SKDARRSTA -0.164456986
44       SKDARRSTA         SKDEPS -0.164456986
50  DOWNLINEATCIMP         SKDEPS -0.163907354
102         SKDEPS DOWNLINEATCIMP -0.163907354
20    UPLINEATCIMP      SKDARRSTA  0.159742306
72       SKDARRSTA   UPLINEATCIMP  0.159742306
125         xDURN2      ARRBUCKET -0.157754195
177      ARRBUCKET         xDURN2 -0.157754195
13          xDURN2      SKDDEPSTA  0.155564090
169      SKDDEPSTA         xDURN2  0.155564090
84    xAVGSKDAVAIL   UPLINEATCIMP  0.155074532
188   UPLINEATCIMP   xAVGSKDAVAIL  0.155074532
69          xDURN2      AVGLOFATC -0.150825874
173      AVGLOFATC         xDURN2 -0.150825874
6     UPLINEATCIMP      SKDDEPSTA -0.146821904
71       SKDDEPSTA   UPLINEATCIMP -0.146821904
64  DOWNLINEATCIMP      AVGLOFATC -0.144293291
103      AVGLOFATC DOWNLINEATCIMP -0.144293291
140   xAVGSKDAVAIL     DEPRANKGRP  0.142201238
192     DEPRANKGRP   xAVGSKDAVAIL  0.142201238
14    xAVGSKDAVAIL      SKDDEPSTA  0.136437376
183      SKDDEPSTA   xAVGSKDAVAIL  0.136437376
83          xDURN2   UPLINEATCIMP -0.127482570
174   UPLINEATCIMP         xDURN2 -0.127482570
41          xDURN2         SKDEQP  0.122708719
171         SKDEQP         xDURN2  0.122708719
123     ARRRANKGRP      ARRBUCKET -0.121546103
149      ARRBUCKET     ARRRANKGRP -0.121546103
94      DEPRANKGRP   DEPSTAATCIMP  0.113478120
133   DEPSTAATCIMP     DEPRANKGRP  0.113478120
98    xAVGSKDAVAIL   DEPSTAATCIMP -0.112484576
189   DEPSTAATCIMP   xAVGSKDAVAIL -0.112484576
79       ARRBUCKET   UPLINEATCIMP  0.111671932
118   UPLINEATCIMP      ARRBUCKET  0.111671932
80      DEPRANKGRP   UPLINEATCIMP -0.108194221
132   UPLINEATCIMP     DEPRANKGRP -0.108194221
62    UPLINEATCIMP      AVGLOFATC -0.107776470
75       AVGLOFATC   UPLINEATCIMP -0.107776470
11      ARRRANKGRP      SKDDEPSTA  0.106846785
141      SKDDEPSTA     ARRRANKGRP  0.106846785
56    xAVGSKDAVAIL         SKDEPS  0.101251560
186         SKDEPS   xAVGSKDAVAIL  0.101251560
126   xAVGSKDAVAIL      ARRBUCKET -0.101248535
191      ARRBUCKET   xAVGSKDAVAIL -0.101248535
168   xAVGSKDAVAIL       ARRSPOKE  0.101156933
194       ARRSPOKE   xAVGSKDAVAIL  0.101156933
70    xAVGSKDAVAIL      AVGLOFATC -0.100162290
187      AVGLOFATC   xAVGSKDAVAIL -0.100162290
66      DEPRANKGRP      AVGLOFATC  0.094490883
131      AVGLOFATC     DEPRANKGRP  0.094490883
93       ARRBUCKET   DEPSTAATCIMP -0.092239439
119   DEPSTAATCIMP      ARRBUCKET -0.092239439
112   xAVGSKDAVAIL DOWNLINEATCIMP  0.091025429
190 DOWNLINEATCIMP   xAVGSKDAVAIL  0.091025429
153         xDURN2     ARRRANKGRP  0.086208265
179     ARRRANKGRP         xDURN2  0.086208265
42    xAVGSKDAVAIL         SKDEQP  0.085219910
185         SKDEQP   xAVGSKDAVAIL  0.085219910
19       AVGLOFATC      SKDARRSTA -0.079122260
58       SKDARRSTA      AVGLOFATC -0.079122260
36  DOWNLINEATCIMP         SKDEQP -0.078229054
101         SKDEQP DOWNLINEATCIMP -0.078229054
9        ARRBUCKET      SKDDEPSTA -0.076894214
113      SKDDEPSTA      ARRBUCKET -0.076894214
54        ARRSPOKE         SKDEPS -0.076025316
158         SKDEPS       ARRSPOKE -0.076025316
182   xAVGSKDAVAIL         xDURN2  0.075398007
195         xDURN2   xAVGSKDAVAIL  0.075398007
27          xDURN2      SKDARRSTA  0.072540811
170      SKDARRSTA         xDURN2  0.072540811
49    DEPSTAATCIMP         SKDEPS -0.072038619
88          SKDEPS   DEPSTAATCIMP -0.072038619
52      DEPRANKGRP         SKDEPS  0.063126960
130         SKDEPS     DEPRANKGRP  0.063126960
23       ARRBUCKET      SKDARRSTA  0.061406824
114      SKDARRSTA      ARRBUCKET  0.061406824
25      ARRRANKGRP      SKDARRSTA  0.061061397
142      SKDARRSTA     ARRRANKGRP  0.061061397
97          xDURN2   DEPSTAATCIMP -0.058571246
175   DEPSTAATCIMP         xDURN2 -0.058571246
17          SKDEQP      SKDARRSTA  0.055643632
30       SKDARRSTA         SKDEQP  0.055643632
152       ARRSPOKE     ARRRANKGRP  0.047198197
165     ARRRANKGRP       ARRSPOKE  0.047198197
65       ARRBUCKET      AVGLOFATC -0.046716218
117      AVGLOFATC      ARRBUCKET -0.046716218
5        AVGLOFATC      SKDDEPSTA -0.043670512
57       SKDDEPSTA      AVGLOFATC -0.043670512
40        ARRSPOKE         SKDEQP  0.041581874
157         SKDEQP       ARRSPOKE  0.041581874
33       AVGLOFATC         SKDEQP  0.039212863
59          SKDEQP      AVGLOFATC  0.039212863
34    UPLINEATCIMP         SKDEQP -0.036743149
73          SKDEQP   UPLINEATCIMP -0.036743149
53      ARRRANKGRP         SKDEPS  0.034554108
144         SKDEPS     ARRRANKGRP  0.034554108
35    DEPSTAATCIMP         SKDEQP -0.033412491
87          SKDEQP   DEPSTAATCIMP -0.033412491
67      ARRRANKGRP      AVGLOFATC -0.033080387
145      AVGLOFATC     ARRRANKGRP -0.033080387
37       ARRBUCKET         SKDEQP -0.032086314
115         SKDEQP      ARRBUCKET -0.032086314
51       ARRBUCKET         SKDEPS -0.032023722
116         SKDEPS      ARRBUCKET -0.032023722
154   xAVGSKDAVAIL     ARRRANKGRP -0.031558241
193     ARRRANKGRP   xAVGSKDAVAIL -0.031558241
81      ARRRANKGRP   UPLINEATCIMP -0.029624279
146   UPLINEATCIMP     ARRRANKGRP -0.029624279
48    UPLINEATCIMP         SKDEPS -0.021787103
74          SKDEPS   UPLINEATCIMP -0.021787103
55          xDURN2         SKDEPS  0.019241544
172         SKDEPS         xDURN2  0.019241544
68        ARRSPOKE      AVGLOFATC -0.018812820
159      AVGLOFATC       ARRSPOKE -0.018812820
122     DEPRANKGRP      ARRBUCKET -0.013268207
135      ARRBUCKET     DEPRANKGRP -0.013268207
47       AVGLOFATC         SKDEPS  0.012372611
60          SKDEPS      AVGLOFATC  0.012372611
28    xAVGSKDAVAIL      SKDARRSTA -0.012226256
184      SKDARRSTA   xAVGSKDAVAIL -0.012226256
95      ARRRANKGRP   DEPSTAATCIMP  0.011385713
147   DEPSTAATCIMP     ARRRANKGRP  0.011385713
4           SKDEPS      SKDDEPSTA -0.008713182
43       SKDDEPSTA         SKDEPS -0.008713182
39      ARRRANKGRP         SKDEQP -0.003128426
143         SKDEQP     ARRRANKGRP -0.003128426

> ### Models
> 
> ## Try GBM (gradient boosting). Works well for mixed data.
> ## And there is a tutorial for it with caret.
> 
> ## Training controller and big grid
> ## Check the ROC (my preferred.)
> 
> fitControl <- trainControl(## 10-fold CV
+     method = "repeatedcv",
+     number = 10,
+     .... [TRUNCATED] 

> ## Some trial and error with variables to branch and boost.
> ## I'm just going to try the airports and the planes and the duration
> ## of the flight. There may be some distance relationship there that
> ## air traffic control use.
> 
> ## Annoying because I drop variables, this needs to be looke .... [TRUNCATED] 

> tr.cols
 [1] "SKDDEPSTA"      "SKDARRSTA"      "SKDEQP"         "SKDEPS"        
 [5] "AVGLOFATC"      "UPLINEATCIMP"   "DEPSTAATCIMP"   "DOWNLINEATCIMP"
 [9] "ARRBUCKET"      "DEPRANKGRP"     "ARRRANKGRP"     "ARRSPOKE"      
[13] "xDURN2"         "xAVGSKDAVAIL"  

> tr.icols <- grep("((STA|EQP)$)|(^xD)", tr.cols)

> tr.icols <- rev(tr.icols)

> gbmGrid <- expand.grid(interaction.depth = tr.icols,
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.1,
+                         n.minobsinnode = 20)

> set.seed(seed.mine)

> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "ROC" .... [TRUNCATED] 
Loading required package: gbm
Loading required package: survival

Attaching package: 'survival'

The following object is masked from 'package:caret':

    cluster

Loading required package: splines
Loaded gbm 2.1.1
Loading required package: plyr

> gbmFit1
Stochastic Gradient Boosting 

209 samples
 14 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 187, 189, 188, 188, 188, 188, ... 

Resampling results across tuning parameters:

  interaction.depth  n.trees  ROC        Sens       Spec       ROC SD    
   1                   90     0.8411264  0.5544643  0.8795604  0.09021351
   1                  180     0.8250657  0.5660714  0.8749451  0.10042798
   1                  270     0.8206073  0.5883929  0.8572527  0.09220171
   1                  360     0.8120124  0.5966071  0.8564286  0.10021116
   1                  450     0.8069241  0.6048214  0.8519780  0.10525979
   1                  540     0.8024097  0.6026786  0.8528571  0.09834527
   1                  630     0.7924627  0.6126786  0.8530220  0.10794288
   1                  720     0.7924598  0.6062500  0.8471429  0.10125943
   1                  810     0.7856662  0.6048214  0.8449451  0.10305010
   1                  900     0.7799676  0.6042857  0.8420879  0.11682700
   1                  990     0.7819584  0.6046429  0.8367582  0.10449876
   1                 1080     0.7776177  0.6042857  0.8331319  0.11363870
   1                 1170     0.7755239  0.6016071  0.8286813  0.11799593
   1                 1260     0.7709262  0.5958929  0.8330769  0.11544039
   1                 1350     0.7746458  0.6005357  0.8324176  0.11132263
   1                 1440     0.7737529  0.6019643  0.8278571  0.10982753
   1                 1530     0.7727374  0.6019643  0.8307692  0.11069139
   1                 1620     0.7677198  0.5966071  0.8287363  0.11279420
   1                 1710     0.7686205  0.6003571  0.8227473  0.11173524
   1                 1800     0.7675442  0.5896429  0.8196154  0.11287931
   1                 1890     0.7661646  0.5869643  0.8182418  0.11156619
   1                 1980     0.7652453  0.5898214  0.8159341  0.10980020
   1                 2070     0.7621998  0.5925000  0.8145055  0.11001818
   1                 2160     0.7623342  0.5883929  0.8137363  0.11034874
   1                 2250     0.7628532  0.5871429  0.8202747  0.11112433
   1                 2340     0.7608821  0.5857143  0.8145055  0.11339341
   1                 2430     0.7586185  0.5826786  0.8175824  0.11303508
   1                 2520     0.7576874  0.5841071  0.8070330  0.11379790
   1                 2610     0.7583870  0.5841071  0.8123626  0.11123275
   1                 2700     0.7561156  0.5732143  0.8086813  0.11299614
   2                   90     0.8287892  0.5464286  0.8526923  0.09369249
   2                  180     0.8159802  0.5582143  0.8387912  0.09956153
   2                  270     0.8063991  0.5600000  0.8345604  0.10278603
   2                  360     0.8044505  0.5550000  0.8284066  0.09980624
   2                  450     0.8007918  0.5562500  0.8241758  0.10037815
   2                  540     0.7975098  0.5407143  0.8183516  0.09557477
   2                  630     0.7945290  0.5485714  0.8124725  0.09910800
   2                  720     0.7926658  0.5414286  0.8139011  0.10604465
   2                  810     0.7911637  0.5371429  0.8167033  0.10689352
   2                  900     0.7936077  0.5412500  0.8181868  0.10697842
   2                  990     0.7897635  0.5319643  0.8146154  0.10815360
   2                 1080     0.7893573  0.5362500  0.8108242  0.11075431
   2                 1170     0.7879641  0.5362500  0.8100549  0.10712605
   2                 1260     0.7869780  0.5333929  0.8101099  0.10925780
   2                 1350     0.7867367  0.5308929  0.8048352  0.10775247
   2                 1440     0.7845546  0.5300000  0.8137912  0.10706040
   2                 1530     0.7858497  0.5296429  0.8121978  0.10685670
   2                 1620     0.7851432  0.5394643  0.8084615  0.10544171
   2                 1710     0.7841425  0.5362500  0.8106593  0.10620182
   2                 1800     0.7847626  0.5405357  0.8092857  0.10403246
   2                 1890     0.7841091  0.5407143  0.8070330  0.10467441
   2                 1980     0.7835469  0.5426786  0.8079121  0.10471659
   2                 2070     0.7839178  0.5457143  0.8086813  0.10373475
   2                 2160     0.7838854  0.5401786  0.8058242  0.10491702
   2                 2250     0.7835224  0.5305357  0.8035714  0.10268515
   2                 2340     0.7831731  0.5444643  0.8057143  0.10472041
   2                 2430     0.7824951  0.5391071  0.8043407  0.10349774
   2                 2520     0.7830926  0.5366071  0.8050000  0.10438491
   2                 2610     0.7834890  0.5378571  0.8049451  0.10307555
   2                 2700     0.7831064  0.5389286  0.8072527  0.10201975
   3                   90     0.8262637  0.5700000  0.8491209  0.10370375
   3                  180     0.8145349  0.5628571  0.8415934  0.10949802
   3                  270     0.8077198  0.5580357  0.8306593  0.10086678
   3                  360     0.8011195  0.5546429  0.8253846  0.10309939
   3                  450     0.8019407  0.5458929  0.8174725  0.09449692
   3                  540     0.7991179  0.5467857  0.8183516  0.09592114
   3                  630     0.7973175  0.5433929  0.8190659  0.09510530
   3                  720     0.7960047  0.5546429  0.8160440  0.09623692
   3                  810     0.7916081  0.5457143  0.8118132  0.10829128
   3                  900     0.7905396  0.5542857  0.8087912  0.10315993
   3                  990     0.7890473  0.5546429  0.8088462  0.10655655
   3                 1080     0.7871841  0.5464286  0.8096154  0.10697307
   3                 1170     0.7851236  0.5396429  0.8132967  0.11048761
   3                 1260     0.7870016  0.5460714  0.8058242  0.10142692
   3                 1350     0.7863766  0.5421429  0.8086264  0.10255478
   3                 1440     0.7846605  0.5419643  0.8079670  0.10196110
   3                 1530     0.7838442  0.5391071  0.8093956  0.10172476
   3                 1620     0.7834910  0.5376786  0.8057692  0.10236001
   3                 1710     0.7828601  0.5392857  0.8014835  0.10140356
   3                 1800     0.7831005  0.5391071  0.8013187  0.10180459
   3                 1890     0.7833987  0.5414286  0.8028022  0.10057504
   3                 1980     0.7815453  0.5385714  0.8026923  0.10122897
   3                 2070     0.7820212  0.5375000  0.7990659  0.10180395
   3                 2160     0.7818524  0.5346429  0.8012088  0.10207336
   3                 2250     0.7819780  0.5416071  0.8034615  0.10293441
   3                 2340     0.7827973  0.5442857  0.8005495  0.10268799
   3                 2430     0.7823656  0.5389286  0.8012088  0.10280208
   3                 2520     0.7807928  0.5376786  0.8034066  0.10248355
   3                 2610     0.7811332  0.5387500  0.8034615  0.10333968
   3                 2700     0.7803042  0.5414286  0.8020879  0.10323439
  13                   90     0.8216170  0.5526786  0.8460989  0.10207209
  13                  180     0.8083477  0.5630357  0.8365934  0.10095151
  13                  270     0.8020850  0.5464286  0.8307692  0.10150178
  13                  360     0.7974029  0.5525000  0.8197253  0.10734511
  13                  450     0.7917033  0.5592857  0.8160440  0.11223576
  13                  540     0.7901737  0.5462500  0.8101099  0.11017456
  13                  630     0.7879729  0.5430357  0.8079670  0.11508749
  13                  720     0.7908310  0.5416071  0.8056593  0.10334215
  13                  810     0.7880445  0.5403571  0.8035165  0.10786557
  13                  900     0.7888874  0.5348214  0.8042857  0.09916155
  13                  990     0.7896507  0.5369643  0.8078571  0.09891464
  13                 1080     0.7865473  0.5400000  0.8042857  0.10775912
  13                 1170     0.7856574  0.5333929  0.8071978  0.10412989
  13                 1260     0.7868838  0.5291071  0.8035165  0.09967763
  13                 1350     0.7866513  0.5332143  0.8050549  0.09903337
  13                 1440     0.7831407  0.5353571  0.8028571  0.10343168
  13                 1530     0.7827208  0.5353571  0.8086264  0.10354256
  13                 1620     0.7853287  0.5289286  0.8048901  0.09915695
  13                 1710     0.7812304  0.5357143  0.8048901  0.10858283
  13                 1800     0.7835655  0.5383929  0.8034615  0.10097554
  13                 1890     0.7837794  0.5385714  0.8003846  0.10604950
  13                 1980     0.7813717  0.5385714  0.8018681  0.10702858
  13                 2070     0.7826923  0.5385714  0.7996703  0.10414023
  13                 2160     0.7851550  0.5344643  0.8032967  0.09936576
  13                 2250     0.7823989  0.5371429  0.7990110  0.10224439
  13                 2340     0.7831790  0.5425000  0.8005495  0.09886195
  13                 2430     0.7830190  0.5355357  0.7990659  0.09913737
  13                 2520     0.7813216  0.5360714  0.7969231  0.09925582
  13                 2610     0.7799156  0.5358929  0.7976374  0.10329450
  13                 2700     0.7798401  0.5332143  0.7997253  0.10421949
  Sens SD    Spec SD   
  0.1777103  0.08663914
  0.1701192  0.08374489
  0.1808900  0.08590853
  0.1752228  0.08739949
  0.1846661  0.08970389
  0.1835766  0.08265065
  0.1761140  0.09025480
  0.1777284  0.09143639
  0.1806812  0.09641104
  0.1782595  0.08849506
  0.1752950  0.09337001
  0.1789988  0.09635116
  0.1809847  0.09408281
  0.1843693  0.09476554
  0.1812507  0.09401187
  0.1835752  0.09408500
  0.1805142  0.09170154
  0.1695806  0.08919332
  0.1697834  0.08874281
  0.1747606  0.09446991
  0.1730320  0.09166057
  0.1724689  0.08953607
  0.1744359  0.09271722
  0.1773656  0.09285979
  0.1712850  0.08927957
  0.1755700  0.09289466
  0.1742377  0.09418201
  0.1732671  0.09437052
  0.1782337  0.09553342
  0.1825936  0.09587119
  0.1865808  0.08887699
  0.1820127  0.08910152
  0.1805539  0.08641081
  0.1860394  0.09219853
  0.1918641  0.09405565
  0.1894602  0.09264055
  0.1874606  0.09886611
  0.2004440  0.09446862
  0.1980157  0.08964506
  0.1991190  0.09139207
  0.1885607  0.08862590
  0.1897724  0.09185855
  0.1902809  0.08933407
  0.1916336  0.09055145
  0.1901522  0.09013682
  0.1915366  0.09303824
  0.1975196  0.08958333
  0.1976512  0.08840680
  0.1894496  0.08992323
  0.1890820  0.08886532
  0.1897151  0.08808979
  0.1896949  0.09027353
  0.1907351  0.09026833
  0.1872249  0.08798220
  0.1841183  0.08962756
  0.1837541  0.08887982
  0.1847191  0.08763726
  0.1874485  0.08865644
  0.1951582  0.08631761
  0.1904150  0.08704997
  0.1733486  0.09387527
  0.1855505  0.09315996
  0.1836994  0.08930718
  0.1827932  0.09180982
  0.1811370  0.09477454
  0.1871975  0.09400966
  0.1925826  0.09531573
  0.1943733  0.09852260
  0.1889536  0.09387838
  0.1893555  0.09770992
  0.1891836  0.09237841
  0.1935294  0.09384914
  0.1961673  0.09626987
  0.1920454  0.09854656
  0.1927041  0.10093690
  0.1896012  0.09350734
  0.1929409  0.09938307
  0.1947884  0.09732020
  0.1924947  0.09811373
  0.1926903  0.10198483
  0.1909639  0.10149680
  0.1894031  0.10066778
  0.1901970  0.10585111
  0.1871466  0.10489938
  0.1889150  0.10035456
  0.1873643  0.10343896
  0.1891420  0.10333537
  0.1889804  0.10045091
  0.1870818  0.09983970
  0.1871820  0.10042176
  0.1827501  0.08815282
  0.1916975  0.09283391
  0.1842880  0.09188094
  0.1981806  0.09674925
  0.1943743  0.09395989
  0.1926636  0.09913614
  0.1929142  0.09834259
  0.1934804  0.09859431
  0.1944694  0.10003275
  0.1943328  0.09259433
  0.1934337  0.09483526
  0.1915910  0.09666753
  0.1910613  0.09399109
  0.1881907  0.09476341
  0.1947740  0.09705383
  0.1920085  0.09773888
  0.1963216  0.09364968
  0.1930925  0.09592561
  0.1927623  0.09699416
  0.1920822  0.09779682
  0.1919538  0.10113912
  0.1911298  0.09963168
  0.1899804  0.09831792
  0.1895312  0.09658933
  0.1891812  0.09753243
  0.1866806  0.09642660
  0.1877252  0.09394618
  0.1872009  0.09575833
  0.1859669  0.09647578
  0.1868917  0.09761118

Tuning parameter 'shrinkage' was held constant at a value of 0.1

Tuning parameter 'n.minobsinnode' was held constant at a value of 20
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 90, interaction.depth =
 1, shrinkage = 0.1 and n.minobsinnode = 20. 

> ## The acid test is dissapointing, but I've seen worse.
> 
> testPred <- predict(gbmFit1, testDescr)

> postResample(testPred, testClass)
  Accuracy      Kappa 
0.60360360 0.07289294 

> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     12   18
    Weak       26   55
                                          
               Accuracy : 0.6036          
                 95% CI : (0.5063, 0.6952)
    No Information Rate : 0.6577          
    P-Value [Acc > NIR] : 0.9022          
                                          
                  Kappa : 0.0729          
 Mcnemar's Test P-Value : 0.2913          
                                          
            Sensitivity : 0.7534          
            Specificity : 0.3158          
         Pos Pred Value : 0.6790          
         Neg Pred Value : 0.4000          
             Prevalence : 0.6577          
         Detection Rate : 0.4955          
   Detection Prevalence : 0.7297          
      Balanced Accuracy : 0.5346          
                                          
       'Positive' Class : Weak            
                                          

> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)

> postResample(trainPred, trainClass)
 Accuracy     Kappa 
0.8086124 0.5623037 

> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     47   14
    Weak       26  122
                                          
               Accuracy : 0.8086          
                 95% CI : (0.7486, 0.8596)
    No Information Rate : 0.6507          
    P-Value [Acc > NIR] : 3.926e-07       
                                          
                  Kappa : 0.5623          
 Mcnemar's Test P-Value : 0.08199         
                                          
            Sensitivity : 0.8971          
            Specificity : 0.6438          
         Pos Pred Value : 0.8243          
         Neg Pred Value : 0.7705          
             Prevalence : 0.6507          
         Detection Rate : 0.5837          
   Detection Prevalence : 0.7081          
      Balanced Accuracy : 0.7704          
                                          
       'Positive' Class : Weak            
                                          
Warning messages:
1: In eval(expr, envir, enclos) : adjusting
2: In eval(expr, envir, enclos) :
  overfitting: correlations: err.trainDescr: DEPSPOKE, DEPBUCKET, SDEPHR, AVGSQ, TRNRANKGRP, xAVAILBUCKET
> ## *Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> flight <- flight1
> 
> ## So something is defining the behaviour.
> 
> ## Try to simplify structure
> 
> head(model.matrix(LEGTYPE ~ ., data = flight))
   (Intercept) SDEPHR SKDDEPSTAALB SKDDEPSTAAMS SKDDEPSTAANC SKDDEPSTAATT
2            1     14            0            0            0            0
5            1     11            0            0            0            0
7            1     14            0            0            0            0
13           1     13            0            0            0            0
14           1     16            0            0            0            0
17           1     15            0            0            0            0
   SKDDEPSTAAUA SKDDEPSTAAUS SKDDEPSTABDA SKDDEPSTABDL SKDDEPSTABNA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTABOI SKDDEPSTABOS SKDDEPSTABRU SKDDEPSTABUF SKDDEPSTABWI
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTACCC SKDDEPSTACDG SKDDEPSTACHS SKDDEPSTACLE SKDDEPSTACMH
2             1            0            0            0            0
5             0            0            0            0            0
7             1            0            0            0            0
13            0            0            0            0            0
14            1            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTACUN SKDDEPSTADDD SKDDEPSTADEN SKDDEPSTADFW SKDDEPSTADSM
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            1            0            0            0
   SKDDEPSTADTW SKDDEPSTADUB SKDDEPSTAEWR SKDDEPSTAFCO SKDDEPSTAFLL
2             0            0            0            0            0
5             1            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAFRA SKDDEPSTAGCM SKDDEPSTAGDL SKDDEPSTAGEG SKDDEPSTAGIG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAHNL SKDDEPSTAIAH SKDDEPSTAILM SKDDEPSTAIND SKDDEPSTAJAX
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAJFK SKDDEPSTAKOA SKDDEPSTALAS SKDDEPSTALAX SKDDEPSTALGA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTALGB SKDDEPSTALGW SKDDEPSTALHR SKDDEPSTALIH SKDDEPSTAMAD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMAN SKDDEPSTAMBJ SKDDEPSTAMCI SKDDEPSTAMCO SKDDEPSTAMDT
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMEX SKDDEPSTAMHT SKDDEPSTAMIA SKDDEPSTAMKE SKDDEPSTAMSP
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMSY SKDDEPSTAMUC SKDDEPSTAMZT SKDDEPSTANAS SKDDEPSTAOAK
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAOGG SKDDEPSTAOMA SKDDEPSTAONT SKDDEPSTAORD SKDDEPSTAORF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAPBI SKDDEPSTAPDX SKDDEPSTAPIT SKDDEPSTAPLS SKDDEPSTAPPP
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            1
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAPUJ SKDDEPSTAPVD SKDDEPSTAPVR SKDDEPSTAPWM SKDDEPSTARDU
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTARIC SKDDEPSTARNO SKDDEPSTAROC SKDDEPSTARSW SKDDEPSTASAN
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASAT SKDDEPSTASEA SKDDEPSTASFO SKDDEPSTASJC SKDDEPSTASJD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASJO SKDDEPSTASJU SKDDEPSTASLC SKDDEPSTASMF SKDDEPSTASNA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASRQ SKDDEPSTASTL SKDDEPSTASTT SKDDEPSTASXM SKDDEPSTASYR
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTATLV SKDDEPSTATPA SKDDEPSTAXHP SKDDEPSTAYEG SKDDEPSTAYVR
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAYYC SKDDEPSTAZRH SKDARRSTAALB SKDARRSTAAMS SKDARRSTAANC
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAATT SKDARRSTAAUA SKDARRSTAAUS SKDARRSTABDA SKDARRSTABDL
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTABNA SKDARRSTABOI SKDARRSTABOS SKDARRSTABRU SKDARRSTABUF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            1            0            0
17            0            0            0            0            0
   SKDARRSTABWI SKDARRSTACCC SKDARRSTACDG SKDARRSTACHS SKDARRSTACLE
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            1            0            0            0
   SKDARRSTACMH SKDARRSTACUN SKDARRSTADDD SKDARRSTADEN SKDARRSTADFW
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTADSM SKDARRSTADTW SKDARRSTADUB SKDARRSTAEWR SKDARRSTAFCO
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAFLL SKDARRSTAFRA SKDARRSTAGCM SKDARRSTAGDL SKDARRSTAGEG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAGIG SKDARRSTAHNL SKDARRSTAIAH SKDARRSTAILM SKDARRSTAIND
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAJAX SKDARRSTAJFK SKDARRSTAKOA SKDARRSTALAS SKDARRSTALAX
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTALGA SKDARRSTALGB SKDARRSTALGW SKDARRSTALHR SKDARRSTALIH
2             0            0            0            0            0
5             0            0            0            0            0
7             1            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMAD SKDARRSTAMAN SKDARRSTAMBJ SKDARRSTAMCI SKDARRSTAMCO
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMDT SKDARRSTAMEX SKDARRSTAMHT SKDARRSTAMIA SKDARRSTAMKE
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMSP SKDARRSTAMSY SKDARRSTAMUC SKDARRSTAMZT SKDARRSTANAS
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAOAK SKDARRSTAOGG SKDARRSTAOMA SKDARRSTAONT SKDARRSTAORD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            1
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAORF SKDARRSTAPBI SKDARRSTAPDX SKDARRSTAPIT SKDARRSTAPLS
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAPPP SKDARRSTAPUJ SKDARRSTAPVD SKDARRSTAPVR SKDARRSTAPWM
2             1            0            0            0            0
5             1            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTARDU SKDARRSTARIC SKDARRSTARNO SKDARRSTAROC SKDARRSTARSW
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASAN SKDARRSTASAT SKDARRSTASEA SKDARRSTASFO SKDARRSTASJC
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASJD SKDARRSTASJO SKDARRSTASJU SKDARRSTASLC SKDARRSTASMF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASNA SKDARRSTASRQ SKDARRSTASTL SKDARRSTASTT SKDARRSTASXM
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASYR SKDARRSTATLV SKDARRSTATPA SKDARRSTAXHP SKDARRSTAYEG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAYVR SKDARRSTAYYC SKDARRSTAZRH SKDEQP319 SKDEQP320 SKDEQP321
2             0            0            0         0         0         0
5             0            0            0         0         0         0
7             0            0            0         0         0         1
13            0            0            0         0         0         0
14            0            0            0         0         0         1
17            0            0            0         0         0         0
   SKDEQP332 SKDEQP333 SKDEQP734 SKDEQP75E SKDEQP75H SKDEQP767 SKDEQPA01
2          0         0         1         0         0         0         0
5          0         0         0         0         0         0         0
7          0         0         0         0         0         0         0
13         0         0         1         0         0         0         0
14         0         0         0         0         0         0         0
17         0         0         0         0         0         0         0
   SKDEQPA05 SKDEQPA19 SKDEQPA21 SKDEQPE90 SKDEPS       D00    AVGSQ AVGLOFATC
2          0         0         0         0     32 0.2500000 3.258065  3.258065
5          0         0         0         1     72 0.2916667 2.986111  3.805556
7          0         0         0         0     88 0.3295455 2.551724  3.701149
13         0         0         0         0     32 0.3750000 3.000000  3.903226
14         0         0         0         0     72 0.3750000 3.295775  3.859155
17         0         0         0         0     84 0.3809524 3.939759  3.361446
   UPLINEATCIMPLow UPLINEATCIMPMed UPLINEATCIMPMedHigh UPLINEATCIMPMedLow
2                0               1                   0                  0
5                0               0                   0                  0
7                0               0                   0                  1
13               0               1                   0                  0
14               0               0                   0                  1
17               1               0                   0                  0
   DEPSTAATCIMPLow DOWNLINEATCIMPLow AVGSKDAVAIL AVAILBUCKETA05 AVAILBUCKETA10
2                0                 0   10.903226              0              1
5                1                 0    2.000000              0              0
7                0                 0    9.647059              1              0
13               0                 0   17.354839              0              0
14               0                 0   17.057143              0              0
17               0                 0   10.621951              0              1
   AVAILBUCKETA15 AVAILBUCKETA20 AVAILBUCKETA25 AVAILBUCKETA30 AVAILBUCKETA<0
2               0              0              0              0              0
5               0              0              0              0              0
7               0              0              0              0              0
13              1              0              0              0              0
14              1              0              0              0              0
17              0              0              0              0              0
   DEPBUCKETD2 DEPBUCKETD3 DEPBUCKETD4 DEPBUCKETD5 DEPBUCKETD6 DEPBUCKETD7
2            0           0           0           1           0           0
5            0           0           1           0           0           0
7            0           0           0           1           0           0
13           0           0           0           1           0           0
14           0           0           0           0           1           0
17           0           0           0           0           1           0
   DEPBUCKETD8 ARRBUCKETA2 ARRBUCKETA3 ARRBUCKETA4 ARRBUCKETA5 ARRBUCKETA6
2            0           0           0           0           0           1
5            0           0           0           0           1           0
7            0           0           0           0           0           1
13           0           0           0           0           0           1
14           0           0           0           0           0           0
17           0           0           0           0           0           1
   ARRBUCKETA7 ARRBUCKETA8 DEPRANKGRPLow DEPRANKGRPMed DEPRANKGRPMedHigh
2            0           0             1             0                 0
5            0           0             0             1                 0
7            0           0             1             0                 0
13           0           0             0             0                 0
14           1           0             1             0                 0
17           0           0             0             0                 0
   DEPRANKGRPMedLow TRNRANKGRPLow TRNRANKGRPMed TRNRANKGRPMedHigh
2                 0             1             0                 0
5                 0             1             0                 0
7                 0             1             0                 0
13                1             0             0                 0
14                0             1             0                 0
17                1             0             1                 0
   TRNRANKGRPMedLow ARRRANKGRPLow ARRRANKGRPMed ARRRANKGRPMedHigh
2                 0             0             0                 1
5                 0             0             0                 1
7                 0             0             1                 0
13                1             0             0                 0
14                0             0             0                 1
17                0             0             0                 1
   ARRRANKGRPMedLow DEPSPOKETRUE ARRSPOKETRUE xHNGRTRUE xDURN2
2                 0            0            0         0      2
5                 0            1            0         0      2
7                 0            0            1         0      2
13                1            0            1         0      2
14                0            0            1         0      2
17                0            0            0         0      2
> 
> dummies <- dummyVars(LEGTYPE ~ ., data = flight)
> flight.dum <- predict(dummies, newdata = flight)
> 
> ## It may be too big to use, but useful for inspection.
> 
> ### Numeric variables
> 
> ## Check some more numeric correlations, I haven't scaled yet.
> ## I'd cut correlations above 0.75 because of overfitting.
> 
> x1 <- as.data.frame(as.matrix(sapply(flight, class)))
> 
> flight.num <- flight[,names(x1[which(x1$V1 %in% c("numeric", "integer")),])]
> 
> flight.nzv <- nearZeroVar(flight.num, saveMetrics = TRUE)
> flight.nzv
            freqRatio percentUnique zeroVar   nzv
SDEPHR       1.038462        5.9375   FALSE FALSE
SKDEPS       1.000000       19.0625   FALSE FALSE
D00          1.166667       75.3125   FALSE FALSE
AVGSQ        6.333333       82.8125   FALSE FALSE
AVGLOFATC    1.000000       78.4375   FALSE FALSE
AVGSKDAVAIL  1.000000       87.5000   FALSE FALSE
xDURN2       1.428571        2.5000   FALSE FALSE
> 
> # annoying NA
> flight.cor <- cor(flight.num, use = "pairwise.complete.obs")
> 
> descrCorr <- findCorrelation(flight.cor, cutoff = .65, verbose=TRUE)
Considering row	 1 column	 4 value	 0.956 
  Flagging column	 1 
Considering row	 4 column	 3 value	 0.414 
Considering row	 4 column	 6 value	 0.173 
Considering row	 4 column	 7 value	 0.201 
Considering row	 4 column	 5 value	 0.103 
Considering row	 4 column	 2 value	 0.082 
Considering row	 3 column	 6 value	 0.266 
Considering row	 3 column	 7 value	 0.071 
Considering row	 3 column	 5 value	 0.114 
Considering row	 3 column	 2 value	 0.006 
Considering row	 6 column	 7 value	 0.031 
Considering row	 6 column	 5 value	 0.094 
Considering row	 6 column	 2 value	 0.067 
Considering row	 7 column	 5 value	 0.137 
Considering row	 7 column	 2 value	 0.005 
Considering row	 5 column	 2 value	 0.041 
> 
> colnames(flight.num)[descrCorr]
[1] "SDEPHR"
> 
> ## Which tells me that departure time is very highly correlated to AVGSQ.
> ## AVGSQ is average stand queue?
> 
> ### Try and impute the AVG, it might have more information than the
> ### bucket.
> 
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))
> 
> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1
> 
> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]
> 
> preProcValues <- preProcess(flight.na, method = c("knnImpute"))
> flight.na1 <- predict(preProcValues, flight.na)
> 
> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL
> 
> ## And I'll leave the centered and scale values in for now.
> ## and delete the troublesome ones
> 
> flight$AVGSKDAVAIL <- NULL
> flight$xHNGR <- NULL
> flight$AVAILBUCKET <- NULL
> 
> # This should be deleted, leave it in and the results are ideal because it defines LEGTYPE.
> flight$D00 <- NULL
> 
> ## Keep the results but don't change the order.
> outcomes.flight <- flight$LEGTYPE
> 
> flight$LEGTYPE <- NULL
> 
> ## If you know your factors are definitely factors, you don't need this
> ##  asNumeric <- function(x) as.numeric(as.character(x))
> 
> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))
> 
> flight.num0 <- factors.numeric(flight)
> 
> flight.scl0 <- scale(flight.num0)
> 
> ## Now split the results
> 
> set.seed(seed.mine)
> inTrain <- createDataPartition(outcomes.flight, p = 0.65, list = FALSE)
> 
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> 
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> 
> prop.table(table(flight.scl0))
flight.scl0
    -2.99546983996958     -2.98604368384811     -2.82110052361751 
           0.00281250            0.00015625            0.00015625 
    -2.64037641778924     -2.37742331516569     -2.09431321436608 
           0.00015625            0.00015625            0.00031250 
    -2.02525208119049     -2.02364615961949     -1.96706162425765 
           0.00046875            0.00093750            0.00015625 
    -1.94787383036273     -1.91934227796699     -1.87162293167633 
           0.00125000            0.00015625            0.00015625 
    -1.80813803757891      -1.8064397520718     -1.76880294648328 
           0.00093750            0.00093750            0.00453125 
     -1.7104004231695     -1.67620690253875     -1.63572266525187 
           0.00312500            0.00015625            0.00078125 
    -1.60554554037119     -1.58829697245811     -1.58375887562806 
           0.00265625            0.00062500            0.00031250 
    -1.56068940274137     -1.55266802930898     -1.55257138616628 
           0.00593750            0.00015625            0.00015625 
    -1.54865734259279     -1.54635333101763     -1.54295794614133 
           0.00015625            0.00015625            0.00015625 
    -1.53179508600425     -1.53074294246617     -1.50769426210174 
           0.00203125            0.00015625            0.00015625 
    -1.49330986644838     -1.47983129638045     -1.47646498237513 
           0.00015625            0.00171875            0.00015625 
    -1.44796824755814     -1.43812707979848     -1.43616463590287 
           0.00015625            0.00031250            0.00015625 
     -1.4311495031078     -1.42786750675664     -1.42754311366228 
           0.00062500            0.00031250            0.00015625 
     -1.4230237164245     -1.42196682798086     -1.40691590144974 
           0.00015625            0.00015625            0.00750000 
    -1.40295304316347     -1.39839761187043     -1.38337483337197 
           0.00343750            0.00015625            0.00015625 
    -1.37828409873765     -1.37590371713284      -1.3753288895824 
           0.00031250            0.00078125            0.00015625 
    -1.37383369560894     -1.37045453151584     -1.35466334686085 
           0.00015625            0.00015625            0.00015625 
    -1.33716625322094     -1.33398496346823     -1.33080367371552 
           0.00015625            0.00015625            0.00015625 
    -1.32393992750903      -1.3160853172316     -1.31578091655701 
           0.00093750            0.00015625            0.00015625 
    -1.31443367614047      -1.3133256164209     -1.30151560934568 
           0.00015625            0.00015625            0.00015625 
    -1.30111163600234     -1.29600486257245     -1.28619597667342 
           0.00015625            0.00031250            0.00031250 
    -1.28367748081635     -1.28186181839242      -1.2799413346293 
           0.00031250            0.00015625            0.00015625 
    -1.27197613788523     -1.26773489691459      -1.2671778786613 
           0.00109375            0.00015625            0.00015625 
     -1.2615812276646     -1.25974760485758     -1.25283365916062 
           0.00031250            0.00078125            0.00015625 
    -1.25178454113998     -1.24659260411695     -1.24079645146543 
           0.00015625            0.00015625            0.00015625 
     -1.2302338686483     -1.23020377865797      -1.2268968080815 
           0.00015625            0.00687500            0.00031250 
    -1.22001234826142     -1.21809512250389     -1.21512040999215 
           0.00046875            0.00015625            0.00015625 
    -1.21024953572476     -1.20647153886774     -1.20560405725029 
           0.00015625            0.00015625            0.00015625 
    -1.20188627600106     -1.20036054595575     -1.20011285144544 
           0.00031250            0.00140625            0.00015625 
    -1.19042311450129     -1.18991798468508     -1.18966337127103 
           0.00015625            0.00015625            0.00062500 
    -1.16804855863761     -1.16764210792351     -1.16749679150174 
           0.00093750            0.00015625            0.00015625 
    -1.16258400593847     -1.16018257780086     -1.15839829359119 
           0.00015625            0.00640625            0.00015625 
    -1.14179763548495     -1.13992628855288     -1.13935994002253 
           0.00015625            0.00031250            0.00031250 
    -1.13310730700243     -1.13102279477938     -1.12993289335973 
           0.00015625            0.00015625            0.00015625 
    -1.12915754122589     -1.12753063368423     -1.12667091460446 
           0.00015625            0.00015625            0.00015625 
    -1.12622940836933     -1.12368140470519     -1.12361616254288 
           0.00031250            0.00015625            0.00062500 
    -1.12145428351456     -1.11910330109794     -1.11800948418703 
           0.00015625            0.00015625            0.00015625 
    -1.11608476901381     -1.11429923219746     -1.09261479989672 
           0.00062500            0.00015625            0.00015625 
    -1.09084552937417     -1.09012044993392      -1.0895833019642 
           0.00015625            0.00015625            0.00031250 
    -1.08549109658463     -1.06938028371369     -1.06604781193988 
           0.00031250            0.00015625            0.00015625 
    -1.06587003530766        -1.06412097939     -1.05534288054392 
           0.00015625            0.00046875            0.00015625 
    -1.04945721011816     -1.04845626690162     -1.04766888572427 
           0.00015625            0.00015625            0.00015625 
    -1.04755297964098     -1.04598728075964     -1.04536609890991 
           0.00031250            0.00031250            0.00031250 
    -1.02993885350447     -1.02151758080685     -1.01733580186582 
           0.00015625            0.00203125            0.02453125 
    -1.01577847702439      -1.0138904262493      -1.0121571897662 
           0.00015625            0.00015625            0.00062500 
    -1.00929178081963     -1.00745946934895     -1.00714202059705 
           0.00015625            0.00015625            0.00015625 
    -1.00664275166081     -1.00407661804032     -1.00110637205939 
           0.00046875            0.00015625            0.00015625 
   -0.997768048748026    -0.991929422812267    -0.989060788495757 
           0.00328125            0.00015625            0.00031250 
    -0.98572380365604    -0.979554261682366    -0.976324799963229 
           0.00015625            0.00031250            0.00875000 
   -0.973173077974651    -0.971118460177678     -0.96975725707502 
           0.01640625            0.00015625            0.00015625 
   -0.963461694934854    -0.961159884505833    -0.960193400142389 
           0.00015625            0.00015625            0.00046875 
   -0.958010282948452    -0.957720936633644    -0.955230663538487 
           0.00015625            0.00015625            0.00015625 
   -0.953451859649493    -0.952397629449069    -0.951677411170411 
           0.00031250            0.00015625            0.01765625 
   -0.947281520180146    -0.946066444247069    -0.942123167843126 
           0.00015625            0.00015625            0.00015625 
   -0.941185041055857    -0.939666457415937    -0.937914389255748 
           0.00015625            0.00031250            0.00015625 
   -0.937428692031181    -0.937143144639067    -0.929006249994557 
           0.00015625            0.00203125            0.00031250 
   -0.928956547037233    -0.927234345076844    -0.926325405165677 
           0.00015625            0.00015625            0.00015625 
   -0.926208874394783     -0.92432711582923    -0.923751900565718 
           0.00015625            0.00015625            0.00015625 
   -0.921447647976772    -0.920026610901552    -0.919775930100724 
           0.00015625            0.00015625            0.00031250 
   -0.919418999070816    -0.918979533540974    -0.918834367344145 
           0.00093750            0.00015625            0.00015625 
   -0.918602057207572    -0.918233359080158    -0.916620305783416 
           0.00015625            0.00015625            0.00031250 
   -0.908229610518583    -0.907879271266391    -0.907626204980156 
           0.00031250            0.00015625            0.00015625 
   -0.906631706666217    -0.905610577820333    -0.905104725277818 
           0.00015625            0.00015625            0.00015625 
   -0.904170844231002    -0.902563699445797    -0.902495470961171 
           0.00031250            0.00015625            0.00046875 
   -0.902207570970879    -0.900277820755885    -0.900269127160796 
           0.00015625            0.00609375            0.00015625 
   -0.900105713501894    -0.897103060359799    -0.896252308815885 
           0.00015625            0.00015625            0.00015625 
   -0.895759768448355    -0.895685333371447    -0.891948830933419 
           0.00015625            0.00015625            0.00015625 
   -0.891482707849845     -0.89086838304768    -0.889814536282523 
           0.00015625            0.02343750            0.00015625 
   -0.886894039811436    -0.885423108336021    -0.885386138492139 
           0.00093750            0.00015625            0.01593750 
   -0.884574764423174    -0.881181388644532    -0.881133728915611 
           0.00015625            0.00015625            0.00015625 
   -0.879323305434347    -0.878872666379052    -0.877901133624378 
           0.00015625            0.00015625            0.00015625 
   -0.876749332956921    -0.876685019263073    -0.875765771148607 
           0.00031250            0.00015625            0.00031250 
   -0.875473779114446     -0.87537693015952    -0.872246314823305 
           0.00015625            0.00015625            0.00015625 
   -0.871001261435858    -0.870353841103083    -0.869162583211394 
           0.00015625            0.00015625            0.00015625 
   -0.866780745576637    -0.866244907634358    -0.858819232798091 
           0.00015625            0.00015625            0.00015625 
   -0.856265820894777    -0.844253476212177    -0.844066341550782 
           0.00078125            0.00015625            0.00015625 
   -0.842025743633279    -0.831738843759029    -0.830837909586882 
           0.02921875            0.00015625            0.02515625 
   -0.829374923233683    -0.828920190368225    -0.827915178181078 
           0.00015625            0.00093750            0.00015625 
   -0.827728686266157    -0.826039032973297    -0.822416105203804 
           0.00015625            0.00015625            0.00015625 
   -0.821797313281808    -0.819285769008092    -0.816336564086851 
           0.00015625            0.00015625            0.00015625 
   -0.814051297945908    -0.811605617460827    -0.809148421270981 
           0.00015625            0.00015625            0.00015625 
   -0.804302031270971    -0.800154571238789    -0.795175551540305 
           0.00062500            0.00015625            0.00171875 
   -0.792845872277945    -0.790185643279993    -0.789212464897955 
           0.02015625            0.00859375            0.00046875 
   -0.787996109659257    -0.785742695872334    -0.783287556756109 
           0.00015625            0.00015625            0.00015625 
    -0.78222517242437    -0.777611190965241    -0.777259256743858 
           0.00015625            0.00015625            0.00015625 
   -0.775052088417874    -0.768725111385422      -0.7653899578722 
           0.00031250            0.00015625            0.00015625 
   -0.764328853007072    -0.759372004638613    -0.759121665238872 
           0.00015625            0.00015625            0.00015625 
   -0.758171518227594    -0.752387355098689    -0.752338241647165 
           0.00015625            0.00015625            0.00031250 
   -0.751716727129916    -0.750007134146443    -0.748171465050933 
           0.00015625            0.00562500            0.00015625 
   -0.743693425437366     -0.74226506946404    -0.738477819728135 
           0.00718750            0.00015625            0.00015625 
   -0.735940818773818    -0.734501921638923    -0.723911474638978 
           0.00015625            0.00015625            0.00015625 
   -0.720697236097384    -0.718445199078953    -0.715142805531928 
           0.00031250            0.00015625            0.00031250 
   -0.713461500253351    -0.710452171936934    -0.708684788599593 
           0.00015625            0.00015625            0.00015625 
   -0.708003561812545    -0.702080356630785     -0.70037445202336 
           0.00015625            0.00015625            0.00203125 
    -0.69602539257426     -0.69280361708918    -0.687853983052082 
           0.00015625            0.03375000            0.00015625 
    -0.68694861300278    -0.684622918007104    -0.682222958529648 
           0.00015625            0.00015625            0.00015625 
   -0.681188975020078    -0.673798181086569     -0.66884926915034 
           0.00187500            0.00015625            0.00015625 
     -0.6653122497357    -0.654779601264497    -0.648410662399554 
           0.00015625            0.00015625            0.00078125 
   -0.647068571912601    -0.646559789740211    -0.633905116384853 
           0.00015625            0.00015625            0.00015625 
   -0.633276439235621    -0.626480919280269    -0.624813955253419 
           0.00015625            0.00015625            0.00015625 
   -0.621563193776932    -0.615573756562581    -0.613123253862724 
           0.00015625            0.00015625            0.00171875 
   -0.604038319371604    -0.596446872775748    -0.596237216599971 
           0.00015625            0.00046875            0.00015625 
   -0.596137826610777    -0.592583054332584    -0.590968847296576 
           0.00015625            0.00359375            0.00015625 
   -0.581016668721787     -0.57842864719944    -0.577046832499099 
           0.00015625            0.00015625            0.00015625 
   -0.576399963736262    -0.567294133064953    -0.562646449882806 
           0.00187500            0.00015625            0.00031250 
   -0.559949234902497    -0.553868745195444    -0.551562209118441 
           0.00031250            0.00015625            0.00859375 
   -0.548486073402725    -0.545057532705371    -0.544483083151942 
           0.00015625            0.00046875            0.00093750 
   -0.543553164656681    -0.542887786706365    -0.542791834600063 
           0.00015625            0.00015625            0.03859375 
   -0.535816263171991    -0.529620965141671    -0.523583345339874 
           0.00031250            0.00015625            0.00015625 
   -0.522876883678594    -0.515144874010522    -0.511242837482551 
           0.00015625            0.00015625            0.00015625 
   -0.511062050911504    -0.509452501139644    -0.507981951223969 
           0.00500000            0.00015625            0.00015625 
   -0.506004946851197    -0.504251327555701    -0.503668338010739 
           0.00015625            0.00203125            0.00015625 
   -0.497665904683127    -0.492519293528136    -0.488304476973275 
           0.00015625            0.00062500            0.00015625 
   -0.486275884354524    -0.480531685495119    -0.479070530598709 
           0.00015625            0.00015625            0.00015625 
   -0.476991811548017    -0.475764665500524    -0.473473045518126 
           0.00078125            0.00015625            0.00015625 
   -0.472612890303562    -0.464757185992567    -0.456186401194196 
           0.00015625            0.00015625            0.00015625 
   -0.454553689487183    -0.453074332488957    -0.452195518537862 
           0.00015625            0.00015625            0.00015625 
   -0.450040882361118    -0.446015592229304    -0.443168278929009 
           0.00015625            0.00015625            0.00015625 
    -0.44055550390433    -0.439275967288811    -0.439064986884659 
           0.00093750            0.00015625            0.00031250 
   -0.436572045333686    -0.433356062339654     -0.43210269137514 
           0.00015625            0.00015625            0.00031250 
   -0.429159183376661     -0.42811270638386    -0.424489571114943 
           0.00015625            0.00015625            0.00015625 
   -0.424136094192972    -0.422368710855631    -0.422286506964679 
           0.00015625            0.00015625            0.00015625 
     -0.4217879739841     -0.42160028367728    -0.408926090390664 
           0.00015625            0.00015625            0.00062500 
   -0.406238662084726    -0.405337563546837    -0.402845924603104 
           0.00015625            0.00015625            0.00015625 
   -0.398392401687235    -0.392753100892855    -0.392721940787981 
           0.00015625            0.00015625            0.00015625 
   -0.389990557124863    -0.383778543291898    -0.381829344162238 
           0.00203125            0.00031250            0.00031250 
   -0.378610740922975    -0.377352421209284     -0.37278098800314 
           0.00015625            0.00015625            0.00015625 
   -0.368704530397105    -0.364033384865912    -0.363121805899083 
           0.00015625            0.00015625            0.00015625 
   -0.361905601371654    -0.360992312891898     -0.36077985218898 
           0.00015625            0.00015625            0.00015625 
    -0.35995405519458    -0.354602189779798    -0.354221703071568 
           0.00046875            0.00015625            0.00015625 
   -0.354125613590753     -0.35383985286255    -0.350820163721666 
           0.00015625            0.00015625            0.00015625 
   -0.347880750045415    -0.347682518083072    -0.344794514479224 
           0.00031250            0.00015625            0.00015625 
   -0.344246401931106    -0.340586009596143    -0.338241270869783 
           0.00015625            0.00015625            0.00031250 
   -0.336627924656718    -0.333999550987416    -0.331679860754818 
           0.00015625            0.00015625            0.00015625 
   -0.327473828580897    -0.325591270635287    -0.320604647133837 
           0.00015625            0.00015625            0.00015625 
   -0.320293393650012    -0.318998347766866    -0.313800886365509 
           0.00015625            0.00015625            0.00015625 
   -0.308729731711204     -0.30775968479621    -0.307488803472333 
           0.00015625            0.00062500            0.00015625 
   -0.305912488397539    -0.300040013990283    -0.299281804870489 
           0.00015625            0.00015625            0.00015625 
   -0.297576089117692    -0.294612153988498    -0.290886990303406 
           0.00015625            0.00015625            0.00015625 
   -0.289476667647491    -0.287805419014019    -0.284664135032912 
           0.00015625            0.00031250            0.00062500 
   -0.283279035792871    -0.278947445070673    -0.278430676385642 
           0.00015625            0.00015625            0.01140625 
   -0.277028655971768    -0.274352800845479    -0.269810489634915 
           0.00015625            0.00015625            0.00875000 
   -0.268327804913194    -0.264273008183568    -0.263991250766728 
           0.00015625            0.00015625            0.00015625 
   -0.263633329101249    -0.256569345435893    -0.255210887064625 
           0.00015625            0.00015625            0.00015625 
   -0.254264930167697    -0.253205544043426    -0.250717006205447 
           0.00015625            0.00015625            0.00015625 
   -0.250531752899298    -0.249985351299549    -0.247578088366761 
           0.00015625            0.00015625            0.00015625 
   -0.244437996150226    -0.243268618233703    -0.242824942853484 
           0.00015625            0.00015625            0.00015625 
   -0.233740722783471    -0.232700345409106    -0.232349973253986 
           0.00015625            0.00015625            0.00015625 
   -0.231815214890401    -0.231309362347886     -0.23037548130107 
           0.00015625            0.00015625            0.00015625 
   -0.228412208040947    -0.226589859802479    -0.224837647995068 
           0.00015625            0.01656250            0.00015625 
   -0.223464759128966     -0.22331717855311    -0.222588752387258 
           0.00015625            0.00015625            0.00015625 
   -0.222456945885953    -0.220222816737245    -0.217487288707678 
           0.00015625            0.00031250            0.00046875 
   -0.216388232760497    -0.213098676881504    -0.212807560710942 
           0.00015625            0.00093750            0.00015625 
   -0.205527942504415    -0.202889656333141    -0.199061273711729 
           0.00015625            0.00015625            0.00015625 
   -0.197285663071406    -0.196655198635886    -0.187398059917142 
           0.00015625            0.00015625            0.00328125 
    -0.18553936273967    -0.184426534107832      -0.1807365557853 
           0.00015625            0.00015625            0.00031250 
   -0.173455385110242    -0.170696066339926    -0.167983070845547 
           0.00953125            0.00062500            0.00015625 
    -0.16706735776498     -0.16549287956689    -0.163323851054559 
           0.00015625            0.00015625            0.00015625 
   -0.163005226779217    -0.155721964916119     -0.15557956030375 
           0.00015625            0.00015625            0.00015625 
   -0.145050220201077    -0.140627037006184    -0.136663205761249 
           0.00015625            0.00015625            0.00015625 
   -0.135547666352963    -0.135353058341049    -0.135168941442998 
           0.00015625            0.00015625            0.00015625 
    -0.13422823788067    -0.128983100398563    -0.128772766161494 
           0.00015625            0.00015625            0.00062500 
   -0.128276147190878    -0.124732071896041    -0.122750748897942 
           0.00015625            0.00015625            0.00015625 
   -0.121913567685457    -0.114572129500928    -0.113273027561381 
           0.00015625            0.00015625            0.00015625 
   -0.107405286684043    -0.105529863556612    -0.103356043915892 
           0.00015625            0.00953125            0.00015625 
  -0.0959919473132286   -0.0946576344451732   -0.0921610479659292 
           0.00015625            0.00031250            0.00015625 
  -0.0897276946329045    -0.082082912166815   -0.0820786945748793 
           0.00015625            0.00015625            0.00031250 
  -0.0807439358161152   -0.0768089765376881   -0.0759616047321375 
           0.00015625            0.00140625            0.00015625 
  -0.0741942213947964   -0.0733788467156504   -0.0726315828860554 
           0.00015625            0.00718750            0.00015625 
  -0.0685974846038955   -0.0532150311664168   -0.0498043335027671 
           0.00093750            0.00015625            0.00015625 
  -0.0497543467601004   -0.0473016251818649   -0.0451490777305966 
           0.00015625            0.00015625            0.00031250 
  -0.0446498361490209   -0.0392160026639466   -0.0373582346840002 
           0.00015625            0.00015625            0.00015625 
  -0.0352851923820555   -0.0345646240252186   -0.0326438116903773 
           0.00031250            0.00031250            0.00015625 
  -0.0248451869138821   -0.0188880173129063    -0.013807090586871 
           0.00109375            0.00015625            0.00015625 
  -0.0119657325121257   -0.0114810502208166  -0.00721676013122688 
           0.00015625            0.00015625            0.00015625 
 -0.00368424503602545 -0.000580656453063986   0.00425466589044258 
           0.00015625            0.00015625            0.00015625 
  0.00624696207963468   0.00661720265702806    0.0104887638020741 
           0.00015625            0.00015625            0.00015625 
   0.0151944372905789    0.0177528116242494    0.0194770878491831 
           0.00421875            0.00015625            0.00015625 
   0.0217087977522383    0.0235168212825711    0.0255537765734798 
           0.00015625            0.00015625            0.00015625 
   0.0264730080152699    0.0271186027099238    0.0361351573082595 
           0.00015625            0.00031250            0.00015625 
   0.0362911121323546    0.0368634437985054    0.0454309894047899 
           0.00015625            0.00015625            0.00015625 
   0.0533298995579193    0.0570581595639766    0.0585759323236618 
           0.00015625            0.00937500            0.00015625 
   0.0675339577108118    0.0702113818864803    0.0729377618887858 
           0.00046875            0.00015625            0.00062500 
   0.0788793134968683    0.0789059252411879    0.0790823923337298 
           0.00015625            0.02343750            0.00046875 
   0.0797510873183287    0.0806069942083428    0.0841639835120876 
           0.00015625            0.00015625            0.00015625 
   0.0899621750174284    0.0966606496804153    0.0972018193465008 
           0.00015625            0.00015625            0.00015625 
    0.101566818289489     0.108411810410797     0.109012079979066 
           0.00062500            0.00015625            0.00046875 
     0.11244290268093     0.119444894039026     0.131046181957536 
           0.00015625            0.00015625            0.00203125 
    0.134889340170799     0.135028927523559     0.136658265622521 
           0.00015625            0.00015625            0.00015625 
    0.144157938789208     0.146258849789861     0.147318188850963 
           0.00015625            0.00015625            0.02984375 
    0.151115033119933     0.152349655315244     0.154426066228552 
           0.00015625            0.00015625            0.00015625 
     0.15737266071083     0.162873929857665     0.162973153669365 
           0.00015625            0.00015625            0.00015625 
    0.164891939398059     0.165580765616732     0.173693095305534 
           0.00015625            0.00015625            0.00015625 
    0.183009971581342     0.186789363756051     0.187969991368742 
           0.00093750            0.00015625            0.00015625 
    0.192709893790261     0.194724832331223     0.194735738184732 
           0.00015625            0.00015625            0.00015625 
    0.195991364801127     0.206802781312992     0.210386154876613 
           0.00015625            0.00015625            0.00500000 
    0.217235034249908       0.2177869344983     0.234906769563277 
           0.00031250            0.00203125            0.00015625 
    0.234973761205148     0.238837237065174     0.241127733319099 
           0.00031250            0.00015625            0.00015625 
    0.250135635132824      0.25028785413495     0.253309352340188 
           0.00015625            0.00015625            0.00078125 
    0.254814769298151     0.260835355687548     0.264960519475955 
           0.00015625            0.00015625            0.00015625 
    0.266044692238248      0.27127954776092     0.273304013334367 
           0.00015625            0.00015625            0.00015625 
    0.273531307307048     0.274822103147971     0.280770740587068 
           0.00015625            0.00015625            0.00015625 
    0.284591080073122     0.285810915205503     0.286937550828954 
           0.00015625            0.00015625            0.00046875 
    0.289640625615739     0.301307082566931     0.302882181759369 
           0.00015625            0.00015625            0.00015625 
    0.304256560508303     0.309710068792923     0.311251030414092 
           0.00015625            0.00015625            0.00015625 
    0.311802268812853     0.318128929047187     0.318922298138204 
           0.00015625            0.00031250            0.00015625 
    0.320852365313198     0.322875645177539     0.334350357273903 
           0.00015625            0.00015625            0.00015625 
    0.337167536402539     0.338400625416362     0.338901340452759 
           0.00015625            0.00031250            0.00140625 
    0.346939027258188     0.348766831423466     0.358991725758732 
           0.00015625            0.00015625            0.00015625 
    0.364034892089946     0.365884194608935     0.368674799710984 
           0.00015625            0.00015625            0.00015625 
    0.369643258716518     0.373829702918903     0.379821273586168 
           0.00015625            0.00062500            0.00015625 
    0.382087226815338      0.38685609839469       0.3878539441829 
           0.00015625            0.00015625            0.00015625 
     0.38923354153609     0.390865130076565     0.393785793790202 
           0.00015625            0.00093750            0.00015625 
    0.402956322412276     0.404247945632944      0.40569298299336 
           0.00015625            0.00015625            0.00015625 
    0.406064629649282      0.40786256349758     0.408056423319527 
           0.00015625            0.00109375            0.00015625 
    0.412247177017014     0.414419483912049     0.416346031539166 
           0.00015625            0.00046875            0.00015625 
     0.41794166276908     0.419463447191946     0.420106603846799 
           0.00015625            0.01078125            0.00015625 
    0.420379431706021     0.420869449539072     0.431214346889845 
           0.00406250            0.00015625            0.00015625 
    0.433937840525743     0.440278644951702     0.441895424076257 
           0.00031250            0.00015625            0.00015625 
    0.442828919700371     0.443274873059508     0.446173888246631 
           0.00046875            0.00984375            0.00015625 
    0.450718587802467     0.456900610463576     0.459555681956315 
           0.00015625            0.00031250            0.00015625 
    0.460696686048428     0.467876105484108     0.472728746197005 
           0.00015625            0.00015625            0.00015625 
    0.474472217743954     0.474601080341499     0.474734089218203 
           0.00015625            0.00031250            0.00015625 
    0.477973490467994     0.484307789443022     0.484652344952628 
           0.00015625            0.00015625            0.00015625 
    0.494792709324177     0.498497691565453     0.500784787450151 
           0.00109375            0.00515625            0.00015625 
    0.504691880000581     0.508425703980646      0.50861676779181 
           0.00031250            0.00015625            0.00015625 
     0.50996114523361     0.514344382856681     0.516995457862692 
           0.00015625            0.00015625            0.00015625 
    0.518586102739047     0.521829770584971     0.523840570430114 
           0.00015625            0.00015625            0.00015625 
    0.524285913333902     0.525227742436545     0.527917885589494 
           0.00015625            0.00015625            0.00015625 
    0.531983533422768     0.539966728864973     0.541903897062432 
           0.00015625            0.00015625            0.00046875 
    0.543994005812287     0.545724786000498     0.546756498947983 
           0.00125000            0.00015625            0.00203125 
    0.548923619243861     0.549353970396232       0.5588553176537 
           0.00015625            0.00015625            0.00031250 
    0.564138483610525     0.566992546543754     0.569133261860447 
           0.00015625            0.00015625            0.00015625 
    0.574903744908869     0.577978215152712     0.578343495716271 
           0.00031250            0.00109375            0.00015625 
    0.580241024741447     0.581634314964003     0.583204933976379 
           0.00015625            0.00015625            0.00015625 
     0.58873859479558     0.595455758634415     0.597057916427158 
           0.00015625            0.00031250            0.00015625 
    0.598720288571789     0.599162991111384     0.599578938399305 
           0.00031250            0.00015625            0.00015625 
     0.60342049593258     0.604292419065582     0.607847397763963 
           0.00015625            0.00015625            0.00015625 
    0.611956869618315     0.612059726969641     0.612784292101807 
           0.00015625            0.00062500            0.00015625 
    0.613557486760981     0.620580331763515     0.622971928913742 
           0.00015625            0.00015625            0.00375000 
     0.63588348041021     0.641390081029809     0.643182929950686 
           0.00015625            0.00015625            0.00015625 
    0.648293425210027     0.650684078195595     0.657754904789885 
           0.00015625            0.00046875            0.00015625 
    0.664732625480728     0.665678528246394     0.665791697835918 
           0.00015625            0.00984375            0.00015625 
    0.666578602798705     0.678050028820375     0.678379635730825 
           0.00015625            0.00015625            0.00015625 
    0.679808655934455     0.680412565586961     0.680711498268701 
           0.00328125            0.00015625            0.00015625 
    0.684080216155581     0.684149053017272     0.685295140133807 
           0.00281250            0.00015625            0.00031250 
    0.686201169423553     0.690582799388141     0.692180702201577 
           0.00015625            0.00421875            0.00015625 
    0.696595449900374     0.697435597111395     0.698914306548046 
           0.00015625            0.00015625            0.00015625 
     0.70193206265865     0.702647867819401     0.707754986014002 
           0.00015625            0.00062500            0.00015625 
    0.711210346763156     0.712920206015224     0.713369947147153 
           0.00015625            0.00015625            0.00015625 
    0.715327471836729     0.722275487513834     0.722728216151602 
           0.00031250            0.00156250            0.00015625 
      0.7239248415172      0.72708089915877     0.729737150343281 
           0.00015625            0.00015625            0.00015625 
    0.735388003016973     0.740385327518889     0.741422651587756 
           0.00031250            0.00015625            0.00015625 
    0.741444754160499     0.747108762937508     0.748191169284348 
           0.00015625            0.00031250            0.00015625 
    0.751436430272142     0.752533256420978     0.752674676426801 
           0.00015625            0.00015625            0.00015625 
    0.754611657443207     0.754889027400603     0.756349639135923 
           0.00125000            0.00015625            0.00015625 
    0.763526062479594     0.768717423291569     0.770997182276433 
           0.00015625            0.00015625            0.00015625 
     0.77805655959217     0.780455501601279      0.79111659134251 
           0.00015625            0.00015625            0.00015625 
    0.794424123694395     0.794542595446869     0.797594367513394 
           0.00046875            0.00015625            0.00015625 
    0.806459604893308     0.806575447067013     0.815325824113437 
           0.00015625            0.00171875            0.00031250 
    0.820054212719794     0.821566079066492     0.822735985643791 
           0.00015625            0.00015625            0.00015625 
    0.824910396049865     0.825564426121463     0.827093295015157 
           0.00015625            0.00281250            0.00015625 
    0.830498441784675     0.839706577696515     0.854374875678462 
           0.00031250            0.00015625            0.00015625 
    0.857045424718981     0.857046899457354     0.858539236690819 
           0.00031250            0.00015625            0.00109375 
    0.861958482401254     0.864973903806387     0.868060666977836 
           0.00015625            0.00031250            0.00015625 
    0.871547517399078     0.877907606552374     0.878620392468042 
           0.00015625            0.00031250            0.00015625 
    0.882079910398028     0.886773165429333     0.895872264013794 
           0.00015625            0.00015625            0.00031250 
    0.902874892971196     0.909893594892982     0.910503026314625 
           0.00015625            0.00015625            0.00015625 
    0.918355472177732     0.923930998062757     0.928610132228083 
           0.00156250            0.00015625            0.00015625 
    0.930580294371997     0.932353440099381     0.933043163131344 
           0.00015625            0.00015625            0.00015625 
    0.935865275090846     0.938721396055517      0.94732667023698 
           0.00015625            0.00015625            0.00015625 
    0.952388332756409     0.953472399517577     0.960457391255192 
           0.00046875            0.00015625            0.00015625 
    0.962466815938431     0.974608403263273     0.977273131185975 
           0.00031250            0.00015625            0.00015625 
    0.979887858238853     0.981765099822977     0.982533764258785 
           0.02546875            0.00015625            0.00015625 
    0.986421193335086     0.991131333762411      0.99464772824313 
           0.00046875            0.00015625            0.00015625 
     1.00529335053186      1.01443060556224       1.0145402019372 
           0.00015625            0.00062500            0.00015625 
     1.02257036343242      1.02480443153783      1.02810330735672 
           0.00015625            0.00015625            0.00015625 
     1.02815692332918       1.0286099206142      1.03278708868866 
           0.00265625            0.00015625            0.00015625 
     1.03867605371823      1.04030809775545      1.05026762861212 
           0.00015625            0.00046875            0.00015625 
     1.05448691449244       1.0552263521649      1.05588258974527 
           0.00125000            0.00015625            0.00015625 
     1.06000513122926      1.06639439518604      1.07107601485988 
           0.00906250            0.00078125            0.00015625 
     1.07323792501438      1.07985999257921      1.08185178624946 
           0.00015625            0.00015625            0.00015625 
     1.08200577310599      1.08501442587133      1.08924264046828 
           0.00015625            0.00015625            0.00015625 
     1.09237983879524      1.09858922192811      1.09934822043348 
           0.00015625            0.00015625            0.00015625 
      1.1078948637414      1.11407400788163      1.11835818480985 
           0.00015625            0.00015625            0.00093750 
     1.11909298650692      1.12255263564979      1.13098492845703 
           0.00125000            0.00640625            0.00718750 
     1.13520899613199      1.13659865262031      1.14324263811607 
           0.00015625            0.00031250            0.00015625 
      1.1444495252129       1.1551673045972      1.15841602768456 
           0.00578125            0.00046875            0.00015625 
     1.17032197443365      1.17077944389967      1.17660425916148 
           0.00156250            0.01546875            0.00015625 
     1.17671971786951      1.18390085758965      1.19061835680715 
           0.00031250            0.02078125            0.00078125 
     1.19124162268748      1.19491419845781      1.20187158527135 
           0.00046875            0.01000000            0.00015625 
     1.20935820034015      1.21534749252995      1.21684078311872 
           0.00015625            0.00015625            0.00015625 
     1.22228576405746      1.22358524293339       1.2307494205369 
           0.00046875            0.00375000            0.00359375 
     1.23190824585799      1.23309624815214       1.2482497077686 
           0.00015625            0.00015625            0.00015625 
     1.24914605564843      1.25030062698194      1.25167385090479 
           0.00015625            0.00015625            0.00015625 
      1.2521388586462      1.25403638767138      1.25696184836792 
           0.00015625            0.00015625            0.00015625 
     1.25865710330342      1.26219503016375      1.26339025886804 
           0.00015625            0.00015625            0.00062500 
     1.27424955368127      1.27429889692881      1.27581391381442 
           0.00062500            0.01093750            0.00015625 
     1.28103448636196      1.28422435170195      1.28502302740832 
           0.00015625            0.00015625            0.00015625 
     1.28694332261892      1.28862136579613      1.29135133286724 
           0.00015625            0.00015625            0.00015625 
     1.29271693854318      1.29352984392642      1.29416501801516 
           0.00093750            0.00015625            0.00015625 
     1.32000923372796      1.32621334330507      1.32674979912185 
           0.00015625            0.00031250            0.00031250 
      1.3355388950486      1.33819762355126      1.34572143844383 
           0.00703125            0.00015625            0.00015625 
     1.34900429115538      1.35106912963136      1.35909050306374 
           0.00015625            0.00015625            0.00015625 
     1.36740896432616      1.37732504122682      1.37817713292888 
           0.00015625            0.00015625            0.00171875 
     1.38155034894393      1.38244688032714      1.38971756538262 
           0.00015625            0.00015625            0.00015625 
     1.39337346848199      1.39481552027921      1.39920925968592 
           0.00015625            0.00015625            0.00015625 
     1.40401019415033      1.40768753122916      1.42034462702771 
           0.00015625            0.00046875            0.00031250 
     1.42884838085788      1.43014092255268      1.43175470937195 
           0.00062500            0.00078125            0.00015625 
     1.43334191774463      1.43396654425843      1.43750664054499 
           0.00046875            0.00015625            0.00015625 
     1.43754219334743       1.4388998201083      1.44153927902681 
           0.00015625            0.01625000            0.01421875 
     1.44769121849116      1.44889234688456      1.45317034273597 
           0.00015625            0.00015625            0.00015625 
     1.45756717172523      1.46514717542552      1.48152004641465 
           0.00015625            0.01359375            0.00015625 
     1.48210471217649       1.4854271336131      1.49691410201524 
           0.00187500            0.00015625            0.00031250 
     1.50460499505036          1.5159104855      1.51944062018193 
           0.00015625            0.00062500            0.00015625 
     1.51951797036384      1.52322014302823      1.52914361888698 
           0.00015625            0.00015625            0.00015625 
     1.53094696259391      1.53185854523801      1.54534195968881 
           0.00015625            0.00015625            0.00015625 
     1.55198480359028      1.55950143190504      1.56497982317259 
           0.00031250            0.00015625            0.00015625 
     1.58262031982126      1.59616721426295      1.60437565730193 
           0.00062500            0.00015625            0.00015625 
     1.61266940307664      1.61805143272205      1.63593441495235 
           0.00015625            0.00015625            0.00390625 
     1.66020775786113      1.67542635415394      1.67673538939901 
           0.00046875            0.00015625            0.00437500 
     1.68035708519021      1.68346836697786      1.68837599513398 
           0.00015625            0.00015625            0.00015625 
     1.68938234802037      1.70189867028665      1.70300688645049 
           0.00015625            0.00015625            0.00015625 
     1.70487078400102      1.71353493899627      1.72834558905075 
           0.00015625            0.00015625            0.00015625 
     1.72915591888238      1.73426417234817      1.74021109248258 
           0.00015625            0.00015625            0.00015625 
     1.74232222740301      1.74349939634561       1.7580041756475 
           0.00015625            0.00015625            0.00015625 
     1.76113921780106      1.76617520172517      1.77211632108358 
           0.00015625            0.00015625            0.00015625 
     1.77514993495452      1.79958280830507      1.81629669477704 
           0.00015625            0.00015625            0.00031250 
     1.81990457312901      1.83656963213994      1.83724270780201 
           0.00015625            0.01140625            0.00015625 
     1.84610801109783      1.87127556838068      1.87941151145041 
           0.00015625            0.00031250            0.00015625 
     1.88207392317223      1.89017691499225      1.91733288828094 
           0.00031250            0.00015625            0.00015625 
     1.94867279430132      1.95578696468731      1.95652907096428 
           0.00687500            0.00015625            0.00015625 
     1.96029188648611      1.97337415011671      1.97682872944693 
           0.00015625            0.00015625            0.00015625 
     1.97898223695928      2.01790204562771      2.04143987127407 
           0.00015625            0.00015625            0.00171875 
     2.04788306887298      2.07547273185274      2.09309957494449 
           0.00062500            0.00031250            0.00015625 
     2.09950420993508      2.10052429104874      2.10697756530747 
           0.00031250            0.00015625            0.00015625 
     2.11999156344762      2.12917389303477      2.15933629269958 
           0.00015625            0.00015625            0.00015625 
     2.18306393167287      2.18323513022319      2.18704108088277 
           0.00187500            0.00015625            0.00015625 
     2.23887211958444      2.24380917557826      2.28051444339884 
           0.00015625            0.00015625            0.00562500 
     2.28417103037285      2.30954548348617      2.34561980157645 
           0.00015625            0.00125000            0.00015625 
     2.52385907644018      3.01185818638057      3.23514293488871 
           0.00015625            0.00015625            0.00031250 
     3.52347021972545      4.91171482734768      5.33930094132038 
           0.00015625            0.00015625            0.00015625 
     6.39137994453622      6.97999767626588 
           0.00015625            0.00015625 
> 
> prop.table(table(trainClass))
trainClass
   Strong      Weak 
0.3492823 0.6507177 
> 
> dim(trainDescr)
[1] 209  20
> dim(testDescr)
[1] 111  20
> 
> ## Check Near-zero variance
> 
> nzv <- nearZeroVar(trainDescr, saveMetrics= TRUE)
> stopifnot( all(nzv$nzv == FALSE) )
> 
> # It's imputed and behaves well, no need for this.
> # descrCorr <- cor(scale(trainDescr), use = "pairwise.complete.obs")
> 
> descrCorr <- cor(scale(trainDescr))
> 
> ## This cut-off should be under src.adjust control.
> ## I'm under Git, so I can tinker with it.
> highCorr <- findCorrelation(descrCorr, cutoff = .65, verbose = TRUE)
Considering row	 10 column	 16 value	 0.55 
Considering row	 10 column	 17 value	 0.647 
Considering row	 10 column	 11 value	 0.297 
Considering row	 10 column	 1 value	 0.286 
Considering row	 10 column	 6 value	 0.307 
Considering row	 10 column	 12 value	 0.26 
Considering row	 10 column	 14 value	 0.272 
Considering row	 10 column	 2 value	 0.293 
Considering row	 10 column	 9 value	 0.365 
Considering row	 10 column	 8 value	 0.363 
Considering row	 10 column	 13 value	 0.231 
Considering row	 10 column	 18 value	 0.191 
Considering row	 10 column	 19 value	 0.166 
Considering row	 10 column	 3 value	 0.423 
Considering row	 10 column	 20 value	 0.091 
Considering row	 10 column	 4 value	 0.078 
Considering row	 10 column	 5 value	 0.164 
Considering row	 10 column	 15 value	 0.168 
Considering row	 10 column	 7 value	 0.144 
Considering row	 16 column	 17 value	 0.855 
  Flagging column	 16 
Considering row	 17 column	 11 value	 0.252 
Considering row	 17 column	 1 value	 0.245 
Considering row	 17 column	 6 value	 0.183 
Considering row	 17 column	 12 value	 0.195 
Considering row	 17 column	 14 value	 0.217 
Considering row	 17 column	 2 value	 0.232 
Considering row	 17 column	 9 value	 0.547 
Considering row	 17 column	 8 value	 0.503 
Considering row	 17 column	 13 value	 0.19 
Considering row	 17 column	 18 value	 0.241 
Considering row	 17 column	 19 value	 0.214 
Considering row	 17 column	 3 value	 0.259 
Considering row	 17 column	 20 value	 0.101 
Considering row	 17 column	 4 value	 0.042 
Considering row	 17 column	 5 value	 0.076 
Considering row	 17 column	 15 value	 0.047 
Considering row	 17 column	 7 value	 0.019 
Considering row	 11 column	 1 value	 0.988 
  Flagging column	 11 
Considering row	 1 column	 6 value	 0.955 
  Flagging column	 1 
Considering row	 6 column	 12 value	 0.87 
  Flagging column	 6 
Considering row	 12 column	 14 value	 0.07 
Considering row	 12 column	 2 value	 0.077 
Considering row	 12 column	 9 value	 0.092 
Considering row	 12 column	 8 value	 0.112 
Considering row	 12 column	 13 value	 0.013 
Considering row	 12 column	 18 value	 0.158 
Considering row	 12 column	 19 value	 0.037 
Considering row	 12 column	 3 value	 0.061 
Considering row	 12 column	 20 value	 0.101 
Considering row	 12 column	 4 value	 0.032 
Considering row	 12 column	 5 value	 0.032 
Considering row	 12 column	 15 value	 0.122 
Considering row	 12 column	 7 value	 0.047 
Considering row	 14 column	 2 value	 0.602 
Considering row	 14 column	 9 value	 0.16 
Considering row	 14 column	 8 value	 0.113 
Considering row	 14 column	 13 value	 0.692 
  Flagging column	 14 
Considering row	 2 column	 9 value	 0.371 
Considering row	 2 column	 8 value	 0.147 
Considering row	 2 column	 13 value	 0.602 
Considering row	 2 column	 18 value	 0.156 
Considering row	 2 column	 19 value	 0.043 
Considering row	 2 column	 3 value	 0.261 
Considering row	 2 column	 20 value	 0.136 
Considering row	 2 column	 4 value	 0.224 
Considering row	 2 column	 5 value	 0.009 
Considering row	 2 column	 15 value	 0.107 
Considering row	 2 column	 7 value	 0.044 
Considering row	 9 column	 8 value	 0.416 
Considering row	 9 column	 13 value	 0.113 
Considering row	 9 column	 18 value	 0.059 
Considering row	 9 column	 19 value	 0.222 
Considering row	 9 column	 3 value	 0.274 
Considering row	 9 column	 20 value	 0.112 
Considering row	 9 column	 4 value	 0.033 
Considering row	 9 column	 5 value	 0.072 
Considering row	 9 column	 15 value	 0.011 
Considering row	 9 column	 7 value	 0.165 
Considering row	 8 column	 13 value	 0.108 
Considering row	 8 column	 18 value	 0.127 
Considering row	 8 column	 19 value	 0.221 
Considering row	 8 column	 3 value	 0.16 
Considering row	 8 column	 20 value	 0.155 
Considering row	 8 column	 4 value	 0.037 
Considering row	 8 column	 5 value	 0.022 
Considering row	 8 column	 15 value	 0.03 
Considering row	 8 column	 7 value	 0.108 
Considering row	 13 column	 18 value	 0.186 
Considering row	 13 column	 19 value	 0.084 
Considering row	 13 column	 3 value	 0.179 
Considering row	 13 column	 20 value	 0.142 
Considering row	 13 column	 4 value	 0.229 
Considering row	 13 column	 5 value	 0.063 
Considering row	 13 column	 15 value	 0.182 
Considering row	 13 column	 7 value	 0.094 
Considering row	 18 column	 19 value	 0.086 
Considering row	 18 column	 3 value	 0.073 
Considering row	 18 column	 20 value	 0.075 
Considering row	 18 column	 4 value	 0.123 
Considering row	 18 column	 5 value	 0.019 
Considering row	 18 column	 15 value	 0.086 
Considering row	 18 column	 7 value	 0.151 
Considering row	 19 column	 3 value	 0.093 
Considering row	 19 column	 20 value	 0.846 
  Flagging column	 19 
Considering row	 3 column	 20 value	 0.012 
Considering row	 3 column	 4 value	 0.056 
Considering row	 3 column	 5 value	 0.164 
Considering row	 3 column	 15 value	 0.061 
Considering row	 3 column	 7 value	 0.079 
Considering row	 20 column	 4 value	 0.085 
Considering row	 20 column	 5 value	 0.101 
Considering row	 20 column	 15 value	 0.032 
Considering row	 20 column	 7 value	 0.1 
Considering row	 4 column	 5 value	 0.255 
Considering row	 4 column	 15 value	 0.003 
Considering row	 4 column	 7 value	 0.039 
Considering row	 5 column	 15 value	 0.035 
Considering row	 5 column	 7 value	 0.012 
Considering row	 15 column	 7 value	 0.033 
> 
> colnames(trainDescr)[highCorr]
[1] "DEPSPOKE"     "DEPBUCKET"    "SDEPHR"       "AVGSQ"        "TRNRANKGRP"  
[6] "xAVAILBUCKET"
> 
> descr.ncol0 <- ncol(trainDescr)
> 
> # I've switched off the correlation remover and the results are better.
> if (sum(highCorr) > 0) {
+     warning("overfitting: correlations: err.trainDescr: ", paste(colnames(trainDescr)[highCorr], collapse = ", ") )
+     err.trainDescr <- trainDescr
+     trainDescr <- trainDescr[,-highCorr]
+ }
Warning message:
overfitting: correlations: err.trainDescr: DEPSPOKE, DEPBUCKET, SDEPHR, AVGSQ, TRNRANKGRP, xAVAILBUCKET 
> 
> descr.ncol1 <- ncol(trainDescr)
> 
> paste("Dropped: ", as.character(descr.ncol0 - descr.ncol1))
[1] "Dropped:  6"
> 
> descrCorr <- cor(trainDescr)
> summary(descrCorr[upper.tri(descrCorr)])
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
-0.54690 -0.11030 -0.01327  0.00736  0.10400  0.64730 
> 
> ## Dominant correlations
> ## At 0.9, there are some big ones that might need re-thinking.
> 
> table.descrCorr <- as.data.frame(as.table(descrCorr))
> table.descrCorr <- table.descrCorr[which(table.descrCorr$Var1 != table.descrCorr$Var2),]
> table.descrCorr[order(abs(table.descrCorr$Freq), decreasing = TRUE),]
              Var1           Var2         Freq
110       ARRSPOKE DOWNLINEATCIMP  0.647266036
162 DOWNLINEATCIMP       ARRSPOKE  0.647266036
10      DEPRANKGRP      SKDDEPSTA  0.602444444
127      SKDDEPSTA     DEPRANKGRP  0.602444444
96        ARRSPOKE   DEPSTAATCIMP -0.546894213
161   DEPSTAATCIMP       ARRSPOKE -0.546894213
82        ARRSPOKE   UPLINEATCIMP  0.503083376
160   UPLINEATCIMP       ARRSPOKE  0.503083376
22  DOWNLINEATCIMP      SKDARRSTA  0.423085302
100      SKDARRSTA DOWNLINEATCIMP  0.423085302
77    DEPSTAATCIMP   UPLINEATCIMP -0.415657487
90    UPLINEATCIMP   DEPSTAATCIMP -0.415657487
7     DEPSTAATCIMP      SKDDEPSTA  0.371415190
85       SKDDEPSTA   DEPSTAATCIMP  0.371415190
92  DOWNLINEATCIMP   DEPSTAATCIMP -0.365064678
105   DEPSTAATCIMP DOWNLINEATCIMP -0.365064678
78  DOWNLINEATCIMP   UPLINEATCIMP  0.362606504
104   UPLINEATCIMP DOWNLINEATCIMP  0.362606504
8   DOWNLINEATCIMP      SKDDEPSTA -0.292861955
99       SKDDEPSTA DOWNLINEATCIMP -0.292861955
21    DEPSTAATCIMP      SKDARRSTA -0.273653815
86       SKDARRSTA   DEPSTAATCIMP -0.273653815
2        SKDARRSTA      SKDDEPSTA -0.261225264
15       SKDDEPSTA      SKDARRSTA -0.261225264
107      ARRBUCKET DOWNLINEATCIMP  0.260336603
120 DOWNLINEATCIMP      ARRBUCKET  0.260336603
26        ARRSPOKE      SKDARRSTA  0.259207810
156      SKDARRSTA       ARRSPOKE  0.259207810
32          SKDEPS         SKDEQP  0.254961381
45          SKDEQP         SKDEPS  0.254961381
167         xDURN2       ARRSPOKE -0.240925782
180       ARRSPOKE         xDURN2 -0.240925782
12        ARRSPOKE      SKDDEPSTA -0.231962447
155      SKDDEPSTA       ARRSPOKE -0.231962447
108     DEPRANKGRP DOWNLINEATCIMP -0.230708862
134 DOWNLINEATCIMP     DEPRANKGRP -0.230708862
38      DEPRANKGRP         SKDEQP  0.229386430
129         SKDEQP     DEPRANKGRP  0.229386430
3           SKDEQP      SKDDEPSTA  0.224186605
29       SKDDEPSTA         SKDEQP  0.224186605
124       ARRSPOKE      ARRBUCKET  0.194637431
163      ARRBUCKET       ARRSPOKE  0.194637431
111         xDURN2 DOWNLINEATCIMP -0.190870792
176 DOWNLINEATCIMP         xDURN2 -0.190870792
138       ARRSPOKE     DEPRANKGRP -0.190129997
164     DEPRANKGRP       ARRSPOKE -0.190129997
139         xDURN2     DEPRANKGRP  0.185783873
178     DEPRANKGRP         xDURN2  0.185783873
137     ARRRANKGRP     DEPRANKGRP  0.182490249
150     DEPRANKGRP     ARRRANKGRP  0.182490249
24      DEPRANKGRP      SKDARRSTA -0.178745408
128      SKDARRSTA     DEPRANKGRP -0.178745408
109     ARRRANKGRP DOWNLINEATCIMP -0.168270397
148 DOWNLINEATCIMP     ARRRANKGRP -0.168270397
63    DEPSTAATCIMP      AVGLOFATC -0.165076256
89       AVGLOFATC   DEPSTAATCIMP -0.165076256
18          SKDEPS      SKDARRSTA -0.164456986
44       SKDARRSTA         SKDEPS -0.164456986
50  DOWNLINEATCIMP         SKDEPS -0.163907354
102         SKDEPS DOWNLINEATCIMP -0.163907354
20    UPLINEATCIMP      SKDARRSTA  0.159742306
72       SKDARRSTA   UPLINEATCIMP  0.159742306
125         xDURN2      ARRBUCKET -0.157754195
177      ARRBUCKET         xDURN2 -0.157754195
13          xDURN2      SKDDEPSTA  0.155564090
169      SKDDEPSTA         xDURN2  0.155564090
84    xAVGSKDAVAIL   UPLINEATCIMP  0.155074532
188   UPLINEATCIMP   xAVGSKDAVAIL  0.155074532
69          xDURN2      AVGLOFATC -0.150825874
173      AVGLOFATC         xDURN2 -0.150825874
6     UPLINEATCIMP      SKDDEPSTA -0.146821904
71       SKDDEPSTA   UPLINEATCIMP -0.146821904
64  DOWNLINEATCIMP      AVGLOFATC -0.144293291
103      AVGLOFATC DOWNLINEATCIMP -0.144293291
140   xAVGSKDAVAIL     DEPRANKGRP  0.142201238
192     DEPRANKGRP   xAVGSKDAVAIL  0.142201238
14    xAVGSKDAVAIL      SKDDEPSTA  0.136437376
183      SKDDEPSTA   xAVGSKDAVAIL  0.136437376
83          xDURN2   UPLINEATCIMP -0.127482570
174   UPLINEATCIMP         xDURN2 -0.127482570
41          xDURN2         SKDEQP  0.122708719
171         SKDEQP         xDURN2  0.122708719
123     ARRRANKGRP      ARRBUCKET -0.121546103
149      ARRBUCKET     ARRRANKGRP -0.121546103
94      DEPRANKGRP   DEPSTAATCIMP  0.113478120
133   DEPSTAATCIMP     DEPRANKGRP  0.113478120
98    xAVGSKDAVAIL   DEPSTAATCIMP -0.112484576
189   DEPSTAATCIMP   xAVGSKDAVAIL -0.112484576
79       ARRBUCKET   UPLINEATCIMP  0.111671932
118   UPLINEATCIMP      ARRBUCKET  0.111671932
80      DEPRANKGRP   UPLINEATCIMP -0.108194221
132   UPLINEATCIMP     DEPRANKGRP -0.108194221
62    UPLINEATCIMP      AVGLOFATC -0.107776470
75       AVGLOFATC   UPLINEATCIMP -0.107776470
11      ARRRANKGRP      SKDDEPSTA  0.106846785
141      SKDDEPSTA     ARRRANKGRP  0.106846785
56    xAVGSKDAVAIL         SKDEPS  0.101251560
186         SKDEPS   xAVGSKDAVAIL  0.101251560
126   xAVGSKDAVAIL      ARRBUCKET -0.101248535
191      ARRBUCKET   xAVGSKDAVAIL -0.101248535
168   xAVGSKDAVAIL       ARRSPOKE  0.101156933
194       ARRSPOKE   xAVGSKDAVAIL  0.101156933
70    xAVGSKDAVAIL      AVGLOFATC -0.100162290
187      AVGLOFATC   xAVGSKDAVAIL -0.100162290
66      DEPRANKGRP      AVGLOFATC  0.094490883
131      AVGLOFATC     DEPRANKGRP  0.094490883
93       ARRBUCKET   DEPSTAATCIMP -0.092239439
119   DEPSTAATCIMP      ARRBUCKET -0.092239439
112   xAVGSKDAVAIL DOWNLINEATCIMP  0.091025429
190 DOWNLINEATCIMP   xAVGSKDAVAIL  0.091025429
153         xDURN2     ARRRANKGRP  0.086208265
179     ARRRANKGRP         xDURN2  0.086208265
42    xAVGSKDAVAIL         SKDEQP  0.085219910
185         SKDEQP   xAVGSKDAVAIL  0.085219910
19       AVGLOFATC      SKDARRSTA -0.079122260
58       SKDARRSTA      AVGLOFATC -0.079122260
36  DOWNLINEATCIMP         SKDEQP -0.078229054
101         SKDEQP DOWNLINEATCIMP -0.078229054
9        ARRBUCKET      SKDDEPSTA -0.076894214
113      SKDDEPSTA      ARRBUCKET -0.076894214
54        ARRSPOKE         SKDEPS -0.076025316
158         SKDEPS       ARRSPOKE -0.076025316
182   xAVGSKDAVAIL         xDURN2  0.075398007
195         xDURN2   xAVGSKDAVAIL  0.075398007
27          xDURN2      SKDARRSTA  0.072540811
170      SKDARRSTA         xDURN2  0.072540811
49    DEPSTAATCIMP         SKDEPS -0.072038619
88          SKDEPS   DEPSTAATCIMP -0.072038619
52      DEPRANKGRP         SKDEPS  0.063126960
130         SKDEPS     DEPRANKGRP  0.063126960
23       ARRBUCKET      SKDARRSTA  0.061406824
114      SKDARRSTA      ARRBUCKET  0.061406824
25      ARRRANKGRP      SKDARRSTA  0.061061397
142      SKDARRSTA     ARRRANKGRP  0.061061397
97          xDURN2   DEPSTAATCIMP -0.058571246
175   DEPSTAATCIMP         xDURN2 -0.058571246
17          SKDEQP      SKDARRSTA  0.055643632
30       SKDARRSTA         SKDEQP  0.055643632
152       ARRSPOKE     ARRRANKGRP  0.047198197
165     ARRRANKGRP       ARRSPOKE  0.047198197
65       ARRBUCKET      AVGLOFATC -0.046716218
117      AVGLOFATC      ARRBUCKET -0.046716218
5        AVGLOFATC      SKDDEPSTA -0.043670512
57       SKDDEPSTA      AVGLOFATC -0.043670512
40        ARRSPOKE         SKDEQP  0.041581874
157         SKDEQP       ARRSPOKE  0.041581874
33       AVGLOFATC         SKDEQP  0.039212863
59          SKDEQP      AVGLOFATC  0.039212863
34    UPLINEATCIMP         SKDEQP -0.036743149
73          SKDEQP   UPLINEATCIMP -0.036743149
53      ARRRANKGRP         SKDEPS  0.034554108
144         SKDEPS     ARRRANKGRP  0.034554108
35    DEPSTAATCIMP         SKDEQP -0.033412491
87          SKDEQP   DEPSTAATCIMP -0.033412491
67      ARRRANKGRP      AVGLOFATC -0.033080387
145      AVGLOFATC     ARRRANKGRP -0.033080387
37       ARRBUCKET         SKDEQP -0.032086314
115         SKDEQP      ARRBUCKET -0.032086314
51       ARRBUCKET         SKDEPS -0.032023722
116         SKDEPS      ARRBUCKET -0.032023722
154   xAVGSKDAVAIL     ARRRANKGRP -0.031558241
193     ARRRANKGRP   xAVGSKDAVAIL -0.031558241
81      ARRRANKGRP   UPLINEATCIMP -0.029624279
146   UPLINEATCIMP     ARRRANKGRP -0.029624279
48    UPLINEATCIMP         SKDEPS -0.021787103
74          SKDEPS   UPLINEATCIMP -0.021787103
55          xDURN2         SKDEPS  0.019241544
172         SKDEPS         xDURN2  0.019241544
68        ARRSPOKE      AVGLOFATC -0.018812820
159      AVGLOFATC       ARRSPOKE -0.018812820
122     DEPRANKGRP      ARRBUCKET -0.013268207
135      ARRBUCKET     DEPRANKGRP -0.013268207
47       AVGLOFATC         SKDEPS  0.012372611
60          SKDEPS      AVGLOFATC  0.012372611
28    xAVGSKDAVAIL      SKDARRSTA -0.012226256
184      SKDARRSTA   xAVGSKDAVAIL -0.012226256
95      ARRRANKGRP   DEPSTAATCIMP  0.011385713
147   DEPSTAATCIMP     ARRRANKGRP  0.011385713
4           SKDEPS      SKDDEPSTA -0.008713182
43       SKDDEPSTA         SKDEPS -0.008713182
39      ARRRANKGRP         SKDEQP -0.003128426
143         SKDEQP     ARRRANKGRP -0.003128426
> 
> ### Models
> 
> ## Try GBM (gradient boosting). Works well for mixed data.
> ## And there is a tutorial for it with caret.
> 
> ## Training controller and big grid
> ## Check the ROC (my preferred.)
> 
> fitControl <- trainControl(## 10-fold CV
+     method = "repeatedcv",
+     number = 10,
+     ## repeated ten times
+     repeats = 10,
+     classProbs = 10,
+     summaryFunction = twoClassSummary)
> 
> ## Some trial and error with variables to branch and boost.
> ## I'm just going to try the airports and the planes and the duration
> ## of the flight. There may be some distance relationship there that
> ## air traffic control use.
> 
> ## Annoying because I drop variables, this needs to be looked up.
> 
> tr.cols <- colnames(trainDescr)
> tr.cols
 [1] "SKDDEPSTA"      "SKDARRSTA"      "SKDEQP"         "SKDEPS"        
 [5] "AVGLOFATC"      "UPLINEATCIMP"   "DEPSTAATCIMP"   "DOWNLINEATCIMP"
 [9] "ARRBUCKET"      "DEPRANKGRP"     "ARRRANKGRP"     "ARRSPOKE"      
[13] "xDURN2"         "xAVGSKDAVAIL"  
> tr.icols <- grep("((STA|EQP)$)|(^xD)", tr.cols)
> tr.icols <- rev(tr.icols)
> 
> gbmGrid <- expand.grid(interaction.depth = tr.icols,
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.1,
+                         n.minobsinnode = 20)
> 
> set.seed(seed.mine)
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "ROC",
+                  verbose = FALSE)
> gbmFit1
Stochastic Gradient Boosting 

209 samples
 14 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 187, 189, 188, 188, 188, 188, ... 

Resampling results across tuning parameters:

  interaction.depth  n.trees  ROC        Sens       Spec       ROC SD    
   1                   90     0.8400706  0.5528571  0.8779670  0.08848851
   1                  180     0.8295202  0.5775000  0.8714286  0.09058119
   1                  270     0.8173558  0.5982143  0.8641758  0.10252343
   1                  360     0.8082467  0.6030357  0.8596154  0.10841119
   1                  450     0.8007241  0.5951786  0.8573626  0.10535878
   1                  540     0.7937461  0.6030357  0.8514835  0.11514889
   1                  630     0.7873175  0.6071429  0.8381868  0.11596604
   1                  720     0.7852983  0.6044643  0.8382418  0.11516407
   1                  810     0.7816111  0.6042857  0.8374176  0.11407080
   1                  900     0.7790522  0.6055357  0.8321978  0.11617712
   1                  990     0.7792494  0.6087500  0.8322527  0.11646429
   1                 1080     0.7767710  0.6014286  0.8301099  0.11137635
   1                 1170     0.7710067  0.5933929  0.8321429  0.12037161
   1                 1260     0.7679219  0.6008929  0.8286813  0.11678514
   1                 1350     0.7678552  0.5987500  0.8263187  0.12029344
   1                 1440     0.7653699  0.5948214  0.8196703  0.12054101
   1                 1530     0.7632889  0.5991071  0.8168681  0.11533833
   1                 1620     0.7636666  0.5989286  0.8176374  0.11996812
   1                 1710     0.7615964  0.6048214  0.8196703  0.11396202
   1                 1800     0.7650402  0.5917857  0.8146703  0.11238802
   1                 1890     0.7620801  0.5976786  0.8110989  0.11268386
   1                 1980     0.7600569  0.5964286  0.8129670  0.11144293
   1                 2070     0.7608958  0.5925000  0.8118132  0.11247734
   1                 2160     0.7576639  0.5966071  0.8108791  0.11189763
   1                 2250     0.7590002  0.5935714  0.8138462  0.11419463
   1                 2340     0.7571370  0.5925000  0.8117582  0.11370290
   1                 2430     0.7567720  0.5828571  0.8101099  0.11371748
   1                 2520     0.7576923  0.5898214  0.8114835  0.11307210
   1                 2610     0.7541523  0.5939286  0.8100549  0.11247881
   1                 2700     0.7556132  0.5817857  0.8109341  0.11310675
   2                   90     0.8300579  0.5650000  0.8558791  0.10574315
   2                  180     0.8156299  0.5691071  0.8418132  0.09836844
   2                  270     0.8095320  0.5683929  0.8367582  0.09586820
   2                  360     0.8026648  0.5725000  0.8255495  0.09195872
   2                  450     0.7999284  0.5601786  0.8255495  0.09491854
   2                  540     0.7958860  0.5580357  0.8232418  0.09199941
   2                  630     0.7950863  0.5635714  0.8189011  0.09995120
   2                  720     0.7950255  0.5662500  0.8211538  0.09453389
   2                  810     0.7939050  0.5589286  0.8137363  0.09566299
   2                  900     0.7916631  0.5546429  0.8198352  0.09469018
   2                  990     0.7923116  0.5439286  0.8137912  0.09681969
   2                 1080     0.7899961  0.5525000  0.8131319  0.09681021
   2                 1170     0.7909282  0.5508929  0.8145604  0.09544413
   2                 1260     0.7900549  0.5494643  0.8152747  0.09366220
   2                 1350     0.7868672  0.5525000  0.8146154  0.10076529
   2                 1440     0.7877325  0.5492857  0.8130769  0.09640894
   2                 1530     0.7868564  0.5505357  0.8102198  0.09905518
   2                 1620     0.7876315  0.5519643  0.8087363  0.09891384
   2                 1710     0.7840914  0.5546429  0.8102198  0.10647215
   2                 1800     0.7850442  0.5517857  0.8071429  0.10479805
   2                 1890     0.7827836  0.5478571  0.8064835  0.10469448
   2                 1980     0.7837382  0.5480357  0.8035165  0.10334628
   2                 2070     0.7859468  0.5492857  0.8028022  0.09647373
   2                 2160     0.7850991  0.5453571  0.8028022  0.10439321
   2                 2250     0.7829592  0.5503571  0.8057143  0.10472064
   2                 2340     0.7849715  0.5587500  0.8064286  0.09824606
   2                 2430     0.7825589  0.5508929  0.8050000  0.10483827
   2                 2520     0.7819731  0.5451786  0.8051099  0.10504106
   2                 2610     0.7822665  0.5478571  0.8072527  0.10611705
   2                 2700     0.7822410  0.5455357  0.8056044  0.10518571
   3                   90     0.8255436  0.5569643  0.8513736  0.09646844
   3                  180     0.8151354  0.5605357  0.8391209  0.09493023
   3                  270     0.8013628  0.5532143  0.8278571  0.10437806
   3                  360     0.8036303  0.5389286  0.8152198  0.09578434
   3                  450     0.7971536  0.5450000  0.8205495  0.09798037
   3                  540     0.7975932  0.5517857  0.8174725  0.10027825
   3                  630     0.7978699  0.5537500  0.8219231  0.09453959
   3                  720     0.7964315  0.5428571  0.8188462  0.09408846
   3                  810     0.7950294  0.5521429  0.8099451  0.09763363
   3                  900     0.7876187  0.5505357  0.8115934  0.11091444
   3                  990     0.7869535  0.5489286  0.8071978  0.10663790
   3                 1080     0.7843024  0.5475000  0.8079670  0.11056957
   3                 1170     0.7855671  0.5396429  0.8085714  0.10620437
   3                 1260     0.7846124  0.5408929  0.8071429  0.10627253
   3                 1350     0.7842818  0.5423214  0.8021429  0.10508509
   3                 1440     0.7830916  0.5405357  0.8050000  0.10428511
   3                 1530     0.7843632  0.5394643  0.8028022  0.10313849
   3                 1620     0.7825736  0.5353571  0.8048901  0.10678519
   3                 1710     0.7820222  0.5328571  0.8055495  0.10601595
   3                 1800     0.7819074  0.5396429  0.8032418  0.10576073
   3                 1890     0.7818946  0.5380357  0.7990110  0.10546887
   3                 1980     0.7815345  0.5448214  0.8020330  0.10632267
   3                 2070     0.7801589  0.5394643  0.8004396  0.10634472
   3                 2160     0.7806289  0.5421429  0.8004945  0.10874116
   3                 2250     0.7798646  0.5339286  0.8019780  0.10749537
   3                 2340     0.7787775  0.5364286  0.8012088  0.10896600
   3                 2430     0.7803110  0.5353571  0.8028571  0.10759943
   3                 2520     0.7800873  0.5333929  0.7997802  0.10677971
   3                 2610     0.7797665  0.5350000  0.8003846  0.10671314
   3                 2700     0.7790208  0.5323214  0.7959890  0.10605921
  13                   90     0.8279739  0.5526786  0.8484066  0.08627236
  13                  180     0.8169643  0.5562500  0.8329670  0.09304222
  13                  270     0.8062510  0.5517857  0.8300549  0.09447690
  13                  360     0.7976501  0.5425000  0.8227473  0.09970912
  13                  450     0.7977580  0.5464286  0.8140110  0.10216203
  13                  540     0.7935822  0.5448214  0.8175275  0.10342965
  13                  630     0.7943593  0.5323214  0.8138462  0.10207670
  13                  720     0.7835420  0.5391071  0.8132418  0.12136802
  13                  810     0.7826746  0.5353571  0.8132418  0.11788600
  13                  900     0.7800363  0.5351786  0.8123626  0.12066814
  13                  990     0.7867641  0.5362500  0.8123626  0.10332480
  13                 1080     0.7857908  0.5350000  0.8066484  0.10379401
  13                 1170     0.7862039  0.5294643  0.8109890  0.10615053
  13                 1260     0.7794015  0.5308929  0.8064835  0.11675233
  13                 1350     0.7781554  0.5312500  0.8086813  0.11722598
  13                 1440     0.7830436  0.5269643  0.8086813  0.10588199
  13                 1530     0.7822959  0.5267857  0.8078022  0.10274147
  13                 1620     0.7803071  0.5258929  0.8057692  0.10682728
  13                 1710     0.7824097  0.5233929  0.8086813  0.10175970
  13                 1800     0.7818613  0.5242857  0.8094505  0.10196749
  13                 1890     0.7815473  0.5257143  0.8072527  0.09992838
  13                 1980     0.7782104  0.5219643  0.8056044  0.10442788
  13                 2070     0.7800363  0.5235714  0.8035165  0.09892656
  13                 2160     0.7800569  0.5221429  0.8035165  0.10176909
  13                 2250     0.7790267  0.5250000  0.8005495  0.10154632
  13                 2340     0.7784400  0.5258929  0.8034615  0.10095989
  13                 2430     0.7790493  0.5258929  0.8026923  0.09818202
  13                 2520     0.7793083  0.5230357  0.8042308  0.09842263
  13                 2610     0.7781083  0.5201786  0.8041209  0.10368967
  13                 2700     0.7793936  0.5189286  0.8026923  0.09821058
  Sens SD    Spec SD   
  0.1789124  0.09344509
  0.1781058  0.08416217
  0.1773860  0.08220856
  0.1723269  0.08355990
  0.1759376  0.08287298
  0.1805064  0.08458667
  0.1732058  0.08927984
  0.1741216  0.08896486
  0.1793403  0.09357163
  0.1772697  0.09061575
  0.1701684  0.08818381
  0.1748509  0.09024570
  0.1788752  0.09139635
  0.1793701  0.09112236
  0.1756701  0.08986378
  0.1798062  0.08767722
  0.1884595  0.08880957
  0.1895510  0.08814313
  0.1835990  0.08427217
  0.1832191  0.08955091
  0.1881188  0.09434951
  0.1855595  0.08884687
  0.1831199  0.08775021
  0.1816668  0.08685533
  0.1823044  0.09169915
  0.1819907  0.09120344
  0.1783823  0.09551409
  0.1831740  0.09137406
  0.1846306  0.09416340
  0.1809043  0.09143544
  0.1790671  0.08744205
  0.1854320  0.08722011
  0.1736155  0.08701709
  0.1771011  0.08713643
  0.1862812  0.08831139
  0.1832253  0.08816859
  0.1918632  0.09075866
  0.1833294  0.09028520
  0.1880168  0.09033965
  0.1928762  0.08946042
  0.1931865  0.09100018
  0.1966469  0.09277764
  0.1937518  0.08610140
  0.1879029  0.08918896
  0.1899312  0.08920551
  0.1888820  0.09233114
  0.1922780  0.09296127
  0.1923959  0.09297201
  0.1888087  0.08987235
  0.1949802  0.08758368
  0.1919901  0.09016084
  0.1963498  0.09182490
  0.1899702  0.09279867
  0.1904495  0.09279867
  0.1947964  0.09267248
  0.1996779  0.09176422
  0.1970977  0.08944405
  0.1940522  0.09215751
  0.1943080  0.09082839
  0.1936521  0.09167753
  0.1844923  0.09258970
  0.1758431  0.09100415
  0.1760643  0.09030776
  0.1890058  0.09672705
  0.1898916  0.09292780
  0.1913956  0.09304049
  0.1907549  0.09127856
  0.1865290  0.09218067
  0.1910449  0.09338895
  0.1948407  0.09629937
  0.1929730  0.09650119
  0.1984145  0.09361815
  0.2008726  0.09689106
  0.1971127  0.09871438
  0.1954448  0.09492217
  0.1923919  0.09554976
  0.1917956  0.10049739
  0.1902897  0.09547313
  0.1915675  0.09524416
  0.1913464  0.09694447
  0.1910107  0.09530909
  0.1906029  0.09564214
  0.1928674  0.09687897
  0.1913791  0.09624679
  0.1897901  0.09636466
  0.1914868  0.09622995
  0.1900357  0.09532540
  0.1911287  0.09916997
  0.1879212  0.09644416
  0.1901664  0.10209820
  0.1872077  0.08139970
  0.1816718  0.08572026
  0.1883933  0.08640502
  0.1832676  0.08864999
  0.1833593  0.09531611
  0.1862265  0.09113546
  0.1835471  0.08981417
  0.1824735  0.09000484
  0.1811499  0.08943041
  0.1821513  0.09317410
  0.1909230  0.09244137
  0.1877325  0.09509292
  0.1842946  0.09519326
  0.1899657  0.09664797
  0.1862936  0.09334415
  0.1889054  0.09640724
  0.1912609  0.09793120
  0.1901440  0.09949862
  0.1942552  0.09835501
  0.1921014  0.09388327
  0.1864655  0.09586260
  0.1932938  0.09781217
  0.1886219  0.09663705
  0.1851619  0.10148546
  0.1847942  0.09862475
  0.1869839  0.09796505
  0.1836468  0.10017584
  0.1851476  0.10067251
  0.1899454  0.09923777
  0.1871466  0.09966006

Tuning parameter 'shrinkage' was held constant at a value of 0.1

Tuning parameter 'n.minobsinnode' was held constant at a value of 20
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 90, interaction.depth =
 1, shrinkage = 0.1 and n.minobsinnode = 20. 
> 
> ## The acid test is dissapointing, but I've seen worse.
> 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
  Accuracy      Kappa 
0.60360360 0.07289294 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     12   18
    Weak       26   55
                                          
               Accuracy : 0.6036          
                 95% CI : (0.5063, 0.6952)
    No Information Rate : 0.6577          
    P-Value [Acc > NIR] : 0.9022          
                                          
                  Kappa : 0.0729          
 Mcnemar's Test P-Value : 0.2913          
                                          
            Sensitivity : 0.7534          
            Specificity : 0.3158          
         Pos Pred Value : 0.6790          
         Neg Pred Value : 0.4000          
             Prevalence : 0.6577          
         Detection Rate : 0.4955          
   Detection Prevalence : 0.7297          
      Balanced Accuracy : 0.5346          
                                          
       'Positive' Class : Weak            
                                          
> 
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
 Accuracy     Kappa 
0.8086124 0.5623037 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     47   14
    Weak       26  122
                                          
               Accuracy : 0.8086          
                 95% CI : (0.7486, 0.8596)
    No Information Rate : 0.6507          
    P-Value [Acc > NIR] : 3.926e-07       
                                          
                  Kappa : 0.5623          
 Mcnemar's Test P-Value : 0.08199         
                                          
            Sensitivity : 0.8971          
            Specificity : 0.6438          
         Pos Pred Value : 0.8243          
         Neg Pred Value : 0.7705          
             Prevalence : 0.6507          
         Detection Rate : 0.5837          
   Detection Prevalence : 0.7081          
      Balanced Accuracy : 0.7704          
                                          
       'Positive' Class : Weak            
                                          
> set.seed(seed.mine)
> inTrain <- createDataPartition(outcomes.flight, p = 0.65, list = FALSE)
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> prop.table(table(trainClass))
trainClass
   Strong      Weak 
0.3492823 0.6507177 
> dim(trainDescr)
[1] 209  20
> dim(testDescr)
[1] 111  20
> set.seed(seed.mine)
> inTrain <- createDataPartition(outcomes.flight, p = 0.70, list = FALSE)
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> prop.table(table(trainClass))
trainClass
   Strong      Weak 
0.3466667 0.6533333 
> dim(trainDescr)
[1] 225  20
> dim(testDescr)
[1] 95 20
> set.seed(seed.mine)
> inTrain <- createDataPartition(outcomes.flight, p = 0.75, list = FALSE)
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> prop.table(table(trainClass))
trainClass
   Strong      Weak 
0.3485477 0.6514523 
> dim(trainDescr)
[1] 241  20
> dim(testDescr)
[1] 79 20
> set.seed(seed.mine)
> inTrain <- createDataPartition(outcomes.flight, p = 0.77, list = FALSE)
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> prop.table(table(trainClass))
trainClass
   Strong      Weak 
0.3481781 0.6518219 
> dim(trainDescr)
[1] 247  20
> dim(testDescr)
[1] 73 20
> length(outcomes.flight)
[1] 320
> seed.mine = 107
> set.seed(seed.mine)                     # helpful for testing
> 
> flight <- read.csv("../bak/flight.csv")
> flight <- flight[order(flight$D00),]
> 
> # Backup
> flight.raw <- flight
> 
> # Check warnings
> src.adjust <- TRUE
> source(file = "flight1.R")
Warning message:
In eval(expr, envir, enclos) : adjusting
> 
> # To check adjustment, there is test code in flight-nb.R
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"
> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"
> 
> # And some deletions
> 
> t.cols <- colnames(flight)
> 
> t.drops <- t.cols[grep("^RANK*", t.cols)]
> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])
> t.drops <- c(t.drops, "D80THPCTL")
> 
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR
> flight$xHNGR <- flight$xDURN < 0
> 
> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+ }
> 
> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))
> 
> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE
> t.cols <- colnames(flight)
> 
> t.drops <- c("SARRHR", "xDURN")
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Backup
> 
> flight00 <- flight
> 
> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]
> 
> paste("samples in use: ", dim(flight)[1])
[1] "samples in use:  320"
> 
> ## Take another copy - this is all we need as the training/prediction
> ## set.
> 
> flight1 <- flight
> 
> ## Data insights
> 
> ## *Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> flight <- flight1
> 
> ## So something is defining the behaviour.
> 
> ## Try to simplify structure
> 
> head(model.matrix(LEGTYPE ~ ., data = flight))
   (Intercept) SDEPHR SKDDEPSTAALB SKDDEPSTAAMS SKDDEPSTAANC SKDDEPSTAATT
2            1     14            0            0            0            0
5            1     11            0            0            0            0
7            1     14            0            0            0            0
13           1     13            0            0            0            0
14           1     16            0            0            0            0
17           1     15            0            0            0            0
   SKDDEPSTAAUA SKDDEPSTAAUS SKDDEPSTABDA SKDDEPSTABDL SKDDEPSTABNA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTABOI SKDDEPSTABOS SKDDEPSTABRU SKDDEPSTABUF SKDDEPSTABWI
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTACCC SKDDEPSTACDG SKDDEPSTACHS SKDDEPSTACLE SKDDEPSTACMH
2             1            0            0            0            0
5             0            0            0            0            0
7             1            0            0            0            0
13            0            0            0            0            0
14            1            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTACUN SKDDEPSTADDD SKDDEPSTADEN SKDDEPSTADFW SKDDEPSTADSM
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            1            0            0            0
   SKDDEPSTADTW SKDDEPSTADUB SKDDEPSTAEWR SKDDEPSTAFCO SKDDEPSTAFLL
2             0            0            0            0            0
5             1            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAFRA SKDDEPSTAGCM SKDDEPSTAGDL SKDDEPSTAGEG SKDDEPSTAGIG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAHNL SKDDEPSTAIAH SKDDEPSTAILM SKDDEPSTAIND SKDDEPSTAJAX
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAJFK SKDDEPSTAKOA SKDDEPSTALAS SKDDEPSTALAX SKDDEPSTALGA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTALGB SKDDEPSTALGW SKDDEPSTALHR SKDDEPSTALIH SKDDEPSTAMAD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMAN SKDDEPSTAMBJ SKDDEPSTAMCI SKDDEPSTAMCO SKDDEPSTAMDT
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMEX SKDDEPSTAMHT SKDDEPSTAMIA SKDDEPSTAMKE SKDDEPSTAMSP
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMSY SKDDEPSTAMUC SKDDEPSTAMZT SKDDEPSTANAS SKDDEPSTAOAK
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAOGG SKDDEPSTAOMA SKDDEPSTAONT SKDDEPSTAORD SKDDEPSTAORF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAPBI SKDDEPSTAPDX SKDDEPSTAPIT SKDDEPSTAPLS SKDDEPSTAPPP
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            1
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAPUJ SKDDEPSTAPVD SKDDEPSTAPVR SKDDEPSTAPWM SKDDEPSTARDU
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTARIC SKDDEPSTARNO SKDDEPSTAROC SKDDEPSTARSW SKDDEPSTASAN
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASAT SKDDEPSTASEA SKDDEPSTASFO SKDDEPSTASJC SKDDEPSTASJD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASJO SKDDEPSTASJU SKDDEPSTASLC SKDDEPSTASMF SKDDEPSTASNA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASRQ SKDDEPSTASTL SKDDEPSTASTT SKDDEPSTASXM SKDDEPSTASYR
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTATLV SKDDEPSTATPA SKDDEPSTAXHP SKDDEPSTAYEG SKDDEPSTAYVR
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAYYC SKDDEPSTAZRH SKDARRSTAALB SKDARRSTAAMS SKDARRSTAANC
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAATT SKDARRSTAAUA SKDARRSTAAUS SKDARRSTABDA SKDARRSTABDL
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTABNA SKDARRSTABOI SKDARRSTABOS SKDARRSTABRU SKDARRSTABUF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            1            0            0
17            0            0            0            0            0
   SKDARRSTABWI SKDARRSTACCC SKDARRSTACDG SKDARRSTACHS SKDARRSTACLE
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            1            0            0            0
   SKDARRSTACMH SKDARRSTACUN SKDARRSTADDD SKDARRSTADEN SKDARRSTADFW
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTADSM SKDARRSTADTW SKDARRSTADUB SKDARRSTAEWR SKDARRSTAFCO
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAFLL SKDARRSTAFRA SKDARRSTAGCM SKDARRSTAGDL SKDARRSTAGEG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAGIG SKDARRSTAHNL SKDARRSTAIAH SKDARRSTAILM SKDARRSTAIND
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAJAX SKDARRSTAJFK SKDARRSTAKOA SKDARRSTALAS SKDARRSTALAX
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTALGA SKDARRSTALGB SKDARRSTALGW SKDARRSTALHR SKDARRSTALIH
2             0            0            0            0            0
5             0            0            0            0            0
7             1            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMAD SKDARRSTAMAN SKDARRSTAMBJ SKDARRSTAMCI SKDARRSTAMCO
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMDT SKDARRSTAMEX SKDARRSTAMHT SKDARRSTAMIA SKDARRSTAMKE
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMSP SKDARRSTAMSY SKDARRSTAMUC SKDARRSTAMZT SKDARRSTANAS
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAOAK SKDARRSTAOGG SKDARRSTAOMA SKDARRSTAONT SKDARRSTAORD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            1
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAORF SKDARRSTAPBI SKDARRSTAPDX SKDARRSTAPIT SKDARRSTAPLS
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAPPP SKDARRSTAPUJ SKDARRSTAPVD SKDARRSTAPVR SKDARRSTAPWM
2             1            0            0            0            0
5             1            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTARDU SKDARRSTARIC SKDARRSTARNO SKDARRSTAROC SKDARRSTARSW
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASAN SKDARRSTASAT SKDARRSTASEA SKDARRSTASFO SKDARRSTASJC
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASJD SKDARRSTASJO SKDARRSTASJU SKDARRSTASLC SKDARRSTASMF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASNA SKDARRSTASRQ SKDARRSTASTL SKDARRSTASTT SKDARRSTASXM
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASYR SKDARRSTATLV SKDARRSTATPA SKDARRSTAXHP SKDARRSTAYEG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAYVR SKDARRSTAYYC SKDARRSTAZRH SKDEQP319 SKDEQP320 SKDEQP321
2             0            0            0         0         0         0
5             0            0            0         0         0         0
7             0            0            0         0         0         1
13            0            0            0         0         0         0
14            0            0            0         0         0         1
17            0            0            0         0         0         0
   SKDEQP332 SKDEQP333 SKDEQP734 SKDEQP75E SKDEQP75H SKDEQP767 SKDEQPA01
2          0         0         1         0         0         0         0
5          0         0         0         0         0         0         0
7          0         0         0         0         0         0         0
13         0         0         1         0         0         0         0
14         0         0         0         0         0         0         0
17         0         0         0         0         0         0         0
   SKDEQPA05 SKDEQPA19 SKDEQPA21 SKDEQPE90 SKDEPS       D00    AVGSQ AVGLOFATC
2          0         0         0         0     32 0.2500000 3.258065  3.258065
5          0         0         0         1     72 0.2916667 2.986111  3.805556
7          0         0         0         0     88 0.3295455 2.551724  3.701149
13         0         0         0         0     32 0.3750000 3.000000  3.903226
14         0         0         0         0     72 0.3750000 3.295775  3.859155
17         0         0         0         0     84 0.3809524 3.939759  3.361446
   UPLINEATCIMPLow UPLINEATCIMPMed UPLINEATCIMPMedHigh UPLINEATCIMPMedLow
2                0               1                   0                  0
5                0               0                   0                  0
7                0               0                   0                  1
13               0               1                   0                  0
14               0               0                   0                  1
17               1               0                   0                  0
   DEPSTAATCIMPLow DOWNLINEATCIMPLow AVGSKDAVAIL AVAILBUCKETA05 AVAILBUCKETA10
2                0                 0   10.903226              0              1
5                1                 0    2.000000              0              0
7                0                 0    9.647059              1              0
13               0                 0   17.354839              0              0
14               0                 0   17.057143              0              0
17               0                 0   10.621951              0              1
   AVAILBUCKETA15 AVAILBUCKETA20 AVAILBUCKETA25 AVAILBUCKETA30 AVAILBUCKETA<0
2               0              0              0              0              0
5               0              0              0              0              0
7               0              0              0              0              0
13              1              0              0              0              0
14              1              0              0              0              0
17              0              0              0              0              0
   DEPBUCKETD2 DEPBUCKETD3 DEPBUCKETD4 DEPBUCKETD5 DEPBUCKETD6 DEPBUCKETD7
2            0           0           0           1           0           0
5            0           0           1           0           0           0
7            0           0           0           1           0           0
13           0           0           0           1           0           0
14           0           0           0           0           1           0
17           0           0           0           0           1           0
   DEPBUCKETD8 ARRBUCKETA2 ARRBUCKETA3 ARRBUCKETA4 ARRBUCKETA5 ARRBUCKETA6
2            0           0           0           0           0           1
5            0           0           0           0           1           0
7            0           0           0           0           0           1
13           0           0           0           0           0           1
14           0           0           0           0           0           0
17           0           0           0           0           0           1
   ARRBUCKETA7 ARRBUCKETA8 DEPRANKGRPLow DEPRANKGRPMed DEPRANKGRPMedHigh
2            0           0             1             0                 0
5            0           0             0             1                 0
7            0           0             1             0                 0
13           0           0             0             0                 0
14           1           0             1             0                 0
17           0           0             0             0                 0
   DEPRANKGRPMedLow TRNRANKGRPLow TRNRANKGRPMed TRNRANKGRPMedHigh
2                 0             1             0                 0
5                 0             1             0                 0
7                 0             1             0                 0
13                1             0             0                 0
14                0             1             0                 0
17                1             0             1                 0
   TRNRANKGRPMedLow ARRRANKGRPLow ARRRANKGRPMed ARRRANKGRPMedHigh
2                 0             0             0                 1
5                 0             0             0                 1
7                 0             0             1                 0
13                1             0             0                 0
14                0             0             0                 1
17                0             0             0                 1
   ARRRANKGRPMedLow DEPSPOKETRUE ARRSPOKETRUE xHNGRTRUE xDURN2
2                 0            0            0         0      2
5                 0            1            0         0      2
7                 0            0            1         0      2
13                1            0            1         0      2
14                0            0            1         0      2
17                0            0            0         0      2
> 
> dummies <- dummyVars(LEGTYPE ~ ., data = flight)
> flight.dum <- predict(dummies, newdata = flight)
> 
> ## It may be too big to use, but useful for inspection.
> 
> ### Numeric variables
> 
> ## Check some more numeric correlations, I haven't scaled yet.
> ## I'd cut correlations above 0.75 because of overfitting.
> 
> x1 <- as.data.frame(as.matrix(sapply(flight, class)))
> 
> flight.num <- flight[,names(x1[which(x1$V1 %in% c("numeric", "integer")),])]
> 
> flight.nzv <- nearZeroVar(flight.num, saveMetrics = TRUE)
> flight.nzv
            freqRatio percentUnique zeroVar   nzv
SDEPHR       1.038462        5.9375   FALSE FALSE
SKDEPS       1.000000       19.0625   FALSE FALSE
D00          1.166667       75.3125   FALSE FALSE
AVGSQ        6.333333       82.8125   FALSE FALSE
AVGLOFATC    1.000000       78.4375   FALSE FALSE
AVGSKDAVAIL  1.000000       87.5000   FALSE FALSE
xDURN2       1.428571        2.5000   FALSE FALSE
> 
> # annoying NA
> flight.cor <- cor(flight.num, use = "pairwise.complete.obs")
> 
> descrCorr <- findCorrelation(flight.cor, cutoff = .65, verbose=TRUE)
Considering row	 1 column	 4 value	 0.956 
  Flagging column	 1 
Considering row	 4 column	 3 value	 0.414 
Considering row	 4 column	 6 value	 0.173 
Considering row	 4 column	 7 value	 0.201 
Considering row	 4 column	 5 value	 0.103 
Considering row	 4 column	 2 value	 0.082 
Considering row	 3 column	 6 value	 0.266 
Considering row	 3 column	 7 value	 0.071 
Considering row	 3 column	 5 value	 0.114 
Considering row	 3 column	 2 value	 0.006 
Considering row	 6 column	 7 value	 0.031 
Considering row	 6 column	 5 value	 0.094 
Considering row	 6 column	 2 value	 0.067 
Considering row	 7 column	 5 value	 0.137 
Considering row	 7 column	 2 value	 0.005 
Considering row	 5 column	 2 value	 0.041 
> 
> colnames(flight.num)[descrCorr]
[1] "SDEPHR"
> 
> ## Which tells me that departure time is very highly correlated to AVGSQ.
> ## AVGSQ is average stand queue?
> 
> ### Try and impute the AVG, it might have more information than the
> ### bucket.
> 
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))
> 
> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1
> 
> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]
> 
> preProcValues <- preProcess(flight.na, method = c("knnImpute"))
> flight.na1 <- predict(preProcValues, flight.na)
> 
> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL
> 
> ## And I'll leave the centered and scale values in for now.
> ## and delete the troublesome ones
> 
> flight$AVGSKDAVAIL <- NULL
> flight$xHNGR <- NULL
> flight$AVAILBUCKET <- NULL
> 
> # This should be deleted, leave it in and the results are ideal because it defines LEGTYPE.
> flight$D00 <- NULL
> 
> ## Keep the results but don't change the order.
> outcomes.flight <- flight$LEGTYPE
> 
> flight$LEGTYPE <- NULL
> 
> ## If you know your factors are definitely factors, you don't need this
> ##  asNumeric <- function(x) as.numeric(as.character(x))
> 
> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))
> 
> flight.num0 <- factors.numeric(flight)
> 
> flight.scl0 <- scale(flight.num0)
> 
> ## Now split the results
> ## we need 80 or so to test with.
> 
> set.seed(seed.mine)
> inTrain <- createDataPartition(outcomes.flight, p = 0.77, list = FALSE)
> 
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> 
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> 
> prop.table(table(trainClass))
trainClass
   Strong      Weak 
0.4475806 0.5524194 
> prop.table(table(testClass))
testClass
   Strong      Weak 
0.4444444 0.5555556 
> dim(testDescr)
[1] 72 20
> 
+ . + 
> ### weaves
> 
> ## Processing for flights data.
> 
> ## Following the caret vignette.
> 
> ###################################################
> ### code chunk number 1: loadLibs
> ###################################################
> library(MASS)

> library(caret)

> library(mlbench)

> library(pROC)

> library(pls)

> library(doMC)

> registerDoMC(cores = 4)

> options(useFancyQuotes = FALSE) 

> # Accounting info.
> getInfo <- function(what = "Suggests")
+ {
+   text <- packageDescription("caret")[what][[1]]
+   text <- gsub("\n", ", ", text, fixed = TRUE)
+   text <- gsub(">=", "$\\\\ge$", text, fixed = TRUE)
+   eachPkg <- strsplit(text, ", ", fixed = TRUE)[[1]]
+   eachPkg <- gsub(",", .... [TRUNCATED] 

> ### project-specific: begin
> ## Set-seed, load original CSV file, order it
> ## and do some simple-cleaning
> ## Various datasets 
> 
> seed.mine = 107

> set.seed(seed.mine)                     # helpful for testing

> flight <- read.csv("../bak/flight.csv")

> flight <- flight[order(flight$D00),]

> # Backup
> flight.raw <- flight

> # Check warnings
> src.adjust <- TRUE

> source(file = "flight1.R")

> # To check adjustment, there is test code in flight-nb.R
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"

> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"

> # And some deletions
> 
> t.cols <- colnames(flight)

> t.drops <- t.cols[grep("^RANK*", t.cols)]

> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])

> t.drops <- c(t.drops, "D80THPCTL")

> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]

> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR

> flight$xHNGR <- flight$xDURN < 0

> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+  .... [TRUNCATED] 

> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))

> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE

> t.cols <- colnames(flight)

> t.drops <- c("SARRHR", "xDURN")

> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]

> ## Backup
> 
> flight00 <- flight

> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]

> paste("samples in use: ", dim(flight)[1])
[1] "samples in use:  320"

> ## Take another copy - this is all we need as the training/prediction
> ## set.
> 
> flight1 <- flight

> ## Data insights
> 
> ## *Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> flight <- flight1

> ## So something is defining the behaviour.
> 
> ## Try to simplify structure
> 
> head(model.matrix(LEGTYPE ~ ., data = flight))
   (Intercept) SDEPHR SKDDEPSTAALB SKDDEPSTAAMS SKDDEPSTAANC SKDDEPSTAATT
2            1     14            0            0            0            0
5            1     11            0            0            0            0
7            1     14            0            0            0            0
13           1     13            0            0            0            0
14           1     16            0            0            0            0
17           1     15            0            0            0            0
   SKDDEPSTAAUA SKDDEPSTAAUS SKDDEPSTABDA SKDDEPSTABDL SKDDEPSTABNA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTABOI SKDDEPSTABOS SKDDEPSTABRU SKDDEPSTABUF SKDDEPSTABWI
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTACCC SKDDEPSTACDG SKDDEPSTACHS SKDDEPSTACLE SKDDEPSTACMH
2             1            0            0            0            0
5             0            0            0            0            0
7             1            0            0            0            0
13            0            0            0            0            0
14            1            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTACUN SKDDEPSTADDD SKDDEPSTADEN SKDDEPSTADFW SKDDEPSTADSM
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            1            0            0            0
   SKDDEPSTADTW SKDDEPSTADUB SKDDEPSTAEWR SKDDEPSTAFCO SKDDEPSTAFLL
2             0            0            0            0            0
5             1            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAFRA SKDDEPSTAGCM SKDDEPSTAGDL SKDDEPSTAGEG SKDDEPSTAGIG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAHNL SKDDEPSTAIAH SKDDEPSTAILM SKDDEPSTAIND SKDDEPSTAJAX
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAJFK SKDDEPSTAKOA SKDDEPSTALAS SKDDEPSTALAX SKDDEPSTALGA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTALGB SKDDEPSTALGW SKDDEPSTALHR SKDDEPSTALIH SKDDEPSTAMAD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMAN SKDDEPSTAMBJ SKDDEPSTAMCI SKDDEPSTAMCO SKDDEPSTAMDT
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMEX SKDDEPSTAMHT SKDDEPSTAMIA SKDDEPSTAMKE SKDDEPSTAMSP
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMSY SKDDEPSTAMUC SKDDEPSTAMZT SKDDEPSTANAS SKDDEPSTAOAK
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAOGG SKDDEPSTAOMA SKDDEPSTAONT SKDDEPSTAORD SKDDEPSTAORF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAPBI SKDDEPSTAPDX SKDDEPSTAPIT SKDDEPSTAPLS SKDDEPSTAPPP
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            1
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAPUJ SKDDEPSTAPVD SKDDEPSTAPVR SKDDEPSTAPWM SKDDEPSTARDU
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTARIC SKDDEPSTARNO SKDDEPSTAROC SKDDEPSTARSW SKDDEPSTASAN
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASAT SKDDEPSTASEA SKDDEPSTASFO SKDDEPSTASJC SKDDEPSTASJD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASJO SKDDEPSTASJU SKDDEPSTASLC SKDDEPSTASMF SKDDEPSTASNA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASRQ SKDDEPSTASTL SKDDEPSTASTT SKDDEPSTASXM SKDDEPSTASYR
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTATLV SKDDEPSTATPA SKDDEPSTAXHP SKDDEPSTAYEG SKDDEPSTAYVR
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAYYC SKDDEPSTAZRH SKDARRSTAALB SKDARRSTAAMS SKDARRSTAANC
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAATT SKDARRSTAAUA SKDARRSTAAUS SKDARRSTABDA SKDARRSTABDL
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTABNA SKDARRSTABOI SKDARRSTABOS SKDARRSTABRU SKDARRSTABUF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            1            0            0
17            0            0            0            0            0
   SKDARRSTABWI SKDARRSTACCC SKDARRSTACDG SKDARRSTACHS SKDARRSTACLE
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            1            0            0            0
   SKDARRSTACMH SKDARRSTACUN SKDARRSTADDD SKDARRSTADEN SKDARRSTADFW
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTADSM SKDARRSTADTW SKDARRSTADUB SKDARRSTAEWR SKDARRSTAFCO
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAFLL SKDARRSTAFRA SKDARRSTAGCM SKDARRSTAGDL SKDARRSTAGEG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAGIG SKDARRSTAHNL SKDARRSTAIAH SKDARRSTAILM SKDARRSTAIND
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAJAX SKDARRSTAJFK SKDARRSTAKOA SKDARRSTALAS SKDARRSTALAX
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTALGA SKDARRSTALGB SKDARRSTALGW SKDARRSTALHR SKDARRSTALIH
2             0            0            0            0            0
5             0            0            0            0            0
7             1            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMAD SKDARRSTAMAN SKDARRSTAMBJ SKDARRSTAMCI SKDARRSTAMCO
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMDT SKDARRSTAMEX SKDARRSTAMHT SKDARRSTAMIA SKDARRSTAMKE
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMSP SKDARRSTAMSY SKDARRSTAMUC SKDARRSTAMZT SKDARRSTANAS
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAOAK SKDARRSTAOGG SKDARRSTAOMA SKDARRSTAONT SKDARRSTAORD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            1
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAORF SKDARRSTAPBI SKDARRSTAPDX SKDARRSTAPIT SKDARRSTAPLS
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAPPP SKDARRSTAPUJ SKDARRSTAPVD SKDARRSTAPVR SKDARRSTAPWM
2             1            0            0            0            0
5             1            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTARDU SKDARRSTARIC SKDARRSTARNO SKDARRSTAROC SKDARRSTARSW
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASAN SKDARRSTASAT SKDARRSTASEA SKDARRSTASFO SKDARRSTASJC
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASJD SKDARRSTASJO SKDARRSTASJU SKDARRSTASLC SKDARRSTASMF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASNA SKDARRSTASRQ SKDARRSTASTL SKDARRSTASTT SKDARRSTASXM
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASYR SKDARRSTATLV SKDARRSTATPA SKDARRSTAXHP SKDARRSTAYEG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAYVR SKDARRSTAYYC SKDARRSTAZRH SKDEQP319 SKDEQP320 SKDEQP321
2             0            0            0         0         0         0
5             0            0            0         0         0         0
7             0            0            0         0         0         1
13            0            0            0         0         0         0
14            0            0            0         0         0         1
17            0            0            0         0         0         0
   SKDEQP332 SKDEQP333 SKDEQP734 SKDEQP75E SKDEQP75H SKDEQP767 SKDEQPA01
2          0         0         1         0         0         0         0
5          0         0         0         0         0         0         0
7          0         0         0         0         0         0         0
13         0         0         1         0         0         0         0
14         0         0         0         0         0         0         0
17         0         0         0         0         0         0         0
   SKDEQPA05 SKDEQPA19 SKDEQPA21 SKDEQPE90 SKDEPS       D00    AVGSQ AVGLOFATC
2          0         0         0         0     32 0.2500000 3.258065  3.258065
5          0         0         0         1     72 0.2916667 2.986111  3.805556
7          0         0         0         0     88 0.3295455 2.551724  3.701149
13         0         0         0         0     32 0.3750000 3.000000  3.903226
14         0         0         0         0     72 0.3750000 3.295775  3.859155
17         0         0         0         0     84 0.3809524 3.939759  3.361446
   UPLINEATCIMPLow UPLINEATCIMPMed UPLINEATCIMPMedHigh UPLINEATCIMPMedLow
2                0               1                   0                  0
5                0               0                   0                  0
7                0               0                   0                  1
13               0               1                   0                  0
14               0               0                   0                  1
17               1               0                   0                  0
   DEPSTAATCIMPLow DOWNLINEATCIMPLow AVGSKDAVAIL AVAILBUCKETA05 AVAILBUCKETA10
2                0                 0   10.903226              0              1
5                1                 0    2.000000              0              0
7                0                 0    9.647059              1              0
13               0                 0   17.354839              0              0
14               0                 0   17.057143              0              0
17               0                 0   10.621951              0              1
   AVAILBUCKETA15 AVAILBUCKETA20 AVAILBUCKETA25 AVAILBUCKETA30 AVAILBUCKETA<0
2               0              0              0              0              0
5               0              0              0              0              0
7               0              0              0              0              0
13              1              0              0              0              0
14              1              0              0              0              0
17              0              0              0              0              0
   DEPBUCKETD2 DEPBUCKETD3 DEPBUCKETD4 DEPBUCKETD5 DEPBUCKETD6 DEPBUCKETD7
2            0           0           0           1           0           0
5            0           0           1           0           0           0
7            0           0           0           1           0           0
13           0           0           0           1           0           0
14           0           0           0           0           1           0
17           0           0           0           0           1           0
   DEPBUCKETD8 ARRBUCKETA2 ARRBUCKETA3 ARRBUCKETA4 ARRBUCKETA5 ARRBUCKETA6
2            0           0           0           0           0           1
5            0           0           0           0           1           0
7            0           0           0           0           0           1
13           0           0           0           0           0           1
14           0           0           0           0           0           0
17           0           0           0           0           0           1
   ARRBUCKETA7 ARRBUCKETA8 DEPRANKGRPLow DEPRANKGRPMed DEPRANKGRPMedHigh
2            0           0             1             0                 0
5            0           0             0             1                 0
7            0           0             1             0                 0
13           0           0             0             0                 0
14           1           0             1             0                 0
17           0           0             0             0                 0
   DEPRANKGRPMedLow TRNRANKGRPLow TRNRANKGRPMed TRNRANKGRPMedHigh
2                 0             1             0                 0
5                 0             1             0                 0
7                 0             1             0                 0
13                1             0             0                 0
14                0             1             0                 0
17                1             0             1                 0
   TRNRANKGRPMedLow ARRRANKGRPLow ARRRANKGRPMed ARRRANKGRPMedHigh
2                 0             0             0                 1
5                 0             0             0                 1
7                 0             0             1                 0
13                1             0             0                 0
14                0             0             0                 1
17                0             0             0                 1
   ARRRANKGRPMedLow DEPSPOKETRUE ARRSPOKETRUE xHNGRTRUE xDURN2
2                 0            0            0         0      2
5                 0            1            0         0      2
7                 0            0            1         0      2
13                1            0            1         0      2
14                0            0            1         0      2
17                0            0            0         0      2

> dummies <- dummyVars(LEGTYPE ~ ., data = flight)

> flight.dum <- predict(dummies, newdata = flight)

> ## It may be too big to use, but useful for inspection.
> 
> ### Numeric variables
> 
> ## Check some more numeric correlations, I haven't scaled yet.
> ## I'd cut correlations above 0.75 because of overfitting.
> 
> x1 <- as.data.frame(as.matrix(sapply(flight, class)))

> flight.num <- flight[,names(x1[which(x1$V1 %in% c("numeric", "integer")),])]

> flight.nzv <- nearZeroVar(flight.num, saveMetrics = TRUE)

> flight.nzv
            freqRatio percentUnique zeroVar   nzv
SDEPHR       1.038462        5.9375   FALSE FALSE
SKDEPS       1.000000       19.0625   FALSE FALSE
D00          1.166667       75.3125   FALSE FALSE
AVGSQ        6.333333       82.8125   FALSE FALSE
AVGLOFATC    1.000000       78.4375   FALSE FALSE
AVGSKDAVAIL  1.000000       87.5000   FALSE FALSE
xDURN2       1.428571        2.5000   FALSE FALSE

> # annoying NA
> flight.cor <- cor(flight.num, use = "pairwise.complete.obs")

> descrCorr <- findCorrelation(flight.cor, cutoff = .65, verbose=TRUE)
Considering row	 1 column	 4 value	 0.956 
  Flagging column	 1 
Considering row	 4 column	 3 value	 0.414 
Considering row	 4 column	 6 value	 0.173 
Considering row	 4 column	 7 value	 0.201 
Considering row	 4 column	 5 value	 0.103 
Considering row	 4 column	 2 value	 0.082 
Considering row	 3 column	 6 value	 0.266 
Considering row	 3 column	 7 value	 0.071 
Considering row	 3 column	 5 value	 0.114 
Considering row	 3 column	 2 value	 0.006 
Considering row	 6 column	 7 value	 0.031 
Considering row	 6 column	 5 value	 0.094 
Considering row	 6 column	 2 value	 0.067 
Considering row	 7 column	 5 value	 0.137 
Considering row	 7 column	 2 value	 0.005 
Considering row	 5 column	 2 value	 0.041 

> colnames(flight.num)[descrCorr]
[1] "SDEPHR"

> ## Which tells me that departure time is very highly correlated to AVGSQ.
> ## AVGSQ is average stand queue?
> 
> ### Try and impute the AVG, it might have more information than the
> ### bucket.
> 
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))

> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1

> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]

> preProcValues <- preProcess(flight.na, method = c("knnImpute"))

> flight.na1 <- predict(preProcValues, flight.na)

> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL

> ## And I'll leave the centered and scale values in for now.
> ## and delete the troublesome ones
> 
> flight$AVGSKDAVAIL <- NULL

> flight$xHNGR <- NULL

> flight$AVAILBUCKET <- NULL

> # This should be deleted, leave it in and the results are ideal because it defines LEGTYPE.
> flight$D00 <- NULL

> ## Keep the results but don't change the order.
> outcomes.flight <- flight$LEGTYPE

> flight$LEGTYPE <- NULL

> ## If you know your factors are definitely factors, you don't need this
> ##  asNumeric <- function(x) as.numeric(as.character(x))
> 
> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))

> flight.num0 <- factors.numeric(flight)

> flight.scl0 <- scale(flight.num0)

> ## Now split the results
> ## we need 80 or so to test with.
> 
> set.seed(seed.mine)

> inTrain <- createDataPartition(outcomes.flight, p = 0.77, list = FALSE)

> trainDescr <- flight.scl0[inTrain,]

> testDescr <- flight.scl0[-inTrain,]

> trainClass <- outcomes.flight[inTrain]

> testClass <- outcomes.flight[-inTrain]

> prop.table(table(trainClass))
trainClass
   Strong      Weak 
0.3481781 0.6518219 

> dim(trainDescr)
[1] 247  20

> prop.table(table(testClass))
testClass
   Strong      Weak 
0.3424658 0.6575342 

> dim(testDescr)
[1] 73 20

> ## Check Near-zero variance
> 
> nzv <- nearZeroVar(trainDescr, saveMetrics= TRUE)

> stopifnot( all(nzv$nzv == FALSE) )

> # It's imputed and behaves well, no need for this.
> # descrCorr <- cor(scale(trainDescr), use = "pairwise.complete.obs")
> 
> descrCorr <- cor(scale(trainDescr))

> ## This cut-off should be under src.adjust control.
> ## I'm under Git, so I can tinker with it.
> highCorr <- findCorrelation(descrCorr, cutoff = .65, verbose = TRUE)
Considering row	 16 column	 17 value	 0.877 
  Flagging column	 16 
Considering row	 17 column	 1 value	 0.276 
Considering row	 17 column	 10 value	 0.65 
  Flagging column	 17 
Considering row	 1 column	 10 value	 0.294 
Considering row	 1 column	 11 value	 0.988 
  Flagging column	 1 
Considering row	 10 column	 11 value	 0.291 
Considering row	 10 column	 6 value	 0.298 
Considering row	 10 column	 12 value	 0.263 
Considering row	 10 column	 14 value	 0.26 
Considering row	 10 column	 2 value	 0.29 
Considering row	 10 column	 13 value	 0.25 
Considering row	 10 column	 9 value	 0.383 
Considering row	 10 column	 8 value	 0.343 
Considering row	 10 column	 19 value	 0.13 
Considering row	 10 column	 18 value	 0.245 
Considering row	 10 column	 3 value	 0.444 
Considering row	 10 column	 20 value	 0.07 
Considering row	 10 column	 7 value	 0.134 
Considering row	 10 column	 15 value	 0.193 
Considering row	 10 column	 5 value	 0.094 
Considering row	 10 column	 4 value	 0.001 
Considering row	 11 column	 6 value	 0.947 
  Flagging column	 11 
Considering row	 6 column	 12 value	 0.884 
  Flagging column	 6 
Considering row	 12 column	 14 value	 0.133 
Considering row	 12 column	 2 value	 0.106 
Considering row	 12 column	 13 value	 0.088 
Considering row	 12 column	 9 value	 0.077 
Considering row	 12 column	 8 value	 0.083 
Considering row	 12 column	 19 value	 0.129 
Considering row	 12 column	 18 value	 0.111 
Considering row	 12 column	 3 value	 0.094 
Considering row	 12 column	 20 value	 0.173 
Considering row	 12 column	 7 value	 0.111 
Considering row	 12 column	 15 value	 0.134 
Considering row	 12 column	 5 value	 0.07 
Considering row	 12 column	 4 value	 0.027 
Considering row	 14 column	 2 value	 0.624 
Considering row	 14 column	 13 value	 0.698 
  Flagging column	 14 
Considering row	 2 column	 13 value	 0.642 
Considering row	 2 column	 9 value	 0.413 
Considering row	 2 column	 8 value	 0.19 
Considering row	 2 column	 19 value	 0.03 
Considering row	 2 column	 18 value	 0.183 
Considering row	 2 column	 3 value	 0.254 
Considering row	 2 column	 20 value	 0.113 
Considering row	 2 column	 7 value	 0.054 
Considering row	 2 column	 15 value	 0.113 
Considering row	 2 column	 5 value	 0.062 
Considering row	 2 column	 4 value	 0.197 
Considering row	 13 column	 9 value	 0.155 
Considering row	 13 column	 8 value	 0.169 
Considering row	 13 column	 19 value	 0.098 
Considering row	 13 column	 18 value	 0.206 
Considering row	 13 column	 3 value	 0.209 
Considering row	 13 column	 20 value	 0.151 
Considering row	 13 column	 7 value	 0.093 
Considering row	 13 column	 15 value	 0.17 
Considering row	 13 column	 5 value	 0.064 
Considering row	 13 column	 4 value	 0.224 
Considering row	 9 column	 8 value	 0.443 
Considering row	 9 column	 19 value	 0.257 
Considering row	 9 column	 18 value	 0.002 
Considering row	 9 column	 3 value	 0.28 
Considering row	 9 column	 20 value	 0.16 
Considering row	 9 column	 7 value	 0.149 
Considering row	 9 column	 15 value	 0.031 
Considering row	 9 column	 5 value	 0.153 
Considering row	 9 column	 4 value	 0.032 
Considering row	 8 column	 19 value	 0.26 
Considering row	 8 column	 18 value	 0.165 
Considering row	 8 column	 3 value	 0.162 
Considering row	 8 column	 20 value	 0.192 
Considering row	 8 column	 7 value	 0.1 
Considering row	 8 column	 15 value	 0.013 
Considering row	 8 column	 5 value	 0.01 
Considering row	 8 column	 4 value	 0.031 
Considering row	 19 column	 18 value	 0.131 
Considering row	 19 column	 3 value	 0.12 
Considering row	 19 column	 20 value	 0.859 
  Flagging column	 19 
Considering row	 18 column	 3 value	 0.004 
Considering row	 18 column	 20 value	 0.005 
Considering row	 18 column	 7 value	 0.11 
Considering row	 18 column	 15 value	 0.118 
Considering row	 18 column	 5 value	 0.024 
Considering row	 18 column	 4 value	 0.131 
Considering row	 3 column	 20 value	 0.021 
Considering row	 3 column	 7 value	 0.094 
Considering row	 3 column	 15 value	 0.021 
Considering row	 3 column	 5 value	 0.076 
Considering row	 3 column	 4 value	 0.131 
Considering row	 20 column	 7 value	 0.09 
Considering row	 20 column	 15 value	 0.025 
Considering row	 20 column	 5 value	 0.136 
Considering row	 20 column	 4 value	 0.053 
Considering row	 7 column	 15 value	 0.088 
Considering row	 7 column	 5 value	 0.026 
Considering row	 7 column	 4 value	 0.024 
Considering row	 15 column	 5 value	 0.05 
Considering row	 15 column	 4 value	 0.019 
Considering row	 5 column	 4 value	 0.231 

> colnames(trainDescr)[highCorr]
[1] "DEPSPOKE"     "ARRSPOKE"     "SDEPHR"       "DEPBUCKET"    "AVGSQ"       
[6] "TRNRANKGRP"   "xAVAILBUCKET"

> descr.ncol0 <- ncol(trainDescr)

> # I've switched off the correlation remover and the results are better.
> if (sum(highCorr) > 0) {
+     warning("overfitting: correlations: err.trainDescr: ", paste(colnames(trainDescr)[highCorr], collapse = ", ") )
+     err.trainDescr <- trainDescr
+     trainDescr <- trainDescr[,-highCorr]
+ }

> descr.ncol1 <- ncol(trainDescr)

> paste("Dropped: ", as.character(descr.ncol0 - descr.ncol1))
[1] "Dropped:  7"

> descrCorr <- cor(trainDescr)

> summary(descrCorr[upper.tri(descrCorr)])
      Min.    1st Qu.     Median       Mean    3rd Qu.       Max. 
-0.4427000 -0.1109000  0.0025490  0.0003403  0.1134000  0.6423000 

> ## Dominant correlations
> ## At 0.9, there are some big ones that might need re-thinking.
> 
> table.descrCorr <- as.data.frame(as.table(descrCorr))

> table.descrCorr <- table.descrCorr[which(table.descrCorr$Var1 != table.descrCorr$Var2),]

> table.descrCorr[order(abs(table.descrCorr$Freq), decreasing = TRUE),]
              Var1           Var2         Freq
10      DEPRANKGRP      SKDDEPSTA  0.642308679
118      SKDDEPSTA     DEPRANKGRP  0.642308679
21  DOWNLINEATCIMP      SKDARRSTA  0.443932788
93       SKDARRSTA DOWNLINEATCIMP  0.443932788
72    DEPSTAATCIMP   UPLINEATCIMP -0.442720708
84    UPLINEATCIMP   DEPSTAATCIMP -0.442720708
7     DEPSTAATCIMP      SKDDEPSTA  0.412753737
79       SKDDEPSTA   DEPSTAATCIMP  0.412753737
86  DOWNLINEATCIMP   DEPSTAATCIMP -0.383415665
98    DEPSTAATCIMP DOWNLINEATCIMP -0.383415665
73  DOWNLINEATCIMP   UPLINEATCIMP  0.342517313
97    UPLINEATCIMP DOWNLINEATCIMP  0.342517313
8   DOWNLINEATCIMP      SKDDEPSTA -0.290377112
92       SKDDEPSTA DOWNLINEATCIMP -0.290377112
20    DEPSTAATCIMP      SKDARRSTA -0.280392851
80       SKDARRSTA   DEPSTAATCIMP -0.280392851
100      ARRBUCKET DOWNLINEATCIMP  0.262860959
112 DOWNLINEATCIMP      ARRBUCKET  0.262860959
2        SKDARRSTA      SKDDEPSTA -0.253612805
14       SKDDEPSTA      SKDARRSTA -0.253612805
101     DEPRANKGRP DOWNLINEATCIMP -0.249796537
125 DOWNLINEATCIMP     DEPRANKGRP -0.249796537
103         xDURN2 DOWNLINEATCIMP -0.245009289
151 DOWNLINEATCIMP         xDURN2 -0.245009289
30          SKDEPS         SKDEQP  0.230929143
42          SKDEQP         SKDEPS  0.230929143
36      DEPRANKGRP         SKDEQP  0.223615941
120         SKDEQP     DEPRANKGRP  0.223615941
23      DEPRANKGRP      SKDARRSTA -0.209068746
119      SKDARRSTA     DEPRANKGRP -0.209068746
129         xDURN2     DEPRANKGRP  0.206090722
153     DEPRANKGRP         xDURN2  0.206090722
3           SKDEQP      SKDDEPSTA  0.196605361
27       SKDDEPSTA         SKDEQP  0.196605361
102     ARRRANKGRP DOWNLINEATCIMP -0.193068956
138 DOWNLINEATCIMP     ARRRANKGRP -0.193068956
78    xAVGSKDAVAIL   UPLINEATCIMP  0.192206325
162   UPLINEATCIMP   xAVGSKDAVAIL  0.192206325
6     UPLINEATCIMP      SKDDEPSTA -0.190386147
66       SKDDEPSTA   UPLINEATCIMP -0.190386147
12          xDURN2      SKDDEPSTA  0.182957241
144      SKDDEPSTA         xDURN2  0.182957241
117   xAVGSKDAVAIL      ARRBUCKET -0.172788521
165      ARRBUCKET   xAVGSKDAVAIL -0.172788521
128     ARRRANKGRP     DEPRANKGRP  0.170260053
140     DEPRANKGRP     ARRRANKGRP  0.170260053
75      DEPRANKGRP   UPLINEATCIMP -0.169220659
123   UPLINEATCIMP     DEPRANKGRP -0.169220659
77          xDURN2   UPLINEATCIMP -0.165307767
149   UPLINEATCIMP         xDURN2 -0.165307767
19    UPLINEATCIMP      SKDARRSTA  0.162455252
67       SKDARRSTA   UPLINEATCIMP  0.162455252
91    xAVGSKDAVAIL   DEPSTAATCIMP -0.159775750
163   DEPSTAATCIMP   xAVGSKDAVAIL -0.159775750
88      DEPRANKGRP   DEPSTAATCIMP  0.155051447
124   DEPSTAATCIMP     DEPRANKGRP  0.155051447
46    DEPSTAATCIMP         SKDEPS -0.153163380
82          SKDEPS   DEPSTAATCIMP -0.153163380
130   xAVGSKDAVAIL     DEPRANKGRP  0.151031995
166     DEPRANKGRP   xAVGSKDAVAIL  0.151031995
59    DEPSTAATCIMP      AVGLOFATC -0.148755652
83       AVGLOFATC   DEPSTAATCIMP -0.148755652
52    xAVGSKDAVAIL         SKDEPS  0.136169329
160         SKDEPS   xAVGSKDAVAIL  0.136169329
60  DOWNLINEATCIMP      AVGLOFATC -0.134315702
96       AVGLOFATC DOWNLINEATCIMP -0.134315702
115     ARRRANKGRP      ARRBUCKET -0.134287719
139      ARRBUCKET     ARRRANKGRP -0.134287719
38          xDURN2         SKDEQP  0.131264762
146         SKDEQP         xDURN2  0.131264762
16          SKDEQP      SKDARRSTA  0.130852916
28       SKDARRSTA         SKDEQP  0.130852916
142         xDURN2     ARRRANKGRP  0.117910130
154     ARRRANKGRP         xDURN2  0.117910130
13    xAVGSKDAVAIL      SKDDEPSTA  0.113414821
157      SKDDEPSTA   xAVGSKDAVAIL  0.113414821
11      ARRRANKGRP      SKDDEPSTA  0.113272144
131      SKDDEPSTA     ARRRANKGRP  0.113272144
116         xDURN2      ARRBUCKET -0.111412221
152      ARRBUCKET         xDURN2 -0.111412221
61       ARRBUCKET      AVGLOFATC -0.111293247
109      AVGLOFATC      ARRBUCKET -0.111293247
64          xDURN2      AVGLOFATC -0.109778750
148      AVGLOFATC         xDURN2 -0.109778750
9        ARRBUCKET      SKDDEPSTA -0.106182991
105      SKDDEPSTA      ARRBUCKET -0.106182991
58    UPLINEATCIMP      AVGLOFATC -0.100410511
70       AVGLOFATC   UPLINEATCIMP -0.100410511
18       AVGLOFATC      SKDARRSTA -0.094389176
54       SKDARRSTA      AVGLOFATC -0.094389176
47  DOWNLINEATCIMP         SKDEPS -0.093911134
95          SKDEPS DOWNLINEATCIMP -0.093911134
22       ARRBUCKET      SKDARRSTA  0.093836632
106      SKDARRSTA      ARRBUCKET  0.093836632
62      DEPRANKGRP      AVGLOFATC  0.093472836
122      AVGLOFATC     DEPRANKGRP  0.093472836
65    xAVGSKDAVAIL      AVGLOFATC -0.090103316
161      AVGLOFATC   xAVGSKDAVAIL -0.090103316
63      ARRRANKGRP      AVGLOFATC -0.088441101
135      AVGLOFATC     ARRRANKGRP -0.088441101
114     DEPRANKGRP      ARRBUCKET -0.088106733
126      ARRBUCKET     DEPRANKGRP -0.088106733
74       ARRBUCKET   UPLINEATCIMP  0.083046773
110   UPLINEATCIMP      ARRBUCKET  0.083046773
87       ARRBUCKET   DEPSTAATCIMP -0.076902317
111   DEPSTAATCIMP      ARRBUCKET -0.076902317
17          SKDEPS      SKDARRSTA -0.076470108
41       SKDARRSTA         SKDEPS -0.076470108
104   xAVGSKDAVAIL DOWNLINEATCIMP  0.070277352
164 DOWNLINEATCIMP   xAVGSKDAVAIL  0.070277352
48       ARRBUCKET         SKDEPS -0.070227599
108         SKDEPS      ARRBUCKET -0.070227599
49      DEPRANKGRP         SKDEPS  0.063747427
121         SKDEPS     DEPRANKGRP  0.063747427
4           SKDEPS      SKDDEPSTA -0.062351484
40       SKDDEPSTA         SKDEPS -0.062351484
5        AVGLOFATC      SKDDEPSTA -0.054136827
53       SKDDEPSTA      AVGLOFATC -0.054136827
39    xAVGSKDAVAIL         SKDEQP  0.053179917
159         SKDEQP   xAVGSKDAVAIL  0.053179917
50      ARRRANKGRP         SKDEPS  0.050428064
134         SKDEPS     ARRRANKGRP  0.050428064
33    DEPSTAATCIMP         SKDEQP -0.032450085
81          SKDEQP   DEPSTAATCIMP -0.032450085
32    UPLINEATCIMP         SKDEQP -0.030823866
68          SKDEQP   UPLINEATCIMP -0.030823866
89      ARRRANKGRP   DEPSTAATCIMP  0.030740090
137   DEPSTAATCIMP     ARRRANKGRP  0.030740090
35       ARRBUCKET         SKDEQP  0.027235148
107         SKDEQP      ARRBUCKET  0.027235148
44       AVGLOFATC         SKDEPS  0.026250506
56          SKDEPS      AVGLOFATC  0.026250506
143   xAVGSKDAVAIL     ARRRANKGRP -0.025149104
167     ARRRANKGRP   xAVGSKDAVAIL -0.025149104
31       AVGLOFATC         SKDEQP  0.024181196
55          SKDEQP      AVGLOFATC  0.024181196
51          xDURN2         SKDEPS  0.023980545
147         SKDEPS         xDURN2  0.023980545
26    xAVGSKDAVAIL      SKDARRSTA  0.021352068
158      SKDARRSTA   xAVGSKDAVAIL  0.021352068
24      ARRRANKGRP      SKDARRSTA  0.020871101
132      SKDARRSTA     ARRRANKGRP  0.020871101
37      ARRRANKGRP         SKDEQP  0.019028245
133         SKDEQP     ARRRANKGRP  0.019028245
76      ARRRANKGRP   UPLINEATCIMP -0.013193630
136   UPLINEATCIMP     ARRRANKGRP -0.013193630
45    UPLINEATCIMP         SKDEPS  0.009545558
69          SKDEPS   UPLINEATCIMP  0.009545558
156   xAVGSKDAVAIL         xDURN2  0.004760048
168         xDURN2   xAVGSKDAVAIL  0.004760048
25          xDURN2      SKDARRSTA  0.003725015
145      SKDARRSTA         xDURN2  0.003725015
90          xDURN2   DEPSTAATCIMP -0.001752846
150   DEPSTAATCIMP         xDURN2 -0.001752846
34  DOWNLINEATCIMP         SKDEQP  0.001372609
94          SKDEQP DOWNLINEATCIMP  0.001372609

> ### Models
> 
> ## Try GBM (gradient boosting). Works well for mixed data.
> ## And there is a tutorial for it with caret.
> 
> ## Training controller and big grid
> ## Check the ROC (my preferred.)
> 
> fitControl <- trainControl(## 10-fold CV
+     method = "repeatedcv",
+     number = 10,
+     .... [TRUNCATED] 

> ## Some trial and error with variables to branch and boost.
> ## I'm just going to try the airports and the planes and the duration
> ## of the flight. There may be some distance relationship there that
> ## air traffic control use.
> 
> ## Annoying because I drop variables, this needs to be looke .... [TRUNCATED] 

> tr.cols
 [1] "SKDDEPSTA"      "SKDARRSTA"      "SKDEQP"         "SKDEPS"        
 [5] "AVGLOFATC"      "UPLINEATCIMP"   "DEPSTAATCIMP"   "DOWNLINEATCIMP"
 [9] "ARRBUCKET"      "DEPRANKGRP"     "ARRRANKGRP"     "xDURN2"        
[13] "xAVGSKDAVAIL"  

> tr.icols <- grep("((STA|EQP)$)|(^xD)", tr.cols)

> tr.icols <- rev(tr.icols)

> gbmGrid <- expand.grid(interaction.depth = tr.icols,
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.1,
+                         n.minobsinnode = 20)

> set.seed(seed.mine)

> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "ROC" .... [TRUNCATED] 

> gbmFit1
Stochastic Gradient Boosting 

247 samples
 13 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 222, 223, 222, 223, 222, 221, ... 

Resampling results across tuning parameters:

  interaction.depth  n.trees  ROC        Sens       Spec       ROC SD    
   1                   90     0.8487357  0.5643056  0.8905882  0.07494411
   1                  180     0.8384615  0.5961111  0.8887500  0.07837166
   1                  270     0.8308114  0.5972222  0.8795588  0.07971375
   1                  360     0.8252257  0.6063889  0.8793382  0.08192762
   1                  450     0.8198121  0.6062500  0.8750735  0.09320421
   1                  540     0.8162250  0.5995833  0.8657353  0.09702704
   1                  630     0.8094700  0.6004167  0.8626471  0.10036023
   1                  720     0.8109778  0.6019444  0.8557721  0.09431099
   1                  810     0.8066457  0.5969444  0.8545956  0.09601882
   1                  900     0.8038766  0.6016667  0.8520956  0.09455152
   1                  990     0.8012832  0.5958333  0.8520588  0.09545491
   1                 1080     0.8000403  0.5958333  0.8433088  0.09618515
   1                 1170     0.7951578  0.5979167  0.8465074  0.10276924
   1                 1260     0.7949020  0.5943056  0.8426838  0.10044774
   1                 1350     0.7950286  0.5908333  0.8383088  0.09689184
   1                 1440     0.7923366  0.5922222  0.8401471  0.09970806
   1                 1530     0.7857516  0.5865278  0.8401838  0.10737080
   1                 1620     0.7867310  0.5922222  0.8333824  0.10282889
   1                 1710     0.7862776  0.5900000  0.8327206  0.10235497
   1                 1800     0.7882695  0.5955556  0.8334191  0.09662831
   1                 1890     0.7837587  0.5920833  0.8296691  0.10221360
   1                 1980     0.7842734  0.5898611  0.8284191  0.10265006
   1                 2070     0.7874203  0.5852778  0.8321324  0.09688686
   1                 2160     0.7854065  0.5866667  0.8259191  0.09535043
   1                 2250     0.7842984  0.5922222  0.8259191  0.09868639
   1                 2340     0.7822799  0.5900000  0.8259559  0.09828329
   1                 2430     0.7792754  0.5863889  0.8171691  0.10408349
   1                 2520     0.7800153  0.5879167  0.8196691  0.10384621
   1                 2610     0.7776838  0.5934722  0.8215441  0.10600640
   1                 2700     0.7768801  0.5945833  0.8190809  0.10705770
   2                   90     0.8385110  0.6068056  0.8751103  0.07443060
   2                  180     0.8280316  0.6054167  0.8644853  0.07943942
   2                  270     0.8205081  0.5852778  0.8619853  0.09215006
   2                  360     0.8145221  0.5952778  0.8532721  0.09315015
   2                  450     0.8078186  0.5943056  0.8538971  0.10187442
   2                  540     0.8041953  0.6045833  0.8470588  0.10143719
   2                  630     0.8022442  0.5938889  0.8377574  0.10202888
   2                  720     0.8034273  0.5904167  0.8358824  0.09189683
   2                  810     0.7995113  0.5926389  0.8389338  0.09875219
   2                  900     0.7996579  0.5830556  0.8365074  0.09786416
   2                  990     0.7952880  0.5879167  0.8340074  0.10714505
   2                 1080     0.7947998  0.5773611  0.8321324  0.10634144
   2                 1170     0.7931715  0.5794444  0.8315809  0.10657429
   2                 1260     0.7908967  0.5748611  0.8302941  0.11078612
   2                 1350     0.7953488  0.5811111  0.8259559  0.09996763
   2                 1440     0.7963460  0.5763889  0.8284559  0.09207917
   2                 1530     0.7926639  0.5761111  0.8259559  0.10428907
   2                 1620     0.7905428  0.5734722  0.8277941  0.10556117
   2                 1710     0.7898713  0.5715278  0.8302574  0.10591375
   2                 1800     0.7896058  0.5711111  0.8265809  0.10621276
   2                 1890     0.7917923  0.5701389  0.8284559  0.09964252
   2                 1980     0.7897661  0.5701389  0.8290809  0.10394984
   2                 2070     0.7877660  0.5690278  0.8272059  0.10923058
   2                 2160     0.7883604  0.5702778  0.8253309  0.10598199
   2                 2250     0.7865998  0.5761111  0.8259191  0.10939854
   2                 2340     0.7869521  0.5691667  0.8284191  0.10865889
   2                 2430     0.7872891  0.5702778  0.8259559  0.10523242
   2                 2520     0.7836259  0.5712500  0.8272059  0.11311550
   2                 2610     0.7806041  0.5676389  0.8259559  0.11632866
   2                 2700     0.7819143  0.5654167  0.8265809  0.11422562
   3                   90     0.8347426  0.6101389  0.8627206  0.07840346
   3                  180     0.8235468  0.6047222  0.8470588  0.08503222
   3                  270     0.8157011  0.5984722  0.8382721  0.09311910
   3                  360     0.8086949  0.5893056  0.8365809  0.09566418
   3                  450     0.8008037  0.5841667  0.8315074  0.10079451
   3                  540     0.8008635  0.5798611  0.8322426  0.09945449
   3                  630     0.7972575  0.5736111  0.8315809  0.10194717
   3                  720     0.7992713  0.5725000  0.8297794  0.09296762
   3                  810     0.8003196  0.5748611  0.8279412  0.09183043
   3                  900     0.7991697  0.5759722  0.8284926  0.08717623
   3                  990     0.7973218  0.5725000  0.8241176  0.09425917
   3                 1080     0.7958139  0.5702778  0.8260294  0.09284947
   3                 1170     0.7921318  0.5691667  0.8229044  0.10008720
   3                 1260     0.7916493  0.5688889  0.8235294  0.09961246
   3                 1350     0.7919919  0.5631944  0.8229044  0.09984440
   3                 1440     0.7915615  0.5654167  0.8210294  0.09552845
   3                 1530     0.7920874  0.5619444  0.8210294  0.09469154
   3                 1620     0.7919225  0.5631944  0.8191544  0.09409621
   3                 1710     0.7887536  0.5609722  0.8197794  0.10410268
   3                 1800     0.7871952  0.5666667  0.8204044  0.10481590
   3                 1890     0.7879560  0.5633333  0.8191176  0.10362267
   3                 1980     0.7868199  0.5647222  0.8166544  0.10458233
   3                 2070     0.7875020  0.5656944  0.8179412  0.10282547
   3                 2160     0.7877717  0.5619444  0.8191544  0.09922075
   3                 2250     0.7874326  0.5622222  0.8172794  0.09972933
   3                 2340     0.7883645  0.5668056  0.8166544  0.09302230
   3                 2430     0.7865191  0.5644444  0.8141544  0.09923764
   3                 2520     0.7875107  0.5620833  0.8147794  0.09419308
   3                 2610     0.7872855  0.5598611  0.8172794  0.09432589
   3                 2700     0.7827334  0.5608333  0.8160294  0.10610253
  12                   90     0.8301297  0.6063889  0.8634191  0.09384635
  12                  180     0.8158313  0.6116667  0.8447794  0.09742519
  12                  270     0.8112801  0.5891667  0.8460294  0.09158644
  12                  360     0.8070895  0.5722222  0.8354412  0.08790518
  12                  450     0.8050235  0.5781944  0.8329412  0.09027513
  12                  540     0.8028013  0.5688889  0.8323162  0.08910692
  12                  630     0.7981332  0.5694444  0.8298162  0.09938440
  12                  720     0.7979182  0.5668056  0.8280515  0.09847894
  12                  810     0.7953600  0.5690278  0.8262132  0.10364133
  12                  900     0.7913914  0.5644444  0.8268382  0.10926831
  12                  990     0.7940814  0.5645833  0.8268382  0.10277792
  12                 1080     0.7943888  0.5645833  0.8187132  0.10056453
  12                 1170     0.7935355  0.5702778  0.8230515  0.09735351
  12                 1260     0.7896569  0.5702778  0.8223897  0.10393590
  12                 1350     0.7891595  0.5687500  0.8223529  0.10253565
  12                 1440     0.7879779  0.5668056  0.8236397  0.10326830
  12                 1530     0.7875827  0.5658333  0.8211029  0.10314873
  12                 1620     0.7887143  0.5677778  0.8179779  0.09701186
  12                 1710     0.7887071  0.5631944  0.8149265  0.09676010
  12                 1800     0.7893505  0.5636111  0.8148897  0.09235486
  12                 1890     0.7866253  0.5645833  0.8155147  0.09943545
  12                 1980     0.7867387  0.5633333  0.8173529  0.09917524
  12                 2070     0.7849081  0.5704167  0.8198529  0.10598840
  12                 2160     0.7851190  0.5681944  0.8154779  0.10075253
  12                 2250     0.7801527  0.5634722  0.8136029  0.11052351
  12                 2340     0.7771742  0.5658333  0.8148529  0.11631280
  12                 2430     0.7775041  0.5647222  0.8136029  0.11562735
  12                 2520     0.7788909  0.5634722  0.8136029  0.11012369
  12                 2610     0.7797248  0.5668056  0.8142279  0.11104155
  12                 2700     0.7793944  0.5633333  0.8111029  0.11170827
  Sens SD    Spec SD   
  0.1624472  0.07615291
  0.1622675  0.07346741
  0.1723453  0.08043399
  0.1702891  0.08334051
  0.1750195  0.07819424
  0.1648689  0.08213441
  0.1681084  0.08565135
  0.1725850  0.08506006
  0.1700803  0.08263141
  0.1689066  0.08334456
  0.1669762  0.08304797
  0.1716372  0.08569160
  0.1681144  0.08573078
  0.1658850  0.08686186
  0.1677088  0.08709838
  0.1697540  0.08720569
  0.1699184  0.08809663
  0.1645313  0.08965497
  0.1619646  0.09261761
  0.1592446  0.09187194
  0.1600303  0.09392268
  0.1634493  0.09245318
  0.1648330  0.08910865
  0.1631828  0.09862289
  0.1700980  0.09453747
  0.1692937  0.09522364
  0.1675014  0.09243812
  0.1688509  0.09563589
  0.1674581  0.09691087
  0.1677701  0.09408279
  0.1684771  0.08529824
  0.1765682  0.07921260
  0.1647266  0.08232027
  0.1712681  0.08548473
  0.1603787  0.08323271
  0.1634493  0.08690854
  0.1616351  0.08195665
  0.1590636  0.08556842
  0.1557530  0.08535783
  0.1594854  0.08684010
  0.1639563  0.09161550
  0.1547263  0.09052688
  0.1577423  0.09105392
  0.1534953  0.09640704
  0.1557113  0.09480837
  0.1518311  0.09399702
  0.1600160  0.09439127
  0.1554054  0.09277259
  0.1561568  0.09439103
  0.1565918  0.09529220
  0.1614935  0.09566137
  0.1573254  0.09451598
  0.1592345  0.09603994
  0.1581831  0.09610602
  0.1572400  0.09723008
  0.1586770  0.09765977
  0.1587610  0.09420015
  0.1586116  0.09567532
  0.1586362  0.09749350
  0.1587914  0.09556403
  0.1660489  0.08178749
  0.1614458  0.08760638
  0.1610673  0.08568478
  0.1584961  0.09129304
  0.1546075  0.09106496
  0.1556444  0.08985998
  0.1548301  0.09332864
  0.1575383  0.09223798
  0.1562880  0.09034388
  0.1585477  0.08890181
  0.1583279  0.08887162
  0.1549474  0.08817319
  0.1560396  0.09101697
  0.1577526  0.08788490
  0.1553186  0.09024568
  0.1587914  0.08978736
  0.1571276  0.08801201
  0.1571271  0.08704933
  0.1550363  0.09120567
  0.1567624  0.08784664
  0.1571512  0.08938826
  0.1570011  0.08855294
  0.1563000  0.08718847
  0.1610954  0.09103743
  0.1582282  0.08962850
  0.1572054  0.09075348
  0.1581178  0.09126761
  0.1543758  0.09232864
  0.1520131  0.09093960
  0.1514878  0.09228892
  0.1630048  0.08495489
  0.1588849  0.08546155
  0.1572858  0.09290870
  0.1509881  0.09307291
  0.1578728  0.08751176
  0.1571710  0.09301682
  0.1599615  0.09440729
  0.1572054  0.09353200
  0.1578210  0.09342099
  0.1546667  0.09140383
  0.1573501  0.09469926
  0.1583500  0.09370968
  0.1585031  0.09262963
  0.1616677  0.09496589
  0.1620476  0.09670844
  0.1545933  0.09565456
  0.1595299  0.09924369
  0.1598552  0.09766598
  0.1534887  0.09582108
  0.1530158  0.09714017
  0.1585591  0.09646460
  0.1529157  0.09790108
  0.1596109  0.09693282
  0.1584450  0.09238026
  0.1602080  0.09306026
  0.1597374  0.09089158
  0.1537911  0.09306026
  0.1611901  0.09177947
  0.1578363  0.09025233
  0.1559814  0.09134448

Tuning parameter 'shrinkage' was held constant at a value of 0.1

Tuning parameter 'n.minobsinnode' was held constant at a value of 20
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 90, interaction.depth =
 1, shrinkage = 0.1 and n.minobsinnode = 20. 

> ## The acid test is dissapointing, but I've seen worse.
> 
> testPred <- predict(gbmFit1, testDescr)

> postResample(testPred, testClass)
   Accuracy       Kappa 
 0.53424658 -0.07538995 

> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong      6   15
    Weak       19   33
                                         
               Accuracy : 0.5342         
                 95% CI : (0.4137, 0.652)
    No Information Rate : 0.6575         
    P-Value [Acc > NIR] : 0.9893         
                                         
                  Kappa : -0.0754        
 Mcnemar's Test P-Value : 0.6069         
                                         
            Sensitivity : 0.6875         
            Specificity : 0.2400         
         Pos Pred Value : 0.6346         
         Neg Pred Value : 0.2857         
             Prevalence : 0.6575         
         Detection Rate : 0.4521         
   Detection Prevalence : 0.7123         
      Balanced Accuracy : 0.4637         
                                         
       'Positive' Class : Weak           
                                         

> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)

> postResample(trainPred, trainClass)
 Accuracy     Kappa 
0.8340081 0.6188128 

> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     58   13
    Weak       28  148
                                          
               Accuracy : 0.834           
                 95% CI : (0.7816, 0.8782)
    No Information Rate : 0.6518          
    P-Value [Acc > NIR] : 1.479e-10       
                                          
                  Kappa : 0.6188          
 Mcnemar's Test P-Value : 0.02878         
                                          
            Sensitivity : 0.9193          
            Specificity : 0.6744          
         Pos Pred Value : 0.8409          
         Neg Pred Value : 0.8169          
             Prevalence : 0.6518          
         Detection Rate : 0.5992          
   Detection Prevalence : 0.7126          
      Balanced Accuracy : 0.7968          
                                          
       'Positive' Class : Weak            
                                          
Warning messages:
1: In eval(expr, envir, enclos) : adjusting
2: In eval(expr, envir, enclos) :
  overfitting: correlations: err.trainDescr: DEPSPOKE, ARRSPOKE, SDEPHR, DEPBUCKET, AVGSQ, TRNRANKGRP, xAVAILBUCKET
> seed.mine = 107
> set.seed(seed.mine)                     # helpful for testing
> 
> flight <- read.csv("../bak/flight.csv")
> flight <- flight[order(flight$D00),]
> 
> # Backup
> flight.raw <- flight
> 
> # To check adjustment, there is test code in flight-nb.R
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"
> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"
> 
> # And some deletions
> 
> t.cols <- colnames(flight)
> 
> t.drops <- t.cols[grep("^RANK*", t.cols)]
> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])
> t.drops <- c(t.drops, "D80THPCTL")
> 
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR
> flight$xHNGR <- flight$xDURN < 0
> 
> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+ }
> 
> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))
> 
> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE
> t.cols <- colnames(flight)
> 
> t.drops <- c("SARRHR", "xDURN")
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Backup
> 
> flight00 <- flight
> 
> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]
> 
> paste("samples in use: ", dim(flight)[1])
[1] "samples in use:  320"
> 
> ## Check warnings to see what happened.
> src.adjust <- TRUE
> source(file = "flight1.R")
Warning message:
In eval(expr, envir, enclos) : adjusting
> 
> ## Take another copy - this is all we need as the training/prediction
> ## set.
> 
> flight1 <- flight
> 
> ## Data insights
> 
> ## *Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> flight <- flight1
> 
> ## So something is defining the behaviour.
> 
> ## Try to simplify structure
> 
> head(model.matrix(LEGTYPE ~ ., data = flight))
   (Intercept) SDEPHR SKDDEPSTAALB SKDDEPSTAAMS SKDDEPSTAANC SKDDEPSTAATT
2            1     14            0            0            0            0
5            1     11            0            0            0            0
7            1     14            0            0            0            0
13           1     13            0            0            0            0
14           1     16            0            0            0            0
17           1     15            0            0            0            0
   SKDDEPSTAAUA SKDDEPSTAAUS SKDDEPSTABDA SKDDEPSTABDL SKDDEPSTABNA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTABOI SKDDEPSTABOS SKDDEPSTABRU SKDDEPSTABUF SKDDEPSTABWI
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTACCC SKDDEPSTACDG SKDDEPSTACHS SKDDEPSTACLE SKDDEPSTACMH
2             1            0            0            0            0
5             0            0            0            0            0
7             1            0            0            0            0
13            0            0            0            0            0
14            1            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTACUN SKDDEPSTADDD SKDDEPSTADEN SKDDEPSTADFW SKDDEPSTADSM
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            1            0            0            0
   SKDDEPSTADTW SKDDEPSTADUB SKDDEPSTAEWR SKDDEPSTAFCO SKDDEPSTAFLL
2             0            0            0            0            0
5             1            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAFRA SKDDEPSTAGCM SKDDEPSTAGDL SKDDEPSTAGEG SKDDEPSTAGIG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAHNL SKDDEPSTAIAH SKDDEPSTAILM SKDDEPSTAIND SKDDEPSTAJAX
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAJFK SKDDEPSTAKOA SKDDEPSTALAS SKDDEPSTALAX SKDDEPSTALGA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTALGB SKDDEPSTALGW SKDDEPSTALHR SKDDEPSTALIH SKDDEPSTAMAD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMAN SKDDEPSTAMBJ SKDDEPSTAMCI SKDDEPSTAMCO SKDDEPSTAMDT
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMEX SKDDEPSTAMHT SKDDEPSTAMIA SKDDEPSTAMKE SKDDEPSTAMSP
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMSY SKDDEPSTAMUC SKDDEPSTAMZT SKDDEPSTANAS SKDDEPSTAOAK
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAOGG SKDDEPSTAOMA SKDDEPSTAONT SKDDEPSTAORD SKDDEPSTAORF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAPBI SKDDEPSTAPDX SKDDEPSTAPIT SKDDEPSTAPLS SKDDEPSTAPPP
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            1
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAPUJ SKDDEPSTAPVD SKDDEPSTAPVR SKDDEPSTAPWM SKDDEPSTARDU
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTARIC SKDDEPSTARNO SKDDEPSTAROC SKDDEPSTARSW SKDDEPSTASAN
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASAT SKDDEPSTASEA SKDDEPSTASFO SKDDEPSTASJC SKDDEPSTASJD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASJO SKDDEPSTASJU SKDDEPSTASLC SKDDEPSTASMF SKDDEPSTASNA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASRQ SKDDEPSTASTL SKDDEPSTASTT SKDDEPSTASXM SKDDEPSTASYR
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTATLV SKDDEPSTATPA SKDDEPSTAXHP SKDDEPSTAYEG SKDDEPSTAYVR
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAYYC SKDDEPSTAZRH SKDARRSTAALB SKDARRSTAAMS SKDARRSTAANC
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAATT SKDARRSTAAUA SKDARRSTAAUS SKDARRSTABDA SKDARRSTABDL
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTABNA SKDARRSTABOI SKDARRSTABOS SKDARRSTABRU SKDARRSTABUF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            1            0            0
17            0            0            0            0            0
   SKDARRSTABWI SKDARRSTACCC SKDARRSTACDG SKDARRSTACHS SKDARRSTACLE
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            1            0            0            0
   SKDARRSTACMH SKDARRSTACUN SKDARRSTADDD SKDARRSTADEN SKDARRSTADFW
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTADSM SKDARRSTADTW SKDARRSTADUB SKDARRSTAEWR SKDARRSTAFCO
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAFLL SKDARRSTAFRA SKDARRSTAGCM SKDARRSTAGDL SKDARRSTAGEG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAGIG SKDARRSTAHNL SKDARRSTAIAH SKDARRSTAILM SKDARRSTAIND
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAJAX SKDARRSTAJFK SKDARRSTAKOA SKDARRSTALAS SKDARRSTALAX
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTALGA SKDARRSTALGB SKDARRSTALGW SKDARRSTALHR SKDARRSTALIH
2             0            0            0            0            0
5             0            0            0            0            0
7             1            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMAD SKDARRSTAMAN SKDARRSTAMBJ SKDARRSTAMCI SKDARRSTAMCO
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMDT SKDARRSTAMEX SKDARRSTAMHT SKDARRSTAMIA SKDARRSTAMKE
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMSP SKDARRSTAMSY SKDARRSTAMUC SKDARRSTAMZT SKDARRSTANAS
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAOAK SKDARRSTAOGG SKDARRSTAOMA SKDARRSTAONT SKDARRSTAORD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            1
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAORF SKDARRSTAPBI SKDARRSTAPDX SKDARRSTAPIT SKDARRSTAPLS
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAPPP SKDARRSTAPUJ SKDARRSTAPVD SKDARRSTAPVR SKDARRSTAPWM
2             1            0            0            0            0
5             1            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTARDU SKDARRSTARIC SKDARRSTARNO SKDARRSTAROC SKDARRSTARSW
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASAN SKDARRSTASAT SKDARRSTASEA SKDARRSTASFO SKDARRSTASJC
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASJD SKDARRSTASJO SKDARRSTASJU SKDARRSTASLC SKDARRSTASMF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASNA SKDARRSTASRQ SKDARRSTASTL SKDARRSTASTT SKDARRSTASXM
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASYR SKDARRSTATLV SKDARRSTATPA SKDARRSTAXHP SKDARRSTAYEG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAYVR SKDARRSTAYYC SKDARRSTAZRH SKDEQP319 SKDEQP320 SKDEQP321
2             0            0            0         0         0         0
5             0            0            0         0         0         0
7             0            0            0         0         0         1
13            0            0            0         0         0         0
14            0            0            0         0         0         1
17            0            0            0         0         0         0
   SKDEQP332 SKDEQP333 SKDEQP734 SKDEQP75E SKDEQP75H SKDEQP767 SKDEQPA01
2          0         0         1         0         0         0         0
5          0         0         0         0         0         0         0
7          0         0         0         0         0         0         0
13         0         0         1         0         0         0         0
14         0         0         0         0         0         0         0
17         0         0         0         0         0         0         0
   SKDEQPA05 SKDEQPA19 SKDEQPA21 SKDEQPE90 SKDEPS       D00    AVGSQ AVGLOFATC
2          0         0         0         0     32 0.2500000 3.258065  3.258065
5          0         0         0         1     72 0.2916667 2.986111  3.805556
7          0         0         0         0     88 0.3295455 2.551724  3.701149
13         0         0         0         0     32 0.3750000 3.000000  3.903226
14         0         0         0         0     72 0.3750000 3.295775  3.859155
17         0         0         0         0     84 0.3809524 3.939759  3.361446
   UPLINEATCIMPLow UPLINEATCIMPMed UPLINEATCIMPMedHigh UPLINEATCIMPMedLow
2                0               1                   0                  0
5                0               0                   0                  0
7                0               0                   0                  1
13               0               1                   0                  0
14               0               0                   0                  1
17               1               0                   0                  0
   DEPSTAATCIMPLow DOWNLINEATCIMPLow AVGSKDAVAIL AVAILBUCKETA05 AVAILBUCKETA10
2                0                 0   10.903226              0              1
5                1                 0    2.000000              0              0
7                0                 0    9.647059              1              0
13               0                 0   17.354839              0              0
14               0                 0   17.057143              0              0
17               0                 0   10.621951              0              1
   AVAILBUCKETA15 AVAILBUCKETA20 AVAILBUCKETA25 AVAILBUCKETA30 AVAILBUCKETA<0
2               0              0              0              0              0
5               0              0              0              0              0
7               0              0              0              0              0
13              1              0              0              0              0
14              1              0              0              0              0
17              0              0              0              0              0
   DEPBUCKETD2 DEPBUCKETD3 DEPBUCKETD4 DEPBUCKETD5 DEPBUCKETD6 DEPBUCKETD7
2            0           0           0           1           0           0
5            0           0           1           0           0           0
7            0           0           0           1           0           0
13           0           0           0           1           0           0
14           0           0           0           0           1           0
17           0           0           0           0           1           0
   DEPBUCKETD8 ARRBUCKETA2 ARRBUCKETA3 ARRBUCKETA4 ARRBUCKETA5 ARRBUCKETA6
2            0           0           0           0           0           1
5            0           0           0           0           1           0
7            0           0           0           0           0           1
13           0           0           0           0           0           1
14           0           0           0           0           0           0
17           0           0           0           0           0           1
   ARRBUCKETA7 ARRBUCKETA8 DEPRANKGRPLow DEPRANKGRPMed DEPRANKGRPMedHigh
2            0           0             1             0                 0
5            0           0             0             1                 0
7            0           0             1             0                 0
13           0           0             0             0                 0
14           1           0             1             0                 0
17           0           0             0             0                 0
   DEPRANKGRPMedLow TRNRANKGRPLow TRNRANKGRPMed TRNRANKGRPMedHigh
2                 0             1             0                 0
5                 0             1             0                 0
7                 0             1             0                 0
13                1             0             0                 0
14                0             1             0                 0
17                1             0             1                 0
   TRNRANKGRPMedLow ARRRANKGRPLow ARRRANKGRPMed ARRRANKGRPMedHigh
2                 0             0             0                 1
5                 0             0             0                 1
7                 0             0             1                 0
13                1             0             0                 0
14                0             0             0                 1
17                0             0             0                 1
   ARRRANKGRPMedLow DEPSPOKETRUE ARRSPOKETRUE xHNGRTRUE xDURN2
2                 0            0            0         0      2
5                 0            1            0         0      2
7                 0            0            1         0      2
13                1            0            1         0      2
14                0            0            1         0      2
17                0            0            0         0      2
> 
> dummies <- dummyVars(LEGTYPE ~ ., data = flight)
> flight.dum <- predict(dummies, newdata = flight)
> 
> ## It may be too big to use, but useful for inspection.
> 
> ### Numeric variables
> 
> ## Check some more numeric correlations, I haven't scaled yet.
> ## I'd cut correlations above 0.75 because of overfitting.
> 
> x1 <- as.data.frame(as.matrix(sapply(flight, class)))
> 
> flight.num <- flight[,names(x1[which(x1$V1 %in% c("numeric", "integer")),])]
> 
> flight.nzv <- nearZeroVar(flight.num, saveMetrics = TRUE)
> flight.nzv
            freqRatio percentUnique zeroVar   nzv
SDEPHR       1.038462        5.9375   FALSE FALSE
SKDEPS       1.000000       19.0625   FALSE FALSE
D00          1.166667       75.3125   FALSE FALSE
AVGSQ        6.333333       82.8125   FALSE FALSE
AVGLOFATC    1.000000       78.4375   FALSE FALSE
AVGSKDAVAIL  1.000000       87.5000   FALSE FALSE
xDURN2       1.428571        2.5000   FALSE FALSE
> 
> # annoying NA
> flight.cor <- cor(flight.num, use = "pairwise.complete.obs")
> 
> descrCorr <- findCorrelation(flight.cor, cutoff = .65, verbose=TRUE)
Considering row	 1 column	 4 value	 0.956 
  Flagging column	 1 
Considering row	 4 column	 3 value	 0.414 
Considering row	 4 column	 6 value	 0.173 
Considering row	 4 column	 7 value	 0.201 
Considering row	 4 column	 5 value	 0.103 
Considering row	 4 column	 2 value	 0.082 
Considering row	 3 column	 6 value	 0.266 
Considering row	 3 column	 7 value	 0.071 
Considering row	 3 column	 5 value	 0.114 
Considering row	 3 column	 2 value	 0.006 
Considering row	 6 column	 7 value	 0.031 
Considering row	 6 column	 5 value	 0.094 
Considering row	 6 column	 2 value	 0.067 
Considering row	 7 column	 5 value	 0.137 
Considering row	 7 column	 2 value	 0.005 
Considering row	 5 column	 2 value	 0.041 
> 
> colnames(flight.num)[descrCorr]
[1] "SDEPHR"
> 
> ## Which tells me that departure time is very highly correlated to AVGSQ.
> ## AVGSQ is average stand queue?
> 
> ### Try and impute the AVG, it might have more information than the
> ### bucket.
> 
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))
> 
> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1
> 
> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]
> 
> preProcValues <- preProcess(flight.na, method = c("knnImpute"))
> flight.na1 <- predict(preProcValues, flight.na)
> 
> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL
> 
> ## And I'll leave the centered and scale values in for now.
> ## and delete the troublesome ones
> 
> flight$AVGSKDAVAIL <- NULL
> flight$xHNGR <- NULL
> flight$AVAILBUCKET <- NULL
> 
> # This should be deleted, leave it in and the results are ideal because it defines LEGTYPE.
> flight$D00 <- NULL
> 
> ## Keep the results but don't change the order.
> outcomes.flight <- flight$LEGTYPE
> 
> flight$LEGTYPE <- NULL
> 
> ## If you know your factors are definitely factors, you don't need this
> ##  asNumeric <- function(x) as.numeric(as.character(x))
> 
> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))
> 
> flight.num0 <- factors.numeric(flight)
> 
> flight.scl0 <- scale(flight.num0)
> 
> ## Now split the results
> ## we need 80 or so to test with.
> 
> set.seed(seed.mine)
> inTrain <- createDataPartition(outcomes.flight, p = 0.77, list = FALSE)
> 
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> 
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> 
> prop.table(table(trainClass))
trainClass
   Strong      Weak 
0.3481781 0.6518219 
> dim(trainDescr)
[1] 247  20
> 
> prop.table(table(testClass))
testClass
   Strong      Weak 
0.3424658 0.6575342 
> dim(testDescr)
[1] 73 20
> seed.mine = 107
> set.seed(seed.mine)                     # helpful for testing
> 
> flight <- read.csv("../bak/flight.csv")
> flight <- flight[order(flight$D00),]
> 
> # Backup
> flight.raw <- flight
> 
> # To check adjustment, there is test code in flight-nb.R
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"
> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"
> 
> # And some deletions
> 
> t.cols <- colnames(flight)
> 
> t.drops <- t.cols[grep("^RANK*", t.cols)]
> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])
> t.drops <- c(t.drops, "D80THPCTL")
> 
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR
> flight$xHNGR <- flight$xDURN < 0
> 
> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+ }
> 
> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))
> 
> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE
> t.cols <- colnames(flight)
> 
> t.drops <- c("SARRHR", "xDURN")
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Backup
> 
> flight00 <- flight
> 
> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]
> 
> paste("samples in use: ", dim(flight)[1])
[1] "samples in use:  320"
> 
> ## Check warnings to see what happened.
> src.adjust <- TRUE
> source(file = "flight1.R")
Warning message:
In eval(expr, envir, enclos) : adjusting
> 
> ## Take another copy - this is all we need as the training/prediction
> ## set.
> 
> flight1 <- flight
> 
> ## Data insights
> 
> ## *Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> flight <- flight1
> 
> ## So something is defining the behaviour.
> 
> ## Try to simplify structure
> 
> head(model.matrix(LEGTYPE ~ ., data = flight))
   (Intercept) SDEPHR SKDDEPSTAALB SKDDEPSTAAMS SKDDEPSTAANC SKDDEPSTAATT
2            1     14            0            0            0            0
5            1     11            0            0            0            0
7            1     14            0            0            0            0
13           1     13            0            0            0            0
14           1     16            0            0            0            0
17           1     15            0            0            0            0
   SKDDEPSTAAUA SKDDEPSTAAUS SKDDEPSTABDA SKDDEPSTABDL SKDDEPSTABNA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTABOI SKDDEPSTABOS SKDDEPSTABRU SKDDEPSTABUF SKDDEPSTABWI
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTACCC SKDDEPSTACDG SKDDEPSTACHS SKDDEPSTACLE SKDDEPSTACMH
2             1            0            0            0            0
5             0            0            0            0            0
7             1            0            0            0            0
13            0            0            0            0            0
14            1            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTACUN SKDDEPSTADDD SKDDEPSTADEN SKDDEPSTADFW SKDDEPSTADSM
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            1            0            0            0
   SKDDEPSTADTW SKDDEPSTADUB SKDDEPSTAEWR SKDDEPSTAFCO SKDDEPSTAFLL
2             0            0            0            0            0
5             1            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAFRA SKDDEPSTAGCM SKDDEPSTAGDL SKDDEPSTAGEG SKDDEPSTAGIG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAHNL SKDDEPSTAIAH SKDDEPSTAILM SKDDEPSTAIND SKDDEPSTAJAX
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAJFK SKDDEPSTAKOA SKDDEPSTALAS SKDDEPSTALAX SKDDEPSTALGA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTALGB SKDDEPSTALGW SKDDEPSTALHR SKDDEPSTALIH SKDDEPSTAMAD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMAN SKDDEPSTAMBJ SKDDEPSTAMCI SKDDEPSTAMCO SKDDEPSTAMDT
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMEX SKDDEPSTAMHT SKDDEPSTAMIA SKDDEPSTAMKE SKDDEPSTAMSP
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMSY SKDDEPSTAMUC SKDDEPSTAMZT SKDDEPSTANAS SKDDEPSTAOAK
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAOGG SKDDEPSTAOMA SKDDEPSTAONT SKDDEPSTAORD SKDDEPSTAORF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAPBI SKDDEPSTAPDX SKDDEPSTAPIT SKDDEPSTAPLS SKDDEPSTAPPP
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            1
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAPUJ SKDDEPSTAPVD SKDDEPSTAPVR SKDDEPSTAPWM SKDDEPSTARDU
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTARIC SKDDEPSTARNO SKDDEPSTAROC SKDDEPSTARSW SKDDEPSTASAN
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASAT SKDDEPSTASEA SKDDEPSTASFO SKDDEPSTASJC SKDDEPSTASJD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASJO SKDDEPSTASJU SKDDEPSTASLC SKDDEPSTASMF SKDDEPSTASNA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASRQ SKDDEPSTASTL SKDDEPSTASTT SKDDEPSTASXM SKDDEPSTASYR
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTATLV SKDDEPSTATPA SKDDEPSTAXHP SKDDEPSTAYEG SKDDEPSTAYVR
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAYYC SKDDEPSTAZRH SKDARRSTAALB SKDARRSTAAMS SKDARRSTAANC
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAATT SKDARRSTAAUA SKDARRSTAAUS SKDARRSTABDA SKDARRSTABDL
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTABNA SKDARRSTABOI SKDARRSTABOS SKDARRSTABRU SKDARRSTABUF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            1            0            0
17            0            0            0            0            0
   SKDARRSTABWI SKDARRSTACCC SKDARRSTACDG SKDARRSTACHS SKDARRSTACLE
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            1            0            0            0
   SKDARRSTACMH SKDARRSTACUN SKDARRSTADDD SKDARRSTADEN SKDARRSTADFW
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTADSM SKDARRSTADTW SKDARRSTADUB SKDARRSTAEWR SKDARRSTAFCO
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAFLL SKDARRSTAFRA SKDARRSTAGCM SKDARRSTAGDL SKDARRSTAGEG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAGIG SKDARRSTAHNL SKDARRSTAIAH SKDARRSTAILM SKDARRSTAIND
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAJAX SKDARRSTAJFK SKDARRSTAKOA SKDARRSTALAS SKDARRSTALAX
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTALGA SKDARRSTALGB SKDARRSTALGW SKDARRSTALHR SKDARRSTALIH
2             0            0            0            0            0
5             0            0            0            0            0
7             1            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMAD SKDARRSTAMAN SKDARRSTAMBJ SKDARRSTAMCI SKDARRSTAMCO
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMDT SKDARRSTAMEX SKDARRSTAMHT SKDARRSTAMIA SKDARRSTAMKE
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMSP SKDARRSTAMSY SKDARRSTAMUC SKDARRSTAMZT SKDARRSTANAS
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAOAK SKDARRSTAOGG SKDARRSTAOMA SKDARRSTAONT SKDARRSTAORD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            1
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAORF SKDARRSTAPBI SKDARRSTAPDX SKDARRSTAPIT SKDARRSTAPLS
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAPPP SKDARRSTAPUJ SKDARRSTAPVD SKDARRSTAPVR SKDARRSTAPWM
2             1            0            0            0            0
5             1            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTARDU SKDARRSTARIC SKDARRSTARNO SKDARRSTAROC SKDARRSTARSW
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASAN SKDARRSTASAT SKDARRSTASEA SKDARRSTASFO SKDARRSTASJC
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASJD SKDARRSTASJO SKDARRSTASJU SKDARRSTASLC SKDARRSTASMF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASNA SKDARRSTASRQ SKDARRSTASTL SKDARRSTASTT SKDARRSTASXM
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASYR SKDARRSTATLV SKDARRSTATPA SKDARRSTAXHP SKDARRSTAYEG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAYVR SKDARRSTAYYC SKDARRSTAZRH SKDEQP319 SKDEQP320 SKDEQP321
2             0            0            0         0         0         0
5             0            0            0         0         0         0
7             0            0            0         0         0         1
13            0            0            0         0         0         0
14            0            0            0         0         0         1
17            0            0            0         0         0         0
   SKDEQP332 SKDEQP333 SKDEQP734 SKDEQP75E SKDEQP75H SKDEQP767 SKDEQPA01
2          0         0         1         0         0         0         0
5          0         0         0         0         0         0         0
7          0         0         0         0         0         0         0
13         0         0         1         0         0         0         0
14         0         0         0         0         0         0         0
17         0         0         0         0         0         0         0
   SKDEQPA05 SKDEQPA19 SKDEQPA21 SKDEQPE90 SKDEPS       D00    AVGSQ AVGLOFATC
2          0         0         0         0     32 0.2500000 3.258065  3.258065
5          0         0         0         1     72 0.2916667 2.986111  3.805556
7          0         0         0         0     88 0.3295455 2.551724  3.701149
13         0         0         0         0     32 0.3750000 3.000000  3.903226
14         0         0         0         0     72 0.3750000 3.295775  3.859155
17         0         0         0         0     84 0.3809524 3.939759  3.361446
   UPLINEATCIMPLow UPLINEATCIMPMed UPLINEATCIMPMedHigh UPLINEATCIMPMedLow
2                0               1                   0                  0
5                0               0                   0                  0
7                0               0                   0                  1
13               0               1                   0                  0
14               0               0                   0                  1
17               1               0                   0                  0
   DEPSTAATCIMPLow DOWNLINEATCIMPLow AVGSKDAVAIL AVAILBUCKETA05 AVAILBUCKETA10
2                0                 0   10.903226              0              1
5                1                 0    2.000000              0              0
7                0                 0    9.647059              1              0
13               0                 0   17.354839              0              0
14               0                 0   17.057143              0              0
17               0                 0   10.621951              0              1
   AVAILBUCKETA15 AVAILBUCKETA20 AVAILBUCKETA25 AVAILBUCKETA30 AVAILBUCKETA<0
2               0              0              0              0              0
5               0              0              0              0              0
7               0              0              0              0              0
13              1              0              0              0              0
14              1              0              0              0              0
17              0              0              0              0              0
   DEPBUCKETD2 DEPBUCKETD3 DEPBUCKETD4 DEPBUCKETD5 DEPBUCKETD6 DEPBUCKETD7
2            0           0           0           1           0           0
5            0           0           1           0           0           0
7            0           0           0           1           0           0
13           0           0           0           1           0           0
14           0           0           0           0           1           0
17           0           0           0           0           1           0
   DEPBUCKETD8 ARRBUCKETA2 ARRBUCKETA3 ARRBUCKETA4 ARRBUCKETA5 ARRBUCKETA6
2            0           0           0           0           0           1
5            0           0           0           0           1           0
7            0           0           0           0           0           1
13           0           0           0           0           0           1
14           0           0           0           0           0           0
17           0           0           0           0           0           1
   ARRBUCKETA7 ARRBUCKETA8 DEPRANKGRPLow DEPRANKGRPMed DEPRANKGRPMedHigh
2            0           0             1             0                 0
5            0           0             0             1                 0
7            0           0             1             0                 0
13           0           0             0             0                 0
14           1           0             1             0                 0
17           0           0             0             0                 0
   DEPRANKGRPMedLow TRNRANKGRPLow TRNRANKGRPMed TRNRANKGRPMedHigh
2                 0             1             0                 0
5                 0             1             0                 0
7                 0             1             0                 0
13                1             0             0                 0
14                0             1             0                 0
17                1             0             1                 0
   TRNRANKGRPMedLow ARRRANKGRPLow ARRRANKGRPMed ARRRANKGRPMedHigh
2                 0             0             0                 1
5                 0             0             0                 1
7                 0             0             1                 0
13                1             0             0                 0
14                0             0             0                 1
17                0             0             0                 1
   ARRRANKGRPMedLow DEPSPOKETRUE ARRSPOKETRUE xHNGRTRUE xDURN2
2                 0            0            0         0      2
5                 0            1            0         0      2
7                 0            0            1         0      2
13                1            0            1         0      2
14                0            0            1         0      2
17                0            0            0         0      2
> 
> dummies <- dummyVars(LEGTYPE ~ ., data = flight)
> flight.dum <- predict(dummies, newdata = flight)
> 
> ## It may be too big to use, but useful for inspection.
> 
> ### Numeric variables
> 
> ## Check some more numeric correlations, I haven't scaled yet.
> ## I'd cut correlations above 0.75 because of overfitting.
> 
> x1 <- as.data.frame(as.matrix(sapply(flight, class)))
> 
> flight.num <- flight[,names(x1[which(x1$V1 %in% c("numeric", "integer")),])]
> 
> flight.nzv <- nearZeroVar(flight.num, saveMetrics = TRUE)
> flight.nzv
            freqRatio percentUnique zeroVar   nzv
SDEPHR       1.038462        5.9375   FALSE FALSE
SKDEPS       1.000000       19.0625   FALSE FALSE
D00          1.166667       75.3125   FALSE FALSE
AVGSQ        6.333333       82.8125   FALSE FALSE
AVGLOFATC    1.000000       78.4375   FALSE FALSE
AVGSKDAVAIL  1.000000       87.5000   FALSE FALSE
xDURN2       1.428571        2.5000   FALSE FALSE
> 
> # annoying NA
> flight.cor <- cor(flight.num, use = "pairwise.complete.obs")
> 
> descrCorr <- findCorrelation(flight.cor, cutoff = .65, verbose=TRUE)
Considering row	 1 column	 4 value	 0.956 
  Flagging column	 1 
Considering row	 4 column	 3 value	 0.414 
Considering row	 4 column	 6 value	 0.173 
Considering row	 4 column	 7 value	 0.201 
Considering row	 4 column	 5 value	 0.103 
Considering row	 4 column	 2 value	 0.082 
Considering row	 3 column	 6 value	 0.266 
Considering row	 3 column	 7 value	 0.071 
Considering row	 3 column	 5 value	 0.114 
Considering row	 3 column	 2 value	 0.006 
Considering row	 6 column	 7 value	 0.031 
Considering row	 6 column	 5 value	 0.094 
Considering row	 6 column	 2 value	 0.067 
Considering row	 7 column	 5 value	 0.137 
Considering row	 7 column	 2 value	 0.005 
Considering row	 5 column	 2 value	 0.041 
> 
> colnames(flight.num)[descrCorr]
[1] "SDEPHR"
> 
> ## Which tells me that departure time is very highly correlated to AVGSQ.
> ## AVGSQ is average stand queue?
> 
> ### Try and impute the AVG, it might have more information than the
> ### bucket.
> 
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))
> 
> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1
> 
> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]
> 
> preProcValues <- preProcess(flight.na, method = c("knnImpute"))
> flight.na1 <- predict(preProcValues, flight.na)
> 
> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL
> 
> ## And I'll leave the centered and scale values in for now.
> ## and delete the troublesome ones
> 
> flight$AVGSKDAVAIL <- NULL
> flight$xHNGR <- NULL
> flight$AVAILBUCKET <- NULL
> 
> # This should be deleted, leave it in and the results are ideal because it defines LEGTYPE.
> flight$D00 <- NULL
> 
> ## Keep the results but don't change the order.
> outcomes.flight <- flight$LEGTYPE
> 
> flight$LEGTYPE <- NULL
> 
> ## If you know your factors are definitely factors, you don't need this
> ##  asNumeric <- function(x) as.numeric(as.character(x))
> 
> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))
> 
> flight.num0 <- factors.numeric(flight)
> 
> flight.scl0 <- scale(flight.num0)
> 
> ## Now split the results
> ## we need 80 or so to test with.
> 
> set.seed(seed.mine)
> inTrain <- createDataPartition(outcomes.flight, p = 0.77, list = FALSE)
> 
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> 
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> 
> prop.table(table(trainClass))
trainClass
   Strong      Weak 
0.4475806 0.5524194 
> dim(trainDescr)
[1] 248  20
> 
> prop.table(table(testClass))
testClass
   Strong      Weak 
0.4444444 0.5555556 
> dim(testDescr)
[1] 72 20
> seed.mine = 107
> set.seed(seed.mine)                     # helpful for testing
> 
> flight <- read.csv("../bak/flight.csv")
> flight <- flight[order(flight$D00),]
> 
> # Backup
> flight.raw <- flight
> 
> # To check adjustment, there is test code in flight-nb.R
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"
> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"
> 
> # And some deletions
> 
> t.cols <- colnames(flight)
> 
> t.drops <- t.cols[grep("^RANK*", t.cols)]
> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])
> t.drops <- c(t.drops, "D80THPCTL")
> 
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR
> flight$xHNGR <- flight$xDURN < 0
> 
> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+ }
> 
> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))
> 
> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE
> t.cols <- colnames(flight)
> 
> t.drops <- c("SARRHR", "xDURN")
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Backup
> 
> flight00 <- flight
> 
> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]
> 
> paste("samples in use: ", dim(flight)[1])
[1] "samples in use:  320"
> 
> ## Check warnings to see what happened.
> src.adjust <- TRUE
> source(file = "flight1.R")
Warning message:
In eval(expr, envir, enclos) : adjusting
> 
> ## Take another copy - this is all we need as the training/prediction
> ## set.
> 
> flight1 <- flight
> 
> ## Data insights
> 
> ## *Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> flight <- flight1
> 
> ## So something is defining the behaviour.
> 
> ## Try to simplify structure
> 
> head(model.matrix(LEGTYPE ~ ., data = flight))
   (Intercept) SDEPHR SKDDEPSTAALB SKDDEPSTAAMS SKDDEPSTAANC SKDDEPSTAATT
2            1     14            0            0            0            0
5            1     11            0            0            0            0
7            1     14            0            0            0            0
13           1     13            0            0            0            0
14           1     16            0            0            0            0
17           1     15            0            0            0            0
   SKDDEPSTAAUA SKDDEPSTAAUS SKDDEPSTABDA SKDDEPSTABDL SKDDEPSTABNA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTABOI SKDDEPSTABOS SKDDEPSTABRU SKDDEPSTABUF SKDDEPSTABWI
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTACCC SKDDEPSTACDG SKDDEPSTACHS SKDDEPSTACLE SKDDEPSTACMH
2             1            0            0            0            0
5             0            0            0            0            0
7             1            0            0            0            0
13            0            0            0            0            0
14            1            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTACUN SKDDEPSTADDD SKDDEPSTADEN SKDDEPSTADFW SKDDEPSTADSM
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            1            0            0            0
   SKDDEPSTADTW SKDDEPSTADUB SKDDEPSTAEWR SKDDEPSTAFCO SKDDEPSTAFLL
2             0            0            0            0            0
5             1            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAFRA SKDDEPSTAGCM SKDDEPSTAGDL SKDDEPSTAGEG SKDDEPSTAGIG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAHNL SKDDEPSTAIAH SKDDEPSTAILM SKDDEPSTAIND SKDDEPSTAJAX
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAJFK SKDDEPSTAKOA SKDDEPSTALAS SKDDEPSTALAX SKDDEPSTALGA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTALGB SKDDEPSTALGW SKDDEPSTALHR SKDDEPSTALIH SKDDEPSTAMAD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMAN SKDDEPSTAMBJ SKDDEPSTAMCI SKDDEPSTAMCO SKDDEPSTAMDT
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMEX SKDDEPSTAMHT SKDDEPSTAMIA SKDDEPSTAMKE SKDDEPSTAMSP
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMSY SKDDEPSTAMUC SKDDEPSTAMZT SKDDEPSTANAS SKDDEPSTAOAK
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAOGG SKDDEPSTAOMA SKDDEPSTAONT SKDDEPSTAORD SKDDEPSTAORF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAPBI SKDDEPSTAPDX SKDDEPSTAPIT SKDDEPSTAPLS SKDDEPSTAPPP
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            1
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAPUJ SKDDEPSTAPVD SKDDEPSTAPVR SKDDEPSTAPWM SKDDEPSTARDU
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTARIC SKDDEPSTARNO SKDDEPSTAROC SKDDEPSTARSW SKDDEPSTASAN
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASAT SKDDEPSTASEA SKDDEPSTASFO SKDDEPSTASJC SKDDEPSTASJD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASJO SKDDEPSTASJU SKDDEPSTASLC SKDDEPSTASMF SKDDEPSTASNA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASRQ SKDDEPSTASTL SKDDEPSTASTT SKDDEPSTASXM SKDDEPSTASYR
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTATLV SKDDEPSTATPA SKDDEPSTAXHP SKDDEPSTAYEG SKDDEPSTAYVR
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAYYC SKDDEPSTAZRH SKDARRSTAALB SKDARRSTAAMS SKDARRSTAANC
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAATT SKDARRSTAAUA SKDARRSTAAUS SKDARRSTABDA SKDARRSTABDL
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTABNA SKDARRSTABOI SKDARRSTABOS SKDARRSTABRU SKDARRSTABUF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            1            0            0
17            0            0            0            0            0
   SKDARRSTABWI SKDARRSTACCC SKDARRSTACDG SKDARRSTACHS SKDARRSTACLE
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            1            0            0            0
   SKDARRSTACMH SKDARRSTACUN SKDARRSTADDD SKDARRSTADEN SKDARRSTADFW
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTADSM SKDARRSTADTW SKDARRSTADUB SKDARRSTAEWR SKDARRSTAFCO
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAFLL SKDARRSTAFRA SKDARRSTAGCM SKDARRSTAGDL SKDARRSTAGEG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAGIG SKDARRSTAHNL SKDARRSTAIAH SKDARRSTAILM SKDARRSTAIND
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAJAX SKDARRSTAJFK SKDARRSTAKOA SKDARRSTALAS SKDARRSTALAX
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTALGA SKDARRSTALGB SKDARRSTALGW SKDARRSTALHR SKDARRSTALIH
2             0            0            0            0            0
5             0            0            0            0            0
7             1            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMAD SKDARRSTAMAN SKDARRSTAMBJ SKDARRSTAMCI SKDARRSTAMCO
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMDT SKDARRSTAMEX SKDARRSTAMHT SKDARRSTAMIA SKDARRSTAMKE
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMSP SKDARRSTAMSY SKDARRSTAMUC SKDARRSTAMZT SKDARRSTANAS
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAOAK SKDARRSTAOGG SKDARRSTAOMA SKDARRSTAONT SKDARRSTAORD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            1
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAORF SKDARRSTAPBI SKDARRSTAPDX SKDARRSTAPIT SKDARRSTAPLS
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAPPP SKDARRSTAPUJ SKDARRSTAPVD SKDARRSTAPVR SKDARRSTAPWM
2             1            0            0            0            0
5             1            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTARDU SKDARRSTARIC SKDARRSTARNO SKDARRSTAROC SKDARRSTARSW
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASAN SKDARRSTASAT SKDARRSTASEA SKDARRSTASFO SKDARRSTASJC
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASJD SKDARRSTASJO SKDARRSTASJU SKDARRSTASLC SKDARRSTASMF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASNA SKDARRSTASRQ SKDARRSTASTL SKDARRSTASTT SKDARRSTASXM
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASYR SKDARRSTATLV SKDARRSTATPA SKDARRSTAXHP SKDARRSTAYEG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAYVR SKDARRSTAYYC SKDARRSTAZRH SKDEQP319 SKDEQP320 SKDEQP321
2             0            0            0         0         0         0
5             0            0            0         0         0         0
7             0            0            0         0         0         1
13            0            0            0         0         0         0
14            0            0            0         0         0         1
17            0            0            0         0         0         0
   SKDEQP332 SKDEQP333 SKDEQP734 SKDEQP75E SKDEQP75H SKDEQP767 SKDEQPA01
2          0         0         1         0         0         0         0
5          0         0         0         0         0         0         0
7          0         0         0         0         0         0         0
13         0         0         1         0         0         0         0
14         0         0         0         0         0         0         0
17         0         0         0         0         0         0         0
   SKDEQPA05 SKDEQPA19 SKDEQPA21 SKDEQPE90 SKDEPS       D00    AVGSQ AVGLOFATC
2          0         0         0         0     32 0.2500000 3.258065  3.258065
5          0         0         0         1     72 0.2916667 2.986111  3.805556
7          0         0         0         0     88 0.3295455 2.551724  3.701149
13         0         0         0         0     32 0.3750000 3.000000  3.903226
14         0         0         0         0     72 0.3750000 3.295775  3.859155
17         0         0         0         0     84 0.3809524 3.939759  3.361446
   UPLINEATCIMPLow UPLINEATCIMPMed UPLINEATCIMPMedHigh UPLINEATCIMPMedLow
2                0               1                   0                  0
5                0               0                   0                  0
7                0               0                   0                  1
13               0               1                   0                  0
14               0               0                   0                  1
17               1               0                   0                  0
   DEPSTAATCIMPLow DOWNLINEATCIMPLow AVGSKDAVAIL AVAILBUCKETA05 AVAILBUCKETA10
2                0                 0   10.903226              0              1
5                1                 0    2.000000              0              0
7                0                 0    9.647059              1              0
13               0                 0   17.354839              0              0
14               0                 0   17.057143              0              0
17               0                 0   10.621951              0              1
   AVAILBUCKETA15 AVAILBUCKETA20 AVAILBUCKETA25 AVAILBUCKETA30 AVAILBUCKETA<0
2               0              0              0              0              0
5               0              0              0              0              0
7               0              0              0              0              0
13              1              0              0              0              0
14              1              0              0              0              0
17              0              0              0              0              0
   DEPBUCKETD2 DEPBUCKETD3 DEPBUCKETD4 DEPBUCKETD5 DEPBUCKETD6 DEPBUCKETD7
2            0           0           0           1           0           0
5            0           0           1           0           0           0
7            0           0           0           1           0           0
13           0           0           0           1           0           0
14           0           0           0           0           1           0
17           0           0           0           0           1           0
   DEPBUCKETD8 ARRBUCKETA2 ARRBUCKETA3 ARRBUCKETA4 ARRBUCKETA5 ARRBUCKETA6
2            0           0           0           0           0           1
5            0           0           0           0           1           0
7            0           0           0           0           0           1
13           0           0           0           0           0           1
14           0           0           0           0           0           0
17           0           0           0           0           0           1
   ARRBUCKETA7 ARRBUCKETA8 DEPRANKGRPLow DEPRANKGRPMed DEPRANKGRPMedHigh
2            0           0             1             0                 0
5            0           0             0             1                 0
7            0           0             1             0                 0
13           0           0             0             0                 0
14           1           0             1             0                 0
17           0           0             0             0                 0
   DEPRANKGRPMedLow TRNRANKGRPLow TRNRANKGRPMed TRNRANKGRPMedHigh
2                 0             1             0                 0
5                 0             1             0                 0
7                 0             1             0                 0
13                1             0             0                 0
14                0             1             0                 0
17                1             0             1                 0
   TRNRANKGRPMedLow ARRRANKGRPLow ARRRANKGRPMed ARRRANKGRPMedHigh
2                 0             0             0                 1
5                 0             0             0                 1
7                 0             0             1                 0
13                1             0             0                 0
14                0             0             0                 1
17                0             0             0                 1
   ARRRANKGRPMedLow DEPSPOKETRUE ARRSPOKETRUE xHNGRTRUE xDURN2
2                 0            0            0         0      2
5                 0            1            0         0      2
7                 0            0            1         0      2
13                1            0            1         0      2
14                0            0            1         0      2
17                0            0            0         0      2
> 
> dummies <- dummyVars(LEGTYPE ~ ., data = flight)
> flight.dum <- predict(dummies, newdata = flight)
> 
> ## It may be too big to use, but useful for inspection.
> 
> ### Numeric variables
> 
> ## Check some more numeric correlations, I haven't scaled yet.
> ## I'd cut correlations above 0.75 because of overfitting.
> 
> x1 <- as.data.frame(as.matrix(sapply(flight, class)))
> 
> flight.num <- flight[,names(x1[which(x1$V1 %in% c("numeric", "integer")),])]
> 
> flight.nzv <- nearZeroVar(flight.num, saveMetrics = TRUE)
> flight.nzv
            freqRatio percentUnique zeroVar   nzv
SDEPHR       1.038462        5.9375   FALSE FALSE
SKDEPS       1.000000       19.0625   FALSE FALSE
D00          1.166667       75.3125   FALSE FALSE
AVGSQ        6.333333       82.8125   FALSE FALSE
AVGLOFATC    1.000000       78.4375   FALSE FALSE
AVGSKDAVAIL  1.000000       87.5000   FALSE FALSE
xDURN2       1.428571        2.5000   FALSE FALSE
> 
> # annoying NA
> flight.cor <- cor(flight.num, use = "pairwise.complete.obs")
> 
> descrCorr <- findCorrelation(flight.cor, cutoff = .65, verbose=TRUE)
Considering row	 1 column	 4 value	 0.956 
  Flagging column	 1 
Considering row	 4 column	 3 value	 0.414 
Considering row	 4 column	 6 value	 0.173 
Considering row	 4 column	 7 value	 0.201 
Considering row	 4 column	 5 value	 0.103 
Considering row	 4 column	 2 value	 0.082 
Considering row	 3 column	 6 value	 0.266 
Considering row	 3 column	 7 value	 0.071 
Considering row	 3 column	 5 value	 0.114 
Considering row	 3 column	 2 value	 0.006 
Considering row	 6 column	 7 value	 0.031 
Considering row	 6 column	 5 value	 0.094 
Considering row	 6 column	 2 value	 0.067 
Considering row	 7 column	 5 value	 0.137 
Considering row	 7 column	 2 value	 0.005 
Considering row	 5 column	 2 value	 0.041 
> 
> colnames(flight.num)[descrCorr]
[1] "SDEPHR"
> 
> ## Which tells me that departure time is very highly correlated to AVGSQ.
> ## AVGSQ is average stand queue?
> 
> ### Try and impute the AVG, it might have more information than the
> ### bucket.
> 
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))
> 
> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1
> 
> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]
> 
> preProcValues <- preProcess(flight.na, method = c("knnImpute"))
> flight.na1 <- predict(preProcValues, flight.na)
> 
> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL
> 
> ## And I'll leave the centered and scale values in for now.
> ## and delete the troublesome ones
> 
> flight$AVGSKDAVAIL <- NULL
> flight$xHNGR <- NULL
> flight$AVAILBUCKET <- NULL
> 
> # This should be deleted, leave it in and the results are ideal because it defines LEGTYPE.
> flight$D00 <- NULL
> 
> ## Keep the results but don't change the order.
> outcomes.flight <- flight$LEGTYPE
> 
> flight$LEGTYPE <- NULL
> 
> ## If you know your factors are definitely factors, you don't need this
> ##  asNumeric <- function(x) as.numeric(as.character(x))
> 
> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))
> 
> flight.num0 <- factors.numeric(flight)
> 
> flight.scl0 <- scale(flight.num0)
> 
> ## Now split the results
> ## we need 80 or so to test with.
> 
> set.seed(seed.mine)
> inTrain <- createDataPartition(outcomes.flight, p = 0.77, list = FALSE)
> 
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> 
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> 
> prop.table(table(trainClass))
trainClass
   Strong      Weak 
0.3481781 0.6518219 
> dim(trainDescr)
[1] 247  20
> 
> prop.table(table(testClass))
testClass
   Strong      Weak 
0.3424658 0.6575342 
> dim(testDescr)
[1] 73 20
> seed.mine = 107
> set.seed(seed.mine)                     # helpful for testing
> 
> flight <- read.csv("../bak/flight.csv")
> flight <- flight[order(flight$D00),]
> 
> # Backup
> flight.raw <- flight
> 
> # To check adjustment, there is test code in flight-nb.R
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"
> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"
> 
> # And some deletions
> 
> t.cols <- colnames(flight)
> 
> t.drops <- t.cols[grep("^RANK*", t.cols)]
> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])
> t.drops <- c(t.drops, "D80THPCTL")
> 
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR
> flight$xHNGR <- flight$xDURN < 0
> 
> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+ }
> 
> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))
> 
> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE
> t.cols <- colnames(flight)
> 
> t.drops <- c("SARRHR", "xDURN")
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Backup
> 
> flight00 <- flight
> 
> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]
> 
> paste("samples in use: ", dim(flight)[1])
[1] "samples in use:  320"
> 
> ## Check warnings to see what happened.
> src.adjust <- TRUE
> source(file = "flight1.R")
Warning message:
In eval(expr, envir, enclos) : adjusting
> 
> ## Take another copy - this is all we need as the training/prediction
> ## set.
> 
> flight1 <- flight
> 
> ## Data insights
> 
> ## *Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> flight <- flight1
> 
> ## So something is defining the behaviour.
> 
> ## Try to simplify structure
> 
> head(model.matrix(LEGTYPE ~ ., data = flight))
   (Intercept) SDEPHR SKDDEPSTAALB SKDDEPSTAAMS SKDDEPSTAANC SKDDEPSTAATT
2            1     14            0            0            0            0
5            1     11            0            0            0            0
7            1     14            0            0            0            0
13           1     13            0            0            0            0
14           1     16            0            0            0            0
17           1     15            0            0            0            0
   SKDDEPSTAAUA SKDDEPSTAAUS SKDDEPSTABDA SKDDEPSTABDL SKDDEPSTABNA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTABOI SKDDEPSTABOS SKDDEPSTABRU SKDDEPSTABUF SKDDEPSTABWI
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTACCC SKDDEPSTACDG SKDDEPSTACHS SKDDEPSTACLE SKDDEPSTACMH
2             1            0            0            0            0
5             0            0            0            0            0
7             1            0            0            0            0
13            0            0            0            0            0
14            1            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTACUN SKDDEPSTADDD SKDDEPSTADEN SKDDEPSTADFW SKDDEPSTADSM
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            1            0            0            0
   SKDDEPSTADTW SKDDEPSTADUB SKDDEPSTAEWR SKDDEPSTAFCO SKDDEPSTAFLL
2             0            0            0            0            0
5             1            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAFRA SKDDEPSTAGCM SKDDEPSTAGDL SKDDEPSTAGEG SKDDEPSTAGIG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAHNL SKDDEPSTAIAH SKDDEPSTAILM SKDDEPSTAIND SKDDEPSTAJAX
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAJFK SKDDEPSTAKOA SKDDEPSTALAS SKDDEPSTALAX SKDDEPSTALGA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTALGB SKDDEPSTALGW SKDDEPSTALHR SKDDEPSTALIH SKDDEPSTAMAD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMAN SKDDEPSTAMBJ SKDDEPSTAMCI SKDDEPSTAMCO SKDDEPSTAMDT
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMEX SKDDEPSTAMHT SKDDEPSTAMIA SKDDEPSTAMKE SKDDEPSTAMSP
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAMSY SKDDEPSTAMUC SKDDEPSTAMZT SKDDEPSTANAS SKDDEPSTAOAK
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAOGG SKDDEPSTAOMA SKDDEPSTAONT SKDDEPSTAORD SKDDEPSTAORF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAPBI SKDDEPSTAPDX SKDDEPSTAPIT SKDDEPSTAPLS SKDDEPSTAPPP
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            1
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAPUJ SKDDEPSTAPVD SKDDEPSTAPVR SKDDEPSTAPWM SKDDEPSTARDU
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTARIC SKDDEPSTARNO SKDDEPSTAROC SKDDEPSTARSW SKDDEPSTASAN
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASAT SKDDEPSTASEA SKDDEPSTASFO SKDDEPSTASJC SKDDEPSTASJD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASJO SKDDEPSTASJU SKDDEPSTASLC SKDDEPSTASMF SKDDEPSTASNA
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTASRQ SKDDEPSTASTL SKDDEPSTASTT SKDDEPSTASXM SKDDEPSTASYR
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTATLV SKDDEPSTATPA SKDDEPSTAXHP SKDDEPSTAYEG SKDDEPSTAYVR
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDDEPSTAYYC SKDDEPSTAZRH SKDARRSTAALB SKDARRSTAAMS SKDARRSTAANC
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAATT SKDARRSTAAUA SKDARRSTAAUS SKDARRSTABDA SKDARRSTABDL
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTABNA SKDARRSTABOI SKDARRSTABOS SKDARRSTABRU SKDARRSTABUF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            1            0            0
17            0            0            0            0            0
   SKDARRSTABWI SKDARRSTACCC SKDARRSTACDG SKDARRSTACHS SKDARRSTACLE
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            1            0            0            0
   SKDARRSTACMH SKDARRSTACUN SKDARRSTADDD SKDARRSTADEN SKDARRSTADFW
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTADSM SKDARRSTADTW SKDARRSTADUB SKDARRSTAEWR SKDARRSTAFCO
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAFLL SKDARRSTAFRA SKDARRSTAGCM SKDARRSTAGDL SKDARRSTAGEG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAGIG SKDARRSTAHNL SKDARRSTAIAH SKDARRSTAILM SKDARRSTAIND
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAJAX SKDARRSTAJFK SKDARRSTAKOA SKDARRSTALAS SKDARRSTALAX
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTALGA SKDARRSTALGB SKDARRSTALGW SKDARRSTALHR SKDARRSTALIH
2             0            0            0            0            0
5             0            0            0            0            0
7             1            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMAD SKDARRSTAMAN SKDARRSTAMBJ SKDARRSTAMCI SKDARRSTAMCO
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMDT SKDARRSTAMEX SKDARRSTAMHT SKDARRSTAMIA SKDARRSTAMKE
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAMSP SKDARRSTAMSY SKDARRSTAMUC SKDARRSTAMZT SKDARRSTANAS
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAOAK SKDARRSTAOGG SKDARRSTAOMA SKDARRSTAONT SKDARRSTAORD
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            1
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAORF SKDARRSTAPBI SKDARRSTAPDX SKDARRSTAPIT SKDARRSTAPLS
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAPPP SKDARRSTAPUJ SKDARRSTAPVD SKDARRSTAPVR SKDARRSTAPWM
2             1            0            0            0            0
5             1            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTARDU SKDARRSTARIC SKDARRSTARNO SKDARRSTAROC SKDARRSTARSW
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASAN SKDARRSTASAT SKDARRSTASEA SKDARRSTASFO SKDARRSTASJC
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASJD SKDARRSTASJO SKDARRSTASJU SKDARRSTASLC SKDARRSTASMF
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASNA SKDARRSTASRQ SKDARRSTASTL SKDARRSTASTT SKDARRSTASXM
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTASYR SKDARRSTATLV SKDARRSTATPA SKDARRSTAXHP SKDARRSTAYEG
2             0            0            0            0            0
5             0            0            0            0            0
7             0            0            0            0            0
13            0            0            0            0            0
14            0            0            0            0            0
17            0            0            0            0            0
   SKDARRSTAYVR SKDARRSTAYYC SKDARRSTAZRH SKDEQP319 SKDEQP320 SKDEQP321
2             0            0            0         0         0         0
5             0            0            0         0         0         0
7             0            0            0         0         0         1
13            0            0            0         0         0         0
14            0            0            0         0         0         1
17            0            0            0         0         0         0
   SKDEQP332 SKDEQP333 SKDEQP734 SKDEQP75E SKDEQP75H SKDEQP767 SKDEQPA01
2          0         0         1         0         0         0         0
5          0         0         0         0         0         0         0
7          0         0         0         0         0         0         0
13         0         0         1         0         0         0         0
14         0         0         0         0         0         0         0
17         0         0         0         0         0         0         0
   SKDEQPA05 SKDEQPA19 SKDEQPA21 SKDEQPE90 SKDEPS       D00    AVGSQ AVGLOFATC
2          0         0         0         0     32 0.2500000 3.258065  3.258065
5          0         0         0         1     72 0.2916667 2.986111  3.805556
7          0         0         0         0     88 0.3295455 2.551724  3.701149
13         0         0         0         0     32 0.3750000 3.000000  3.903226
14         0         0         0         0     72 0.3750000 3.295775  3.859155
17         0         0         0         0     84 0.3809524 3.939759  3.361446
   UPLINEATCIMPLow UPLINEATCIMPMed UPLINEATCIMPMedHigh UPLINEATCIMPMedLow
2                0               1                   0                  0
5                0               0                   0                  0
7                0               0                   0                  1
13               0               1                   0                  0
14               0               0                   0                  1
17               1               0                   0                  0
   DEPSTAATCIMPLow DOWNLINEATCIMPLow AVGSKDAVAIL AVAILBUCKETA05 AVAILBUCKETA10
2                0                 0   10.903226              0              1
5                1                 0    2.000000              0              0
7                0                 0    9.647059              1              0
13               0                 0   17.354839              0              0
14               0                 0   17.057143              0              0
17               0                 0   10.621951              0              1
   AVAILBUCKETA15 AVAILBUCKETA20 AVAILBUCKETA25 AVAILBUCKETA30 AVAILBUCKETA<0
2               0              0              0              0              0
5               0              0              0              0              0
7               0              0              0              0              0
13              1              0              0              0              0
14              1              0              0              0              0
17              0              0              0              0              0
   DEPBUCKETD2 DEPBUCKETD3 DEPBUCKETD4 DEPBUCKETD5 DEPBUCKETD6 DEPBUCKETD7
2            0           0           0           1           0           0
5            0           0           1           0           0           0
7            0           0           0           1           0           0
13           0           0           0           1           0           0
14           0           0           0           0           1           0
17           0           0           0           0           1           0
   DEPBUCKETD8 ARRBUCKETA2 ARRBUCKETA3 ARRBUCKETA4 ARRBUCKETA5 ARRBUCKETA6
2            0           0           0           0           0           1
5            0           0           0           0           1           0
7            0           0           0           0           0           1
13           0           0           0           0           0           1
14           0           0           0           0           0           0
17           0           0           0           0           0           1
   ARRBUCKETA7 ARRBUCKETA8 DEPRANKGRPLow DEPRANKGRPMed DEPRANKGRPMedHigh
2            0           0             1             0                 0
5            0           0             0             1                 0
7            0           0             1             0                 0
13           0           0             0             0                 0
14           1           0             1             0                 0
17           0           0             0             0                 0
   DEPRANKGRPMedLow TRNRANKGRPLow TRNRANKGRPMed TRNRANKGRPMedHigh
2                 0             1             0                 0
5                 0             1             0                 0
7                 0             1             0                 0
13                1             0             0                 0
14                0             1             0                 0
17                1             0             1                 0
   TRNRANKGRPMedLow ARRRANKGRPLow ARRRANKGRPMed ARRRANKGRPMedHigh
2                 0             0             0                 1
5                 0             0             0                 1
7                 0             0             1                 0
13                1             0             0                 0
14                0             0             0                 1
17                0             0             0                 1
   ARRRANKGRPMedLow DEPSPOKETRUE ARRSPOKETRUE xHNGRTRUE xDURN2
2                 0            0            0         0      2
5                 0            1            0         0      2
7                 0            0            1         0      2
13                1            0            1         0      2
14                0            0            1         0      2
17                0            0            0         0      2
> 
> dummies <- dummyVars(LEGTYPE ~ ., data = flight)
> flight.dum <- predict(dummies, newdata = flight)
> 
> ## It may be too big to use, but useful for inspection.
> 
> ### Numeric variables
> 
> ## Check some more numeric correlations, I haven't scaled yet.
> ## I'd cut correlations above 0.75 because of overfitting.
> 
> x1 <- as.data.frame(as.matrix(sapply(flight, class)))
> 
> flight.num <- flight[,names(x1[which(x1$V1 %in% c("numeric", "integer")),])]
> 
> flight.nzv <- nearZeroVar(flight.num, saveMetrics = TRUE)
> flight.nzv
            freqRatio percentUnique zeroVar   nzv
SDEPHR       1.038462        5.9375   FALSE FALSE
SKDEPS       1.000000       19.0625   FALSE FALSE
D00          1.166667       75.3125   FALSE FALSE
AVGSQ        6.333333       82.8125   FALSE FALSE
AVGLOFATC    1.000000       78.4375   FALSE FALSE
AVGSKDAVAIL  1.000000       87.5000   FALSE FALSE
xDURN2       1.428571        2.5000   FALSE FALSE
> 
> # annoying NA
> flight.cor <- cor(flight.num, use = "pairwise.complete.obs")
> 
> descrCorr <- findCorrelation(flight.cor, cutoff = .65, verbose=TRUE)
Considering row	 1 column	 4 value	 0.956 
  Flagging column	 1 
Considering row	 4 column	 3 value	 0.414 
Considering row	 4 column	 6 value	 0.173 
Considering row	 4 column	 7 value	 0.201 
Considering row	 4 column	 5 value	 0.103 
Considering row	 4 column	 2 value	 0.082 
Considering row	 3 column	 6 value	 0.266 
Considering row	 3 column	 7 value	 0.071 
Considering row	 3 column	 5 value	 0.114 
Considering row	 3 column	 2 value	 0.006 
Considering row	 6 column	 7 value	 0.031 
Considering row	 6 column	 5 value	 0.094 
Considering row	 6 column	 2 value	 0.067 
Considering row	 7 column	 5 value	 0.137 
Considering row	 7 column	 2 value	 0.005 
Considering row	 5 column	 2 value	 0.041 
> 
> colnames(flight.num)[descrCorr]
[1] "SDEPHR"
> 
> ## Which tells me that departure time is very highly correlated to AVGSQ.
> ## AVGSQ is average stand queue?
> 
> ### Try and impute the AVG, it might have more information than the
> ### bucket.
> 
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))
> 
> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1
> 
> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]
> 
> preProcValues <- preProcess(flight.na, method = c("knnImpute"))
> flight.na1 <- predict(preProcValues, flight.na)
> 
> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL
> 
> ## And I'll leave the centered and scale values in for now.
> ## and delete the troublesome ones
> 
> flight$AVGSKDAVAIL <- NULL
> flight$xHNGR <- NULL
> flight$AVAILBUCKET <- NULL
> 
> # This should be deleted, leave it in and the results are ideal because it defines LEGTYPE.
> flight$D00 <- NULL
> 
> ## Keep the results but don't change the order.
> outcomes.flight <- flight$LEGTYPE
> 
> flight$LEGTYPE <- NULL
> 
> ## If you know your factors are definitely factors, you don't need this
> ##  asNumeric <- function(x) as.numeric(as.character(x))
> 
> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))
> 
> flight.num0 <- factors.numeric(flight)
> 
> flight.scl0 <- scale(flight.num0)
> 
> ## Now split the results
> ## we need 80 or so to test with.
> 
> set.seed(seed.mine)
> inTrain <- createDataPartition(outcomes.flight, p = 0.77, list = FALSE)
> 
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> 
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> 
> prop.table(table(trainClass))
trainClass
   Strong      Weak 
0.4475806 0.5524194 
> dim(trainDescr)
[1] 248  20
> 
> prop.table(table(testClass))
testClass
   Strong      Weak 
0.4444444 0.5555556 
> dim(testDescr)
[1] 72 20
> seed.mine = 107
> set.seed(seed.mine)                     # helpful for testing
> 
> flight <- read.csv("../bak/flight.csv")
> flight <- flight[order(flight$D00),]
> 
> # Backup
> flight.raw <- flight
> 
> # To check adjustment, there is test code in flight-nb.R
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"
> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"
> 
> # And some deletions
> 
> t.cols <- colnames(flight)
> 
> t.drops <- t.cols[grep("^RANK*", t.cols)]
> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])
> t.drops <- c(t.drops, "D80THPCTL")
> 
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR
> flight$xHNGR <- flight$xDURN < 0
> 
> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+ }
> 
> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))
> 
> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE
> t.cols <- colnames(flight)
> 
> t.drops <- c("SARRHR", "xDURN")
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Backup
> 
> flight00 <- flight
> 
> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]
> 
> paste("samples in use: ", dim(flight)[1])
[1] "samples in use:  320"
> 
> ## Data insights
> 
> ## *Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> flight <- flight1
> 
> ### Numeric variables
> 
> ## Check some more numeric correlations, I haven't scaled yet.
> ## I'd cut correlations above 0.75 because of overfitting.
> 
> x1 <- as.data.frame(as.matrix(sapply(flight, class)))
> 
> flight.num <- flight[,names(x1[which(x1$V1 %in% c("numeric", "integer")),])]
> 
> flight.nzv <- nearZeroVar(flight.num, saveMetrics = TRUE)
> flight.nzv
            freqRatio percentUnique zeroVar   nzv
SDEPHR       1.038462        5.9375   FALSE FALSE
SKDEPS       1.000000       19.0625   FALSE FALSE
D00          1.166667       75.3125   FALSE FALSE
AVGSQ        6.333333       82.8125   FALSE FALSE
AVGLOFATC    1.000000       78.4375   FALSE FALSE
AVGSKDAVAIL  1.000000       87.5000   FALSE FALSE
xDURN2       1.428571        2.5000   FALSE FALSE
> 
> # annoying NA
> flight.cor <- cor(flight.num, use = "pairwise.complete.obs")
> 
> descrCorr <- findCorrelation(flight.cor, cutoff = .65, verbose=TRUE)
Considering row	 1 column	 4 value	 0.956 
  Flagging column	 1 
Considering row	 4 column	 3 value	 0.414 
Considering row	 4 column	 6 value	 0.173 
Considering row	 4 column	 7 value	 0.201 
Considering row	 4 column	 5 value	 0.103 
Considering row	 4 column	 2 value	 0.082 
Considering row	 3 column	 6 value	 0.266 
Considering row	 3 column	 7 value	 0.071 
Considering row	 3 column	 5 value	 0.114 
Considering row	 3 column	 2 value	 0.006 
Considering row	 6 column	 7 value	 0.031 
Considering row	 6 column	 5 value	 0.094 
Considering row	 6 column	 2 value	 0.067 
Considering row	 7 column	 5 value	 0.137 
Considering row	 7 column	 2 value	 0.005 
Considering row	 5 column	 2 value	 0.041 
> 
> colnames(flight.num)[descrCorr]
[1] "SDEPHR"
> 
> ## Which tells me that departure time is very highly correlated to AVGSQ.
> ## AVGSQ is average stand queue?
> 
> ### Try and impute the AVG, it might have more information than the
> ### bucket.
> 
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))
> 
> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1
> 
> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]
> 
> preProcValues <- preProcess(flight.na, method = c("knnImpute"))
> flight.na1 <- predict(preProcValues, flight.na)
> 
> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL
> 
> ## And I'll leave the centered and scale values in for now.
> ## and delete the troublesome ones
> 
> flight$AVGSKDAVAIL <- NULL
> flight$xHNGR <- NULL
> flight$AVAILBUCKET <- NULL
> 
> ## Re-classing
> ## Check warnings to see what happened.
> ## It doesn't matter if you run this on all or the sub-sample
> ## The proportion is more or less the same
> src.adjust <- TRUE
> source(file = "flight1.R")
Warning message:
In eval(expr, envir, enclos) : adjusting
> flight1 <- flight
> 
> # This should be deleted, leave it in and the results are ideal because it defines LEGTYPE.
> flight$D00 <- NULL
> 
> ## Keep the results but don't change the order.
> outcomes.flight <- flight$LEGTYPE
> 
> flight$LEGTYPE <- NULL
> 
> ## If you know your factors are definitely factors, you don't need this
> ##  asNumeric <- function(x) as.numeric(as.character(x))
> 
> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))
> 
> flight.num0 <- factors.numeric(flight)
> 
> flight.scl0 <- scale(flight.num0)
> 
> ## Now split the samples
> ## we need at least 60 to test with, p at 0.77 gives about 75.
> ## Difficulty here is the bias in the table
> ## Because we only have [3.1, 4.4] the proportion of Weak is higher.
> ## see prop.table(results)
> 
> set.seed(seed.mine)
> inTrain <- createDataPartition(outcomes.flight, p = 0.77, list = FALSE)
> 
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> 
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> 
> prop.table(table(trainClass))
trainClass
   Strong      Weak 
0.4475806 0.5524194 
> dim(trainDescr)
[1] 248  20
> 
> prop.table(table(testClass))
testClass
   Strong      Weak 
0.4444444 0.5555556 
> dim(testDescr)
[1] 72 20
> flight1
     SDEPHR SKDDEPSTA SKDARRSTA SKDEQP SKDEPS       D00    AVGSQ AVGLOFATC
2        14       CCC       PPP    734     32 0.2500000 3.258065  3.258065
5        11       DTW       PPP    E90     72 0.2916667 2.986111  3.805556
7        14       CCC       LGA    321     88 0.3295455 2.551724  3.701149
13       13       PPP       ORD    734     32 0.3750000 3.000000  3.903226
14       16       CCC       BOS    321     72 0.3750000 3.295775  3.859155
17       15       DDD       CCC    19W     84 0.3809524 3.939759  3.361446
18       17       BOS       CCC    19W     63 0.3809524 4.213115  4.196721
20       17       TPA       CCC    734     90 0.3888889 4.388889  3.255556
33       16       ORD       PPP    734     32 0.4062500 4.000000  3.903226
34       22       CCC       EWR    321     64 0.4062500 5.111111  3.746032
36       19       BWI       CCC    734     65 0.4153846 5.174603  3.412698
37       13       DFW       PPP    19W     31 0.4193548 2.870968  3.548387
43        9       PPP       DTW    E90     72 0.4305556 1.986111  3.805556
44        9       CCC       MCO    321     44 0.4318182 1.886364  3.181818
45       16       CCC       ORD    321     67 0.4328358 3.348485  3.954545
46       17       FLL       CCC    734     90 0.4333333 4.449438  3.303371
57       20       CCC       BOS    321     83 0.4457831 4.358025  3.382716
63       14       CCC       RSW    734     46 0.4565217 3.326087  3.108696
68       17       DFW       CCC    734     39 0.4615385 4.025641  3.615385
71       19       CCC       ROC    319     84 0.4642857 5.321429  3.595238
74       16       BOS       XHP    A05     62 0.4677419 3.816667  3.716667
76       16       MSY       CCC    734     64 0.4687500 4.656250  3.109375
81       14       CCC       DFW    734     51 0.4705882 3.156863  3.254902
82       18       CCC       LAX    320     34 0.4705882 4.588235  3.294118
83       19       FLL       CCC    321     55 0.4727273 4.600000  4.054545
84       22       CCC       PPP    734     59 0.4745763 5.881356  3.508475
86       20       CCC       EWR    321     69 0.4782609 4.731343  3.910448
87       22       PPP       BOS    E90     69 0.4782609 5.925373  4.208955
88       14       CCC       EWR    321     73 0.4794521 3.194444  4.027778
99       14       CCC       PPP    321     37 0.4864865 3.540541  3.405405
103      18       CCC       SFO    321     49 0.4897959 3.918367  3.265306
108      18       CCC       ORD    321     75 0.4933333 4.351351  3.216216
114      13       DFW       CCC    321     82 0.5000000 3.085366  3.243902
117      19       PBI       CCC    734     40 0.5000000 4.700000  3.175000
123      22       CCC       TPA    321     60 0.5000000 4.600000  3.416667
133      15       TPA       CCC    320     39 0.5128205 4.179487  3.358974
134      17       CCC       JAX    734     35 0.5142857 4.500000  3.411765
140      19       BDL       CCC    734     33 0.5151515 4.875000  3.343750
143      20       CCC       BDL    321     89 0.5168539 4.218391  3.321839
144      18       CCC       LAX    321     56 0.5178571 4.017857  3.250000
147      15       DFW       PPP    320     48 0.5208333 3.000000  3.854167
150      14       MIA       CCC    734     86 0.5232558 2.953488  3.267442
155      11       SRQ       CCC    19W     36 0.5277778 2.971429  3.714286
165      18       PPP       BOS    E90     64 0.5312500 4.200000  3.716667
170      14       CCC       FLL    734     90 0.5333333 3.483146  3.303371
171      19       MIA       CCC    734     75 0.5333333 4.773333  3.946667
172      16       CCC       FLL    321     56 0.5357143 3.607143  4.053571
184      18       TPA       DDD    319     33 0.5454545 4.969697  3.303030
186      22       CCC       MIA    734     33 0.5454545 5.424242  3.333333
188      14       CCC       PIT    319     53 0.5471698 3.849057  3.264151
189      16       CCC       RSW    734     53 0.5471698 3.792453  3.169811
196      22       CCC       BDL    734     78 0.5512821 5.697368  3.302632
197      16       JFK       XHP    A21     56 0.5535714 3.000000  3.518519
199      22       CCC       LGA    319     65 0.5538462 5.937500  3.765625
202      17       LGA       CCC    321     88 0.5568182 3.558140  3.732558
205      14       CCC       BDL    734     77 0.5584416 3.460526  3.157895
208      13       ORD       PPP    320     68 0.5588235 3.015152  3.530303
213      16       RDU       CCC    734     41 0.5609756 4.609756  3.634146
214      19       CCC       MIA    734     41 0.5609756 5.400000  3.275000
215      19       CCC       CLE    19W     41 0.5609756 5.146341  3.219512
217      10       TPA       CCC    734     80 0.5625000 2.725000  3.450000
218      11       RDU       CCC    320     48 0.5625000 2.937500  3.500000
223      11       TPA       CCC    321     39 0.5641026 2.026316  3.473684
227      13       CCC       PPP    19W     60 0.5666667 3.516667  4.083333
228      16       CCC       JAX    19W     60 0.5666667 3.883333  3.216667
229      17       JAX       CCC    19W     60 0.5666667 4.883333  3.216667
232      16       CCC       MIA    734     88 0.5681818 3.738636  3.693182
233      17       CCC       BWI    734     65 0.5692308 4.174603  3.412698
234      17       ATT       PPP    E90     72 0.5694444 4.722222  4.013889
238      17       BNA       CCC    19W     61 0.5737705 5.366667  4.333333
242      18       CCC       DFW    321     66 0.5757576 3.893939  3.151515
249      19       MCO       CCC    321     76 0.5789474 4.526316  3.552632
250      17       MCO       CCC    321     88 0.5795455 4.181818  3.465909
256      22       CCC       FLL    321     43 0.5813953 4.837209  3.581395
260      18       CCC       STL    19W     84 0.5833333 5.144578  4.048193
262       9       ORD       CCC    A05     89 0.5842697 1.976744  3.813953
266      17       RSW       CCC    734     46 0.5869565 4.326087  3.108696
267      14       CCC       BOS    19W     63 0.5873016 3.131148  3.983607
274      19       CCC       DDD    19W     68 0.5882353 5.441176  3.411765
276      22       CCC       ORD    321     78 0.5897436 5.168831  4.038961
279      12       MCO       CCC    321     44 0.5909091 2.790698  3.325581
281      20       CCC       ORD    321     86 0.5930233 4.905882  4.188235
283      16       CCC       MCI    319     64 0.5937500 4.177419  4.258065
285      22       LAX       CCC    A21     79 0.5949367 4.620253  3.113924
286      13       CCC       BOS    A05     89 0.5955056 2.872093  3.755814
290      20       CCC       PIT    19W     52 0.5961538 5.576923  3.288462
295       9       CCC       JFK    319     77 0.5974026 1.986842  3.960526
296      11       CCC       DFW    321     82 0.5975610 2.085366  3.243902
300      12       BWI       CCC    734     45 0.6000000 2.977273  3.590909
303      15       IAH       CCC    320     30 0.6000000 4.433333  4.000000
310      20       CCC       IAH    320     53 0.6037736 4.415094  3.150943
311      17       CCC       DDD    19W     48 0.6041667 4.270833  4.104167
317      22       CCC       MCO    321     33 0.6060606 4.909091  3.515152
318      16       CCC       BNA    19W     61 0.6065574 4.366667  4.333333
326      13       CCC       JFK    A21     90 0.6111111 2.000000  3.454545
327      14       CCC       TPA    734     90 0.6111111 3.355556  3.244444
337      20       CCC       PVD    734     83 0.6144578 5.345679  3.172840
338      18       PPP       PIT    E90     78 0.6153846 4.371795  3.397436
343      11       CCC       DDD    319     68 0.6176471 2.029851  3.910448
351      16       PVD       CCC    319     74 0.6216216 4.694444  3.486111
352      20       CCC       FLL    321     37 0.6216216 4.540541  3.243243
354      10       DFW       CCC    321     61 0.6229508 2.180328  4.229508
356      22       CCC       JAX    734     61 0.6229508 5.950820  3.393443
357       9       PPP       BOS    E90     64 0.6250000 1.952381  4.063492
359      11       PBI       DDD    19W     32 0.6250000 3.000000  3.161290
362      14       CCC       MCO    321     88 0.6250000 3.250000  3.488636
363      16       BOS       PPP    E90     64 0.6250000 3.542373  3.711864
364      18       PBI       DDD    319     32 0.6250000 5.062500  3.625000
365      18       MCI       CCC    319     64 0.6250000 5.177419  4.258065
369      14       BOS       CCC    321     67 0.6268657 2.984615  3.846154
370      17       ORD       CCC    321     51 0.6274510 4.260000  4.220000
377      16       STL       CCC    319     38 0.6315789 4.918919  3.162162
382      20       BOS       PPP    E90     49 0.6326531 5.333333  4.111111
390      17       MCO       CCC    734     71 0.6338028 4.666667  3.130435
395       7       CCC       ORD    A05     85 0.6352941 1.012048  3.843373
400      15       DDD       TPA    319     33 0.6363636 3.969697  3.303030
401      15       MCI       CCC    19W     33 0.6363636 4.322581  3.258065
402      17       BDL       CCC    734     77 0.6363636 4.460526  3.157895
404      17       PPP       DDD    19W     77 0.6363636 4.131579  3.986842
405      17       IAH       PPP    E90     77 0.6363636 4.697368  3.473684
406      17       RDU       PPP    E90     69 0.6376812 4.632353  3.764706
408      14       PPP       ATT    E90     72 0.6388889 3.722222  4.013889
411       0       XHP       CCC    321     50 0.6400000 1.000000  3.640000
413      16       CCC       SYR    19W     64 0.6406250 4.375000  3.750000
418      22       CCC       PBI    734     78 0.6410256 5.589744  3.487179
419      14       CCC       RDU    734     42 0.6428571 3.595238  3.619048
427       6       JFK       CCC    19W     87 0.6436782 1.000000  3.710843
429      22       CCC       PIT    321     59 0.6440678 4.762712  3.610169
434      11       PPP       DFW    320     48 0.6458333 2.000000  3.854167
435      20       CCC       DFW    734     48 0.6458333 5.520833  3.270833
436      21       PPP       BOS    19W     48 0.6458333 4.787234  3.510638
438      10       PPP       CCC    320     51 0.6470588 1.980392  3.294118
440      11       CCC       BOS    321     68 0.6470588 1.984848  3.848485
445      16       CCC       MCO    321     88 0.6477273 3.545455  3.454545
446      12       PIT       CCC    734     37 0.6486486 2.972973  3.756757
447      16       CCC       RSW    321     37 0.6486486 3.891892  4.108108
448      18       PPP       DFW    19W     37 0.6486486 3.864865  3.189189
450      22       CCC       BUF    734     77 0.6493506 5.842105  3.421053
458      19       DDD       TPA    19W     46 0.6521739 5.173913  4.260870
459      15       DDD       PPP    19W     75 0.6533333 3.890411  4.109589
463      13       CCC       MIA    734     81 0.6543210 2.654321  3.370370
466       8       DDD       PBI    19W     32 0.6562500 2.000000  3.161290
467      17       MSP       CCC    319     32 0.6562500 4.687500  3.281250
482      20       PPP       ORD    320     50 0.6600000 4.224490  3.122449
488      11       PPP       ORD    320     68 0.6617647 2.015152  3.530303
489      13       DDD       CCC    319     68 0.6617647 3.298507  4.283582
495       9       CCC       RDU    320     48 0.6666667 1.937500  3.500000
497      10       CCC       LGA    321     90 0.6666667 1.640449  4.191011
498      10       MIA       CCC    734     69 0.6666667 1.637681  3.637681
501      11       CCC       LGA    321     90 0.6666667 2.011236  3.865169
503      12       JFK       CCC    319     72 0.6666667 2.985915  3.957746
504      12       NAS       CCC    734     84 0.6666667 2.940476  3.214286
505      13       CCC       TPA    320     39 0.6666667 3.179487  3.358974
518      16       MIA       PPP    734     82 0.6707317 3.670732  3.390244
519      17       DDD       CCC    319     76 0.6710526 4.333333  3.800000
520      12       BOS       CCC    321     70 0.6714286 2.955224  4.119403
522      20       CCC       PBI    734     67 0.6716418 5.378788  3.181818
531      11       ORF       CCC    319     49 0.6734694 3.042553  4.085106
532      18       PPP       IAH    E90     49 0.6734694 4.326531  3.204082
535      11       DFW       PPP    19W     46 0.6739130 2.021739  4.043478
544      12       PVD       CCC    734     40 0.6750000 2.925000  3.500000
545      20       PPP       TPA    734     77 0.6753247 4.960526  3.460526
553      20       PPP       BDL    19W     68 0.6764706 4.537313  3.298507
561      11       MIA       CCC    734     84 0.6785714 2.011905  3.916667
562      14       MIA       PPP    734     84 0.6785714 3.000000  3.228916
564      19       RSW       CCC    734     53 0.6792453 4.792453  3.169811
568      20       PPP       PVD    E90     72 0.6805556 5.549296  4.042254
584      13       LAX       CCC    321     73 0.6849315 2.972222  3.750000
590       9       PPP       DFW    19W     32 0.6875000 1.875000  3.531250
592      17       DTW       CCC    19W     64 0.6875000 4.921875  3.578125
593      12       DFW       CCC    321     61 0.6885246 2.918033  3.573770
596      12       DDD       CCC    319     45 0.6888889 2.840909  4.159091
597      18       CCC       SEA    321     45 0.6888889 3.711111  3.111111
598      18       PPP       SAT    E90     90 0.6888889 4.333333  3.244444
610       9       CCC       ORF    319     49 0.6938776 2.041667  4.041667
614      12       BWI       CCC    321     36 0.6944444 2.944444  3.861111
615      18       PPP       RDU    E90     72 0.6944444 4.416667  3.194444
628      19       CCC       ORF    319     86 0.6976744 5.302326  3.418605
629      22       CCC       DDD    19W     63 0.6984127 5.709677  3.387097
638       7       PPP       MIA    734     84 0.7023810 1.011905  3.916667
639       9       PPP       MIA    734     84 0.7023810 2.000000  3.202381
644      10       MCO       CCC    321     88 0.7045455 2.494253  3.275862
647       9       CCC       DFW    321     61 0.7049180 1.918033  3.573770
653      18       BWI       PPP    319     51 0.7058824 5.120000  3.320000
655      22       CCC       PVD    734     65 0.7076923 5.859375  3.453125
657      20       CCC       ATT    321     89 0.7078652 4.584270  3.662921
662      11       CCC       MIA    734     86 0.7093023 1.953488  3.267442
664      12       DFW       PPP    319     31 0.7096774 2.935484  3.774194
668      13       JAX       CCC    319     76 0.7105263 3.605263  3.723684
677      10       EWR       CCC    320     35 0.7142857 2.205882  4.235294
687      15       EWR       CCC    321     81 0.7160494 2.974359  3.474359
688      14       CCC       PVD    319     74 0.7162162 3.694444  3.486111
692      15       PIT       CCC    734     60 0.7166667 4.237288  3.288136
697       9       CCC       LAX    321     78 0.7179487 1.974359  3.602564
702       9       PPP       DFW    319     32 0.7187500 1.937500  3.781250
703      14       CCC       MSP    319     32 0.7187500 3.687500  3.281250
706      22       CCC       DTW    321     32 0.7187500 4.937500  3.531250
717      22       CCC       RSW    321     43 0.7209302 4.395349  3.162791
721      15       MCI       CCC    320     36 0.7222222 4.305556  3.111111
724      20       CCC       BUF    734     90 0.7222222 5.222222  3.188889
729      15       PPP       RDU    E90     69 0.7246377 3.623188  3.782609
735       7       CCC       MCO    321     84 0.7261905 1.583333  3.273810
737      16       ORD       PPP    19W     33 0.7272727 3.242424  3.727273
744      22       CCC       MSP    320     33 0.7272727 5.424242  3.787879
745      11       CCC       EWR    321     81 0.7283951 1.974359  3.474359
747      13       PPP       CCC    320     59 0.7288136 2.355932  3.406780
750       7       CCC       PPP    320     48 0.7291667 1.416667  3.229167
751      13       CCC       JAX    319     48 0.7291667 3.020833  3.770833
758      14       ATT       PPP    E90     52 0.7307692 3.115385  3.230769
766      13       CCC       IAH    320     30 0.7333333 3.433333  4.000000
767      13       CCC       PIT    734     60 0.7333333 3.237288  3.288136
768      13       CCC       BWI    320     60 0.7333333 3.533333  3.966667
772      19       DDD       TPA    19W     30 0.7333333 5.100000  3.866667
773      20       PPP       CCC    319     64 0.7343750 5.171875  3.437500
780      20       PPP       RDU    E90     72 0.7361111 5.585714  3.800000
781      14       CCC       STL    319     38 0.7368421 3.918919  3.162162
787      18       CCC       SAT    319     77 0.7402597 5.012987  3.480519
800      16       CCC       BWI    319     51 0.7450980 4.117647  3.294118
809      10       LGA       CCC    319     76 0.7500000 2.108108  4.270270
812      14       PPP       BOS    E90     64 0.7500000 2.610169  3.661017
813      15       BWI       CCC    320     60 0.7500000 4.533333  3.966667
820      20       CCC       MCI    319     76 0.7500000 6.253333  3.853333
822      21       PPP       BWI    19W     72 0.7500000 4.842857  3.885714
831      16       CCC       DDD    320     78 0.7564103 3.435897  3.538462
836       9       PPP       RDU    19W     33 0.7575758 2.000000  3.212121
839      13       CCC       MCI    19W     33 0.7575758 3.322581  3.258065
848       5       BWI       CCC    19W     75 0.7600000 1.000000  3.306667
851       8       BOS       PPP    E90     71 0.7605634 1.750000  4.102941
854      14       PPP       IAH    E90     88 0.7613636 3.602273  3.352273
857       7       PPP       TPA    321     38 0.7631579 1.026316  3.421053
872       6       TPA       CCC    321     81 0.7654321 1.000000  3.493827
873       8       MIA       CCC    734     47 0.7659574 1.000000  3.425532
877      20       PPP       PIT    734     30 0.7666667 4.766667  3.333333
891      11       PPP       BOS    E90     61 0.7704918 2.016949  4.305085
893       8       PPP       MSP    E90     48 0.7708333 1.434783  3.456522
894       9       CCC       BOS    321     70 0.7714286 1.955882  4.073529
895      16       MSP       PPP    E90     70 0.7714286 4.200000  3.828571
900      11       CCC       ORD    321     88 0.7727273 1.952941  3.129412
906      12       LGA       CCC    321     84 0.7738095 2.626506  4.132530
912      13       PPP       MSP    E90     71 0.7746479 3.183099  3.802817
913       6       RSW       CCC    321     80 0.7750000 1.000000  3.550000
918       6       MIA       CCC    734     85 0.7764706 1.000000  3.892857
922       9       CCC       BWI    734     45 0.7777778 1.977273  3.590909
926      17       DDD       TPA    319     77 0.7792208 4.526316  3.368421
942      14       ORD       CCC    321     83 0.7831325 2.924051  3.151899
947       7       BOS       PPP    19W     56 0.7857143 1.017857  3.982143
948      10       MCO       PPP    320     42 0.7857143 2.000000  3.190476
953       8       DFW       PPP    19W     47 0.7872340 1.000000  3.340426
956      11       RDU       PPP    19W     33 0.7878788 3.000000  3.212121
961      21       PPP       MHT    E90     71 0.7887324 5.571429  4.257143
962      22       CCC       ATT    321     71 0.7887324 4.436620  3.323944
975      16       PPP       ATT    E90     77 0.7922078 3.831169  4.363636
977       7       TPA       DDD    19W     87 0.7931034 1.000000  3.129412
980      16       CCC       TPA    320     34 0.7941176 3.441176  3.764706
982       9       CCC       NAS    734     78 0.7948718 1.948718  3.243590
985       7       MHT       PPP    E90     83 0.7951807 1.000000  3.506329
988       6       IND       CCC    319     88 0.7954545 1.125000  3.329545
998       6       PPP       BOS    E90     50 0.8000000 1.021277  4.340426
1001      7       CHS       CCC    19W     30 0.8000000 1.000000  4.166667
1002      7       CCC       MIA    734     40 0.8000000 1.100000  4.050000
1003      7       CCC       EWR    320     35 0.8000000 1.205882  4.235294
1010     20       CCC       RIC    319     65 0.8000000 5.630769  3.215385
1013     11       CCC       JAX    319     76 0.8026316 2.605263  3.723684
1014     11       BOS       PPP    E90     76 0.8026316 2.780822  3.876712
1023      9       CCC       BWI    321     36 0.8055556 1.944444  3.861111
1024      9       CCC       SRQ    19W     36 0.8055556 1.972222  3.666667
1025     13       CCC       MCI    320     36 0.8055556 3.305556  3.111111
1048     14       CCC       DDD    319     58 0.8103448 3.724138  3.810345
1051      7       ORD       CCC    321     90 0.8111111 1.078652  3.112360
1056      5       MCO       CCC    321     32 0.8125000 1.000000  3.375000
1058      7       CCC       TPA    734     48 0.8125000 1.729167  3.333333
1062     19       DDD       MCO    320     48 0.8125000 4.562500  3.520833
1068      8       MIA       CCC    321     43 0.8139535 1.000000  3.790698
1076      7       DFW       CCC    321     88 0.8181818 1.000000  3.795455
1081      6       MIA       PPP    734     83 0.8192771 1.000000  3.337349
1082      6       EWR       CCC    321    156 0.8205128 1.000000  3.847682
1098     22       CCC       RIC    19W     52 0.8269231 5.903846  3.653846
1099     22       CCC       BNA    19W     64 0.8281250 5.843750  3.531250
1104     19       TPA       CCC    320     35 0.8285714 4.457143  3.742857
1105     22       CCC       ILM    734     35 0.8285714 5.823529  3.470588
1106      6       MSY       PPP    E90     82 0.8292683 1.000000  3.237500
1109     11       MSP       PPP    E90     53 0.8301887 2.431373  3.431373
1110      7       ORD       PPP    320     71 0.8309859 1.000000  3.718310
1113      6       PPP       MCO    320     42 0.8333333 1.000000  3.190476
1129     10       CCC       JAX    19W     68 0.8382353 1.955882  3.338235
1136      7       CCC       DFW    321     57 0.8421053 1.263158  4.245614
1143     14       CCC       DTW    19W     64 0.8437500 3.921875  3.578125
1144     19       ATT       PPP    E90     77 0.8441558 4.842105  4.381579
1147     20       CCC       MDT    19W     71 0.8450704 5.802817  3.971831
1149      7       CHS       CCC    319     39 0.8461538 1.000000  3.605263
1152      5       DFW       CCC    734     72 0.8472222 1.000000  3.750000
1153      7       PVD       PPP    E90     72 0.8472222 1.000000  3.647887
1179      6       DFW       PPP    19W     76 0.8552632 1.000000  3.263158
1180      6       LGA       CCC    321     83 0.8554217 1.000000  3.939024
1181      8       DFW       CCC    A21     90 0.8555556 1.000000  3.438202
1182     14       LGA       CCC    321     90 0.8555556 3.011236  3.865169
1196      6       BOS       PPP    19W     51 0.8627451 1.000000  3.520000
1205      9       CCC       PIT    734     37 0.8648649 1.972973  3.756757
1207      6       BOS       CCC    321     89 0.8651685 1.000000  3.425287
1208     11       PPP       ATT    E90     52 0.8653846 2.115385  3.230769
1211      8       ATT       CCC    321     82 0.8658537 1.000000  3.600000
1213      5       PPP       CCC    734     60 0.8666667 1.000000  3.966667
1214      7       PPP       DFW    19W     45 0.8666667 1.044444  4.088889
1226     17       PIT       CCC    319     53 0.8679245 4.849057  3.264151
1242      9       CCC       PVD    734     40 0.8750000 1.925000  3.500000
1245     15       JAX       CCC    319     48 0.8750000 4.020833  3.770833
1257     12       JAX       CCC    19W     68 0.8823529 2.955882  3.338235
1268      6       CCC       PPP    319     72 0.8888889 1.000000  3.746479
1273      7       BOS       PPP    320     74 0.8918919 1.000000  4.397260
1274      9       CLE       CCC    734     37 0.8918919 1.000000  3.111111
1283     22       CCC       ORF    319     58 0.8965517 6.017241  4.206897
1302      7       RIC       CCC    319     42 0.9047619 1.000000  3.857143
1306      7       ORF       CCC    319     85 0.9058824 1.000000  3.130952
1308     13       PPP       ORD    19W     32 0.9062500 2.250000  3.781250
1309      8       CCC       PIT    19W     65 0.9076923 1.969231  4.107692
1311     10       PIT       CCC    19W     66 0.9090909 2.909091  4.090909
1331      6       DDD       CCC    19W     62 0.9193548 1.000000  3.590164
1363      5       ORF       CCC    319     69 0.9420290 1.000000  4.362319
1370      5       RIC       CCC    19W     59 0.9491525 1.000000  3.966102
1387      6       BOS       DDD    320     39 0.9743590 1.000000  4.205128
     UPLINEATCIMP DEPSTAATCIMP DOWNLINEATCIMP DEPBUCKET ARRBUCKET DEPRANKGRP
2             Med         High           High        D5        A6        Low
5            High          Low           High        D4        A5        Med
7          MedLow         High           High        D5        A6        Low
13            Med         High           High        D5        A6     MedLow
14         MedLow         High           High        D6        A7        Low
17            Low         High           High        D6        A6     MedLow
18           High         High           High        D6        A7        Med
20           High          Low           High        D6        A7        Low
33           High         High           High        D6        A7        Med
34            Low         High           High        D8        A8        Low
36           High          Low           High        D7        A8        Low
37           High         High           High        D5        A6        Med
43            Low         High            Low        D4        A4     MedLow
44         MedLow         High            Low        D4        A4        Low
45            Med         High           High        D6        A6        Low
46           High          Low           High        D6        A7     MedLow
57            Med         High           High        D7        A8        Low
63         MedLow         High            Low        D5        A6        Low
68           High         High           High        D6        A7        Med
71         MedLow         High            Low        D7        A8        Low
74           High         High            Low        D6        A7        Med
76           High          Low           High        D6        A7        Low
81         MedLow         High           High        D5        A6        Low
82            Low         High           High        D7        A7        Low
83           High          Low           High        D7        A8     MedLow
84            Low         High           High        D8        A8        Low
86        MedHigh         High           High        D7        A8        Low
87         MedLow         High           High        D8        A8     MedLow
88        MedHigh         High           High        D5        A6        Low
99         MedLow         High           High        D5        A6        Low
103       MedHigh         High            Low        D7        A7        Low
108        MedLow         High           High        D7        A7        Low
114          High         High           High        D5        A6        Med
117          High          Low           High        D7        A8        Low
123           Med         High            Low        D8        A8        Low
133          High          Low           High        D6        A6        Low
134        MedLow         High            Low        D6        A7        Low
140          High          Low           High        D7        A8     MedLow
143           Med         High            Low        D7        A8        Low
144           Med         High           High        D7        A7        Low
147          High         High           High        D6        A7        Med
150          High         High           High        D5        A6     MedLow
155          High          Low           High        D4        A5        Low
165        MedLow         High           High        D7        A7     MedLow
170           Low         High            Low        D5        A6        Low
171          High         High           High        D7        A8     MedLow
172       MedHigh         High            Low        D6        A7        Low
184          High          Low           High        D7        A7        Low
186        MedLow         High           High        D8        A1        Low
188        MedLow         High            Low        D5        A6        Low
189           Low         High            Low        D6        A7        Low
196           Low         High            Low        D8        A8        Low
197          High         High            Low        D6        A7     MedLow
199        MedLow         High           High        D8        A8        Low
202          High         High           High        D6        A7        Med
205           Low         High            Low        D5        A6        Low
208          High         High           High        D5        A6        Med
213          High          Low           High        D6        A6        Med
214           Low         High           High        D7        A8        Low
215           Low         High            Low        D7        A8        Low
217          High          Low           High        D4        A5        Low
218          High          Low           High        D4        A5        Med
223          High          Low           High        D4        A5        Low
227           Med         High           High        D5        A5        Low
228           Low         High            Low        D6        A6        Low
229          High          Low           High        D6        A7    MedHigh
232           Low         High           High        D6        A7        Low
233        MedLow         High            Low        D6        A7        Low
234          High         High           High        D6        A7        Med
238          High          Low           High        D6        A7    MedHigh
242       MedHigh         High           High        D7        A7        Low
249          High          Low           High        D7        A7     MedLow
250          High          Low           High        D6        A7     MedLow
256        MedLow         High            Low        D8        A8        Low
260       MedHigh         High            Low        D7        A7        Low
262          High         High           High        D4        A5        Med
266          High          Low           High        D6        A7     MedLow
267        MedLow         High           High        D5        A6        Low
274           Low         High           High        D7        A8        Low
276       MedHigh         High           High        D8        A8        Low
279          High          Low           High        D5        A5     MedLow
281       MedHigh         High           High        D7        A8        Low
283       MedHigh         High            Low        D6        A6        Low
285           Low         High           High        D8        A3     MedLow
286          High         High           High        D5        A6        Low
290           Low         High            Low        D7        A8        Low
295           Low         High           High        D4        A4        Low
296        MedLow         High           High        D4        A5        Low
300          High          Low           High        D5        A5        Low
303          High          Low           High        D6        A7        Med
310           Low         High            Low        D7        A8        Low
311        MedLow         High           High        D6        A7        Low
317        MedLow         High            Low        D8        A8        Low
318           Med         High            Low        D6        A6        Low
326          High         High           High        D5        A6        Low
327           Med         High            Low        D5        A6        Low
337           Low         High            Low        D7        A8        Low
338       MedHigh         High            Low        D7        A7     MedLow
343           Low         High           High        D4        A5        Low
351          High          Low           High        D6        A7    MedHigh
352           Low         High            Low        D7        A8        Low
354          High         High           High        D4        A5        Med
356           Low         High            Low        D8        A8        Low
357           Low         High           High        D4        A4     MedLow
359          High          Low           High        D4        A5        Low
362           Med         High            Low        D5        A6        Low
363          High         High           High        D6        A7        Med
364          High          Low           High        D7        A7        Low
365          High          Low           High        D7        A8        Med
369          High         High           High        D5        A6        Med
370          High         High           High        D6        A7        Med
377          High          Low           High        D6        A7        Med
382          High         High           High        D7        A8        Med
390          High          Low           High        D6        A7     MedLow
395           Low         High           High        D3        A3        Low
400        MedLow         High            Low        D6        A6     MedLow
401          High          Low           High        D6        A7        Med
402          High          Low           High        D6        A7     MedLow
404           Med         High           High        D6        A7     MedLow
405          High          Low           High        D6        A8        Med
406          High          Low           High        D6        A7        Med
408           Low         High           High        D5        A6     MedLow
411          High          Low           High        D1        A2     MedLow
413        MedLow         High            Low        D6        A7        Low
418        MedLow         High            Low        D8        A8        Low
419           Low         High            Low        D5        A6        Low
427           Low         High           High        D3        A3     MedLow
429           Med         High            Low        D8        A8        Low
434          High         High           High        D4        A5     MedLow
435           Low         High           High        D7        A8        Low
436           Med         High           High        D8        A8     MedLow
438        MedLow         High           High        D4        A5     MedLow
440          High         High           High        D4        A5        Low
445       MedHigh         High            Low        D6        A7        Low
446          High          Low           High        D5        A5    MedHigh
447          High         High            Low        D6        A7        Low
448           Med         High           High        D7        A8     MedLow
450           Low         High            Low        D8        A8        Low
458          High         High            Low        D7        A8     MedLow
459        MedLow         High           High        D6        A6     MedLow
463           Low         High           High        D5        A6        Low
466           Low         High            Low        D3        A4     MedLow
467          High          Low           High        D6        A7        Med
482        MedLow         High           High        D7        A8     MedLow
488           Med         High           High        D4        A5     MedLow
489          High         High           High        D5        A6     MedLow
495           Low         High            Low        D4        A4        Low
497           Med         High           High        D4        A4        Low
498           Med         High           High        D4        A5     MedLow
501          High         High           High        D4        A5        Low
503          High         High           High        D5        A5     MedLow
504          High          Low           High        D5        A6        Low
505           Med         High            Low        D5        A5        Low
518          High         High           High        D6        A7     MedLow
519        MedLow         High           High        D6        A7     MedLow
520          High         High           High        D5        A6        Med
522           Low         High            Low        D7        A8        Low
531          High          Low           High        D4        A5    MedHigh
532        MedLow         High            Low        D7        A8     MedLow
535          High         High           High        D4        A6        Med
544          High          Low           High        D5        A6    MedHigh
545           Med         High            Low        D7        A8     MedLow
553        MedLow         High            Low        D7        A8     MedLow
561          High         High           High        D4        A5     MedLow
562          High         High           High        D5        A6     MedLow
564          High          Low           High        D7        A8     MedLow
568          High         High            Low        D7        A8     MedLow
584          High         High           High        D5        A7     MedLow
590           Med         High           High        D4        A5     MedLow
592          High          Low           High        D6        A7        Med
593          High         High           High        D5        A6        Med
596          High         High           High        D5        A5     MedLow
597       MedHigh         High            Low        D7        A8        Low
598           Med         High            Low        D7        A8     MedLow
610           Low         High            Low        D4        A4        Low
614          High          Low           High        D5        A5        Low
615        MedLow         High            Low        D7        A7     MedLow
628        MedLow         High            Low        D7        A8        Low
629           Low         High           High        D8        A8        Low
638           Low         High           High        D3        A4     MedLow
639        MedLow         High           High        D4        A5     MedLow
644          High          Low           High        D4        A5     MedLow
647           Low         High           High        D4        A4        Low
653          High          Low           High        D7        A7        Low
655           Low         High            Low        D8        A8        Low
657          High         High           High        D7        A8        Low
662           Low         High           High        D4        A5        Low
664          High         High           High        D5        A6        Med
668          High          Low           High        D5        A6    MedHigh
677          High         High           High        D4        A5        Med
687          High         High           High        D6        A6        Med
688        MedLow         High            Low        D5        A6        Low
692          High          Low           High        D6        A6    MedHigh
697          High         High           High        D4        A5        Low
702       MedHigh         High           High        D4        A5     MedLow
703           Med         High            Low        D5        A6        Low
706        MedLow         High            Low        D8        A8        Low
717        MedLow         High            Low        D8        A8        Low
721          High          Low           High        D6        A7        Med
724           Low         High            Low        D7        A8        Low
729           Med         High            Low        D6        A6     MedLow
735        MedLow         High            Low        D3        A4        Low
737          High         High           High        D6        A7        Med
744        MedLow         High            Low        D8        A8        Low
745           Med         High           High        D4        A5        Low
747           Med         High           High        D5        A6     MedLow
750           Low         High           High        D3        A4        Low
751          High         High            Low        D5        A5        Low
758          High         High           High        D5        A6        Med
766          High         High            Low        D5        A5        Low
767           Low         High            Low        D5        A5        Low
768          High         High            Low        D5        A5        Low
772          High         High            Low        D7        A8     MedLow
773        MedLow         High           High        D7        A8     MedLow
780           Low         High            Low        D7        A8     MedLow
781           Low         High            Low        D5        A6        Low
787           Low         High            Low        D7        A7        Low
800           Low         High            Low        D6        A6        Low
809       MedHigh         High           High        D4        A5        Med
812           Low         High           High        D5        A6     MedLow
813          High          Low           High        D6        A6        Low
820           Low         High            Low        D7        A8        Low
822           Med         High            Low        D8        A8     MedLow
831           Med         High           High        D6        A7        Low
836           Low         High            Low        D4        A4     MedLow
839           Med         High            Low        D5        A5        Low
848           Low          Low           High        D2        A3        Low
851       MedHigh         High           High        D3        A4        Med
854       MedHigh         High            Low        D5        A6     MedLow
857           Low         High            Low        D3        A4     MedLow
872           Low          Low           High        D3        A3        Low
873           Low         High           High        D3        A4     MedLow
877       MedHigh         High            Low        D7        A8     MedLow
891           Low         High           High        D4        A5     MedLow
893        MedLow         High            Low        D3        A4     MedLow
894           Low         High           High        D4        A4        Low
895          High          Low           High        D6        A7        Med
900           Low         High           High        D4        A5        Low
906          High         High           High        D5        A5        Med
912       MedHigh         High            Low        D5        A6     MedLow
913           Low          Low           High        D3        A3     MedLow
918           Low         High           High        D3        A3     MedLow
922       MedHigh         High            Low        D4        A4        Low
926       MedHigh         High            Low        D6        A7     MedLow
942          High         High           High        D5        A6        Med
947           Low         High           High        D3        A4        Med
948          High          Low           High        D4        A5     MedLow
953           Low         High           High        D3        A5        Med
956          High          Low           High        D4        A5        Med
961           Low         High            Low        D8        A8     MedLow
962        MedLow         High           High        D8        A8        Low
975       MedHigh         High           High        D6        A7     MedLow
977           Low          Low           High        D3        A4        Low
980          High         High            Low        D6        A7        Low
982        MedLow         High            Low        D4        A5        Low
985           Low          Low           High        D3        A3    MedHigh
988           Low          Low           High        D3        A3    MedHigh
998           Low         High           High        D3        A3     MedLow
1001          Low          Low           High        D3        A3    MedHigh
1002          Low         High           High        D3        A4        Low
1003          Low         High           High        D3        A4        Low
1010          Low         High            Low        D7        A8        Low
1013          Med         High            Low        D4        A5        Low
1014         High         High           High        D4        A5        Med
1023       MedLow         High            Low        D4        A4        Low
1024      MedHigh         High            Low        D4        A4        Low
1025          Med         High            Low        D5        A5        Low
1048          Med         High           High        D5        A6        Low
1051          Low         High           High        D3        A4        Med
1056          Low          Low           High        D2        A3     MedLow
1058       MedLow         High            Low        D3        A4        Low
1062         High         High            Low        D7        A8     MedLow
1068          Low         High           High        D3        A4     MedLow
1076          Low         High           High        D3        A4        Med
1081          Low         High           High        D3        A3     MedLow
1082          Low         High           High        D3        A3        Med
1098       MedLow         High            Low        D8        A8        Low
1099          Low         High            Low        D8        A8        Low
1104         High          Low           High        D7        A7        Low
1105          Low         High            Low        D8        A8        Low
1106          Low          Low           High        D3        A4        Low
1109         High          Low           High        D4        A5        Med
1110          Low         High           High        D3        A4        Med
1113          Low         High            Low        D3        A4     MedLow
1129          Low         High            Low        D4        A4        Low
1136          Low         High           High        D3        A4        Low
1143          Low         High            Low        D5        A6        Low
1144         High         High           High        D7        A8        Med
1147          Low         High            Low        D7        A8        Low
1149          Low          Low           High        D3        A3    MedHigh
1152          Low         High           High        D2        A3        Med
1153          Low          Low           High        D3        A3    MedHigh
1179          Low         High           High        D3        A4        Med
1180          Low         High           High        D3        A3        Med
1181          Low         High           High        D3        A5        Med
1182         High         High           High        D5        A6        Med
1196          Low         High           High        D3        A3        Med
1205      MedHigh         High            Low        D4        A4        Low
1207          Low         High           High        D3        A3        Med
1208          Low         High           High        D4        A5     MedLow
1211          Low         High           High        D3        A4        Med
1213          Low         High           High        D2        A3     MedLow
1214          Low         High           High        D3        A4     MedLow
1226         High          Low           High        D6        A7    MedHigh
1242         High         High            Low        D4        A4        Low
1245         High          Low           High        D6        A6    MedHigh
1257         High          Low           High        D5        A5    MedHigh
1268          Low         High           High        D3        A3        Low
1273          Low         High           High        D3        A3        Med
1274          Low          Low           High        D4        A4       High
1283          Low         High            Low        D8        A8        Low
1302          Low          Low           High        D3        A3    MedHigh
1306          Low          Low           High        D3        A3    MedHigh
1308      MedHigh         High           High        D5        A6     MedLow
1309          Med         High            Low        D3        A4        Low
1311         High          Low           High        D4        A5    MedHigh
1331          Low         High           High        D3        A3     MedLow
1363          Low          Low           High        D2        A3    MedHigh
1370          Low          Low           High        D2        A3    MedHigh
1387          Low         High           High        D3        A3        Med
     TRNRANKGRP ARRRANKGRP LEGTYPE DEPSPOKE ARRSPOKE xDURN2 xAVAILBUCKET
2           Low    MedHigh    Weak    FALSE    FALSE      2           10
5           Low    MedHigh    Weak     TRUE    FALSE      2            0
7           Low        Med    Weak    FALSE     TRUE      2            5
13       MedLow     MedLow    Weak    FALSE     TRUE      2           15
14          Low    MedHigh    Weak    FALSE     TRUE      2           15
17          Med    MedHigh    Weak    FALSE    FALSE      2           10
18          Med    MedHigh    Weak     TRUE    FALSE      2            5
20          Low    MedHigh    Weak     TRUE    FALSE      1            0
33       MedLow    MedHigh    Weak     TRUE    FALSE      3           15
34          Low        Med    Weak    FALSE     TRUE      1           20
36          Low    MedHigh    Weak     TRUE    FALSE      2            0
37       MedLow    MedHigh    Weak     TRUE    FALSE      4            0
43       MedLow       High    Weak    FALSE     TRUE      1            0
44          Low     MedLow    Weak    FALSE     TRUE      2            5
45          Low     MedLow    Weak    FALSE     TRUE      1           15
46          Low    MedHigh    Weak     TRUE    FALSE      2            5
57          Low    MedHigh    Weak    FALSE     TRUE      2           20
63          Low        Med    Weak    FALSE     TRUE      2           15
68       MedLow    MedHigh    Weak     TRUE    FALSE      3            5
71          Low        Low    Weak    FALSE     TRUE      2           25
74          Med       High    Weak     TRUE    FALSE      4            5
76          Low    MedHigh    Weak     TRUE    FALSE      3            0
81          Low     MedLow    Weak    FALSE     TRUE      2           15
82          Low        Med    Weak    FALSE     TRUE      2           20
83          Low    MedHigh    Weak     TRUE    FALSE      2            5
84          Low    MedHigh    Weak    FALSE    FALSE      1           30
86          Low        Med    Weak    FALSE     TRUE      1           15
87       MedLow    MedHigh    Weak    FALSE     TRUE      1           15
88          Low        Med    Weak    FALSE     TRUE      2           20
99          Low    MedHigh    Weak    FALSE    FALSE      2           15
103         Low        Med    Weak    FALSE     TRUE      2           20
108         Low     MedLow    Weak    FALSE     TRUE      1           10
114      MedLow    MedHigh    Weak     TRUE    FALSE      4            0
117         Low    MedHigh    Weak     TRUE    FALSE      2            5
123         Low     MedLow    Weak    FALSE     TRUE      1           25
133         Low    MedHigh    Weak     TRUE    FALSE      2            5
134         Low     MedLow    Weak    FALSE     TRUE      2           10
140         Low    MedHigh    Weak     TRUE    FALSE      2           10
143         Low     MedLow    Weak    FALSE     TRUE      2           10
144         Low        Med    Weak    FALSE     TRUE      2           15
147      MedLow    MedHigh    Weak     TRUE    FALSE      4           15
150      MedLow    MedHigh    Weak     TRUE    FALSE      2           10
155      MedLow    MedHigh    Weak     TRUE    FALSE      2            0
165      MedLow    MedHigh    Weak    FALSE     TRUE      1           30
170         Low        Low    Weak    FALSE     TRUE      2            5
171      MedLow    MedHigh    Weak     TRUE    FALSE      2            5
172         Low        Low    Weak    FALSE     TRUE      2           15
184         Low        Med    Weak     TRUE    FALSE      2           10
186         Low     MedLow    Weak    FALSE     TRUE      2           30
188         Low       High    Weak    FALSE     TRUE      2           15
189         Low        Med    Weak    FALSE     TRUE      2           20
196         Low     MedLow    Weak    FALSE     TRUE      1           25
197      MedLow       High    Weak     TRUE    FALSE      4           20
199         Low        Med    Weak    FALSE     TRUE      1           30
202     MedHigh    MedHigh    Weak     TRUE    FALSE      2           10
205         Low     MedLow    Weak    FALSE     TRUE      2            5
208      MedLow    MedHigh    Weak     TRUE    FALSE      3           10
213      MedLow    MedHigh    Weak     TRUE    FALSE      1            0
214         Low     MedLow    Weak    FALSE     TRUE      2            5
215         Low       High    Weak    FALSE     TRUE      2           30
217         Low    MedHigh    Weak     TRUE    FALSE      2            5
218      MedLow    MedHigh    Weak     TRUE    FALSE      1            5
223         Low    MedHigh    Weak     TRUE    FALSE      2           20
227         Low    MedHigh    Weak    FALSE    FALSE      1           15
228         Low     MedLow    Weak    FALSE     TRUE      1           10
229     MedHigh    MedHigh    Weak     TRUE    FALSE      2            0
232         Low     MedLow    Weak    FALSE     TRUE      2           15
233         Low        Med    Weak    FALSE     TRUE      2           -1
234      MedLow    MedHigh    Weak     TRUE    FALSE      2            5
238         Med    MedHigh    Weak     TRUE    FALSE      2            0
242         Low     MedLow    Weak    FALSE     TRUE      2           30
249         Low    MedHigh    Weak     TRUE    FALSE      1           10
250         Low    MedHigh    Weak     TRUE    FALSE      1            5
256         Low        Low    Weak    FALSE     TRUE      1           25
260         Low    MedHigh    Weak    FALSE     TRUE      1           15
262      MedLow    MedHigh    Weak     TRUE    FALSE      3            5
266         Med    MedHigh    Weak     TRUE    FALSE      2            5
267         Low    MedHigh    Weak    FALSE     TRUE      2           15
274         Low        Med    Weak    FALSE    FALSE      2           15
276         Low     MedLow    Weak    FALSE     TRUE      1           20
279         Low    MedHigh    Weak     TRUE    FALSE      1           15
281         Low     MedLow    Weak    FALSE     TRUE      1           15
283         Low    MedHigh    Weak    FALSE     TRUE      1           15
285      MedLow    MedHigh    Weak     TRUE    FALSE      8           30
286         Low    MedHigh    Weak    FALSE     TRUE      2           10
290         Low       High    Weak    FALSE     TRUE      1           30
295         Low     MedLow    Weak    FALSE     TRUE      2           10
296         Low     MedLow    Weak    FALSE     TRUE      2           10
300         Low    MedHigh    Weak     TRUE    FALSE      1           15
303         Med    MedHigh    Weak     TRUE    FALSE      4            5
310         Low    MedHigh    Weak    FALSE     TRUE      1           30
311         Low        Med    Weak    FALSE    FALSE      2           30
317         Low     MedLow    Weak    FALSE     TRUE      1           25
318         Low    MedHigh    Weak    FALSE     TRUE      0            5
326         Low     MedLow    Weak    FALSE     TRUE      2           20
327         Low     MedLow    Weak    FALSE     TRUE      2           15
337         Low    MedHigh    Weak    FALSE     TRUE      1           10
338      MedLow       High    Weak    FALSE     TRUE      2           30
343         Low        Med    Weak    FALSE    FALSE      1           15
351         Med    MedHigh    Weak     TRUE    FALSE      3            0
352         Low        Low    Weak    FALSE     TRUE      1           10
354      MedLow    MedHigh    Weak     TRUE    FALSE      3            0
356         Low     MedLow    Weak    FALSE     TRUE      1           30
357      MedLow    MedHigh    Weak    FALSE     TRUE      1           10
359         Low        Med    Weak     TRUE    FALSE      3           10
362         Low     MedLow    Weak    FALSE     TRUE      2           15
363         Med    MedHigh    Weak     TRUE    FALSE      2           30
364         Low        Med    Weak     TRUE    FALSE      2            5
365         Med    MedHigh    Weak     TRUE    FALSE      3            0
369         Med    MedHigh    Weak     TRUE    FALSE      3           15
370      MedLow    MedHigh    Weak     TRUE    FALSE      3            0
377         Med    MedHigh    Weak     TRUE    FALSE      3            5
382         Med    MedHigh    Weak     TRUE    FALSE      1           15
390         Low    MedHigh    Weak     TRUE    FALSE      2           10
395         Low     MedLow    Weak    FALSE     TRUE      1           30
400         Med     MedLow    Weak    FALSE     TRUE      2           15
401         Med    MedHigh    Weak     TRUE    FALSE      3            5
402         Low    MedHigh    Weak     TRUE    FALSE      2           10
404      MedLow        Med    Weak    FALSE    FALSE      1           30
405         Med    MedHigh    Weak     TRUE    FALSE      4           10
406      MedLow    MedHigh    Weak     TRUE    FALSE      2            5
408      MedLow    MedHigh    Weak    FALSE     TRUE      2           30
411      MedLow    MedHigh    Weak    FALSE    FALSE      5           30
413         Low    MedHigh    Weak    FALSE     TRUE      2           15
418         Low     MedLow    Weak    FALSE     TRUE      1           30
419         Low    MedHigh    Weak    FALSE     TRUE      1            5
427      MedLow    MedHigh    Weak     TRUE    FALSE      2           30
429         Low       High    Weak    FALSE     TRUE      1           30
434      MedLow     MedLow    Weak    FALSE     TRUE      3           10
435         Low     MedLow    Weak    FALSE     TRUE      2           20
436      MedLow    MedHigh    Weak    FALSE     TRUE      1           30
438      MedLow    MedHigh    Weak    FALSE    FALSE      2           20
440         Low    MedHigh    Weak    FALSE     TRUE      2           25
445         Low     MedLow    Weak    FALSE     TRUE      2           25
446     MedHigh    MedHigh    Weak     TRUE    FALSE      1            0
447         Low        Med    Weak    FALSE     TRUE      2           20
448      MedLow     MedLow    Weak    FALSE     TRUE      3           30
450         Low       High    Weak    FALSE     TRUE      1           20
458         Med     MedLow    Weak    FALSE     TRUE      2           30
459         Med    MedHigh    Weak    FALSE    FALSE      1           20
463         Low     MedLow    Weak    FALSE     TRUE      2           25
466         Med     MedLow    Weak    FALSE     TRUE      3            5
467         Med    MedHigh    Weak     TRUE    FALSE      3            5
482      MedLow     MedLow    Weak    FALSE     TRUE      2           30
488      MedLow     MedLow    Weak    FALSE     TRUE      1           20
489         Med    MedHigh    Weak    FALSE    FALSE      2           10
495         Low    MedHigh    Weak    FALSE     TRUE      1            5
497         Low        Med    Weak    FALSE     TRUE      1           30
498      MedLow    MedHigh    Weak     TRUE    FALSE      2            5
501         Low        Med    Weak    FALSE     TRUE      2           15
503      MedLow    MedHigh    Weak     TRUE    FALSE      2            5
504         Med    MedHigh    Weak     TRUE    FALSE      3            0
505         Low     MedLow    Weak    FALSE     TRUE      1            5
518      MedLow    MedHigh    Weak     TRUE    FALSE      3           20
519         Med    MedHigh    Weak    FALSE    FALSE      1            5
520         Med    MedHigh    Weak     TRUE    FALSE      3           10
522         Low     MedLow    Weak    FALSE     TRUE      2           15
531         Med    MedHigh    Weak     TRUE    FALSE      1            5
532      MedLow    MedHigh    Weak    FALSE     TRUE      3           30
535      MedLow    MedHigh    Weak     TRUE    FALSE      4            5
544         Med    MedHigh    Weak     TRUE    FALSE      3           20
545      MedLow     MedLow    Weak    FALSE     TRUE      3           30
553      MedLow     MedLow    Weak    FALSE     TRUE      1           30
561      MedLow    MedHigh    Weak     TRUE    FALSE      2           15
562      MedLow    MedHigh    Weak     TRUE    FALSE      2           30
564         Med    MedHigh    Weak     TRUE    FALSE      2           10
568      MedLow    MedHigh    Weak    FALSE     TRUE      1           30
584      MedLow    MedHigh    Weak     TRUE    FALSE      7            5
590      MedLow     MedLow    Weak    FALSE     TRUE      3           25
592         Low    MedHigh    Weak     TRUE    FALSE      1            5
593      MedLow    MedHigh    Weak     TRUE    FALSE      3            5
596         Med    MedHigh    Weak    FALSE    FALSE      1            5
597         Low     MedLow    Weak    FALSE     TRUE      3           20
598      MedLow        Low    Weak    FALSE     TRUE      3           30
610         Low    MedHigh    Weak    FALSE     TRUE      1           10
614         Low    MedHigh    Weak     TRUE    FALSE      1           15
615      MedLow    MedHigh    Weak    FALSE     TRUE      2           30
628         Low    MedHigh  Strong    FALSE     TRUE      2           30
629         Low        Med  Strong    FALSE    FALSE      1           30
638      MedLow     MedLow  Strong    FALSE     TRUE      3           -1
639      MedLow     MedLow  Strong    FALSE     TRUE      3           15
644         Low    MedHigh  Strong     TRUE    FALSE      2           10
647         Low     MedLow  Strong    FALSE     TRUE      2           15
653         Low    MedHigh  Strong     TRUE    FALSE      1           15
655         Low    MedHigh  Strong    FALSE     TRUE      1           15
657         Low    MedHigh  Strong    FALSE     TRUE      1           15
662         Low     MedLow  Strong    FALSE     TRUE      2           25
664      MedLow    MedHigh  Strong     TRUE    FALSE      5            0
668     MedHigh    MedHigh  Strong     TRUE    FALSE      2            5
677     MedHigh    MedHigh  Strong     TRUE    FALSE      2            0
687     MedHigh    MedHigh  Strong     TRUE    FALSE      1           30
688         Low    MedHigh  Strong    FALSE     TRUE      2           15
692     MedHigh    MedHigh  Strong     TRUE    FALSE      2           10
697         Low        Med  Strong    FALSE     TRUE      3           15
702      MedLow     MedLow  Strong    FALSE     TRUE      3           30
703         Low        Med  Strong    FALSE     TRUE      2           15
706         Low       High  Strong    FALSE     TRUE      1           15
717         Low        Med  Strong    FALSE     TRUE      1           25
721         Med    MedHigh  Strong     TRUE    FALSE      3           10
724         Low       High  Strong    FALSE     TRUE      2           25
729      MedLow    MedHigh  Strong    FALSE     TRUE      2           15
735         Low     MedLow  Strong    FALSE     TRUE      2           20
737      MedLow    MedHigh  Strong     TRUE    FALSE      3           15
744         Low        Med  Strong    FALSE     TRUE      1           30
745         Low        Med  Strong    FALSE     TRUE      2           25
747      MedLow    MedHigh  Strong    FALSE    FALSE      2           15
750         Low    MedHigh  Strong    FALSE    FALSE      2           10
751         Low     MedLow  Strong    FALSE     TRUE      1           15
758      MedLow    MedHigh  Strong     TRUE    FALSE      2            5
766         Low    MedHigh  Strong    FALSE     TRUE      1           10
767         Low       High  Strong    FALSE     TRUE      1           15
768         Low        Med  Strong    FALSE     TRUE      1           20
772         Med     MedLow  Strong    FALSE     TRUE      3           30
773      MedLow    MedHigh  Strong    FALSE    FALSE      2           30
780      MedLow    MedHigh  Strong    FALSE     TRUE      1           25
781         Low    MedHigh  Strong    FALSE     TRUE      1           10
787         Low        Low  Strong    FALSE     TRUE      2           30
800         Low        Med  Strong    FALSE     TRUE      1           20
809     MedHigh    MedHigh  Strong     TRUE    FALSE      2            5
812      MedLow    MedHigh  Strong    FALSE     TRUE      1           30
813         Low    MedHigh  Strong     TRUE    FALSE      1           15
820         Low    MedHigh  Strong    FALSE     TRUE      1           20
822      MedLow        Med  Strong    FALSE     TRUE      0           30
831         Low        Med  Strong    FALSE    FALSE      2           25
836      MedLow    MedHigh  Strong    FALSE     TRUE      2           25
839         Low    MedHigh  Strong    FALSE     TRUE      1           20
848         Low    MedHigh  Strong     TRUE    FALSE      1           30
851         Med    MedHigh  Strong     TRUE    FALSE      2           25
854      MedLow    MedHigh  Strong    FALSE     TRUE      3           30
857      MedLow     MedLow  Strong    FALSE     TRUE      3           20
872         Low    MedHigh  Strong     TRUE    FALSE      2           30
873      MedLow    MedHigh  Strong     TRUE    FALSE      2           30
877      MedLow       High  Strong    FALSE     TRUE      1           30
891      MedLow    MedHigh  Strong    FALSE     TRUE      1            5
893      MedLow        Med  Strong    FALSE     TRUE      2           30
894         Low    MedHigh  Strong    FALSE     TRUE      2           15
895         Med    MedHigh  Strong     TRUE    FALSE      3           15
900         Low     MedLow  Strong    FALSE     TRUE      1           30
906     MedHigh    MedHigh  Strong     TRUE    FALSE      2           25
912      MedLow        Med  Strong    FALSE     TRUE      2           25
913         Med    MedHigh  Strong     TRUE    FALSE      2           30
918      MedLow    MedHigh  Strong     TRUE    FALSE      2           30
922         Low        Med  Strong    FALSE     TRUE      2           20
926         Med     MedLow  Strong    FALSE     TRUE      2           25
942      MedLow    MedHigh  Strong     TRUE    FALSE      2           25
947         Med    MedHigh  Strong     TRUE    FALSE      2           -1
948         Low    MedHigh  Strong     TRUE    FALSE      2           10
953      MedLow    MedHigh  Strong     TRUE    FALSE      4           30
956      MedLow    MedHigh  Strong     TRUE    FALSE      2            0
961      MedLow    MedHigh  Strong    FALSE     TRUE      1           30
962         Low    MedHigh  Strong    FALSE     TRUE      1           30
975      MedLow    MedHigh  Strong    FALSE     TRUE      2           30
977         Low        Med  Strong     TRUE    FALSE      2           30
980         Low     MedLow  Strong    FALSE     TRUE      2           25
982         Low     MedLow  Strong    FALSE     TRUE      3           15
985        High    MedHigh  Strong     TRUE    FALSE      1           30
988         Med    MedHigh  Strong     TRUE    FALSE      2           10
998      MedLow    MedHigh  Strong    FALSE     TRUE      1           -1
1001       High    MedHigh  Strong     TRUE    FALSE      1           30
1002        Low     MedLow  Strong    FALSE     TRUE      2           -1
1003        Low        Med  Strong    FALSE     TRUE      2           20
1010        Low    MedHigh  Strong    FALSE     TRUE      1           30
1013        Low     MedLow  Strong    FALSE     TRUE      2           20
1014        Med    MedHigh  Strong     TRUE    FALSE      2           30
1023        Low        Med  Strong    FALSE     TRUE      2           20
1024        Low        Low  Strong    FALSE     TRUE      2           30
1025        Low    MedHigh  Strong    FALSE     TRUE      1           15
1048        Low        Med  Strong    FALSE    FALSE      2           25
1051     MedLow    MedHigh  Strong     TRUE    FALSE      3           30
1056        Low    MedHigh  Strong     TRUE    FALSE      1           30
1058        Low     MedLow  Strong    FALSE     TRUE      2            5
1062        Med     MedLow  Strong    FALSE     TRUE      2           30
1068     MedLow    MedHigh  Strong     TRUE    FALSE      2           30
1076     MedLow    MedHigh  Strong     TRUE    FALSE      3           30
1081     MedLow    MedHigh  Strong     TRUE    FALSE      2           30
1082    MedHigh    MedHigh  Strong     TRUE    FALSE      2           30
1098        Low    MedHigh  Strong    FALSE     TRUE      1           30
1099        Low    MedHigh  Strong    FALSE     TRUE      0           30
1104        Low    MedHigh  Strong     TRUE    FALSE      1           15
1105        Low       High  Strong    FALSE     TRUE      1           25
1106        Low    MedHigh  Strong     TRUE    FALSE      4           30
1109        Med    MedHigh  Strong     TRUE    FALSE      3           20
1110     MedLow    MedHigh  Strong     TRUE    FALSE      3           30
1113     MedLow     MedLow  Strong    FALSE     TRUE      3           30
1129        Low     MedLow  Strong    FALSE     TRUE      1           30
1136        Low     MedLow  Strong    FALSE     TRUE      2           10
1143        Low       High  Strong    FALSE     TRUE      2           15
1144     MedLow    MedHigh  Strong     TRUE    FALSE      2           30
1147        Low       High  Strong    FALSE     TRUE      1           30
1149       High    MedHigh  Strong     TRUE    FALSE      1           30
1152     MedLow    MedHigh  Strong     TRUE    FALSE      3           30
1153        Med    MedHigh  Strong     TRUE    FALSE      1           30
1179     MedLow    MedHigh  Strong     TRUE    FALSE      4           30
1180    MedHigh    MedHigh  Strong     TRUE    FALSE      2           30
1181     MedLow    MedHigh  Strong     TRUE    FALSE      4           30
1182    MedHigh    MedHigh  Strong     TRUE    FALSE      2           25
1196        Med    MedHigh  Strong     TRUE    FALSE      2           30
1205        Low       High  Strong    FALSE     TRUE      2           20
1207        Med    MedHigh  Strong     TRUE    FALSE      2           30
1208     MedLow    MedHigh  Strong    FALSE     TRUE      3           30
1211     MedLow    MedHigh  Strong     TRUE    FALSE      2           30
1213     MedLow    MedHigh  Strong    FALSE    FALSE      2           30
1214     MedLow     MedLow  Strong    FALSE     TRUE      3           -1
1226    MedHigh    MedHigh  Strong     TRUE    FALSE      1           30
1242        Low    MedHigh  Strong    FALSE     TRUE      2           25
1245    MedHigh    MedHigh  Strong     TRUE    FALSE      1           20
1257    MedHigh    MedHigh  Strong     TRUE    FALSE      1           15
1268        Low    MedHigh  Strong    FALSE    FALSE      2           30
1273        Med    MedHigh  Strong     TRUE    FALSE      1           30
1274       High    MedHigh  Strong     TRUE    FALSE      1           30
1283        Low    MedHigh  Strong    FALSE     TRUE      1           30
1302    MedHigh    MedHigh  Strong     TRUE    FALSE      1           30
1306        Med    MedHigh  Strong     TRUE    FALSE      1           30
1308     MedLow     MedLow  Strong    FALSE     TRUE      2           30
1309        Low       High  Strong    FALSE     TRUE      1           15
1311    MedHigh    MedHigh  Strong     TRUE    FALSE      2           25
1331        Med    MedHigh  Strong    FALSE    FALSE      2           30
1363        Med    MedHigh  Strong     TRUE    FALSE      1           30
1370    MedHigh    MedHigh  Strong     TRUE    FALSE      1           30
1387        Med        Med  Strong     TRUE    FALSE      1           30
     xAVGSKDAVAIL
2    -0.635067532
5    -1.220310866
7    -0.717640228
13   -0.210978159
14   -0.230546855
17   -0.653556794
18   -0.946599414
20   -1.154577014
33   -0.365770781
34    0.015909655
36   -1.190052426
37   -1.042193330
43   -1.261275441
44   -0.766434264
45   -0.261607906
46   -0.755742401
57    0.037559156
63   -0.152850258
68   -0.802310982
71    0.347563251
74   -0.755791640
76   -1.244961061
81   -0.164373444
82    0.009298850
83   -1.001596411
84    1.051406519
86   -0.220567643
87   -0.316715666
88    0.161039096
99   -0.161462860
103   0.215101836
108  -0.532770298
114  -1.341357351
117  -0.927795222
123   0.476718099
133  -0.974230289
134  -0.487571743
140  -0.628706192
143  -0.455963741
144  -0.149788121
147  -0.287711830
150  -0.492652403
155  -1.103868042
165   1.065890250
170  -0.817783341
171  -0.745274224
172  -0.296451445
184  -0.622730387
186   1.893830408
188  -0.359569474
189   0.036217012
196   0.444658431
197   0.055412795
199   1.327406040
202  -0.564501033
205  -0.749794868
208  -0.371746585
213  -1.127321514
214  -0.717446893
215   0.777998258
217  -0.829367426
218  -1.009414756
223   0.028632336
227  -0.236569760
228  -0.370227313
229  -1.189635068
232  -0.313500488
233   0.620237011
234  -0.824081810
238  -1.223597559
242   0.834132881
249  -0.691845287
250  -0.879689993
256   0.355772906
260  -0.104438634
262  -0.799772604
266  -0.885925615
267  -0.334575054
274  -0.077701838
276   0.178881143
279  -0.211372661
281  -0.174982281
283  -0.145939535
285   3.266232603
286  -0.608359999
290   0.975452638
295  -0.461303980
296  -0.499673073
300  -0.264182099
303  -0.698822301
310   0.787672296
311   0.841341788
317   0.303519357
318  -0.775511796
326   0.077932726
327  -0.283603465
337  -0.443008058
338   0.699994085
343  -0.218367596
351  -1.204790373
352  -0.582514836
354  -1.095762514
356   0.671962010
357  -0.648426347
359  -0.694440044
362  -0.207858422
363   0.935994268
364  -0.704710959
365  -1.138673662
369  -0.183738573
370  -1.226884252
377  -0.882758650
382  -0.283968653
390  -0.622037540
395   1.045102157
400  -0.226335335
401  -0.770776131
402  -0.392583273
404   0.824357922
405  -0.570756611
406  -0.783374080
408   1.290357121
411   7.365844981
413  -0.076130992
418   1.484167647
419  -0.814404326
427   1.336952727
429   0.788471108
434  -0.541537387
435   0.014937784
436   1.974074659
438   0.047804710
440   0.324940319
445   0.584725619
446  -1.085289980
447   0.192078673
448   2.762065047
450   0.115989167
458   0.721695784
459  -0.016390851
463   0.589398907
466  -1.004025286
467  -1.023109308
482   1.751127580
488   0.021328575
489  -0.555123520
495  -0.782085181
497   0.920572718
498  -1.023109308
501  -0.281692597
503  -0.835166039
504  -1.074757335
505  -0.766915831
518   0.172926159
519  -0.759297446
520  -0.406977076
522  -0.194862763
531  -1.006326197
532   0.688709774
535  -0.760173897
544  -0.037101517
545   0.697214812
553   1.485901287
561  -0.333686400
562   0.685970864
564  -0.629946453
568   2.196910422
584  -0.996633173
590   0.615541736
592  -0.822826476
593  -0.886253582
596  -0.802431374
597   0.014546511
598   0.637962994
610  -0.612272728
614  -0.281777524
615   0.742575015
628   0.679856086
629   2.179825679
638  -2.009117100
639  -0.299244954
644  -0.605738942
647  -0.315028859
653  -0.194862763
655  -0.065273168
657  -0.201066857
662   0.325651967
664  -1.116408970
668  -0.744605353
677  -1.025042657
687   0.932051440
688  -0.280983637
692  -0.431504633
697  -0.288792979
702   0.655295065
703  -0.190480506
706  -0.204616819
717   0.580490961
721  -0.577579862
724   0.428324383
729  -0.086899890
735   0.022058951
737  -0.068972475
744   2.472736498
745   0.397274889
747  -0.219311143
750  -0.659518935
751  -0.133604407
758  -0.700760607
766  -0.657190861
767  -0.176641801
768   0.103130702
772   0.690353121
773   0.855440953
780   0.546990718
781  -0.579405802
787   0.644777649
800   0.227122793
809  -0.795923887
812   2.324704281
813  -0.163091401
820   0.201521374
822   1.490972394
831   0.500013254
836   0.532591874
839  -0.018017495
848   1.336952727
851   0.449865597
854   1.121457638
857   0.076106785
872   1.336952727
873   1.336952727
877   1.544893207
891  -0.805149691
893   0.771424872
894  -0.049236997
895  -0.310366533
900   0.971913123
906   0.293943670
912   0.467502471
913   1.336952727
918   1.336952727
922   0.153985264
926   0.535474938
942   0.453822194
947  -1.877649394
948  -0.373596239
953   1.336952727
956  -1.100794771
961   1.954634222
962   1.482183728
975   2.175938193
977   1.336952727
980   0.586374117
982  -0.251180686
985   1.336952727
988  -0.521888681
998  -2.009117100
1001  1.336952727
1002 -1.828349005
1003  0.004729117
1010  1.272440081
1013  0.027767417
1014  0.737414749
1023  0.071166005
1024  1.003371467
1025 -0.341867562
1048  0.484074030
1051  3.794795430
1056  1.336952727
1058 -0.803370429
1062  2.385464849
1068  1.336952727
1076  1.336952727
1081  1.336952727
1082  1.336952727
1098  1.639756178
1099  2.331371366
1104 -0.211765754
1105  0.403701966
1106  1.336952727
1109  0.266588883
1110  1.336952727
1113  1.336952727
1129  1.118542024
1136 -0.593311040
1143 -0.188083960
1144  0.958420385
1147  0.842435950
1149  1.336952727
1152  1.336952727
1153  1.336952727
1179  1.336952727
1180  1.336952727
1181  1.336952727
1182  0.434852774
1196  1.336952727
1205  0.174707564
1207  1.336952727
1208  0.693704258
1211  1.336952727
1213  1.336952727
1214 -1.779048615
1226  0.774029421
1242  0.474556580
1245 -0.013820777
1257 -0.235269749
1268  1.336952727
1273  1.336952727
1274  1.336952727
1283  1.351381970
1302  1.336952727
1306  1.336952727
1308  0.696241778
1309 -0.169612617
1311  0.424062544
1331  1.336952727
1363  1.336952727
1370  1.336952727
1387  1.336952727
> flight <- flight1
> src.adjust <- TRUE
> source(file = "flight1.R")
Warning message:
In eval(expr, envir, enclos) : adjusting
> flight1 <- flight
> 
> # This should be deleted, leave it in and the results are ideal because it defines LEGTYPE.
> flight$D00 <- NULL
> 
> ## Keep the results but don't change the order.
> outcomes.flight <- flight$LEGTYPE
> 
> flight$LEGTYPE <- NULL
> 
> ## If you know your factors are definitely factors, you don't need this
> ##  asNumeric <- function(x) as.numeric(as.character(x))
> 
> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))
> 
> flight.num0 <- factors.numeric(flight)
> 
> flight.scl0 <- scale(flight.num0)
> 
> ## Now split the samples
> ## we need at least 60 to test with, p at 0.77 gives about 75.
> ## Difficulty here is the bias in the table
> ## Because we only have [3.1, 4.4] the proportion of Weak is higher.
> ## see prop.table(results)
> 
> set.seed(seed.mine)
> inTrain <- createDataPartition(outcomes.flight, p = 0.77, list = FALSE)
> 
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> 
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> 
> prop.table(table(trainClass))
trainClass
   Strong      Weak 
0.3967611 0.6032389 
> dim(trainDescr)
[1] 247  20
> 
> prop.table(table(testClass))
testClass
   Strong      Weak 
0.3972603 0.6027397 
> dim(testDescr)
[1] 73 20
> flight1 <- flight
> src.adjust <- TRUE
> source(file = "flight1.R")
Warning message:
In eval(expr, envir, enclos) : adjusting
> flight1 <- flight
> 
> # This should be deleted, leave it in and the results are ideal because it defines LEGTYPE.
> flight$D00 <- NULL
> 
> ## Keep the results but don't change the order.
> outcomes.flight <- flight$LEGTYPE
> 
> flight$LEGTYPE <- NULL
> 
> ## If you know your factors are definitely factors, you don't need this
> ##  asNumeric <- function(x) as.numeric(as.character(x))
> 
> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))
> 
> flight.num0 <- factors.numeric(flight)
> 
> flight.scl0 <- scale(flight.num0)
> 
> ## Now split the samples
> ## we need at least 60 to test with, p at 0.77 gives about 75.
> ## Difficulty here is the bias in the table
> ## Because we only have [3.1, 4.4] the proportion of Weak is higher.
> ## see prop.table(results)
> 
> set.seed(seed.mine)
> inTrain <- createDataPartition(outcomes.flight, p = 0.77, list = FALSE)
> 
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> 
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> 
> prop.table(table(trainClass))
trainClass
Strong 
     1 
> dim(trainDescr)
[1] 247  20
> 
> prop.table(table(testClass))
testClass
Strong 
     1 
> dim(testDescr)
[1] 73 20
> flight1
     SDEPHR SKDDEPSTA SKDARRSTA SKDEQP SKDEPS    AVGSQ AVGLOFATC UPLINEATCIMP
2        14       CCC       PPP    734     32 3.258065  3.258065          Med
5        11       DTW       PPP    E90     72 2.986111  3.805556         High
7        14       CCC       LGA    321     88 2.551724  3.701149       MedLow
13       13       PPP       ORD    734     32 3.000000  3.903226          Med
14       16       CCC       BOS    321     72 3.295775  3.859155       MedLow
17       15       DDD       CCC    19W     84 3.939759  3.361446          Low
18       17       BOS       CCC    19W     63 4.213115  4.196721         High
20       17       TPA       CCC    734     90 4.388889  3.255556         High
33       16       ORD       PPP    734     32 4.000000  3.903226         High
34       22       CCC       EWR    321     64 5.111111  3.746032          Low
36       19       BWI       CCC    734     65 5.174603  3.412698         High
37       13       DFW       PPP    19W     31 2.870968  3.548387         High
43        9       PPP       DTW    E90     72 1.986111  3.805556          Low
44        9       CCC       MCO    321     44 1.886364  3.181818       MedLow
45       16       CCC       ORD    321     67 3.348485  3.954545          Med
46       17       FLL       CCC    734     90 4.449438  3.303371         High
57       20       CCC       BOS    321     83 4.358025  3.382716          Med
63       14       CCC       RSW    734     46 3.326087  3.108696       MedLow
68       17       DFW       CCC    734     39 4.025641  3.615385         High
71       19       CCC       ROC    319     84 5.321429  3.595238       MedLow
74       16       BOS       XHP    A05     62 3.816667  3.716667         High
76       16       MSY       CCC    734     64 4.656250  3.109375         High
81       14       CCC       DFW    734     51 3.156863  3.254902       MedLow
82       18       CCC       LAX    320     34 4.588235  3.294118          Low
83       19       FLL       CCC    321     55 4.600000  4.054545         High
84       22       CCC       PPP    734     59 5.881356  3.508475          Low
86       20       CCC       EWR    321     69 4.731343  3.910448      MedHigh
87       22       PPP       BOS    E90     69 5.925373  4.208955       MedLow
88       14       CCC       EWR    321     73 3.194444  4.027778      MedHigh
99       14       CCC       PPP    321     37 3.540541  3.405405       MedLow
103      18       CCC       SFO    321     49 3.918367  3.265306      MedHigh
108      18       CCC       ORD    321     75 4.351351  3.216216       MedLow
114      13       DFW       CCC    321     82 3.085366  3.243902         High
117      19       PBI       CCC    734     40 4.700000  3.175000         High
123      22       CCC       TPA    321     60 4.600000  3.416667          Med
133      15       TPA       CCC    320     39 4.179487  3.358974         High
134      17       CCC       JAX    734     35 4.500000  3.411765       MedLow
140      19       BDL       CCC    734     33 4.875000  3.343750         High
143      20       CCC       BDL    321     89 4.218391  3.321839          Med
144      18       CCC       LAX    321     56 4.017857  3.250000          Med
147      15       DFW       PPP    320     48 3.000000  3.854167         High
150      14       MIA       CCC    734     86 2.953488  3.267442         High
155      11       SRQ       CCC    19W     36 2.971429  3.714286         High
165      18       PPP       BOS    E90     64 4.200000  3.716667       MedLow
170      14       CCC       FLL    734     90 3.483146  3.303371          Low
171      19       MIA       CCC    734     75 4.773333  3.946667         High
172      16       CCC       FLL    321     56 3.607143  4.053571      MedHigh
184      18       TPA       DDD    319     33 4.969697  3.303030         High
186      22       CCC       MIA    734     33 5.424242  3.333333       MedLow
188      14       CCC       PIT    319     53 3.849057  3.264151       MedLow
189      16       CCC       RSW    734     53 3.792453  3.169811          Low
196      22       CCC       BDL    734     78 5.697368  3.302632          Low
197      16       JFK       XHP    A21     56 3.000000  3.518519         High
199      22       CCC       LGA    319     65 5.937500  3.765625       MedLow
202      17       LGA       CCC    321     88 3.558140  3.732558         High
205      14       CCC       BDL    734     77 3.460526  3.157895          Low
208      13       ORD       PPP    320     68 3.015152  3.530303         High
213      16       RDU       CCC    734     41 4.609756  3.634146         High
214      19       CCC       MIA    734     41 5.400000  3.275000          Low
215      19       CCC       CLE    19W     41 5.146341  3.219512          Low
217      10       TPA       CCC    734     80 2.725000  3.450000         High
218      11       RDU       CCC    320     48 2.937500  3.500000         High
223      11       TPA       CCC    321     39 2.026316  3.473684         High
227      13       CCC       PPP    19W     60 3.516667  4.083333          Med
228      16       CCC       JAX    19W     60 3.883333  3.216667          Low
229      17       JAX       CCC    19W     60 4.883333  3.216667         High
232      16       CCC       MIA    734     88 3.738636  3.693182          Low
233      17       CCC       BWI    734     65 4.174603  3.412698       MedLow
234      17       ATT       PPP    E90     72 4.722222  4.013889         High
238      17       BNA       CCC    19W     61 5.366667  4.333333         High
242      18       CCC       DFW    321     66 3.893939  3.151515      MedHigh
249      19       MCO       CCC    321     76 4.526316  3.552632         High
250      17       MCO       CCC    321     88 4.181818  3.465909         High
256      22       CCC       FLL    321     43 4.837209  3.581395       MedLow
260      18       CCC       STL    19W     84 5.144578  4.048193      MedHigh
262       9       ORD       CCC    A05     89 1.976744  3.813953         High
266      17       RSW       CCC    734     46 4.326087  3.108696         High
267      14       CCC       BOS    19W     63 3.131148  3.983607       MedLow
274      19       CCC       DDD    19W     68 5.441176  3.411765          Low
276      22       CCC       ORD    321     78 5.168831  4.038961      MedHigh
279      12       MCO       CCC    321     44 2.790698  3.325581         High
281      20       CCC       ORD    321     86 4.905882  4.188235      MedHigh
283      16       CCC       MCI    319     64 4.177419  4.258065      MedHigh
285      22       LAX       CCC    A21     79 4.620253  3.113924          Low
286      13       CCC       BOS    A05     89 2.872093  3.755814         High
290      20       CCC       PIT    19W     52 5.576923  3.288462          Low
295       9       CCC       JFK    319     77 1.986842  3.960526          Low
296      11       CCC       DFW    321     82 2.085366  3.243902       MedLow
300      12       BWI       CCC    734     45 2.977273  3.590909         High
303      15       IAH       CCC    320     30 4.433333  4.000000         High
310      20       CCC       IAH    320     53 4.415094  3.150943          Low
311      17       CCC       DDD    19W     48 4.270833  4.104167       MedLow
317      22       CCC       MCO    321     33 4.909091  3.515152       MedLow
318      16       CCC       BNA    19W     61 4.366667  4.333333          Med
326      13       CCC       JFK    A21     90 2.000000  3.454545         High
327      14       CCC       TPA    734     90 3.355556  3.244444          Med
337      20       CCC       PVD    734     83 5.345679  3.172840          Low
338      18       PPP       PIT    E90     78 4.371795  3.397436      MedHigh
343      11       CCC       DDD    319     68 2.029851  3.910448          Low
351      16       PVD       CCC    319     74 4.694444  3.486111         High
352      20       CCC       FLL    321     37 4.540541  3.243243          Low
354      10       DFW       CCC    321     61 2.180328  4.229508         High
356      22       CCC       JAX    734     61 5.950820  3.393443          Low
357       9       PPP       BOS    E90     64 1.952381  4.063492          Low
359      11       PBI       DDD    19W     32 3.000000  3.161290         High
362      14       CCC       MCO    321     88 3.250000  3.488636          Med
363      16       BOS       PPP    E90     64 3.542373  3.711864         High
364      18       PBI       DDD    319     32 5.062500  3.625000         High
365      18       MCI       CCC    319     64 5.177419  4.258065         High
369      14       BOS       CCC    321     67 2.984615  3.846154         High
370      17       ORD       CCC    321     51 4.260000  4.220000         High
377      16       STL       CCC    319     38 4.918919  3.162162         High
382      20       BOS       PPP    E90     49 5.333333  4.111111         High
390      17       MCO       CCC    734     71 4.666667  3.130435         High
395       7       CCC       ORD    A05     85 1.012048  3.843373          Low
400      15       DDD       TPA    319     33 3.969697  3.303030       MedLow
401      15       MCI       CCC    19W     33 4.322581  3.258065         High
402      17       BDL       CCC    734     77 4.460526  3.157895         High
404      17       PPP       DDD    19W     77 4.131579  3.986842          Med
405      17       IAH       PPP    E90     77 4.697368  3.473684         High
406      17       RDU       PPP    E90     69 4.632353  3.764706         High
408      14       PPP       ATT    E90     72 3.722222  4.013889          Low
411       0       XHP       CCC    321     50 1.000000  3.640000         High
413      16       CCC       SYR    19W     64 4.375000  3.750000       MedLow
418      22       CCC       PBI    734     78 5.589744  3.487179       MedLow
419      14       CCC       RDU    734     42 3.595238  3.619048          Low
427       6       JFK       CCC    19W     87 1.000000  3.710843          Low
429      22       CCC       PIT    321     59 4.762712  3.610169          Med
434      11       PPP       DFW    320     48 2.000000  3.854167         High
435      20       CCC       DFW    734     48 5.520833  3.270833          Low
436      21       PPP       BOS    19W     48 4.787234  3.510638          Med
438      10       PPP       CCC    320     51 1.980392  3.294118       MedLow
440      11       CCC       BOS    321     68 1.984848  3.848485         High
445      16       CCC       MCO    321     88 3.545455  3.454545      MedHigh
446      12       PIT       CCC    734     37 2.972973  3.756757         High
447      16       CCC       RSW    321     37 3.891892  4.108108         High
448      18       PPP       DFW    19W     37 3.864865  3.189189          Med
450      22       CCC       BUF    734     77 5.842105  3.421053          Low
458      19       DDD       TPA    19W     46 5.173913  4.260870         High
459      15       DDD       PPP    19W     75 3.890411  4.109589       MedLow
463      13       CCC       MIA    734     81 2.654321  3.370370          Low
466       8       DDD       PBI    19W     32 2.000000  3.161290          Low
467      17       MSP       CCC    319     32 4.687500  3.281250         High
482      20       PPP       ORD    320     50 4.224490  3.122449       MedLow
488      11       PPP       ORD    320     68 2.015152  3.530303          Med
489      13       DDD       CCC    319     68 3.298507  4.283582         High
495       9       CCC       RDU    320     48 1.937500  3.500000          Low
497      10       CCC       LGA    321     90 1.640449  4.191011          Med
498      10       MIA       CCC    734     69 1.637681  3.637681          Med
501      11       CCC       LGA    321     90 2.011236  3.865169         High
503      12       JFK       CCC    319     72 2.985915  3.957746         High
504      12       NAS       CCC    734     84 2.940476  3.214286         High
505      13       CCC       TPA    320     39 3.179487  3.358974          Med
518      16       MIA       PPP    734     82 3.670732  3.390244         High
519      17       DDD       CCC    319     76 4.333333  3.800000       MedLow
520      12       BOS       CCC    321     70 2.955224  4.119403         High
522      20       CCC       PBI    734     67 5.378788  3.181818          Low
531      11       ORF       CCC    319     49 3.042553  4.085106         High
532      18       PPP       IAH    E90     49 4.326531  3.204082       MedLow
535      11       DFW       PPP    19W     46 2.021739  4.043478         High
544      12       PVD       CCC    734     40 2.925000  3.500000         High
545      20       PPP       TPA    734     77 4.960526  3.460526          Med
553      20       PPP       BDL    19W     68 4.537313  3.298507       MedLow
561      11       MIA       CCC    734     84 2.011905  3.916667         High
562      14       MIA       PPP    734     84 3.000000  3.228916         High
564      19       RSW       CCC    734     53 4.792453  3.169811         High
568      20       PPP       PVD    E90     72 5.549296  4.042254         High
584      13       LAX       CCC    321     73 2.972222  3.750000         High
590       9       PPP       DFW    19W     32 1.875000  3.531250          Med
592      17       DTW       CCC    19W     64 4.921875  3.578125         High
593      12       DFW       CCC    321     61 2.918033  3.573770         High
596      12       DDD       CCC    319     45 2.840909  4.159091         High
597      18       CCC       SEA    321     45 3.711111  3.111111      MedHigh
598      18       PPP       SAT    E90     90 4.333333  3.244444          Med
610       9       CCC       ORF    319     49 2.041667  4.041667          Low
614      12       BWI       CCC    321     36 2.944444  3.861111         High
615      18       PPP       RDU    E90     72 4.416667  3.194444       MedLow
628      19       CCC       ORF    319     86 5.302326  3.418605       MedLow
629      22       CCC       DDD    19W     63 5.709677  3.387097          Low
638       7       PPP       MIA    734     84 1.011905  3.916667          Low
639       9       PPP       MIA    734     84 2.000000  3.202381       MedLow
644      10       MCO       CCC    321     88 2.494253  3.275862         High
647       9       CCC       DFW    321     61 1.918033  3.573770          Low
653      18       BWI       PPP    319     51 5.120000  3.320000         High
655      22       CCC       PVD    734     65 5.859375  3.453125          Low
657      20       CCC       ATT    321     89 4.584270  3.662921         High
662      11       CCC       MIA    734     86 1.953488  3.267442          Low
664      12       DFW       PPP    319     31 2.935484  3.774194         High
668      13       JAX       CCC    319     76 3.605263  3.723684         High
677      10       EWR       CCC    320     35 2.205882  4.235294         High
687      15       EWR       CCC    321     81 2.974359  3.474359         High
688      14       CCC       PVD    319     74 3.694444  3.486111       MedLow
692      15       PIT       CCC    734     60 4.237288  3.288136         High
697       9       CCC       LAX    321     78 1.974359  3.602564         High
702       9       PPP       DFW    319     32 1.937500  3.781250      MedHigh
703      14       CCC       MSP    319     32 3.687500  3.281250          Med
706      22       CCC       DTW    321     32 4.937500  3.531250       MedLow
717      22       CCC       RSW    321     43 4.395349  3.162791       MedLow
721      15       MCI       CCC    320     36 4.305556  3.111111         High
724      20       CCC       BUF    734     90 5.222222  3.188889          Low
729      15       PPP       RDU    E90     69 3.623188  3.782609          Med
735       7       CCC       MCO    321     84 1.583333  3.273810       MedLow
737      16       ORD       PPP    19W     33 3.242424  3.727273         High
744      22       CCC       MSP    320     33 5.424242  3.787879       MedLow
745      11       CCC       EWR    321     81 1.974359  3.474359          Med
747      13       PPP       CCC    320     59 2.355932  3.406780          Med
750       7       CCC       PPP    320     48 1.416667  3.229167          Low
751      13       CCC       JAX    319     48 3.020833  3.770833         High
758      14       ATT       PPP    E90     52 3.115385  3.230769         High
766      13       CCC       IAH    320     30 3.433333  4.000000         High
767      13       CCC       PIT    734     60 3.237288  3.288136          Low
768      13       CCC       BWI    320     60 3.533333  3.966667         High
772      19       DDD       TPA    19W     30 5.100000  3.866667         High
773      20       PPP       CCC    319     64 5.171875  3.437500       MedLow
780      20       PPP       RDU    E90     72 5.585714  3.800000          Low
781      14       CCC       STL    319     38 3.918919  3.162162          Low
787      18       CCC       SAT    319     77 5.012987  3.480519          Low
800      16       CCC       BWI    319     51 4.117647  3.294118          Low
809      10       LGA       CCC    319     76 2.108108  4.270270      MedHigh
812      14       PPP       BOS    E90     64 2.610169  3.661017          Low
813      15       BWI       CCC    320     60 4.533333  3.966667         High
820      20       CCC       MCI    319     76 6.253333  3.853333          Low
822      21       PPP       BWI    19W     72 4.842857  3.885714          Med
831      16       CCC       DDD    320     78 3.435897  3.538462          Med
836       9       PPP       RDU    19W     33 2.000000  3.212121          Low
839      13       CCC       MCI    19W     33 3.322581  3.258065          Med
848       5       BWI       CCC    19W     75 1.000000  3.306667          Low
851       8       BOS       PPP    E90     71 1.750000  4.102941      MedHigh
854      14       PPP       IAH    E90     88 3.602273  3.352273      MedHigh
857       7       PPP       TPA    321     38 1.026316  3.421053          Low
872       6       TPA       CCC    321     81 1.000000  3.493827          Low
873       8       MIA       CCC    734     47 1.000000  3.425532          Low
877      20       PPP       PIT    734     30 4.766667  3.333333      MedHigh
891      11       PPP       BOS    E90     61 2.016949  4.305085          Low
893       8       PPP       MSP    E90     48 1.434783  3.456522       MedLow
894       9       CCC       BOS    321     70 1.955882  4.073529          Low
895      16       MSP       PPP    E90     70 4.200000  3.828571         High
900      11       CCC       ORD    321     88 1.952941  3.129412          Low
906      12       LGA       CCC    321     84 2.626506  4.132530         High
912      13       PPP       MSP    E90     71 3.183099  3.802817      MedHigh
913       6       RSW       CCC    321     80 1.000000  3.550000          Low
918       6       MIA       CCC    734     85 1.000000  3.892857          Low
922       9       CCC       BWI    734     45 1.977273  3.590909      MedHigh
926      17       DDD       TPA    319     77 4.526316  3.368421      MedHigh
942      14       ORD       CCC    321     83 2.924051  3.151899         High
947       7       BOS       PPP    19W     56 1.017857  3.982143          Low
948      10       MCO       PPP    320     42 2.000000  3.190476         High
953       8       DFW       PPP    19W     47 1.000000  3.340426          Low
956      11       RDU       PPP    19W     33 3.000000  3.212121         High
961      21       PPP       MHT    E90     71 5.571429  4.257143          Low
962      22       CCC       ATT    321     71 4.436620  3.323944       MedLow
975      16       PPP       ATT    E90     77 3.831169  4.363636      MedHigh
977       7       TPA       DDD    19W     87 1.000000  3.129412          Low
980      16       CCC       TPA    320     34 3.441176  3.764706         High
982       9       CCC       NAS    734     78 1.948718  3.243590       MedLow
985       7       MHT       PPP    E90     83 1.000000  3.506329          Low
988       6       IND       CCC    319     88 1.125000  3.329545          Low
998       6       PPP       BOS    E90     50 1.021277  4.340426          Low
1001      7       CHS       CCC    19W     30 1.000000  4.166667          Low
1002      7       CCC       MIA    734     40 1.100000  4.050000          Low
1003      7       CCC       EWR    320     35 1.205882  4.235294          Low
1010     20       CCC       RIC    319     65 5.630769  3.215385          Low
1013     11       CCC       JAX    319     76 2.605263  3.723684          Med
1014     11       BOS       PPP    E90     76 2.780822  3.876712         High
1023      9       CCC       BWI    321     36 1.944444  3.861111       MedLow
1024      9       CCC       SRQ    19W     36 1.972222  3.666667      MedHigh
1025     13       CCC       MCI    320     36 3.305556  3.111111          Med
1048     14       CCC       DDD    319     58 3.724138  3.810345          Med
1051      7       ORD       CCC    321     90 1.078652  3.112360          Low
1056      5       MCO       CCC    321     32 1.000000  3.375000          Low
1058      7       CCC       TPA    734     48 1.729167  3.333333       MedLow
1062     19       DDD       MCO    320     48 4.562500  3.520833         High
1068      8       MIA       CCC    321     43 1.000000  3.790698          Low
1076      7       DFW       CCC    321     88 1.000000  3.795455          Low
1081      6       MIA       PPP    734     83 1.000000  3.337349          Low
1082      6       EWR       CCC    321    156 1.000000  3.847682          Low
1098     22       CCC       RIC    19W     52 5.903846  3.653846       MedLow
1099     22       CCC       BNA    19W     64 5.843750  3.531250          Low
1104     19       TPA       CCC    320     35 4.457143  3.742857         High
1105     22       CCC       ILM    734     35 5.823529  3.470588          Low
1106      6       MSY       PPP    E90     82 1.000000  3.237500          Low
1109     11       MSP       PPP    E90     53 2.431373  3.431373         High
1110      7       ORD       PPP    320     71 1.000000  3.718310          Low
1113      6       PPP       MCO    320     42 1.000000  3.190476          Low
1129     10       CCC       JAX    19W     68 1.955882  3.338235          Low
1136      7       CCC       DFW    321     57 1.263158  4.245614          Low
1143     14       CCC       DTW    19W     64 3.921875  3.578125          Low
1144     19       ATT       PPP    E90     77 4.842105  4.381579         High
1147     20       CCC       MDT    19W     71 5.802817  3.971831          Low
1149      7       CHS       CCC    319     39 1.000000  3.605263          Low
1152      5       DFW       CCC    734     72 1.000000  3.750000          Low
1153      7       PVD       PPP    E90     72 1.000000  3.647887          Low
1179      6       DFW       PPP    19W     76 1.000000  3.263158          Low
1180      6       LGA       CCC    321     83 1.000000  3.939024          Low
1181      8       DFW       CCC    A21     90 1.000000  3.438202          Low
1182     14       LGA       CCC    321     90 3.011236  3.865169         High
1196      6       BOS       PPP    19W     51 1.000000  3.520000          Low
1205      9       CCC       PIT    734     37 1.972973  3.756757      MedHigh
1207      6       BOS       CCC    321     89 1.000000  3.425287          Low
1208     11       PPP       ATT    E90     52 2.115385  3.230769          Low
1211      8       ATT       CCC    321     82 1.000000  3.600000          Low
1213      5       PPP       CCC    734     60 1.000000  3.966667          Low
1214      7       PPP       DFW    19W     45 1.044444  4.088889          Low
1226     17       PIT       CCC    319     53 4.849057  3.264151         High
1242      9       CCC       PVD    734     40 1.925000  3.500000         High
1245     15       JAX       CCC    319     48 4.020833  3.770833         High
1257     12       JAX       CCC    19W     68 2.955882  3.338235         High
1268      6       CCC       PPP    319     72 1.000000  3.746479          Low
1273      7       BOS       PPP    320     74 1.000000  4.397260          Low
1274      9       CLE       CCC    734     37 1.000000  3.111111          Low
1283     22       CCC       ORF    319     58 6.017241  4.206897          Low
1302      7       RIC       CCC    319     42 1.000000  3.857143          Low
1306      7       ORF       CCC    319     85 1.000000  3.130952          Low
1308     13       PPP       ORD    19W     32 2.250000  3.781250      MedHigh
1309      8       CCC       PIT    19W     65 1.969231  4.107692          Med
1311     10       PIT       CCC    19W     66 2.909091  4.090909         High
1331      6       DDD       CCC    19W     62 1.000000  3.590164          Low
1363      5       ORF       CCC    319     69 1.000000  4.362319          Low
1370      5       RIC       CCC    19W     59 1.000000  3.966102          Low
1387      6       BOS       DDD    320     39 1.000000  4.205128          Low
     DEPSTAATCIMP DOWNLINEATCIMP DEPBUCKET ARRBUCKET DEPRANKGRP TRNRANKGRP
2            High           High        D5        A6        Low        Low
5             Low           High        D4        A5        Med        Low
7            High           High        D5        A6        Low        Low
13           High           High        D5        A6     MedLow     MedLow
14           High           High        D6        A7        Low        Low
17           High           High        D6        A6     MedLow        Med
18           High           High        D6        A7        Med        Med
20            Low           High        D6        A7        Low        Low
33           High           High        D6        A7        Med     MedLow
34           High           High        D8        A8        Low        Low
36            Low           High        D7        A8        Low        Low
37           High           High        D5        A6        Med     MedLow
43           High            Low        D4        A4     MedLow     MedLow
44           High            Low        D4        A4        Low        Low
45           High           High        D6        A6        Low        Low
46            Low           High        D6        A7     MedLow        Low
57           High           High        D7        A8        Low        Low
63           High            Low        D5        A6        Low        Low
68           High           High        D6        A7        Med     MedLow
71           High            Low        D7        A8        Low        Low
74           High            Low        D6        A7        Med        Med
76            Low           High        D6        A7        Low        Low
81           High           High        D5        A6        Low        Low
82           High           High        D7        A7        Low        Low
83            Low           High        D7        A8     MedLow        Low
84           High           High        D8        A8        Low        Low
86           High           High        D7        A8        Low        Low
87           High           High        D8        A8     MedLow     MedLow
88           High           High        D5        A6        Low        Low
99           High           High        D5        A6        Low        Low
103          High            Low        D7        A7        Low        Low
108          High           High        D7        A7        Low        Low
114          High           High        D5        A6        Med     MedLow
117           Low           High        D7        A8        Low        Low
123          High            Low        D8        A8        Low        Low
133           Low           High        D6        A6        Low        Low
134          High            Low        D6        A7        Low        Low
140           Low           High        D7        A8     MedLow        Low
143          High            Low        D7        A8        Low        Low
144          High           High        D7        A7        Low        Low
147          High           High        D6        A7        Med     MedLow
150          High           High        D5        A6     MedLow     MedLow
155           Low           High        D4        A5        Low     MedLow
165          High           High        D7        A7     MedLow     MedLow
170          High            Low        D5        A6        Low        Low
171          High           High        D7        A8     MedLow     MedLow
172          High            Low        D6        A7        Low        Low
184           Low           High        D7        A7        Low        Low
186          High           High        D8        A1        Low        Low
188          High            Low        D5        A6        Low        Low
189          High            Low        D6        A7        Low        Low
196          High            Low        D8        A8        Low        Low
197          High            Low        D6        A7     MedLow     MedLow
199          High           High        D8        A8        Low        Low
202          High           High        D6        A7        Med    MedHigh
205          High            Low        D5        A6        Low        Low
208          High           High        D5        A6        Med     MedLow
213           Low           High        D6        A6        Med     MedLow
214          High           High        D7        A8        Low        Low
215          High            Low        D7        A8        Low        Low
217           Low           High        D4        A5        Low        Low
218           Low           High        D4        A5        Med     MedLow
223           Low           High        D4        A5        Low        Low
227          High           High        D5        A5        Low        Low
228          High            Low        D6        A6        Low        Low
229           Low           High        D6        A7    MedHigh    MedHigh
232          High           High        D6        A7        Low        Low
233          High            Low        D6        A7        Low        Low
234          High           High        D6        A7        Med     MedLow
238           Low           High        D6        A7    MedHigh        Med
242          High           High        D7        A7        Low        Low
249           Low           High        D7        A7     MedLow        Low
250           Low           High        D6        A7     MedLow        Low
256          High            Low        D8        A8        Low        Low
260          High            Low        D7        A7        Low        Low
262          High           High        D4        A5        Med     MedLow
266           Low           High        D6        A7     MedLow        Med
267          High           High        D5        A6        Low        Low
274          High           High        D7        A8        Low        Low
276          High           High        D8        A8        Low        Low
279           Low           High        D5        A5     MedLow        Low
281          High           High        D7        A8        Low        Low
283          High            Low        D6        A6        Low        Low
285          High           High        D8        A3     MedLow     MedLow
286          High           High        D5        A6        Low        Low
290          High            Low        D7        A8        Low        Low
295          High           High        D4        A4        Low        Low
296          High           High        D4        A5        Low        Low
300           Low           High        D5        A5        Low        Low
303           Low           High        D6        A7        Med        Med
310          High            Low        D7        A8        Low        Low
311          High           High        D6        A7        Low        Low
317          High            Low        D8        A8        Low        Low
318          High            Low        D6        A6        Low        Low
326          High           High        D5        A6        Low        Low
327          High            Low        D5        A6        Low        Low
337          High            Low        D7        A8        Low        Low
338          High            Low        D7        A7     MedLow     MedLow
343          High           High        D4        A5        Low        Low
351           Low           High        D6        A7    MedHigh        Med
352          High            Low        D7        A8        Low        Low
354          High           High        D4        A5        Med     MedLow
356          High            Low        D8        A8        Low        Low
357          High           High        D4        A4     MedLow     MedLow
359           Low           High        D4        A5        Low        Low
362          High            Low        D5        A6        Low        Low
363          High           High        D6        A7        Med        Med
364           Low           High        D7        A7        Low        Low
365           Low           High        D7        A8        Med        Med
369          High           High        D5        A6        Med        Med
370          High           High        D6        A7        Med     MedLow
377           Low           High        D6        A7        Med        Med
382          High           High        D7        A8        Med        Med
390           Low           High        D6        A7     MedLow        Low
395          High           High        D3        A3        Low        Low
400          High            Low        D6        A6     MedLow        Med
401           Low           High        D6        A7        Med        Med
402           Low           High        D6        A7     MedLow        Low
404          High           High        D6        A7     MedLow     MedLow
405           Low           High        D6        A8        Med        Med
406           Low           High        D6        A7        Med     MedLow
408          High           High        D5        A6     MedLow     MedLow
411           Low           High        D1        A2     MedLow     MedLow
413          High            Low        D6        A7        Low        Low
418          High            Low        D8        A8        Low        Low
419          High            Low        D5        A6        Low        Low
427          High           High        D3        A3     MedLow     MedLow
429          High            Low        D8        A8        Low        Low
434          High           High        D4        A5     MedLow     MedLow
435          High           High        D7        A8        Low        Low
436          High           High        D8        A8     MedLow     MedLow
438          High           High        D4        A5     MedLow     MedLow
440          High           High        D4        A5        Low        Low
445          High            Low        D6        A7        Low        Low
446           Low           High        D5        A5    MedHigh    MedHigh
447          High            Low        D6        A7        Low        Low
448          High           High        D7        A8     MedLow     MedLow
450          High            Low        D8        A8        Low        Low
458          High            Low        D7        A8     MedLow        Med
459          High           High        D6        A6     MedLow        Med
463          High           High        D5        A6        Low        Low
466          High            Low        D3        A4     MedLow        Med
467           Low           High        D6        A7        Med        Med
482          High           High        D7        A8     MedLow     MedLow
488          High           High        D4        A5     MedLow     MedLow
489          High           High        D5        A6     MedLow        Med
495          High            Low        D4        A4        Low        Low
497          High           High        D4        A4        Low        Low
498          High           High        D4        A5     MedLow     MedLow
501          High           High        D4        A5        Low        Low
503          High           High        D5        A5     MedLow     MedLow
504           Low           High        D5        A6        Low        Med
505          High            Low        D5        A5        Low        Low
518          High           High        D6        A7     MedLow     MedLow
519          High           High        D6        A7     MedLow        Med
520          High           High        D5        A6        Med        Med
522          High            Low        D7        A8        Low        Low
531           Low           High        D4        A5    MedHigh        Med
532          High            Low        D7        A8     MedLow     MedLow
535          High           High        D4        A6        Med     MedLow
544           Low           High        D5        A6    MedHigh        Med
545          High            Low        D7        A8     MedLow     MedLow
553          High            Low        D7        A8     MedLow     MedLow
561          High           High        D4        A5     MedLow     MedLow
562          High           High        D5        A6     MedLow     MedLow
564           Low           High        D7        A8     MedLow        Med
568          High            Low        D7        A8     MedLow     MedLow
584          High           High        D5        A7     MedLow     MedLow
590          High           High        D4        A5     MedLow     MedLow
592           Low           High        D6        A7        Med        Low
593          High           High        D5        A6        Med     MedLow
596          High           High        D5        A5     MedLow        Med
597          High            Low        D7        A8        Low        Low
598          High            Low        D7        A8     MedLow     MedLow
610          High            Low        D4        A4        Low        Low
614           Low           High        D5        A5        Low        Low
615          High            Low        D7        A7     MedLow     MedLow
628          High            Low        D7        A8        Low        Low
629          High           High        D8        A8        Low        Low
638          High           High        D3        A4     MedLow     MedLow
639          High           High        D4        A5     MedLow     MedLow
644           Low           High        D4        A5     MedLow        Low
647          High           High        D4        A4        Low        Low
653           Low           High        D7        A7        Low        Low
655          High            Low        D8        A8        Low        Low
657          High           High        D7        A8        Low        Low
662          High           High        D4        A5        Low        Low
664          High           High        D5        A6        Med     MedLow
668           Low           High        D5        A6    MedHigh    MedHigh
677          High           High        D4        A5        Med    MedHigh
687          High           High        D6        A6        Med    MedHigh
688          High            Low        D5        A6        Low        Low
692           Low           High        D6        A6    MedHigh    MedHigh
697          High           High        D4        A5        Low        Low
702          High           High        D4        A5     MedLow     MedLow
703          High            Low        D5        A6        Low        Low
706          High            Low        D8        A8        Low        Low
717          High            Low        D8        A8        Low        Low
721           Low           High        D6        A7        Med        Med
724          High            Low        D7        A8        Low        Low
729          High            Low        D6        A6     MedLow     MedLow
735          High            Low        D3        A4        Low        Low
737          High           High        D6        A7        Med     MedLow
744          High            Low        D8        A8        Low        Low
745          High           High        D4        A5        Low        Low
747          High           High        D5        A6     MedLow     MedLow
750          High           High        D3        A4        Low        Low
751          High            Low        D5        A5        Low        Low
758          High           High        D5        A6        Med     MedLow
766          High            Low        D5        A5        Low        Low
767          High            Low        D5        A5        Low        Low
768          High            Low        D5        A5        Low        Low
772          High            Low        D7        A8     MedLow        Med
773          High           High        D7        A8     MedLow     MedLow
780          High            Low        D7        A8     MedLow     MedLow
781          High            Low        D5        A6        Low        Low
787          High            Low        D7        A7        Low        Low
800          High            Low        D6        A6        Low        Low
809          High           High        D4        A5        Med    MedHigh
812          High           High        D5        A6     MedLow     MedLow
813           Low           High        D6        A6        Low        Low
820          High            Low        D7        A8        Low        Low
822          High            Low        D8        A8     MedLow     MedLow
831          High           High        D6        A7        Low        Low
836          High            Low        D4        A4     MedLow     MedLow
839          High            Low        D5        A5        Low        Low
848           Low           High        D2        A3        Low        Low
851          High           High        D3        A4        Med        Med
854          High            Low        D5        A6     MedLow     MedLow
857          High            Low        D3        A4     MedLow     MedLow
872           Low           High        D3        A3        Low        Low
873          High           High        D3        A4     MedLow     MedLow
877          High            Low        D7        A8     MedLow     MedLow
891          High           High        D4        A5     MedLow     MedLow
893          High            Low        D3        A4     MedLow     MedLow
894          High           High        D4        A4        Low        Low
895           Low           High        D6        A7        Med        Med
900          High           High        D4        A5        Low        Low
906          High           High        D5        A5        Med    MedHigh
912          High            Low        D5        A6     MedLow     MedLow
913           Low           High        D3        A3     MedLow        Med
918          High           High        D3        A3     MedLow     MedLow
922          High            Low        D4        A4        Low        Low
926          High            Low        D6        A7     MedLow        Med
942          High           High        D5        A6        Med     MedLow
947          High           High        D3        A4        Med        Med
948           Low           High        D4        A5     MedLow        Low
953          High           High        D3        A5        Med     MedLow
956           Low           High        D4        A5        Med     MedLow
961          High            Low        D8        A8     MedLow     MedLow
962          High           High        D8        A8        Low        Low
975          High           High        D6        A7     MedLow     MedLow
977           Low           High        D3        A4        Low        Low
980          High            Low        D6        A7        Low        Low
982          High            Low        D4        A5        Low        Low
985           Low           High        D3        A3    MedHigh       High
988           Low           High        D3        A3    MedHigh        Med
998          High           High        D3        A3     MedLow     MedLow
1001          Low           High        D3        A3    MedHigh       High
1002         High           High        D3        A4        Low        Low
1003         High           High        D3        A4        Low        Low
1010         High            Low        D7        A8        Low        Low
1013         High            Low        D4        A5        Low        Low
1014         High           High        D4        A5        Med        Med
1023         High            Low        D4        A4        Low        Low
1024         High            Low        D4        A4        Low        Low
1025         High            Low        D5        A5        Low        Low
1048         High           High        D5        A6        Low        Low
1051         High           High        D3        A4        Med     MedLow
1056          Low           High        D2        A3     MedLow        Low
1058         High            Low        D3        A4        Low        Low
1062         High            Low        D7        A8     MedLow        Med
1068         High           High        D3        A4     MedLow     MedLow
1076         High           High        D3        A4        Med     MedLow
1081         High           High        D3        A3     MedLow     MedLow
1082         High           High        D3        A3        Med    MedHigh
1098         High            Low        D8        A8        Low        Low
1099         High            Low        D8        A8        Low        Low
1104          Low           High        D7        A7        Low        Low
1105         High            Low        D8        A8        Low        Low
1106          Low           High        D3        A4        Low        Low
1109          Low           High        D4        A5        Med        Med
1110         High           High        D3        A4        Med     MedLow
1113         High            Low        D3        A4     MedLow     MedLow
1129         High            Low        D4        A4        Low        Low
1136         High           High        D3        A4        Low        Low
1143         High            Low        D5        A6        Low        Low
1144         High           High        D7        A8        Med     MedLow
1147         High            Low        D7        A8        Low        Low
1149          Low           High        D3        A3    MedHigh       High
1152         High           High        D2        A3        Med     MedLow
1153          Low           High        D3        A3    MedHigh        Med
1179         High           High        D3        A4        Med     MedLow
1180         High           High        D3        A3        Med    MedHigh
1181         High           High        D3        A5        Med     MedLow
1182         High           High        D5        A6        Med    MedHigh
1196         High           High        D3        A3        Med        Med
1205         High            Low        D4        A4        Low        Low
1207         High           High        D3        A3        Med        Med
1208         High           High        D4        A5     MedLow     MedLow
1211         High           High        D3        A4        Med     MedLow
1213         High           High        D2        A3     MedLow     MedLow
1214         High           High        D3        A4     MedLow     MedLow
1226          Low           High        D6        A7    MedHigh    MedHigh
1242         High            Low        D4        A4        Low        Low
1245          Low           High        D6        A6    MedHigh    MedHigh
1257          Low           High        D5        A5    MedHigh    MedHigh
1268         High           High        D3        A3        Low        Low
1273         High           High        D3        A3        Med        Med
1274          Low           High        D4        A4       High       High
1283         High            Low        D8        A8        Low        Low
1302          Low           High        D3        A3    MedHigh    MedHigh
1306          Low           High        D3        A3    MedHigh        Med
1308         High           High        D5        A6     MedLow     MedLow
1309         High            Low        D3        A4        Low        Low
1311          Low           High        D4        A5    MedHigh    MedHigh
1331         High           High        D3        A3     MedLow        Med
1363          Low           High        D2        A3    MedHigh        Med
1370          Low           High        D2        A3    MedHigh    MedHigh
1387         High           High        D3        A3        Med        Med
     ARRRANKGRP DEPSPOKE ARRSPOKE xDURN2 xAVAILBUCKET xAVGSKDAVAIL LEGTYPE
2       MedHigh    FALSE    FALSE      2           10 -0.635067532  Strong
5       MedHigh     TRUE    FALSE      2            0 -1.220310866  Strong
7           Med    FALSE     TRUE      2            5 -0.717640228  Strong
13       MedLow    FALSE     TRUE      2           15 -0.210978159  Strong
14      MedHigh    FALSE     TRUE      2           15 -0.230546855  Strong
17      MedHigh    FALSE    FALSE      2           10 -0.653556794  Strong
18      MedHigh     TRUE    FALSE      2            5 -0.946599414  Strong
20      MedHigh     TRUE    FALSE      1            0 -1.154577014  Strong
33      MedHigh     TRUE    FALSE      3           15 -0.365770781  Strong
34          Med    FALSE     TRUE      1           20  0.015909655  Strong
36      MedHigh     TRUE    FALSE      2            0 -1.190052426  Strong
37      MedHigh     TRUE    FALSE      4            0 -1.042193330  Strong
43         High    FALSE     TRUE      1            0 -1.261275441  Strong
44       MedLow    FALSE     TRUE      2            5 -0.766434264  Strong
45       MedLow    FALSE     TRUE      1           15 -0.261607906  Strong
46      MedHigh     TRUE    FALSE      2            5 -0.755742401  Strong
57      MedHigh    FALSE     TRUE      2           20  0.037559156  Strong
63          Med    FALSE     TRUE      2           15 -0.152850258  Strong
68      MedHigh     TRUE    FALSE      3            5 -0.802310982  Strong
71          Low    FALSE     TRUE      2           25  0.347563251  Strong
74         High     TRUE    FALSE      4            5 -0.755791640  Strong
76      MedHigh     TRUE    FALSE      3            0 -1.244961061  Strong
81       MedLow    FALSE     TRUE      2           15 -0.164373444  Strong
82          Med    FALSE     TRUE      2           20  0.009298850  Strong
83      MedHigh     TRUE    FALSE      2            5 -1.001596411  Strong
84      MedHigh    FALSE    FALSE      1           30  1.051406519  Strong
86          Med    FALSE     TRUE      1           15 -0.220567643  Strong
87      MedHigh    FALSE     TRUE      1           15 -0.316715666  Strong
88          Med    FALSE     TRUE      2           20  0.161039096  Strong
99      MedHigh    FALSE    FALSE      2           15 -0.161462860  Strong
103         Med    FALSE     TRUE      2           20  0.215101836  Strong
108      MedLow    FALSE     TRUE      1           10 -0.532770298  Strong
114     MedHigh     TRUE    FALSE      4            0 -1.341357351  Strong
117     MedHigh     TRUE    FALSE      2            5 -0.927795222  Strong
123      MedLow    FALSE     TRUE      1           25  0.476718099  Strong
133     MedHigh     TRUE    FALSE      2            5 -0.974230289  Strong
134      MedLow    FALSE     TRUE      2           10 -0.487571743  Strong
140     MedHigh     TRUE    FALSE      2           10 -0.628706192  Strong
143      MedLow    FALSE     TRUE      2           10 -0.455963741  Strong
144         Med    FALSE     TRUE      2           15 -0.149788121  Strong
147     MedHigh     TRUE    FALSE      4           15 -0.287711830  Strong
150     MedHigh     TRUE    FALSE      2           10 -0.492652403  Strong
155     MedHigh     TRUE    FALSE      2            0 -1.103868042  Strong
165     MedHigh    FALSE     TRUE      1           30  1.065890250  Strong
170         Low    FALSE     TRUE      2            5 -0.817783341  Strong
171     MedHigh     TRUE    FALSE      2            5 -0.745274224  Strong
172         Low    FALSE     TRUE      2           15 -0.296451445  Strong
184         Med     TRUE    FALSE      2           10 -0.622730387  Strong
186      MedLow    FALSE     TRUE      2           30  1.893830408  Strong
188        High    FALSE     TRUE      2           15 -0.359569474  Strong
189         Med    FALSE     TRUE      2           20  0.036217012  Strong
196      MedLow    FALSE     TRUE      1           25  0.444658431  Strong
197        High     TRUE    FALSE      4           20  0.055412795  Strong
199         Med    FALSE     TRUE      1           30  1.327406040  Strong
202     MedHigh     TRUE    FALSE      2           10 -0.564501033  Strong
205      MedLow    FALSE     TRUE      2            5 -0.749794868  Strong
208     MedHigh     TRUE    FALSE      3           10 -0.371746585  Strong
213     MedHigh     TRUE    FALSE      1            0 -1.127321514  Strong
214      MedLow    FALSE     TRUE      2            5 -0.717446893  Strong
215        High    FALSE     TRUE      2           30  0.777998258  Strong
217     MedHigh     TRUE    FALSE      2            5 -0.829367426  Strong
218     MedHigh     TRUE    FALSE      1            5 -1.009414756  Strong
223     MedHigh     TRUE    FALSE      2           20  0.028632336  Strong
227     MedHigh    FALSE    FALSE      1           15 -0.236569760  Strong
228      MedLow    FALSE     TRUE      1           10 -0.370227313  Strong
229     MedHigh     TRUE    FALSE      2            0 -1.189635068  Strong
232      MedLow    FALSE     TRUE      2           15 -0.313500488  Strong
233         Med    FALSE     TRUE      2           -1  0.620237011  Strong
234     MedHigh     TRUE    FALSE      2            5 -0.824081810  Strong
238     MedHigh     TRUE    FALSE      2            0 -1.223597559  Strong
242      MedLow    FALSE     TRUE      2           30  0.834132881  Strong
249     MedHigh     TRUE    FALSE      1           10 -0.691845287  Strong
250     MedHigh     TRUE    FALSE      1            5 -0.879689993  Strong
256         Low    FALSE     TRUE      1           25  0.355772906  Strong
260     MedHigh    FALSE     TRUE      1           15 -0.104438634  Strong
262     MedHigh     TRUE    FALSE      3            5 -0.799772604  Strong
266     MedHigh     TRUE    FALSE      2            5 -0.885925615  Strong
267     MedHigh    FALSE     TRUE      2           15 -0.334575054  Strong
274         Med    FALSE    FALSE      2           15 -0.077701838  Strong
276      MedLow    FALSE     TRUE      1           20  0.178881143  Strong
279     MedHigh     TRUE    FALSE      1           15 -0.211372661  Strong
281      MedLow    FALSE     TRUE      1           15 -0.174982281  Strong
283     MedHigh    FALSE     TRUE      1           15 -0.145939535  Strong
285     MedHigh     TRUE    FALSE      8           30  3.266232603  Strong
286     MedHigh    FALSE     TRUE      2           10 -0.608359999  Strong
290        High    FALSE     TRUE      1           30  0.975452638  Strong
295      MedLow    FALSE     TRUE      2           10 -0.461303980  Strong
296      MedLow    FALSE     TRUE      2           10 -0.499673073  Strong
300     MedHigh     TRUE    FALSE      1           15 -0.264182099  Strong
303     MedHigh     TRUE    FALSE      4            5 -0.698822301  Strong
310     MedHigh    FALSE     TRUE      1           30  0.787672296  Strong
311         Med    FALSE    FALSE      2           30  0.841341788  Strong
317      MedLow    FALSE     TRUE      1           25  0.303519357  Strong
318     MedHigh    FALSE     TRUE      0            5 -0.775511796  Strong
326      MedLow    FALSE     TRUE      2           20  0.077932726  Strong
327      MedLow    FALSE     TRUE      2           15 -0.283603465  Strong
337     MedHigh    FALSE     TRUE      1           10 -0.443008058  Strong
338        High    FALSE     TRUE      2           30  0.699994085  Strong
343         Med    FALSE    FALSE      1           15 -0.218367596  Strong
351     MedHigh     TRUE    FALSE      3            0 -1.204790373  Strong
352         Low    FALSE     TRUE      1           10 -0.582514836  Strong
354     MedHigh     TRUE    FALSE      3            0 -1.095762514  Strong
356      MedLow    FALSE     TRUE      1           30  0.671962010  Strong
357     MedHigh    FALSE     TRUE      1           10 -0.648426347  Strong
359         Med     TRUE    FALSE      3           10 -0.694440044  Strong
362      MedLow    FALSE     TRUE      2           15 -0.207858422  Strong
363     MedHigh     TRUE    FALSE      2           30  0.935994268  Strong
364         Med     TRUE    FALSE      2            5 -0.704710959  Strong
365     MedHigh     TRUE    FALSE      3            0 -1.138673662  Strong
369     MedHigh     TRUE    FALSE      3           15 -0.183738573  Strong
370     MedHigh     TRUE    FALSE      3            0 -1.226884252  Strong
377     MedHigh     TRUE    FALSE      3            5 -0.882758650  Strong
382     MedHigh     TRUE    FALSE      1           15 -0.283968653  Strong
390     MedHigh     TRUE    FALSE      2           10 -0.622037540  Strong
395      MedLow    FALSE     TRUE      1           30  1.045102157  Strong
400      MedLow    FALSE     TRUE      2           15 -0.226335335  Strong
401     MedHigh     TRUE    FALSE      3            5 -0.770776131  Strong
402     MedHigh     TRUE    FALSE      2           10 -0.392583273  Strong
404         Med    FALSE    FALSE      1           30  0.824357922  Strong
405     MedHigh     TRUE    FALSE      4           10 -0.570756611  Strong
406     MedHigh     TRUE    FALSE      2            5 -0.783374080  Strong
408     MedHigh    FALSE     TRUE      2           30  1.290357121  Strong
411     MedHigh    FALSE    FALSE      5           30  7.365844981  Strong
413     MedHigh    FALSE     TRUE      2           15 -0.076130992  Strong
418      MedLow    FALSE     TRUE      1           30  1.484167647  Strong
419     MedHigh    FALSE     TRUE      1            5 -0.814404326  Strong
427     MedHigh     TRUE    FALSE      2           30  1.336952727  Strong
429        High    FALSE     TRUE      1           30  0.788471108  Strong
434      MedLow    FALSE     TRUE      3           10 -0.541537387  Strong
435      MedLow    FALSE     TRUE      2           20  0.014937784  Strong
436     MedHigh    FALSE     TRUE      1           30  1.974074659  Strong
438     MedHigh    FALSE    FALSE      2           20  0.047804710  Strong
440     MedHigh    FALSE     TRUE      2           25  0.324940319  Strong
445      MedLow    FALSE     TRUE      2           25  0.584725619  Strong
446     MedHigh     TRUE    FALSE      1            0 -1.085289980  Strong
447         Med    FALSE     TRUE      2           20  0.192078673  Strong
448      MedLow    FALSE     TRUE      3           30  2.762065047  Strong
450        High    FALSE     TRUE      1           20  0.115989167  Strong
458      MedLow    FALSE     TRUE      2           30  0.721695784  Strong
459     MedHigh    FALSE    FALSE      1           20 -0.016390851  Strong
463      MedLow    FALSE     TRUE      2           25  0.589398907  Strong
466      MedLow    FALSE     TRUE      3            5 -1.004025286  Strong
467     MedHigh     TRUE    FALSE      3            5 -1.023109308  Strong
482      MedLow    FALSE     TRUE      2           30  1.751127580  Strong
488      MedLow    FALSE     TRUE      1           20  0.021328575  Strong
489     MedHigh    FALSE    FALSE      2           10 -0.555123520  Strong
495     MedHigh    FALSE     TRUE      1            5 -0.782085181  Strong
497         Med    FALSE     TRUE      1           30  0.920572718  Strong
498     MedHigh     TRUE    FALSE      2            5 -1.023109308  Strong
501         Med    FALSE     TRUE      2           15 -0.281692597  Strong
503     MedHigh     TRUE    FALSE      2            5 -0.835166039  Strong
504     MedHigh     TRUE    FALSE      3            0 -1.074757335  Strong
505      MedLow    FALSE     TRUE      1            5 -0.766915831  Strong
518     MedHigh     TRUE    FALSE      3           20  0.172926159  Strong
519     MedHigh    FALSE    FALSE      1            5 -0.759297446  Strong
520     MedHigh     TRUE    FALSE      3           10 -0.406977076  Strong
522      MedLow    FALSE     TRUE      2           15 -0.194862763  Strong
531     MedHigh     TRUE    FALSE      1            5 -1.006326197  Strong
532     MedHigh    FALSE     TRUE      3           30  0.688709774  Strong
535     MedHigh     TRUE    FALSE      4            5 -0.760173897  Strong
544     MedHigh     TRUE    FALSE      3           20 -0.037101517  Strong
545      MedLow    FALSE     TRUE      3           30  0.697214812  Strong
553      MedLow    FALSE     TRUE      1           30  1.485901287  Strong
561     MedHigh     TRUE    FALSE      2           15 -0.333686400  Strong
562     MedHigh     TRUE    FALSE      2           30  0.685970864  Strong
564     MedHigh     TRUE    FALSE      2           10 -0.629946453  Strong
568     MedHigh    FALSE     TRUE      1           30  2.196910422  Strong
584     MedHigh     TRUE    FALSE      7            5 -0.996633173  Strong
590      MedLow    FALSE     TRUE      3           25  0.615541736  Strong
592     MedHigh     TRUE    FALSE      1            5 -0.822826476  Strong
593     MedHigh     TRUE    FALSE      3            5 -0.886253582  Strong
596     MedHigh    FALSE    FALSE      1            5 -0.802431374  Strong
597      MedLow    FALSE     TRUE      3           20  0.014546511  Strong
598         Low    FALSE     TRUE      3           30  0.637962994  Strong
610     MedHigh    FALSE     TRUE      1           10 -0.612272728  Strong
614     MedHigh     TRUE    FALSE      1           15 -0.281777524  Strong
615     MedHigh    FALSE     TRUE      2           30  0.742575015  Strong
628     MedHigh    FALSE     TRUE      2           30  0.679856086  Strong
629         Med    FALSE    FALSE      1           30  2.179825679  Strong
638      MedLow    FALSE     TRUE      3           -1 -2.009117100  Strong
639      MedLow    FALSE     TRUE      3           15 -0.299244954  Strong
644     MedHigh     TRUE    FALSE      2           10 -0.605738942  Strong
647      MedLow    FALSE     TRUE      2           15 -0.315028859  Strong
653     MedHigh     TRUE    FALSE      1           15 -0.194862763  Strong
655     MedHigh    FALSE     TRUE      1           15 -0.065273168  Strong
657     MedHigh    FALSE     TRUE      1           15 -0.201066857  Strong
662      MedLow    FALSE     TRUE      2           25  0.325651967  Strong
664     MedHigh     TRUE    FALSE      5            0 -1.116408970  Strong
668     MedHigh     TRUE    FALSE      2            5 -0.744605353  Strong
677     MedHigh     TRUE    FALSE      2            0 -1.025042657  Strong
687     MedHigh     TRUE    FALSE      1           30  0.932051440  Strong
688     MedHigh    FALSE     TRUE      2           15 -0.280983637  Strong
692     MedHigh     TRUE    FALSE      2           10 -0.431504633  Strong
697         Med    FALSE     TRUE      3           15 -0.288792979  Strong
702      MedLow    FALSE     TRUE      3           30  0.655295065  Strong
703         Med    FALSE     TRUE      2           15 -0.190480506  Strong
706        High    FALSE     TRUE      1           15 -0.204616819  Strong
717         Med    FALSE     TRUE      1           25  0.580490961  Strong
721     MedHigh     TRUE    FALSE      3           10 -0.577579862  Strong
724        High    FALSE     TRUE      2           25  0.428324383  Strong
729     MedHigh    FALSE     TRUE      2           15 -0.086899890  Strong
735      MedLow    FALSE     TRUE      2           20  0.022058951  Strong
737     MedHigh     TRUE    FALSE      3           15 -0.068972475  Strong
744         Med    FALSE     TRUE      1           30  2.472736498  Strong
745         Med    FALSE     TRUE      2           25  0.397274889  Strong
747     MedHigh    FALSE    FALSE      2           15 -0.219311143  Strong
750     MedHigh    FALSE    FALSE      2           10 -0.659518935  Strong
751      MedLow    FALSE     TRUE      1           15 -0.133604407  Strong
758     MedHigh     TRUE    FALSE      2            5 -0.700760607  Strong
766     MedHigh    FALSE     TRUE      1           10 -0.657190861  Strong
767        High    FALSE     TRUE      1           15 -0.176641801  Strong
768         Med    FALSE     TRUE      1           20  0.103130702  Strong
772      MedLow    FALSE     TRUE      3           30  0.690353121  Strong
773     MedHigh    FALSE    FALSE      2           30  0.855440953  Strong
780     MedHigh    FALSE     TRUE      1           25  0.546990718  Strong
781     MedHigh    FALSE     TRUE      1           10 -0.579405802  Strong
787         Low    FALSE     TRUE      2           30  0.644777649  Strong
800         Med    FALSE     TRUE      1           20  0.227122793  Strong
809     MedHigh     TRUE    FALSE      2            5 -0.795923887  Strong
812     MedHigh    FALSE     TRUE      1           30  2.324704281  Strong
813     MedHigh     TRUE    FALSE      1           15 -0.163091401  Strong
820     MedHigh    FALSE     TRUE      1           20  0.201521374  Strong
822         Med    FALSE     TRUE      0           30  1.490972394  Strong
831         Med    FALSE    FALSE      2           25  0.500013254  Strong
836     MedHigh    FALSE     TRUE      2           25  0.532591874  Strong
839     MedHigh    FALSE     TRUE      1           20 -0.018017495  Strong
848     MedHigh     TRUE    FALSE      1           30  1.336952727  Strong
851     MedHigh     TRUE    FALSE      2           25  0.449865597  Strong
854     MedHigh    FALSE     TRUE      3           30  1.121457638  Strong
857      MedLow    FALSE     TRUE      3           20  0.076106785  Strong
872     MedHigh     TRUE    FALSE      2           30  1.336952727  Strong
873     MedHigh     TRUE    FALSE      2           30  1.336952727  Strong
877        High    FALSE     TRUE      1           30  1.544893207  Strong
891     MedHigh    FALSE     TRUE      1            5 -0.805149691  Strong
893         Med    FALSE     TRUE      2           30  0.771424872  Strong
894     MedHigh    FALSE     TRUE      2           15 -0.049236997  Strong
895     MedHigh     TRUE    FALSE      3           15 -0.310366533  Strong
900      MedLow    FALSE     TRUE      1           30  0.971913123  Strong
906     MedHigh     TRUE    FALSE      2           25  0.293943670  Strong
912         Med    FALSE     TRUE      2           25  0.467502471  Strong
913     MedHigh     TRUE    FALSE      2           30  1.336952727  Strong
918     MedHigh     TRUE    FALSE      2           30  1.336952727  Strong
922         Med    FALSE     TRUE      2           20  0.153985264  Strong
926      MedLow    FALSE     TRUE      2           25  0.535474938  Strong
942     MedHigh     TRUE    FALSE      2           25  0.453822194  Strong
947     MedHigh     TRUE    FALSE      2           -1 -1.877649394  Strong
948     MedHigh     TRUE    FALSE      2           10 -0.373596239  Strong
953     MedHigh     TRUE    FALSE      4           30  1.336952727  Strong
956     MedHigh     TRUE    FALSE      2            0 -1.100794771  Strong
961     MedHigh    FALSE     TRUE      1           30  1.954634222  Strong
962     MedHigh    FALSE     TRUE      1           30  1.482183728  Strong
975     MedHigh    FALSE     TRUE      2           30  2.175938193  Strong
977         Med     TRUE    FALSE      2           30  1.336952727  Strong
980      MedLow    FALSE     TRUE      2           25  0.586374117  Strong
982      MedLow    FALSE     TRUE      3           15 -0.251180686  Strong
985     MedHigh     TRUE    FALSE      1           30  1.336952727  Strong
988     MedHigh     TRUE    FALSE      2           10 -0.521888681  Strong
998     MedHigh    FALSE     TRUE      1           -1 -2.009117100  Strong
1001    MedHigh     TRUE    FALSE      1           30  1.336952727  Strong
1002     MedLow    FALSE     TRUE      2           -1 -1.828349005  Strong
1003        Med    FALSE     TRUE      2           20  0.004729117  Strong
1010    MedHigh    FALSE     TRUE      1           30  1.272440081  Strong
1013     MedLow    FALSE     TRUE      2           20  0.027767417  Strong
1014    MedHigh     TRUE    FALSE      2           30  0.737414749  Strong
1023        Med    FALSE     TRUE      2           20  0.071166005  Strong
1024        Low    FALSE     TRUE      2           30  1.003371467  Strong
1025    MedHigh    FALSE     TRUE      1           15 -0.341867562  Strong
1048        Med    FALSE    FALSE      2           25  0.484074030  Strong
1051    MedHigh     TRUE    FALSE      3           30  3.794795430  Strong
1056    MedHigh     TRUE    FALSE      1           30  1.336952727  Strong
1058     MedLow    FALSE     TRUE      2            5 -0.803370429  Strong
1062     MedLow    FALSE     TRUE      2           30  2.385464849  Strong
1068    MedHigh     TRUE    FALSE      2           30  1.336952727  Strong
1076    MedHigh     TRUE    FALSE      3           30  1.336952727  Strong
1081    MedHigh     TRUE    FALSE      2           30  1.336952727  Strong
1082    MedHigh     TRUE    FALSE      2           30  1.336952727  Strong
1098    MedHigh    FALSE     TRUE      1           30  1.639756178  Strong
1099    MedHigh    FALSE     TRUE      0           30  2.331371366  Strong
1104    MedHigh     TRUE    FALSE      1           15 -0.211765754  Strong
1105       High    FALSE     TRUE      1           25  0.403701966  Strong
1106    MedHigh     TRUE    FALSE      4           30  1.336952727  Strong
1109    MedHigh     TRUE    FALSE      3           20  0.266588883  Strong
1110    MedHigh     TRUE    FALSE      3           30  1.336952727  Strong
1113     MedLow    FALSE     TRUE      3           30  1.336952727  Strong
1129     MedLow    FALSE     TRUE      1           30  1.118542024  Strong
1136     MedLow    FALSE     TRUE      2           10 -0.593311040  Strong
1143       High    FALSE     TRUE      2           15 -0.188083960  Strong
1144    MedHigh     TRUE    FALSE      2           30  0.958420385  Strong
1147       High    FALSE     TRUE      1           30  0.842435950  Strong
1149    MedHigh     TRUE    FALSE      1           30  1.336952727  Strong
1152    MedHigh     TRUE    FALSE      3           30  1.336952727  Strong
1153    MedHigh     TRUE    FALSE      1           30  1.336952727  Strong
1179    MedHigh     TRUE    FALSE      4           30  1.336952727  Strong
1180    MedHigh     TRUE    FALSE      2           30  1.336952727  Strong
1181    MedHigh     TRUE    FALSE      4           30  1.336952727  Strong
1182    MedHigh     TRUE    FALSE      2           25  0.434852774  Strong
1196    MedHigh     TRUE    FALSE      2           30  1.336952727  Strong
1205       High    FALSE     TRUE      2           20  0.174707564  Strong
1207    MedHigh     TRUE    FALSE      2           30  1.336952727  Strong
1208    MedHigh    FALSE     TRUE      3           30  0.693704258  Strong
1211    MedHigh     TRUE    FALSE      2           30  1.336952727  Strong
1213    MedHigh    FALSE    FALSE      2           30  1.336952727  Strong
1214     MedLow    FALSE     TRUE      3           -1 -1.779048615  Strong
1226    MedHigh     TRUE    FALSE      1           30  0.774029421  Strong
1242    MedHigh    FALSE     TRUE      2           25  0.474556580  Strong
1245    MedHigh     TRUE    FALSE      1           20 -0.013820777  Strong
1257    MedHigh     TRUE    FALSE      1           15 -0.235269749  Strong
1268    MedHigh    FALSE    FALSE      2           30  1.336952727  Strong
1273    MedHigh     TRUE    FALSE      1           30  1.336952727  Strong
1274    MedHigh     TRUE    FALSE      1           30  1.336952727  Strong
1283    MedHigh    FALSE     TRUE      1           30  1.351381970  Strong
1302    MedHigh     TRUE    FALSE      1           30  1.336952727  Strong
1306    MedHigh     TRUE    FALSE      1           30  1.336952727  Strong
1308     MedLow    FALSE     TRUE      2           30  0.696241778  Strong
1309       High    FALSE     TRUE      1           15 -0.169612617  Strong
1311    MedHigh     TRUE    FALSE      2           25  0.424062544  Strong
1331    MedHigh    FALSE    FALSE      2           30  1.336952727  Strong
1363    MedHigh     TRUE    FALSE      1           30  1.336952727  Strong
1370    MedHigh     TRUE    FALSE      1           30  1.336952727  Strong
1387        Med     TRUE    FALSE      1           30  1.336952727  Strong
> flight <- flight1
> src.adjust <- TRUE
> source(file = "flight1.R")
Warning message:
In eval(expr, envir, enclos) : adjusting
> flight1 <- flight
> 
> # This should be deleted, leave it in and the results are ideal because it defines LEGTYPE.
> flight$D00 <- NULL
> 
> ## Keep the results but don't change the order.
> outcomes.flight <- flight$LEGTYPE
> 
> flight$LEGTYPE <- NULL
> 
> ## If you know your factors are definitely factors, you don't need this
> ##  asNumeric <- function(x) as.numeric(as.character(x))
> 
> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))
> 
> flight.num0 <- factors.numeric(flight)
> 
> flight.scl0 <- scale(flight.num0)
> 
> ## Now split the samples
> ## we need at least 60 to test with, p at 0.77 gives about 75.
> ## Difficulty here is the bias in the table
> ## Because we only have [3.1, 4.4] the proportion of Weak is higher.
> ## see prop.table(results)
> 
> set.seed(seed.mine)
> inTrain <- createDataPartition(outcomes.flight, p = 0.77, list = FALSE)
> 
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> 
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> 
> prop.table(table(trainClass))
trainClass
Strong 
     1 
> dim(trainDescr)
[1] 247  20
> 
> prop.table(table(testClass))
testClass
Strong 
     1 
> dim(testDescr)
[1] 73 20
> ### weaves
> 
> ## Processing for flights data.
> 
> ## Following the caret vignette.
> 
> ###################################################
> ### code chunk number 1: loadLibs
> ###################################################
> library(MASS)
> library(caret)
> library(mlbench)
> library(pROC)
> library(pls)
> 
> library(doMC)
> registerDoMC(cores = 4)
> 
> options(useFancyQuotes = FALSE) 
> 
> # Accounting info.
> getInfo <- function(what = "Suggests")
+ {
+   text <- packageDescription("caret")[what][[1]]
+   text <- gsub("\n", ", ", text, fixed = TRUE)
+   text <- gsub(">=", "$\\\\ge$", text, fixed = TRUE)
+   eachPkg <- strsplit(text, ", ", fixed = TRUE)[[1]]
+   eachPkg <- gsub(",", "", eachPkg, fixed = TRUE)
+   # out <- paste("\\\\pkg{", eachPkg[order(tolower(eachPkg))], "}", sep = "")
+   # paste(out, collapse = ", ")
+   length(eachPkg)
+ }
> 
> ### project-specific: begin
> ## Set-seed, load original CSV file, order it
> ## and do some simple-cleaning
> ## Various datasets 
> 
> seed.mine = 107
> set.seed(seed.mine)                     # helpful for testing
> 
> flight <- read.csv("../bak/flight.csv")
> flight <- flight[order(flight$D00),]
> 
> # Backup
> flight.raw <- flight
> 
> # To check adjustment, there is test code in flight-nb.R
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"
> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"
> 
> # And some deletions
> 
> t.cols <- colnames(flight)
> 
> t.drops <- t.cols[grep("^RANK*", t.cols)]
> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])
> t.drops <- c(t.drops, "D80THPCTL")
> 
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR
> flight$xHNGR <- flight$xDURN < 0
> 
> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+ }
> 
> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))
> 
> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE
> t.cols <- colnames(flight)
> 
> t.drops <- c("SARRHR", "xDURN")
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Backup
> 
> flight00 <- flight
> 
> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]
> 
> paste("samples in use: ", dim(flight)[1])
[1] "samples in use:  320"
> 
> ## Data insights
> 
> ## *Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> flight <- flight1
> 
> ### Numeric variables
> 
> ## Check some more numeric correlations, I haven't scaled yet.
> ## I'd cut correlations above 0.75 because of overfitting.
> 
> x1 <- as.data.frame(as.matrix(sapply(flight, class)))
> 
> flight.num <- flight[,names(x1[which(x1$V1 %in% c("numeric", "integer")),])]
> 
> flight.nzv <- nearZeroVar(flight.num, saveMetrics = TRUE)
> flight.nzv
             freqRatio percentUnique zeroVar   nzv
SDEPHR        1.038462        5.9375   FALSE FALSE
SKDEPS        1.000000       19.0625   FALSE FALSE
AVGSQ         6.333333       82.8125   FALSE FALSE
AVGLOFATC     1.000000       78.4375   FALSE FALSE
xDURN2        1.428571        2.5000   FALSE FALSE
xAVAILBUCKET  1.767857        2.5000   FALSE FALSE
xAVGSKDAVAIL 18.500000       87.8125   FALSE FALSE
> 
> # annoying NA
> flight.cor <- cor(flight.num, use = "pairwise.complete.obs")
> 
> descrCorr <- findCorrelation(flight.cor, cutoff = .65, verbose=TRUE)
Considering row	 3 column	 1 value	 0.956 
  Flagging column	 3 
Considering row	 1 column	 6 value	 0.011 
Considering row	 1 column	 7 value	 0.053 
Considering row	 1 column	 5 value	 0.204 
Considering row	 1 column	 4 value	 0.131 
Considering row	 1 column	 2 value	 0.054 
Considering row	 6 column	 7 value	 0.869 
  Flagging column	 6 
Considering row	 7 column	 5 value	 0.019 
Considering row	 7 column	 4 value	 0.07 
Considering row	 7 column	 2 value	 0.113 
Considering row	 5 column	 4 value	 0.137 
Considering row	 5 column	 2 value	 0.005 
Considering row	 4 column	 2 value	 0.041 
> 
> colnames(flight.num)[descrCorr]
[1] "AVGSQ"        "xAVAILBUCKET"
> 
> ## Which tells me that departure time is very highly correlated to AVGSQ.
> ## AVGSQ is average stand queue?
> 
> ### Try and impute the AVG, it might have more information than the
> ### bucket.
> 
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))
Error in `$<-.data.frame`(`*tmp*`, "xAVAILBUCKET", value = numeric(0)) : 
  replacement has 0 rows, data has 320
> 
> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1
> 
> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]
Error in `[.data.frame`(flight, , c("AVGSKDAVAIL", "xAVAILBUCKET")) : 
  undefined columns selected
> 
> preProcValues <- preProcess(flight.na, method = c("knnImpute"))
> flight.na1 <- predict(preProcValues, flight.na)
> 
> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL
> 
> ## And I'll leave the centered and scale values in for now.
> ## and delete the troublesome ones
> 
> flight$AVGSKDAVAIL <- NULL
> flight$xHNGR <- NULL
> flight$AVAILBUCKET <- NULL
> 
> ## Re-classing
> ## Check warnings to see what happened.
> ## It doesn't matter if you run this on all or the sub-sample
> ## The proportion is more or less the same
> src.adjust <- TRUE
> source(file = "flight1.R")
Warning message:
In eval(expr, envir, enclos) : adjusting
> flight1 <- flight
> 
> # This should be deleted, leave it in and the results are ideal because it defines LEGTYPE.
> flight$D00 <- NULL
> 
> ## Keep the results but don't change the order.
> outcomes.flight <- flight$LEGTYPE
> 
> flight$LEGTYPE <- NULL
> 
> ## If you know your factors are definitely factors, you don't need this
> ##  asNumeric <- function(x) as.numeric(as.character(x))
> 
> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))
> 
> flight.num0 <- factors.numeric(flight)
> 
> flight.scl0 <- scale(flight.num0)
> 
> ## Now split the samples
> ## we need at least 60 to test with, p at 0.77 gives about 75.
> ## Difficulty here is the bias in the table
> ## Because we only have [3.1, 4.4] the proportion of Weak is higher.
> ## see prop.table(results)
> 
> set.seed(seed.mine)
> inTrain <- createDataPartition(outcomes.flight, p = 0.77, list = FALSE)
> 
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> 
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> 
> prop.table(table(trainClass))
trainClass
Strong 
     1 
> dim(trainDescr)
[1] 247  20
> 
> prop.table(table(testClass))
testClass
Strong 
     1 
> dim(testDescr)
[1] 73 20
> ### weaves
> 
> ## Processing for flights data.
> 
> ## Following the caret vignette.
> 
> ###################################################
> ### code chunk number 1: loadLibs
> ###################################################
> library(MASS)
> library(caret)
> library(mlbench)
> library(pROC)
> library(pls)
> 
> library(doMC)
> registerDoMC(cores = 4)
> 
> options(useFancyQuotes = FALSE) 
> 
> # Accounting info.
> getInfo <- function(what = "Suggests")
+ {
+   text <- packageDescription("caret")[what][[1]]
+   text <- gsub("\n", ", ", text, fixed = TRUE)
+   text <- gsub(">=", "$\\\\ge$", text, fixed = TRUE)
+   eachPkg <- strsplit(text, ", ", fixed = TRUE)[[1]]
+   eachPkg <- gsub(",", "", eachPkg, fixed = TRUE)
+   # out <- paste("\\\\pkg{", eachPkg[order(tolower(eachPkg))], "}", sep = "")
+   # paste(out, collapse = ", ")
+   length(eachPkg)
+ }
> 
> ### project-specific: begin
> ## Set-seed, load original CSV file, order it
> ## and do some simple-cleaning
> ## Various datasets 
> 
> seed.mine = 107
> set.seed(seed.mine)                     # helpful for testing
> 
> flight <- read.csv("../bak/flight.csv")
> flight <- flight[order(flight$D00),]
> 
> # Backup
> flight.raw <- flight
> 
> # To check adjustment, there is test code in flight-nb.R
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"
> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"
> 
> # And some deletions
> 
> t.cols <- colnames(flight)
> 
> t.drops <- t.cols[grep("^RANK*", t.cols)]
> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])
> t.drops <- c(t.drops, "D80THPCTL")
> 
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR
> flight$xHNGR <- flight$xDURN < 0
> 
> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+ }
> 
> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))
> 
> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE
> t.cols <- colnames(flight)
> 
> t.drops <- c("SARRHR", "xDURN")
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Backup
> 
> flight00 <- flight
> 
> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]
> 
> paste("samples in use: ", dim(flight)[1])
[1] "samples in use:  320"
> 
> ## Data insights
> 
> ## *Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> flight <- flight1
> 
> ### Numeric variables
> 
> ## Check some more numeric correlations, I haven't scaled yet.
> ## I'd cut correlations above 0.75 because of overfitting.
> 
> x1 <- as.data.frame(as.matrix(sapply(flight, class)))
> 
> flight.num <- flight[,names(x1[which(x1$V1 %in% c("numeric", "integer")),])]
> 
> flight.nzv <- nearZeroVar(flight.num, saveMetrics = TRUE)
> flight.nzv
             freqRatio percentUnique zeroVar   nzv
SDEPHR        1.038462        5.9375   FALSE FALSE
SKDEPS        1.000000       19.0625   FALSE FALSE
AVGSQ         6.333333       82.8125   FALSE FALSE
AVGLOFATC     1.000000       78.4375   FALSE FALSE
xDURN2        1.428571        2.5000   FALSE FALSE
xAVAILBUCKET  1.767857        2.5000   FALSE FALSE
xAVGSKDAVAIL 18.500000       87.8125   FALSE FALSE
> 
> # annoying NA
> flight.cor <- cor(flight.num, use = "pairwise.complete.obs")
> 
> descrCorr <- findCorrelation(flight.cor, cutoff = .65, verbose=TRUE)
Considering row	 3 column	 1 value	 0.956 
  Flagging column	 3 
Considering row	 1 column	 6 value	 0.011 
Considering row	 1 column	 7 value	 0.053 
Considering row	 1 column	 5 value	 0.204 
Considering row	 1 column	 4 value	 0.131 
Considering row	 1 column	 2 value	 0.054 
Considering row	 6 column	 7 value	 0.869 
  Flagging column	 6 
Considering row	 7 column	 5 value	 0.019 
Considering row	 7 column	 4 value	 0.07 
Considering row	 7 column	 2 value	 0.113 
Considering row	 5 column	 4 value	 0.137 
Considering row	 5 column	 2 value	 0.005 
Considering row	 4 column	 2 value	 0.041 
> 
> colnames(flight.num)[descrCorr]
[1] "AVGSQ"        "xAVAILBUCKET"
> 
> ## Which tells me that departure time is very highly correlated to AVGSQ.
> ## AVGSQ is average stand queue?
> 
> ### Try and impute the AVG, it might have more information than the
> ### bucket.
> 
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))
Error in `$<-.data.frame`(`*tmp*`, "xAVAILBUCKET", value = numeric(0)) : 
  replacement has 0 rows, data has 320
> 
> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1
> 
> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]
Error in `[.data.frame`(flight, , c("AVGSKDAVAIL", "xAVAILBUCKET")) : 
  undefined columns selected
> 
> preProcValues <- preProcess(flight.na, method = c("knnImpute"))
> flight.na1 <- predict(preProcValues, flight.na)
> 
> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL
> 
> ## And I'll leave the centered and scale values in for now.
> ## and delete the troublesome ones
> 
> flight$AVGSKDAVAIL <- NULL
> flight$xHNGR <- NULL
> flight$AVAILBUCKET <- NULL
> 
> ## Re-classing
> ## Check warnings to see what happened.
> ## It doesn't matter if you run this on all or the sub-sample
> ## The proportion is more or less the same
> src.adjust <- TRUE
> source(file = "flight1.R")
Warning message:
In eval(expr, envir, enclos) : adjusting
> flight1 <- flight
> 
> ## This should be deleted, leave it in and the results
> ## are ideal because it defines LEGTYPE.
> flight$D00 <- NULL
> ### weaves
> 
> ## Processing for flights data.
> 
> ## Following the caret vignette.
> 
> ###################################################
> ### code chunk number 1: loadLibs
> ###################################################
> library(MASS)
> library(caret)
> library(mlbench)
> library(pROC)
> library(pls)
> 
> library(doMC)
> registerDoMC(cores = 4)
> 
> options(useFancyQuotes = FALSE) 
> 
> # Accounting info.
> getInfo <- function(what = "Suggests")
+ {
+   text <- packageDescription("caret")[what][[1]]
+   text <- gsub("\n", ", ", text, fixed = TRUE)
+   text <- gsub(">=", "$\\\\ge$", text, fixed = TRUE)
+   eachPkg <- strsplit(text, ", ", fixed = TRUE)[[1]]
+   eachPkg <- gsub(",", "", eachPkg, fixed = TRUE)
+   # out <- paste("\\\\pkg{", eachPkg[order(tolower(eachPkg))], "}", sep = "")
+   # paste(out, collapse = ", ")
+   length(eachPkg)
+ }
> 
> ### project-specific: begin
> ## Set-seed, load original CSV file, order it
> ## and do some simple-cleaning
> ## Various datasets 
> 
> seed.mine = 107
> set.seed(seed.mine)                     # helpful for testing
> 
> flight <- read.csv("../bak/flight.csv")
> flight <- flight[order(flight$D00),]
> 
> # Backup
> flight.raw <- flight
> 
> # To check adjustment, there is test code in flight-nb.R
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"
> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"
> 
> # And some deletions
> 
> t.cols <- colnames(flight)
> 
> t.drops <- t.cols[grep("^RANK*", t.cols)]
> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])
> t.drops <- c(t.drops, "D80THPCTL")
> 
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR
> flight$xHNGR <- flight$xDURN < 0
> 
> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+ }
> 
> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))
> 
> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE
> t.cols <- colnames(flight)
> 
> t.drops <- c("SARRHR", "xDURN")
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Backup
> 
> flight00 <- flight
> 
> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]
> 
> paste("samples in use: ", dim(flight)[1])
[1] "samples in use:  320"
> 
> ## Data insights
> 
> ## *Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> flight <- flight1
> 
> ### Numeric variables
> 
> ## Check some more numeric correlations, I haven't scaled yet.
> ## I'd cut correlations above 0.75 because of overfitting.
> 
> x1 <- as.data.frame(as.matrix(sapply(flight, class)))
> 
> flight.num <- flight[,names(x1[which(x1$V1 %in% c("numeric", "integer")),])]
> 
> flight.nzv <- nearZeroVar(flight.num, saveMetrics = TRUE)
> flight.nzv
             freqRatio percentUnique zeroVar   nzv
SDEPHR        1.038462        5.9375   FALSE FALSE
SKDEPS        1.000000       19.0625   FALSE FALSE
AVGSQ         6.333333       82.8125   FALSE FALSE
AVGLOFATC     1.000000       78.4375   FALSE FALSE
xDURN2        1.428571        2.5000   FALSE FALSE
xAVAILBUCKET  1.767857        2.5000   FALSE FALSE
xAVGSKDAVAIL 18.500000       87.8125   FALSE FALSE
> 
> # annoying NA
> flight.cor <- cor(flight.num, use = "pairwise.complete.obs")
> 
> descrCorr <- findCorrelation(flight.cor, cutoff = .65, verbose=TRUE)
Considering row	 3 column	 1 value	 0.956 
  Flagging column	 3 
Considering row	 1 column	 6 value	 0.011 
Considering row	 1 column	 7 value	 0.053 
Considering row	 1 column	 5 value	 0.204 
Considering row	 1 column	 4 value	 0.131 
Considering row	 1 column	 2 value	 0.054 
Considering row	 6 column	 7 value	 0.869 
  Flagging column	 6 
Considering row	 7 column	 5 value	 0.019 
Considering row	 7 column	 4 value	 0.07 
Considering row	 7 column	 2 value	 0.113 
Considering row	 5 column	 4 value	 0.137 
Considering row	 5 column	 2 value	 0.005 
Considering row	 4 column	 2 value	 0.041 
> 
> colnames(flight.num)[descrCorr]
[1] "AVGSQ"        "xAVAILBUCKET"
> 
> ## Which tells me that departure time is very highly correlated to AVGSQ.
> ## AVGSQ is average stand queue?
> 
> ### Try and impute the AVG, it might have more information than the
> ### bucket.
> 
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))
Error in `$<-.data.frame`(`*tmp*`, "xAVAILBUCKET", value = numeric(0)) : 
  replacement has 0 rows, data has 320
> 
> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1
> 
> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]
Error in `[.data.frame`(flight, , c("AVGSKDAVAIL", "xAVAILBUCKET")) : 
  undefined columns selected
> 
> preProcValues <- preProcess(flight.na, method = c("knnImpute"))
> flight.na1 <- predict(preProcValues, flight.na)
> 
> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL
> 
> ## And I'll leave the centered and scale values in for now.
> ## and delete the troublesome ones
> 
> flight$AVGSKDAVAIL <- NULL
> flight$xHNGR <- NULL
> flight$AVAILBUCKET <- NULL
> 
> ## Re-classing
> ## Check warnings to see what happened.
> ## It doesn't matter if you run this on all or the sub-sample
> ## The proportion is more or less the same
> src.adjust <- TRUE
> source(file = "flight1.R")
Warning message:
In eval(expr, envir, enclos) : adjusting
> flight1 <- flight
> 
> ## This should be deleted, leave it in and the results
> ## are ideal because it defines LEGTYPE.
> flight$D00 <- NULL
> 
> ## Keep the results but don't change the order.
> outcomes.flight <- flight$LEGTYPE
> 
> flight$LEGTYPE <- NULL
> 
> ## If you know your factors are definitely factors, you don't need this
> ##  asNumeric <- function(x) as.numeric(as.character(x))
> 
> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))
> 
> flight.num0 <- factors.numeric(flight)
> 
> flight.scl0 <- scale(flight.num0)
> 
> ## Now split the samples
> ## we need at least 60 to test with, p at 0.77 gives about 75.
> ## Difficulty here is the bias in the table
> ## Because we only have [3.1, 4.4] the proportion of Weak is higher.
> ## see prop.table(results)
> 
> set.seed(seed.mine)
> inTrain <- createDataPartition(outcomes.flight, p = 0.77, list = FALSE)
> 
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> 
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> 
> prop.table(table(trainClass))
trainClass
Strong 
     1 
> dim(trainDescr)
[1] 247  20
> 
> prop.table(table(testClass))
testClass
Strong 
     1 
> dim(testDescr)
[1] 73 20
> ### weaves
> 
> ## Processing for flights data.
> 
> ## Following the caret vignette.
> 
> ###################################################
> ### code chunk number 1: loadLibs
> ###################################################
> library(MASS)
> library(caret)
> library(mlbench)
> library(pROC)
> library(pls)
> 
> library(doMC)
> registerDoMC(cores = 4)
> 
> options(useFancyQuotes = FALSE) 
> 
> # Accounting info.
> getInfo <- function(what = "Suggests")
+ {
+   text <- packageDescription("caret")[what][[1]]
+   text <- gsub("\n", ", ", text, fixed = TRUE)
+   text <- gsub(">=", "$\\\\ge$", text, fixed = TRUE)
+   eachPkg <- strsplit(text, ", ", fixed = TRUE)[[1]]
+   eachPkg <- gsub(",", "", eachPkg, fixed = TRUE)
+   # out <- paste("\\\\pkg{", eachPkg[order(tolower(eachPkg))], "}", sep = "")
+   # paste(out, collapse = ", ")
+   length(eachPkg)
+ }
> 
> ### project-specific: begin
> ## Set-seed, load original CSV file, order it
> ## and do some simple-cleaning
> ## Various datasets 
> 
> seed.mine = 107
> set.seed(seed.mine)                     # helpful for testing
> 
> flight <- read.csv("../bak/flight.csv")
> flight <- flight[order(flight$D00),]
> 
> # Backup
> flight.raw <- flight
> 
> # To check adjustment, there is test code in flight-nb.R
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"
> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"
> 
> # And some deletions
> 
> t.cols <- colnames(flight)
> 
> t.drops <- t.cols[grep("^RANK*", t.cols)]
> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])
> t.drops <- c(t.drops, "D80THPCTL")
> 
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR
> flight$xHNGR <- flight$xDURN < 0
> 
> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+ }
> 
> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))
> 
> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE
> t.cols <- colnames(flight)
> 
> t.drops <- c("SARRHR", "xDURN")
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Backup
> 
> flight00 <- flight
> 
> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]
> 
> paste("samples in use: ", dim(flight)[1])
[1] "samples in use:  320"
> 
> ## Data insights
> 
> ## *Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> flight <- flight1
> 
> ### Numeric variables
> 
> ### Try and impute the AVG, it might have more information than the
> ### bucket.
> 
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))
Error in `$<-.data.frame`(`*tmp*`, "xAVAILBUCKET", value = numeric(0)) : 
  replacement has 0 rows, data has 320
> 
> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1
> 
> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]
Error in `[.data.frame`(flight, , c("AVGSKDAVAIL", "xAVAILBUCKET")) : 
  undefined columns selected
> 
> preProcValues <- preProcess(flight.na, method = c("knnImpute"))
> flight.na1 <- predict(preProcValues, flight.na)
> 
> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL
> 
> ## Check some more numeric correlations, I haven't scaled everything yet.
> ## I'd cut correlations above 0.65 to 0.75 because of overfitting.
> ### weaves
> 
> ## Processing for flights data.
> 
> ## Following the caret vignette.
> 
> ###################################################
> ### code chunk number 1: loadLibs
> ###################################################
> library(MASS)
> library(caret)
> library(mlbench)
> library(pROC)
> library(pls)
> 
> library(doMC)
> registerDoMC(cores = 4)
> 
> options(useFancyQuotes = FALSE) 
> 
> # Accounting info.
> getInfo <- function(what = "Suggests")
+ {
+   text <- packageDescription("caret")[what][[1]]
+   text <- gsub("\n", ", ", text, fixed = TRUE)
+   text <- gsub(">=", "$\\\\ge$", text, fixed = TRUE)
+   eachPkg <- strsplit(text, ", ", fixed = TRUE)[[1]]
+   eachPkg <- gsub(",", "", eachPkg, fixed = TRUE)
+   # out <- paste("\\\\pkg{", eachPkg[order(tolower(eachPkg))], "}", sep = "")
+   # paste(out, collapse = ", ")
+   length(eachPkg)
+ }
> 
> ### project-specific: begin
> ## Set-seed, load original CSV file, order it
> ## and do some simple-cleaning
> ## Various datasets 
> 
> seed.mine = 107
> set.seed(seed.mine)                     # helpful for testing
> 
> flight <- read.csv("../bak/flight.csv")
> flight <- flight[order(flight$D00),]
> 
> # Backup
> flight.raw <- flight
> 
> # To check adjustment, there is test code in flight-nb.R
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"
> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"
> 
> # And some deletions
> 
> t.cols <- colnames(flight)
> 
> t.drops <- t.cols[grep("^RANK*", t.cols)]
> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])
> t.drops <- c(t.drops, "D80THPCTL")
> 
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR
> flight$xHNGR <- flight$xDURN < 0
> 
> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+ }
> 
> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))
> 
> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE
> t.cols <- colnames(flight)
> 
> t.drops <- c("SARRHR", "xDURN")
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Backup
> 
> flight00 <- flight
> 
> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]
> 
> paste("samples in use: ", dim(flight)[1])
[1] "samples in use:  320"
> 
> ## Data insights
> 
> ## *Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> flight <- flight1
> 
> ### Numeric variables
> 
> ### Try and impute the AVG, it might have more information than the
> ### bucket.
> 
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))
Error in `$<-.data.frame`(`*tmp*`, "xAVAILBUCKET", value = numeric(0)) : 
  replacement has 0 rows, data has 320
> 
> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1
> 
> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]
Error in `[.data.frame`(flight, , c("AVGSKDAVAIL", "xAVAILBUCKET")) : 
  undefined columns selected
> 
> preProcValues <- preProcess(flight.na, method = c("knnImpute"))
> flight.na1 <- predict(preProcValues, flight.na)
> 
> ## I'll add the new imputed value and drop the others
> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL
> flight$AVGSKDAVAIL <- NULL
> flight$xAVAILBUCKET <- NULL
> flight$AVAILBUCKET <- NULL
> 
> flight$xHNGR <- NULL
> 
> ## Check some more numeric correlations, I haven't scaled everything yet.
> ## I'd cut correlations above 0.65 to 0.75 because of overfitting.
> 
> x1 <- as.data.frame(as.matrix(sapply(flight, class)))
> 
> flight.num <- flight[,names(x1[which(x1$V1 %in% c("numeric", "integer")),])]
> 
> flight.nzv <- nearZeroVar(flight.num, saveMetrics = TRUE)
> flight.nzv
             freqRatio percentUnique zeroVar   nzv
SDEPHR        1.038462        5.9375   FALSE FALSE
SKDEPS        1.000000       19.0625   FALSE FALSE
AVGSQ         6.333333       82.8125   FALSE FALSE
AVGLOFATC     1.000000       78.4375   FALSE FALSE
xDURN2        1.428571        2.5000   FALSE FALSE
xAVGSKDAVAIL 18.500000       87.8125   FALSE FALSE
> 
> # annoying NA should be gone.
> flight.cor <- cor(flight.num, use = "pairwise.complete.obs")
> 
> descrCorr <- findCorrelation(flight.cor, cutoff = .65, verbose=TRUE)
Considering row	 3 column	 1 value	 0.956 
  Flagging column	 3 
Considering row	 1 column	 5 value	 0.204 
Considering row	 1 column	 4 value	 0.131 
Considering row	 1 column	 6 value	 0.053 
Considering row	 1 column	 2 value	 0.054 
Considering row	 5 column	 4 value	 0.137 
Considering row	 5 column	 6 value	 0.019 
Considering row	 5 column	 2 value	 0.005 
Considering row	 4 column	 6 value	 0.07 
Considering row	 4 column	 2 value	 0.041 
Considering row	 6 column	 2 value	 0.113 
> 
> colnames(flight.num)[descrCorr]
[1] "AVGSQ"
> 
> ## And I'll leave the centered and scale values in for now.
> ## and delete the troublesome ones
> 
> ## Re-classing
> ## Check warnings to see what happened.
> ## It doesn't matter if you run this on all or the sub-sample
> ## The proportion is more or less the same
> src.adjust <- TRUE
> source(file = "flight1.R")
Warning message:
In eval(expr, envir, enclos) : adjusting
> flight1 <- flight
> 
> ## This should be deleted, leave it in and the results
> ## are ideal because it defines LEGTYPE.
> flight$D00 <- NULL
> 
> ## Keep the results but don't change the order.
> outcomes.flight <- flight$LEGTYPE
> 
> flight$LEGTYPE <- NULL
> 
> ## If you know your factors are definitely factors, you don't need this
> ##  asNumeric <- function(x) as.numeric(as.character(x))
> 
> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))
> 
> flight.num0 <- factors.numeric(flight)
> 
> flight.scl0 <- scale(flight.num0)
> 
> ## Now split the samples
> ## we need at least 60 to test with, p at 0.77 gives about 75.
> ## Difficulty here is the bias in the table
> ## Because we only have [3.1, 4.4] the proportion of Weak is higher.
> ## see prop.table(results)
> 
> set.seed(seed.mine)
> inTrain <- createDataPartition(outcomes.flight, p = 0.77, list = FALSE)
> 
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> 
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> 
> prop.table(table(trainClass))
trainClass
Strong 
     1 
> dim(trainDescr)
[1] 247  19
> 
> prop.table(table(testClass))
testClass
Strong 
     1 
> dim(testDescr)
[1] 73 19
> quit()
Save workspace image? [y/n/c]: n

Process R finished at Sat May  7 03:24:15 2016


R version 3.2.5 (2016-04-14) -- "Very, Very Secure Dishes"
Copyright (C) 2016 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> options(STERM='iESS', str.dendrogram.last="'", editor='emacsclient', show.error.locations=TRUE)
> ### weaves
> 
> ## Processing for flights data.
> 
> ## Following the caret vignette.
> 
> ###################################################
> ### code chunk number 1: loadLibs
> ###################################################
> library(MASS)
> library(caret)
Loading required package: lattice
Loading required package: ggplot2
> library(mlbench)
> library(pROC)
Type 'citation("pROC")' for a citation.

Attaching package: 'pROC'

The following objects are masked from 'package:stats':

    cov, smooth, var

> library(pls)

Attaching package: 'pls'

The following object is masked from 'package:caret':

    R2

The following object is masked from 'package:stats':

    loadings

> 
> library(doMC)
Loading required package: foreach
foreach: simple, scalable parallel programming from Revolution Analytics
Use Revolution R for scalability, fault tolerance and more.
http://www.revolutionanalytics.com
Loading required package: iterators
Loading required package: parallel
> registerDoMC(cores = 4)
> 
> options(useFancyQuotes = FALSE) 
> 
> # Accounting info.
> getInfo <- function(what = "Suggests")
+ {
+   text <- packageDescription("caret")[what][[1]]
+   text <- gsub("\n", ", ", text, fixed = TRUE)
+   text <- gsub(">=", "$\\\\ge$", text, fixed = TRUE)
+   eachPkg <- strsplit(text, ", ", fixed = TRUE)[[1]]
+   eachPkg <- gsub(",", "", eachPkg, fixed = TRUE)
+   # out <- paste("\\\\pkg{", eachPkg[order(tolower(eachPkg))], "}", sep = "")
+   # paste(out, collapse = ", ")
+   length(eachPkg)
+ }
> 
> ### project-specific: begin
> ## Set-seed, load original CSV file, order it
> ## and do some simple-cleaning
> ## Various datasets 
> 
> seed.mine = 107
> set.seed(seed.mine)                     # helpful for testing
> 
> flight <- read.csv("../bak/flight.csv")
> flight <- flight[order(flight$D00),]
> 
> # Backup
> flight.raw <- flight
> 
> # To check adjustment, there is test code in flight-nb.R
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"
> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"
> 
> # And some deletions
> 
> t.cols <- colnames(flight)
> 
> t.drops <- t.cols[grep("^RANK*", t.cols)]
> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])
> t.drops <- c(t.drops, "D80THPCTL")
> 
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR
> flight$xHNGR <- flight$xDURN < 0
> 
> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+ }
> 
> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))
> 
> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE
> t.cols <- colnames(flight)
> 
> t.drops <- c("SARRHR", "xDURN")
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Backup
> 
> flight00 <- flight
> 
> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]
> 
> paste("samples in use: ", dim(flight)[1])
[1] "samples in use:  320"
> 
> ## Data insights
> 
> ## *Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> flight <- flight1
Error: object 'flight1' not found
> 
> ### Numeric variables
> 
> ### Try and impute the AVG, it might have more information than the
> ### bucket.
> 
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))
> 
> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1
> 
> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]
> 
> preProcValues <- preProcess(flight.na, method = c("knnImpute"))
> flight.na1 <- predict(preProcValues, flight.na)
> 
> ## I'll add the new imputed value and drop the others
> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL
> flight$AVGSKDAVAIL <- NULL
> flight$xAVAILBUCKET <- NULL
> flight$AVAILBUCKET <- NULL
> 
> flight$xHNGR <- NULL
> 
> ## Check some more numeric correlations, I haven't scaled everything yet.
> ## I'd cut correlations above 0.65 to 0.75 because of overfitting.
> 
> x1 <- as.data.frame(as.matrix(sapply(flight, class)))
> 
> flight.num <- flight[,names(x1[which(x1$V1 %in% c("numeric", "integer")),])]
> 
> flight.nzv <- nearZeroVar(flight.num, saveMetrics = TRUE)
> flight.nzv
             freqRatio percentUnique zeroVar   nzv
SDEPHR        1.038462        5.9375   FALSE FALSE
SKDEPS        1.000000       19.0625   FALSE FALSE
D00           1.166667       75.3125   FALSE FALSE
AVGSQ         6.333333       82.8125   FALSE FALSE
AVGLOFATC     1.000000       78.4375   FALSE FALSE
xDURN2        1.428571        2.5000   FALSE FALSE
xAVGSKDAVAIL 18.500000       87.8125   FALSE FALSE
> 
> # annoying NA should be gone.
> flight.cor <- cor(flight.num, use = "pairwise.complete.obs")
> 
> descrCorr <- findCorrelation(flight.cor, cutoff = .65, verbose=TRUE)
Considering row	 4 column	 1 value	 0.956 
  Flagging column	 4 
Considering row	 1 column	 3 value	 0.43 
Considering row	 1 column	 7 value	 0.053 
Considering row	 1 column	 6 value	 0.204 
Considering row	 1 column	 5 value	 0.131 
Considering row	 1 column	 2 value	 0.054 
Considering row	 3 column	 7 value	 0.401 
Considering row	 3 column	 6 value	 0.071 
Considering row	 3 column	 5 value	 0.114 
Considering row	 3 column	 2 value	 0.006 
Considering row	 7 column	 6 value	 0.019 
Considering row	 7 column	 5 value	 0.07 
Considering row	 7 column	 2 value	 0.113 
Considering row	 6 column	 5 value	 0.137 
Considering row	 6 column	 2 value	 0.005 
Considering row	 5 column	 2 value	 0.041 
> 
> colnames(flight.num)[descrCorr]
[1] "AVGSQ"
> 
> ## And I'll leave the centered and scale values in for now.
> ## and delete the troublesome ones
> 
> ## Re-classing
> ## Check warnings to see what happened.
> ## It doesn't matter if you run this on all or the sub-sample
> ## The proportion is more or less the same
> src.adjust <- TRUE
> source(file = "flight1.R")
Warning message:
In eval(expr, envir, enclos) : adjusting
> flight1 <- flight
> 
> ## This should be deleted, leave it in and the results
> ## are ideal because it defines LEGTYPE.
> flight$D00 <- NULL
> 
> ## Keep the results but don't change the order.
> outcomes.flight <- flight$LEGTYPE
> 
> flight$LEGTYPE <- NULL
> 
> ## If you know your factors are definitely factors, you don't need this
> ##  asNumeric <- function(x) as.numeric(as.character(x))
> 
> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))
> 
> flight.num0 <- factors.numeric(flight)
> 
> flight.scl0 <- scale(flight.num0)
> 
> ## Now split the samples
> ## we need at least 60 to test with, p at 0.77 gives about 75.
> ## Difficulty here is the bias in the table
> ## Because we only have [3.1, 4.4] the proportion of Weak is higher.
> ## see prop.table(results)
> 
> set.seed(seed.mine)
> inTrain <- createDataPartition(outcomes.flight, p = 0.77, list = FALSE)
> 
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> 
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> 
> prop.table(table(trainClass))
trainClass
   Strong      Weak 
0.4898785 0.5101215 
> dim(trainDescr)
[1] 247  19
> 
> prop.table(table(testClass))
testClass
   Strong      Weak 
0.4931507 0.5068493 
> dim(testDescr)
[1] 73 19
> ### weaves
> 
> ## Processing for flights data.
> 
> ## Following the caret vignette.
> 
> ###################################################
> ### code chunk number 1: loadLibs
> ###################################################
> library(MASS)
> library(caret)
> library(mlbench)
> library(pROC)
> library(pls)
> 
> library(doMC)
> registerDoMC(cores = 4)
> 
> options(useFancyQuotes = FALSE) 
> 
> # Accounting info.
> getInfo <- function(what = "Suggests")
+ {
+   text <- packageDescription("caret")[what][[1]]
+   text <- gsub("\n", ", ", text, fixed = TRUE)
+   text <- gsub(">=", "$\\\\ge$", text, fixed = TRUE)
+   eachPkg <- strsplit(text, ", ", fixed = TRUE)[[1]]
+   eachPkg <- gsub(",", "", eachPkg, fixed = TRUE)
+   # out <- paste("\\\\pkg{", eachPkg[order(tolower(eachPkg))], "}", sep = "")
+   # paste(out, collapse = ", ")
+   length(eachPkg)
+ }
> 
> ### project-specific: begin
> ## Set-seed, load original CSV file, order it
> ## and do some simple-cleaning
> ## Various datasets 
> 
> seed.mine = 107
> set.seed(seed.mine)                     # helpful for testing
> 
> flight <- read.csv("../bak/flight.csv")
> flight <- flight[order(flight$D00),]
> 
> # Backup
> flight.raw <- flight
> 
> # To check adjustment, there is test code in flight-nb.R
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"
> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"
> 
> # And some deletions
> 
> t.cols <- colnames(flight)
> 
> t.drops <- t.cols[grep("^RANK*", t.cols)]
> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])
> t.drops <- c(t.drops, "D80THPCTL")
> 
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR
> flight$xHNGR <- flight$xDURN < 0
> 
> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+ }
> 
> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))
> 
> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE
> t.cols <- colnames(flight)
> 
> t.drops <- c("SARRHR", "xDURN")
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Backup
> 
> flight00 <- flight
> 
> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]
> 
> paste("samples in use: ", dim(flight)[1])
[1] "samples in use:  320"
> 
> ## Data insights
> 
> ## *Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> flight <- flight1
> 
> ### Numeric variables
> 
> ### Try and impute the AVG, it might have more information than the
> ### bucket.
> 
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))
Error in `$<-.data.frame`(`*tmp*`, "xAVAILBUCKET", value = numeric(0)) : 
  replacement has 0 rows, data has 320
> 
> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1
> 
> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]
Error in `[.data.frame`(flight, , c("AVGSKDAVAIL", "xAVAILBUCKET")) : 
  undefined columns selected
> 
> preProcValues <- preProcess(flight.na, method = c("knnImpute"))
> flight.na1 <- predict(preProcValues, flight.na)
> 
> ## I'll add the new imputed value and drop the others
> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL
> flight$AVGSKDAVAIL <- NULL
> flight$xAVAILBUCKET <- NULL
> flight$AVAILBUCKET <- NULL
> 
> flight$xHNGR <- NULL
> 
> ## Check some more numeric correlations, I haven't scaled everything yet.
> ## I'd cut correlations above 0.65 to 0.75 because of overfitting.
> 
> x1 <- as.data.frame(as.matrix(sapply(flight, class)))
> 
> flight.num <- flight[,names(x1[which(x1$V1 %in% c("numeric", "integer")),])]
> 
> flight.nzv <- nearZeroVar(flight.num, saveMetrics = TRUE)
> flight.nzv
             freqRatio percentUnique zeroVar   nzv
SDEPHR        1.038462        5.9375   FALSE FALSE
SKDEPS        1.000000       19.0625   FALSE FALSE
D00           1.166667       75.3125   FALSE FALSE
AVGSQ         6.333333       82.8125   FALSE FALSE
AVGLOFATC     1.000000       78.4375   FALSE FALSE
xDURN2        1.428571        2.5000   FALSE FALSE
xAVGSKDAVAIL 18.500000       87.8125   FALSE FALSE
> 
> # annoying NA should be gone.
> flight.cor <- cor(flight.num, use = "pairwise.complete.obs")
> 
> descrCorr <- findCorrelation(flight.cor, cutoff = .65, verbose=TRUE)
Considering row	 4 column	 1 value	 0.956 
  Flagging column	 4 
Considering row	 1 column	 3 value	 0.43 
Considering row	 1 column	 7 value	 0.053 
Considering row	 1 column	 6 value	 0.204 
Considering row	 1 column	 5 value	 0.131 
Considering row	 1 column	 2 value	 0.054 
Considering row	 3 column	 7 value	 0.401 
Considering row	 3 column	 6 value	 0.071 
Considering row	 3 column	 5 value	 0.114 
Considering row	 3 column	 2 value	 0.006 
Considering row	 7 column	 6 value	 0.019 
Considering row	 7 column	 5 value	 0.07 
Considering row	 7 column	 2 value	 0.113 
Considering row	 6 column	 5 value	 0.137 
Considering row	 6 column	 2 value	 0.005 
Considering row	 5 column	 2 value	 0.041 
> 
> colnames(flight.num)[descrCorr]
[1] "AVGSQ"
> 
> ## And I'll leave the centered and scale values in for now.
> ## and delete the troublesome ones
> 
> ## Re-classing
> ## Check warnings to see what happened.
> ## It doesn't matter if you run this on all or the sub-sample
> ## The proportion is more or less the same
> src.adjust <- TRUE
> source(file = "flight1.R")
Warning message:
In eval(expr, envir, enclos) : adjusting
> flight1 <- flight
> 
> ## This should be deleted, leave it in and the results
> ## are ideal because it defines LEGTYPE.
> flight$D00 <- NULL
> 
> ## Keep the results but don't change the order.
> outcomes.flight <- flight$LEGTYPE
> 
> flight$LEGTYPE <- NULL
> 
> ## If you know your factors are definitely factors, you don't need this
> ##  asNumeric <- function(x) as.numeric(as.character(x))
> 
> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))
> 
> flight.num0 <- factors.numeric(flight)
> 
> flight.scl0 <- scale(flight.num0)
> 
> ## Now split the samples
> ## we need at least 60 to test with, p at 0.77 gives about 75.
> ## Difficulty here is the bias in the table
> ## Because we only have [3.1, 4.4] the proportion of Weak is higher.
> ## see prop.table(results)
> 
> set.seed(seed.mine)
> inTrain <- createDataPartition(outcomes.flight, p = 0.77, list = FALSE)
> 
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> 
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> 
> prop.table(table(trainClass))
trainClass
   Strong      Weak 
0.4898785 0.5101215 
> dim(trainDescr)
[1] 247  19
> 
> prop.table(table(testClass))
testClass
   Strong      Weak 
0.4931507 0.5068493 
> dim(testDescr)
[1] 73 19
> ### weaves
> 
> ## Processing for flights data.
> 
> ## Following the caret vignette.
> 
> ###################################################
> ### code chunk number 1: loadLibs
> ###################################################
> library(MASS)
> library(caret)
> library(mlbench)
> library(pROC)
> library(pls)
> 
> library(doMC)
> registerDoMC(cores = 4)
> 
> options(useFancyQuotes = FALSE) 
> 
> # Accounting info.
> getInfo <- function(what = "Suggests")
+ {
+   text <- packageDescription("caret")[what][[1]]
+   text <- gsub("\n", ", ", text, fixed = TRUE)
+   text <- gsub(">=", "$\\\\ge$", text, fixed = TRUE)
+   eachPkg <- strsplit(text, ", ", fixed = TRUE)[[1]]
+   eachPkg <- gsub(",", "", eachPkg, fixed = TRUE)
+   # out <- paste("\\\\pkg{", eachPkg[order(tolower(eachPkg))], "}", sep = "")
+   # paste(out, collapse = ", ")
+   length(eachPkg)
+ }
> 
> ### project-specific: begin
> ## Set-seed, load original CSV file, order it
> ## and do some simple-cleaning
> ## Various datasets 
> 
> seed.mine = 107
> set.seed(seed.mine)                     # helpful for testing
> 
> flight <- read.csv("../bak/flight.csv")
> flight <- flight[order(flight$D00),]
> 
> # Backup
> flight.raw <- flight
> 
> # To check adjustment, there is test code in flight-nb.R
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"
> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"
> 
> # And some deletions
> 
> t.cols <- colnames(flight)
> 
> t.drops <- t.cols[grep("^RANK*", t.cols)]
> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])
> t.drops <- c(t.drops, "D80THPCTL")
> 
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR
> flight$xHNGR <- flight$xDURN < 0
> 
> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+ }
> 
> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))
> 
> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE
> t.cols <- colnames(flight)
> 
> t.drops <- c("SARRHR", "xDURN")
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Backup
> 
> flight00 <- flight
> 
> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]
> 
> paste("samples in use: ", dim(flight)[1])
[1] "samples in use:  320"
> 
> ## Data insights
> 
> ## *Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> flight <- flight1
> 
> ### Numeric variables
> 
> ### Try and impute the AVG, it might have more information than the
> ### bucket.
> 
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))
Error in `$<-.data.frame`(`*tmp*`, "xAVAILBUCKET", value = numeric(0)) : 
  replacement has 0 rows, data has 320
> 
> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1
> 
> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]
Error in `[.data.frame`(flight, , c("AVGSKDAVAIL", "xAVAILBUCKET")) : 
  undefined columns selected
> 
> preProcValues <- preProcess(flight.na, method = c("knnImpute"))
> flight.na1 <- predict(preProcValues, flight.na)
> 
> ## I'll add the new imputed value and drop the others
> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL
> flight$AVGSKDAVAIL <- NULL
> flight$xAVAILBUCKET <- NULL
> flight$AVAILBUCKET <- NULL
> 
> flight$xHNGR <- NULL
> 
> ## Check some more numeric correlations, I haven't scaled everything yet.
> ## I'd cut correlations above 0.65 to 0.75 because of overfitting.
> 
> x1 <- as.data.frame(as.matrix(sapply(flight, class)))
> 
> flight.num <- flight[,names(x1[which(x1$V1 %in% c("numeric", "integer")),])]
> 
> flight.nzv <- nearZeroVar(flight.num, saveMetrics = TRUE)
> flight.nzv
             freqRatio percentUnique zeroVar   nzv
SDEPHR        1.038462        5.9375   FALSE FALSE
SKDEPS        1.000000       19.0625   FALSE FALSE
D00           1.166667       75.3125   FALSE FALSE
AVGSQ         6.333333       82.8125   FALSE FALSE
AVGLOFATC     1.000000       78.4375   FALSE FALSE
xDURN2        1.428571        2.5000   FALSE FALSE
xAVGSKDAVAIL 18.500000       87.8125   FALSE FALSE
> 
> # annoying NA should be gone.
> flight.cor <- cor(flight.num, use = "pairwise.complete.obs")
> 
> descrCorr <- findCorrelation(flight.cor, cutoff = .65, verbose=TRUE)
Considering row	 4 column	 1 value	 0.956 
  Flagging column	 4 
Considering row	 1 column	 3 value	 0.43 
Considering row	 1 column	 7 value	 0.053 
Considering row	 1 column	 6 value	 0.204 
Considering row	 1 column	 5 value	 0.131 
Considering row	 1 column	 2 value	 0.054 
Considering row	 3 column	 7 value	 0.401 
Considering row	 3 column	 6 value	 0.071 
Considering row	 3 column	 5 value	 0.114 
Considering row	 3 column	 2 value	 0.006 
Considering row	 7 column	 6 value	 0.019 
Considering row	 7 column	 5 value	 0.07 
Considering row	 7 column	 2 value	 0.113 
Considering row	 6 column	 5 value	 0.137 
Considering row	 6 column	 2 value	 0.005 
Considering row	 5 column	 2 value	 0.041 
> 
> colnames(flight.num)[descrCorr]
[1] "AVGSQ"
> 
> ## And I'll leave the centered and scale values in for now.
> ## and delete the troublesome ones
> 
> ## Re-classing
> ## Check warnings to see what happened.
> ## It doesn't matter if you run this on all or the sub-sample
> ## The proportion is more or less the same
> src.adjust <- TRUE
> source(file = "flight1.R")
Warning message:
In eval(expr, envir, enclos) : adjusting
> flight1 <- flight
> 
> ## This should be deleted, leave it in and the results
> ## are ideal because it defines LEGTYPE.
> flight$D00 <- NULL
> 
> ## Keep the results but don't change the order.
> outcomes.flight <- flight$LEGTYPE
> 
> flight$LEGTYPE <- NULL
> 
> ## If you know your factors are definitely factors, you don't need this
> ##  asNumeric <- function(x) as.numeric(as.character(x))
> 
> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))
> 
> flight.num0 <- factors.numeric(flight)
> 
> flight.scl0 <- scale(flight.num0)
> 
> ## Now split the samples
> ## we need at least 60 to test with, p at 0.77 gives about 75.
> ## Difficulty here is the bias in the table
> ## Because we only have [3.1, 4.4] the proportion of Weak is higher.
> ## see prop.table(results)
> 
> set.seed(seed.mine)
> inTrain <- createDataPartition(outcomes.flight, p = 0.77, list = FALSE)
> 
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> 
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> 
> prop.table(table(trainClass))
trainClass
   Strong      Weak 
0.5506073 0.4493927 
> dim(trainDescr)
[1] 247  19
> 
> prop.table(table(testClass))
testClass
   Strong      Weak 
0.5479452 0.4520548 
> dim(testDescr)
[1] 73 19
> ### weaves
> 
> ## Processing for flights data.
> 
> ## Following the caret vignette.
> 
> ###################################################
> ### code chunk number 1: loadLibs
> ###################################################
> library(MASS)
> library(caret)
> library(mlbench)
> library(pROC)
> library(pls)
> 
> library(doMC)
> registerDoMC(cores = 4)
> 
> options(useFancyQuotes = FALSE) 
> 
> # Accounting info.
> getInfo <- function(what = "Suggests")
+ {
+   text <- packageDescription("caret")[what][[1]]
+   text <- gsub("\n", ", ", text, fixed = TRUE)
+   text <- gsub(">=", "$\\\\ge$", text, fixed = TRUE)
+   eachPkg <- strsplit(text, ", ", fixed = TRUE)[[1]]
+   eachPkg <- gsub(",", "", eachPkg, fixed = TRUE)
+   # out <- paste("\\\\pkg{", eachPkg[order(tolower(eachPkg))], "}", sep = "")
+   # paste(out, collapse = ", ")
+   length(eachPkg)
+ }
> 
> ### project-specific: begin
> ## Set-seed, load original CSV file, order it
> ## and do some simple-cleaning
> ## Various datasets 
> 
> seed.mine = 107
> set.seed(seed.mine)                     # helpful for testing
> 
> flight <- read.csv("../bak/flight.csv")
> flight <- flight[order(flight$D00),]
> 
> # Backup
> flight.raw <- flight
> 
> # To check adjustment, there is test code in flight-nb.R
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"
> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"
> 
> # And some deletions
> 
> t.cols <- colnames(flight)
> 
> t.drops <- t.cols[grep("^RANK*", t.cols)]
> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])
> t.drops <- c(t.drops, "D80THPCTL")
> 
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR
> flight$xHNGR <- flight$xDURN < 0
> 
> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+ }
> 
> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))
> 
> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE
> t.cols <- colnames(flight)
> 
> t.drops <- c("SARRHR", "xDURN")
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Backup
> 
> flight00 <- flight
> 
> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]
> 
> paste("samples in use: ", dim(flight)[1])
[1] "samples in use:  320"
> 
> ## Data insights
> 
> ## *Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> flight <- flight1
> 
> ### Numeric variables
> 
> ### Try and impute the AVG, it might have more information than the
> ### bucket.
> 
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))
Error in `$<-.data.frame`(`*tmp*`, "xAVAILBUCKET", value = numeric(0)) : 
  replacement has 0 rows, data has 320
> 
> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1
> 
> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]
Error in `[.data.frame`(flight, , c("AVGSKDAVAIL", "xAVAILBUCKET")) : 
  undefined columns selected
> 
> preProcValues <- preProcess(flight.na, method = c("knnImpute"))
> flight.na1 <- predict(preProcValues, flight.na)
> 
> ## I'll add the new imputed value and drop the others
> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL
> flight$AVGSKDAVAIL <- NULL
> flight$xAVAILBUCKET <- NULL
> flight$AVAILBUCKET <- NULL
> 
> flight$xHNGR <- NULL
> 
> ## Check some more numeric correlations, I haven't scaled everything yet.
> ## I'd cut correlations above 0.65 to 0.75 because of overfitting.
> 
> x1 <- as.data.frame(as.matrix(sapply(flight, class)))
> 
> flight.num <- flight[,names(x1[which(x1$V1 %in% c("numeric", "integer")),])]
> 
> flight.nzv <- nearZeroVar(flight.num, saveMetrics = TRUE)
> flight.nzv
             freqRatio percentUnique zeroVar   nzv
SDEPHR        1.038462        5.9375   FALSE FALSE
SKDEPS        1.000000       19.0625   FALSE FALSE
D00           1.166667       75.3125   FALSE FALSE
AVGSQ         6.333333       82.8125   FALSE FALSE
AVGLOFATC     1.000000       78.4375   FALSE FALSE
xDURN2        1.428571        2.5000   FALSE FALSE
xAVGSKDAVAIL 18.500000       87.8125   FALSE FALSE
> 
> # annoying NA should be gone.
> flight.cor <- cor(flight.num, use = "pairwise.complete.obs")
> 
> descrCorr <- findCorrelation(flight.cor, cutoff = .65, verbose=TRUE)
Considering row	 4 column	 1 value	 0.956 
  Flagging column	 4 
Considering row	 1 column	 3 value	 0.43 
Considering row	 1 column	 7 value	 0.053 
Considering row	 1 column	 6 value	 0.204 
Considering row	 1 column	 5 value	 0.131 
Considering row	 1 column	 2 value	 0.054 
Considering row	 3 column	 7 value	 0.401 
Considering row	 3 column	 6 value	 0.071 
Considering row	 3 column	 5 value	 0.114 
Considering row	 3 column	 2 value	 0.006 
Considering row	 7 column	 6 value	 0.019 
Considering row	 7 column	 5 value	 0.07 
Considering row	 7 column	 2 value	 0.113 
Considering row	 6 column	 5 value	 0.137 
Considering row	 6 column	 2 value	 0.005 
Considering row	 5 column	 2 value	 0.041 
> 
> colnames(flight.num)[descrCorr]
[1] "AVGSQ"
> 
> ## And I'll leave the centered and scale values in for now.
> ## and delete the troublesome ones
> 
> ## Re-classing
> ## Check warnings to see what happened.
> ## It doesn't matter if you run this on all or the sub-sample
> ## The proportion is more or less the same
> src.adjust <- TRUE
> source(file = "flight1.R")
Warning message:
In eval(expr, envir, enclos) : adjusting
> flight1 <- flight
> 
> ## This should be deleted, leave it in and the results
> ## are ideal because it defines LEGTYPE.
> flight$D00 <- NULL
> 
> ## Keep the results but don't change the order.
> outcomes.flight <- flight$LEGTYPE
> 
> flight$LEGTYPE <- NULL
> 
> ## If you know your factors are definitely factors, you don't need this
> ##  asNumeric <- function(x) as.numeric(as.character(x))
> 
> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))
> 
> flight.num0 <- factors.numeric(flight)
> 
> flight.scl0 <- scale(flight.num0)
> 
> ## Now split the samples
> ## we need at least 60 to test with, p at 0.77 gives about 75.
> ## Difficulty here is the bias in the table
> ## Because we only have [3.1, 4.4] the proportion of Weak is higher.
> ## see prop.table(results)
> 
> set.seed(seed.mine)
> inTrain <- createDataPartition(outcomes.flight, p = 0.77, list = FALSE)
> 
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> 
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> 
> prop.table(table(trainClass))
trainClass
   Strong      Weak 
0.5524194 0.4475806 
> dim(trainDescr)
[1] 248  19
> 
> prop.table(table(testClass))
testClass
   Strong      Weak 
0.5555556 0.4444444 
> dim(testDescr)
[1] 72 19
> ## Check Near-zero variance
> 
> nzv <- nearZeroVar(trainDescr, saveMetrics= TRUE)
> stopifnot( all(nzv$nzv == FALSE) )
> 
> # It's imputed and behaves well, no need for this.
> # descrCorr <- cor(scale(trainDescr), use = "pairwise.complete.obs")
> 
> descrCorr <- cor(scale(trainDescr))
> 
> ## This cut-off should be under src.adjust control.
> ## I'm under Git, so I can tinker with it.
> highCorr <- findCorrelation(descrCorr, cutoff = .65, verbose = TRUE)
Considering row	 17 column	 16 value	 0.85 
  Flagging column	 17 
Considering row	 16 column	 10 value	 0.568 
Considering row	 16 column	 1 value	 0.236 
Considering row	 16 column	 11 value	 0.231 
Considering row	 16 column	 6 value	 0.189 
Considering row	 16 column	 12 value	 0.19 
Considering row	 16 column	 2 value	 0.333 
Considering row	 16 column	 9 value	 0.671 
  Flagging column	 16 
Considering row	 10 column	 1 value	 0.281 
Considering row	 10 column	 11 value	 0.275 
Considering row	 10 column	 6 value	 0.298 
Considering row	 10 column	 12 value	 0.255 
Considering row	 10 column	 2 value	 0.286 
Considering row	 10 column	 9 value	 0.404 
Considering row	 10 column	 14 value	 0.224 
Considering row	 10 column	 13 value	 0.199 
Considering row	 10 column	 8 value	 0.366 
Considering row	 10 column	 3 value	 0.462 
Considering row	 10 column	 18 value	 0.226 
Considering row	 10 column	 19 value	 0.103 
Considering row	 10 column	 15 value	 0.274 
Considering row	 10 column	 4 value	 0.018 
Considering row	 10 column	 7 value	 0.127 
Considering row	 10 column	 5 value	 0.096 
Considering row	 1 column	 11 value	 0.988 
  Flagging column	 1 
Considering row	 11 column	 6 value	 0.945 
  Flagging column	 11 
Considering row	 6 column	 12 value	 0.883 
  Flagging column	 6 
Considering row	 12 column	 2 value	 0.121 
Considering row	 12 column	 9 value	 0.128 
Considering row	 12 column	 14 value	 0.092 
Considering row	 12 column	 13 value	 0.105 
Considering row	 12 column	 8 value	 0.071 
Considering row	 12 column	 3 value	 0.093 
Considering row	 12 column	 18 value	 0.126 
Considering row	 12 column	 19 value	 0.171 
Considering row	 12 column	 15 value	 0.13 
Considering row	 12 column	 4 value	 0.01 
Considering row	 12 column	 7 value	 0.043 
Considering row	 12 column	 5 value	 0.017 
Considering row	 2 column	 9 value	 0.423 
Considering row	 2 column	 14 value	 0.574 
Considering row	 2 column	 13 value	 0.557 
Considering row	 2 column	 8 value	 0.165 
Considering row	 2 column	 3 value	 0.263 
Considering row	 2 column	 18 value	 0.128 
Considering row	 2 column	 19 value	 0.089 
Considering row	 2 column	 15 value	 0.069 
Considering row	 2 column	 4 value	 0.27 
Considering row	 2 column	 7 value	 0.045 
Considering row	 2 column	 5 value	 0.024 
Considering row	 9 column	 14 value	 0.147 
Considering row	 9 column	 13 value	 0.125 
Considering row	 9 column	 8 value	 0.449 
Considering row	 9 column	 3 value	 0.322 
Considering row	 9 column	 18 value	 0.018 
Considering row	 9 column	 19 value	 0.141 
Considering row	 9 column	 15 value	 0.073 
Considering row	 9 column	 4 value	 0.006 
Considering row	 9 column	 7 value	 0.136 
Considering row	 9 column	 5 value	 0.123 
Considering row	 14 column	 13 value	 0.659 
  Flagging column	 14 
Considering row	 13 column	 8 value	 0.097 
Considering row	 13 column	 3 value	 0.167 
Considering row	 13 column	 18 value	 0.18 
Considering row	 13 column	 19 value	 0.131 
Considering row	 13 column	 15 value	 0.137 
Considering row	 13 column	 4 value	 0.24 
Considering row	 13 column	 7 value	 0.085 
Considering row	 13 column	 5 value	 0.027 
Considering row	 8 column	 3 value	 0.224 
Considering row	 8 column	 18 value	 0.173 
Considering row	 8 column	 19 value	 0.235 
Considering row	 8 column	 15 value	 0.07 
Considering row	 8 column	 4 value	 0.02 
Considering row	 8 column	 7 value	 0.085 
Considering row	 8 column	 5 value	 0.004 
Considering row	 3 column	 18 value	 0.028 
Considering row	 3 column	 19 value	 0.027 
Considering row	 3 column	 15 value	 0.017 
Considering row	 3 column	 4 value	 0.094 
Considering row	 3 column	 7 value	 0.095 
Considering row	 3 column	 5 value	 0.097 
Considering row	 18 column	 19 value	 0.019 
Considering row	 18 column	 15 value	 0.12 
Considering row	 18 column	 4 value	 0.086 
Considering row	 18 column	 7 value	 0.132 
Considering row	 18 column	 5 value	 0.002 
Considering row	 19 column	 15 value	 0.019 
Considering row	 19 column	 4 value	 0.032 
Considering row	 19 column	 7 value	 0.056 
Considering row	 19 column	 5 value	 0.075 
Considering row	 15 column	 4 value	 0.043 
Considering row	 15 column	 7 value	 0.061 
Considering row	 15 column	 5 value	 0.08 
Considering row	 4 column	 7 value	 0.005 
Considering row	 4 column	 5 value	 0.213 
Considering row	 7 column	 5 value	 0.008 
> 
> colnames(trainDescr)[highCorr]
[1] "ARRSPOKE"   "DEPSPOKE"   "SDEPHR"     "DEPBUCKET"  "AVGSQ"     
[6] "TRNRANKGRP"
> 
> descr.ncol0 <- ncol(trainDescr)
> 
> # I've switched off the correlation remover and the results are better.
> if (sum(highCorr) > 0) {
+     warning("overfitting: correlations: err.trainDescr: ", paste(colnames(trainDescr)[highCorr], collapse = ", ") )
+     err.trainDescr <- trainDescr
+     trainDescr <- trainDescr[,-highCorr]
+ }
Warning message:
overfitting: correlations: err.trainDescr: ARRSPOKE, DEPSPOKE, SDEPHR, DEPBUCKET, AVGSQ, TRNRANKGRP 
> 
> descr.ncol1 <- ncol(trainDescr)
> 
> paste("Dropped: ", as.character(descr.ncol0 - descr.ncol1))
[1] "Dropped:  6"
> 
> descrCorr <- cor(trainDescr)
> summary(descrCorr[upper.tri(descrCorr)])
     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
-0.449200 -0.122800 -0.011790 -0.001662  0.087980  0.557400 
> 
> ## Dominant correlations
> ## At 0.9, there are some big ones that might need re-thinking.
> 
> table.descrCorr <- as.data.frame(as.table(descrCorr))
> table.descrCorr <- table.descrCorr[which(table.descrCorr$Var1 != table.descrCorr$Var2),]
> table.descrCorr[order(abs(table.descrCorr$Freq), decreasing = TRUE),]
              Var1           Var2         Freq
10      DEPRANKGRP      SKDDEPSTA  0.557399203
118      SKDDEPSTA     DEPRANKGRP  0.557399203
21  DOWNLINEATCIMP      SKDARRSTA  0.462378131
93       SKDARRSTA DOWNLINEATCIMP  0.462378131
72    DEPSTAATCIMP   UPLINEATCIMP -0.449249986
84    UPLINEATCIMP   DEPSTAATCIMP -0.449249986
7     DEPSTAATCIMP      SKDDEPSTA  0.423425796
79       SKDDEPSTA   DEPSTAATCIMP  0.423425796
86  DOWNLINEATCIMP   DEPSTAATCIMP -0.403695561
98    DEPSTAATCIMP DOWNLINEATCIMP -0.403695561
73  DOWNLINEATCIMP   UPLINEATCIMP  0.365833687
97    UPLINEATCIMP DOWNLINEATCIMP  0.365833687
20    DEPSTAATCIMP      SKDARRSTA -0.322204878
80       SKDARRSTA   DEPSTAATCIMP -0.322204878
8   DOWNLINEATCIMP      SKDDEPSTA -0.285911992
92       SKDDEPSTA DOWNLINEATCIMP -0.285911992
102     ARRRANKGRP DOWNLINEATCIMP -0.274110143
138 DOWNLINEATCIMP     ARRRANKGRP -0.274110143
3           SKDEQP      SKDDEPSTA  0.270065872
27       SKDDEPSTA         SKDEQP  0.270065872
2        SKDARRSTA      SKDDEPSTA -0.263453106
14       SKDDEPSTA      SKDARRSTA -0.263453106
100      ARRBUCKET DOWNLINEATCIMP  0.255480148
112 DOWNLINEATCIMP      ARRBUCKET  0.255480148
36      DEPRANKGRP         SKDEQP  0.239915140
120         SKDEQP     DEPRANKGRP  0.239915140
78    xAVGSKDAVAIL   UPLINEATCIMP  0.234867014
162   UPLINEATCIMP   xAVGSKDAVAIL  0.234867014
103         xDURN2 DOWNLINEATCIMP -0.226093423
151 DOWNLINEATCIMP         xDURN2 -0.226093423
19    UPLINEATCIMP      SKDARRSTA  0.223824406
67       SKDARRSTA   UPLINEATCIMP  0.223824406
30          SKDEPS         SKDEQP  0.212586898
42          SKDEQP         SKDEPS  0.212586898
101     DEPRANKGRP DOWNLINEATCIMP -0.199411990
125 DOWNLINEATCIMP     DEPRANKGRP -0.199411990
129         xDURN2     DEPRANKGRP  0.180043357
153     DEPRANKGRP         xDURN2  0.180043357
77          xDURN2   UPLINEATCIMP -0.173240320
149   UPLINEATCIMP         xDURN2 -0.173240320
117   xAVGSKDAVAIL      ARRBUCKET -0.170644257
165      ARRBUCKET   xAVGSKDAVAIL -0.170644257
23      DEPRANKGRP      SKDARRSTA -0.167375913
119      SKDARRSTA     DEPRANKGRP -0.167375913
6     UPLINEATCIMP      SKDDEPSTA -0.164964952
66       SKDDEPSTA   UPLINEATCIMP -0.164964952
91    xAVGSKDAVAIL   DEPSTAATCIMP -0.141077194
163   DEPSTAATCIMP   xAVGSKDAVAIL -0.141077194
128     ARRRANKGRP     DEPRANKGRP  0.136562948
140     DEPRANKGRP     ARRRANKGRP  0.136562948
59    DEPSTAATCIMP      AVGLOFATC -0.135778614
83       AVGLOFATC   DEPSTAATCIMP -0.135778614
64          xDURN2      AVGLOFATC -0.132084629
148      AVGLOFATC         xDURN2 -0.132084629
130   xAVGSKDAVAIL     DEPRANKGRP  0.130574789
166     DEPRANKGRP   xAVGSKDAVAIL  0.130574789
115     ARRRANKGRP      ARRBUCKET -0.129698517
139      ARRBUCKET     ARRRANKGRP -0.129698517
87       ARRBUCKET   DEPSTAATCIMP -0.127726148
111   DEPSTAATCIMP      ARRBUCKET -0.127726148
12          xDURN2      SKDDEPSTA  0.127598189
144      SKDDEPSTA         xDURN2  0.127598189
60  DOWNLINEATCIMP      AVGLOFATC -0.126763572
96       AVGLOFATC DOWNLINEATCIMP -0.126763572
116         xDURN2      ARRBUCKET -0.125836459
152      ARRBUCKET         xDURN2 -0.125836459
88      DEPRANKGRP   DEPSTAATCIMP  0.124672682
124   DEPSTAATCIMP     DEPRANKGRP  0.124672682
46    DEPSTAATCIMP         SKDEPS -0.123445793
82          SKDEPS   DEPSTAATCIMP -0.123445793
9        ARRBUCKET      SKDDEPSTA -0.120728212
105      SKDDEPSTA      ARRBUCKET -0.120728212
142         xDURN2     ARRRANKGRP  0.119675180
154     ARRRANKGRP         xDURN2  0.119675180
114     DEPRANKGRP      ARRBUCKET -0.105057984
126      ARRBUCKET     DEPRANKGRP -0.105057984
104   xAVGSKDAVAIL DOWNLINEATCIMP  0.102577364
164 DOWNLINEATCIMP   xAVGSKDAVAIL  0.102577364
75      DEPRANKGRP   UPLINEATCIMP -0.097218129
123   UPLINEATCIMP     DEPRANKGRP -0.097218129
17          SKDEPS      SKDARRSTA -0.096699169
41       SKDARRSTA         SKDEPS -0.096699169
47  DOWNLINEATCIMP         SKDEPS -0.095568613
95          SKDEPS DOWNLINEATCIMP -0.095568613
18       AVGLOFATC      SKDARRSTA -0.095234466
54       SKDARRSTA      AVGLOFATC -0.095234466
16          SKDEQP      SKDARRSTA  0.094073459
28       SKDARRSTA         SKDEQP  0.094073459
22       ARRBUCKET      SKDARRSTA  0.092625400
106      SKDARRSTA      ARRBUCKET  0.092625400
13    xAVGSKDAVAIL      SKDDEPSTA  0.088580325
157      SKDDEPSTA   xAVGSKDAVAIL  0.088580325
38          xDURN2         SKDEQP  0.086170070
146         SKDEQP         xDURN2  0.086170070
62      DEPRANKGRP      AVGLOFATC  0.085474019
122      AVGLOFATC     DEPRANKGRP  0.085474019
58    UPLINEATCIMP      AVGLOFATC -0.085180887
70       AVGLOFATC   UPLINEATCIMP -0.085180887
50      ARRRANKGRP         SKDEPS  0.080398834
134         SKDEPS     ARRRANKGRP  0.080398834
52    xAVGSKDAVAIL         SKDEPS  0.075169577
160         SKDEPS   xAVGSKDAVAIL  0.075169577
89      ARRRANKGRP   DEPSTAATCIMP  0.073371196
137   DEPSTAATCIMP     ARRRANKGRP  0.073371196
74       ARRBUCKET   UPLINEATCIMP  0.071409699
110   UPLINEATCIMP      ARRBUCKET  0.071409699
76      ARRRANKGRP   UPLINEATCIMP -0.069790367
136   UPLINEATCIMP     ARRRANKGRP -0.069790367
11      ARRRANKGRP      SKDDEPSTA  0.068927801
131      SKDDEPSTA     ARRRANKGRP  0.068927801
63      ARRRANKGRP      AVGLOFATC -0.061491190
135      AVGLOFATC     ARRRANKGRP -0.061491190
65    xAVGSKDAVAIL      AVGLOFATC -0.056264979
161      AVGLOFATC   xAVGSKDAVAIL -0.056264979
5        AVGLOFATC      SKDDEPSTA -0.044946507
53       SKDDEPSTA      AVGLOFATC -0.044946507
61       ARRBUCKET      AVGLOFATC -0.043093769
109      AVGLOFATC      ARRBUCKET -0.043093769
37      ARRRANKGRP         SKDEQP -0.042512956
133         SKDEQP     ARRRANKGRP -0.042512956
39    xAVGSKDAVAIL         SKDEQP  0.031863410
159         SKDEQP   xAVGSKDAVAIL  0.031863410
25          xDURN2      SKDARRSTA  0.027576751
145      SKDARRSTA         xDURN2  0.027576751
26    xAVGSKDAVAIL      SKDARRSTA  0.027225219
158      SKDARRSTA   xAVGSKDAVAIL  0.027225219
49      DEPRANKGRP         SKDEPS  0.027025501
121         SKDEPS     DEPRANKGRP  0.027025501
4           SKDEPS      SKDDEPSTA -0.024267794
40       SKDDEPSTA         SKDEPS -0.024267794
32    UPLINEATCIMP         SKDEQP -0.019807499
68          SKDEQP   UPLINEATCIMP -0.019807499
156   xAVGSKDAVAIL         xDURN2 -0.019255572
168         xDURN2   xAVGSKDAVAIL -0.019255572
143   xAVGSKDAVAIL     ARRRANKGRP -0.018743432
167     ARRRANKGRP   xAVGSKDAVAIL -0.018743432
90          xDURN2   DEPSTAATCIMP -0.017999758
150   DEPSTAATCIMP         xDURN2 -0.017999758
34  DOWNLINEATCIMP         SKDEQP -0.017658860
94          SKDEQP DOWNLINEATCIMP -0.017658860
48       ARRBUCKET         SKDEPS  0.017414895
108         SKDEPS      ARRBUCKET  0.017414895
24      ARRRANKGRP      SKDARRSTA  0.016733374
132      SKDARRSTA     ARRRANKGRP  0.016733374
35       ARRBUCKET         SKDEQP  0.009926479
107         SKDEQP      ARRBUCKET  0.009926479
44       AVGLOFATC         SKDEPS  0.008240563
56          SKDEPS      AVGLOFATC  0.008240563
33    DEPSTAATCIMP         SKDEQP -0.005922601
81          SKDEQP   DEPSTAATCIMP -0.005922601
31       AVGLOFATC         SKDEQP -0.004889040
55          SKDEQP      AVGLOFATC -0.004889040
45    UPLINEATCIMP         SKDEPS  0.004016263
69          SKDEPS   UPLINEATCIMP  0.004016263
51          xDURN2         SKDEPS  0.001748012
147         SKDEPS         xDURN2  0.001748012
> 
> ### Models
> 
> ## Try GBM (gradient boosting). Works well for mixed data.
> ## And there is a tutorial for it with caret.
> 
> ## Training controller and big grid
> ## Check the ROC (my preferred.)
> 
> fitControl <- trainControl(## 10-fold CV
+     method = "repeatedcv",
+     number = 10,
+     ## repeated ten times
+     repeats = 10,
+     classProbs = 10,
+     summaryFunction = twoClassSummary)
> 
> ## Some trial and error with variables to branch and boost.
> ## I'm just going to try the airports and the planes and the duration
> ## of the flight. There may be some distance relationship there that
> ## air traffic control use.
> 
> ## Annoying because I drop variables, this needs to be looked up.
> 
> tr.cols <- colnames(trainDescr)
> tr.cols
 [1] "SKDDEPSTA"      "SKDARRSTA"      "SKDEQP"         "SKDEPS"        
 [5] "AVGLOFATC"      "UPLINEATCIMP"   "DEPSTAATCIMP"   "DOWNLINEATCIMP"
 [9] "ARRBUCKET"      "DEPRANKGRP"     "ARRRANKGRP"     "xDURN2"        
[13] "xAVGSKDAVAIL"  
> tr.icols <- grep("((STA|EQP)$)|(^xD)", tr.cols)
> tr.icols <- rev(tr.icols)
> 
> gbmGrid <- expand.grid(interaction.depth = tr.icols,
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.1,
+                         n.minobsinnode = 20)
> 
> set.seed(seed.mine)
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "ROC",
+                  verbose = FALSE)
Loading required package: gbm
Loading required package: survival

Attaching package: 'survival'

The following object is masked from 'package:caret':

    cluster

Loading required package: splines
Loaded gbm 2.1.1
Loading required package: plyr
> gbmFit1
Stochastic Gradient Boosting 

248 samples
 13 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 222, 223, 223, 224, 223, 223, ... 

Resampling results across tuning parameters:

  interaction.depth  n.trees  ROC        Sens       Spec       ROC SD    
   1                   90     0.7554604  0.7408791  0.6568939  0.10560102
   1                  180     0.7536314  0.7134066  0.6658333  0.09567595
   1                  270     0.7523868  0.7082418  0.6690152  0.09096774
   1                  360     0.7452231  0.7132418  0.6590152  0.09082011
   1                  450     0.7382563  0.6980220  0.6547727  0.09097129
   1                  540     0.7308042  0.7037363  0.6511364  0.09545812
   1                  630     0.7272923  0.6856593  0.6501515  0.09830558
   1                  720     0.7253963  0.6900000  0.6435606  0.09304454
   1                  810     0.7232980  0.6886264  0.6383333  0.09766527
   1                  900     0.7212396  0.6871978  0.6384091  0.09515326
   1                  990     0.7135119  0.6834066  0.6130303  0.10138182
   1                 1080     0.7124076  0.6833516  0.6183333  0.09979174
   1                 1170     0.7089311  0.6863736  0.6203788  0.09915626
   1                 1260     0.7045396  0.6849451  0.6140909  0.10670216
   1                 1350     0.7012804  0.6759890  0.6167424  0.10023891
   1                 1440     0.6999938  0.6732418  0.6103030  0.09774637
   1                 1530     0.6972865  0.6693407  0.6166667  0.09993043
   1                 1620     0.6914631  0.6693407  0.6093939  0.09944021
   1                 1710     0.6881185  0.6671978  0.6093182  0.10665477
   1                 1800     0.6883288  0.6700000  0.6093182  0.10562606
   1                 1890     0.6884649  0.6686264  0.6050000  0.10224774
   1                 1980     0.6863849  0.6707143  0.6094697  0.10360891
   1                 2070     0.6769048  0.6612088  0.5986364  0.11214338
   1                 2160     0.6786310  0.6682418  0.5940152  0.10992904
   1                 2250     0.6762059  0.6631868  0.5975758  0.10925550
   1                 2340     0.6725849  0.6604396  0.5914394  0.11128110
   1                 2430     0.6685935  0.6624176  0.5850758  0.11710334
   1                 2520     0.6669322  0.6612088  0.5806818  0.11644469
   1                 2610     0.6670400  0.6543407  0.5922727  0.11429685
   1                 2700     0.6660306  0.6574725  0.5868182  0.11558391
   2                   90     0.7520509  0.7345055  0.6506061  0.09140707
   2                  180     0.7384961  0.7081319  0.6362879  0.09033252
   2                  270     0.7260781  0.7025824  0.6309848  0.09598421
   2                  360     0.7208342  0.6986813  0.6203030  0.09820244
   2                  450     0.7171333  0.6919231  0.6146970  0.10197699
   2                  540     0.7133766  0.6881868  0.6076515  0.10016884
   2                  630     0.7112217  0.6846154  0.6158333  0.09780008
   2                  720     0.7087300  0.6836813  0.6087879  0.09960315
   2                  810     0.7079079  0.6852747  0.6193182  0.09912941
   2                  900     0.7081489  0.6890659  0.6091667  0.10163295
   2                  990     0.7057068  0.6817582  0.6084091  0.09844536
   2                 1080     0.7040052  0.6801648  0.6085606  0.09995219
   2                 1170     0.7036006  0.6786264  0.6032576  0.09911677
   2                 1260     0.7029379  0.6802198  0.6023485  0.09684336
   2                 1350     0.6977002  0.6808791  0.6103030  0.10283554
   2                 1440     0.6989510  0.6828571  0.6084848  0.09685442
   2                 1530     0.6972652  0.6842857  0.6140909  0.09726590
   2                 1620     0.6992199  0.6792308  0.6077273  0.09611660
   2                 1710     0.6984815  0.6800549  0.6068939  0.09617920
   2                 1800     0.6975400  0.6757692  0.6086364  0.09815652
   2                 1890     0.6965052  0.6758791  0.6077273  0.09727240
   2                 1980     0.6967216  0.6800549  0.6095455  0.09862534
   2                 2070     0.6949459  0.6823626  0.6114394  0.09889110
   2                 2160     0.6956935  0.6786813  0.6112879  0.09788807
   2                 2250     0.6934786  0.6780220  0.6095455  0.09859482
   2                 2340     0.6934653  0.6765934  0.6121212  0.09893137
   2                 2430     0.6912100  0.6757692  0.6066667  0.10341222
   2                 2520     0.6916313  0.6758242  0.6094697  0.09971108
   2                 2610     0.6910689  0.6764835  0.6139394  0.10076006
   2                 2700     0.6912296  0.6764835  0.6114394  0.10046073
   3                   90     0.7403030  0.7320879  0.6450000  0.09232386
   3                  180     0.7302131  0.7066484  0.6372727  0.09665597
   3                  270     0.7241858  0.6932967  0.6231818  0.09852536
   3                  360     0.7176698  0.6946703  0.6142424  0.10188424
   3                  450     0.7157834  0.6946703  0.6140152  0.09858078
   3                  540     0.7093656  0.6887912  0.6265909  0.10189768
   3                  630     0.7063511  0.6878571  0.6265909  0.10267065
   3                  720     0.7050154  0.6842857  0.6228788  0.09992368
   3                  810     0.7047490  0.6807143  0.6149242  0.09871438
   3                  900     0.7055349  0.6842857  0.6103788  0.09921367
   3                  990     0.7046637  0.6821429  0.6112879  0.09735370
   3                 1080     0.7029412  0.6778022  0.5996212  0.09885506
   3                 1170     0.7021628  0.6785165  0.6040152  0.09959207
   3                 1260     0.7019181  0.6799451  0.6040909  0.09756377
   3                 1350     0.7002473  0.6748352  0.6068939  0.09674968
   3                 1440     0.6992008  0.6785165  0.6114394  0.09781087
   3                 1530     0.6996499  0.6835714  0.6086364  0.09974660
   3                 1620     0.6963607  0.6776923  0.6103788  0.09799624
   3                 1710     0.6981223  0.6732967  0.6094697  0.09692099
   3                 1800     0.6982917  0.6769780  0.6146970  0.09753600
   3                 1890     0.6994118  0.6762637  0.6119697  0.09805244
   3                 1980     0.7002423  0.6748352  0.6156818  0.09586343
   3                 2070     0.6990647  0.6776374  0.6121212  0.09639777
   3                 2160     0.6980948  0.6785714  0.6138636  0.09676368
   3                 2250     0.6986230  0.6741758  0.6112121  0.09652459
   3                 2340     0.6969560  0.6777473  0.6112879  0.09752725
   3                 2430     0.6976215  0.6734066  0.6130303  0.09652682
   3                 2520     0.6964927  0.6735165  0.6121212  0.09736735
   3                 2610     0.6942803  0.6719780  0.6095455  0.10023596
   3                 2700     0.6949247  0.6726923  0.6075758  0.09990279
  12                   90     0.7358666  0.7279121  0.6437121  0.09988919
  12                  180     0.7284978  0.7118132  0.6274242  0.09858066
  12                  270     0.7191642  0.6962088  0.6231061  0.09865865
  12                  360     0.7161701  0.7032967  0.6218939  0.10191797
  12                  450     0.7113840  0.6903846  0.6201515  0.10058051
  12                  540     0.7123535  0.6875275  0.6193182  0.10182657
  12                  630     0.7135897  0.6865934  0.6175000  0.10039459
  12                  720     0.7115842  0.6821978  0.6193939  0.09913758
  12                  810     0.7117995  0.6886813  0.6221212  0.09423499
  12                  900     0.7086984  0.6858242  0.6221212  0.09530748
  12                  990     0.7094168  0.6857143  0.6202273  0.09474873
  12                 1080     0.7075924  0.6880769  0.6212879  0.09566867
  12                 1170     0.7052227  0.6850000  0.6267424  0.09626121
  12                 1260     0.7037950  0.6820879  0.6240909  0.09779490
  12                 1350     0.7034328  0.6886813  0.6259848  0.09600798
  12                 1440     0.7009932  0.6828022  0.6159091  0.09383577
  12                 1530     0.6998851  0.6828022  0.6140152  0.09485875
  12                 1620     0.7000966  0.6813736  0.6202273  0.09434990
  12                 1710     0.6987013  0.6822527  0.6203788  0.09593377
  12                 1800     0.6973456  0.6836813  0.6221970  0.09722434
  12                 1890     0.6949888  0.6819780  0.6150000  0.09697899
  12                 1980     0.6945034  0.6849451  0.6168182  0.09680580
  12                 2070     0.6939877  0.6806044  0.6168182  0.09396682
  12                 2160     0.6949242  0.6834615  0.6186364  0.09427833
  12                 2250     0.6940343  0.6798901  0.6194697  0.09422508
  12                 2340     0.6946483  0.6821429  0.6177273  0.09588395
  12                 2430     0.6936626  0.6770879  0.6103788  0.09557242
  12                 2520     0.6931360  0.6741209  0.6140909  0.09592334
  12                 2610     0.6944439  0.6763736  0.6140909  0.09564492
  12                 2700     0.6929924  0.6735165  0.6149242  0.09608538
  Sens SD    Spec SD  
  0.1168558  0.1330773
  0.1197454  0.1272455
  0.1197907  0.1365323
  0.1206511  0.1417437
  0.1243876  0.1397575
  0.1241146  0.1459586
  0.1346175  0.1497385
  0.1284907  0.1439711
  0.1333698  0.1409321
  0.1229062  0.1489563
  0.1272209  0.1492394
  0.1298892  0.1459006
  0.1287692  0.1445118
  0.1305018  0.1436666
  0.1338636  0.1454203
  0.1340480  0.1520130
  0.1355770  0.1524192
  0.1369087  0.1433575
  0.1302610  0.1413168
  0.1347409  0.1368273
  0.1351000  0.1459771
  0.1396671  0.1433578
  0.1365404  0.1435784
  0.1374032  0.1337326
  0.1387542  0.1417878
  0.1387069  0.1505142
  0.1384480  0.1442586
  0.1334410  0.1474209
  0.1384387  0.1409435
  0.1323050  0.1384998
  0.1157102  0.1269370
  0.1197774  0.1261133
  0.1307829  0.1277021
  0.1244533  0.1271105
  0.1224214  0.1243287
  0.1235277  0.1185099
  0.1177638  0.1235442
  0.1213305  0.1235124
  0.1181879  0.1224321
  0.1123900  0.1280276
  0.1152952  0.1274767
  0.1122113  0.1298394
  0.1092570  0.1263161
  0.1142626  0.1250747
  0.1112215  0.1276295
  0.1238450  0.1298386
  0.1192752  0.1230859
  0.1187765  0.1239110
  0.1161783  0.1311006
  0.1187860  0.1193042
  0.1180108  0.1180309
  0.1223656  0.1192760
  0.1217581  0.1225406
  0.1217100  0.1233582
  0.1173227  0.1218248
  0.1204799  0.1214033
  0.1194950  0.1214447
  0.1147021  0.1230791
  0.1196475  0.1196812
  0.1197163  0.1241107
  0.1268015  0.1324648
  0.1317939  0.1332644
  0.1292979  0.1364598
  0.1310708  0.1266096
  0.1298060  0.1346454
  0.1319618  0.1258086
  0.1288119  0.1236942
  0.1230182  0.1273806
  0.1250111  0.1240488
  0.1296913  0.1258637
  0.1306703  0.1273812
  0.1288801  0.1280651
  0.1299498  0.1302798
  0.1294016  0.1254779
  0.1267733  0.1307951
  0.1259216  0.1296126
  0.1260779  0.1315258
  0.1251898  0.1308322
  0.1240820  0.1355765
  0.1255282  0.1337236
  0.1271487  0.1354233
  0.1263009  0.1310031
  0.1288624  0.1338319
  0.1303879  0.1323003
  0.1280254  0.1353390
  0.1259406  0.1348920
  0.1251511  0.1376949
  0.1277051  0.1351981
  0.1262481  0.1353541
  0.1219322  0.1336585
  0.1241165  0.1351271
  0.1270712  0.1484437
  0.1390326  0.1330733
  0.1334611  0.1365892
  0.1337678  0.1411639
  0.1374850  0.1381434
  0.1323227  0.1379045
  0.1330714  0.1364109
  0.1289787  0.1297198
  0.1327770  0.1337248
  0.1314976  0.1353123
  0.1289826  0.1357863
  0.1266329  0.1292702
  0.1293136  0.1292205
  0.1247873  0.1296812
  0.1248963  0.1285987
  0.1236522  0.1292815
  0.1258901  0.1300785
  0.1249969  0.1257837
  0.1278007  0.1326906
  0.1295968  0.1351010
  0.1259717  0.1303524
  0.1242127  0.1284168
  0.1245468  0.1272743
  0.1271413  0.1273136
  0.1289555  0.1259428
  0.1270699  0.1296795
  0.1287029  0.1270901
  0.1306426  0.1278496
  0.1281080  0.1285696

Tuning parameter 'shrinkage' was held constant at a value of 0.1

Tuning parameter 'n.minobsinnode' was held constant at a value of 20
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 90, interaction.depth =
 1, shrinkage = 0.1 and n.minobsinnode = 20. 
> 
> ## The acid test is dissapointing, but I've seen worse.
> 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
  Accuracy      Kappa 
0.55555556 0.05263158 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     32   24
    Weak        8    8
                                          
               Accuracy : 0.5556          
                 95% CI : (0.4336, 0.6728)
    No Information Rate : 0.5556          
    P-Value [Acc > NIR] : 0.54887         
                                          
                  Kappa : 0.0526          
 Mcnemar's Test P-Value : 0.00801         
                                          
            Sensitivity : 0.2500          
            Specificity : 0.8000          
         Pos Pred Value : 0.5000          
         Neg Pred Value : 0.5714          
             Prevalence : 0.4444          
         Detection Rate : 0.1111          
   Detection Prevalence : 0.2222          
      Balanced Accuracy : 0.5250          
                                          
       'Positive' Class : Weak            
                                          
> 
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
 Accuracy     Kappa 
0.8024194 0.6001053 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    113   25
    Weak       24   86
                                          
               Accuracy : 0.8024          
                 95% CI : (0.7473, 0.8501)
    No Information Rate : 0.5524          
    P-Value [Acc > NIR] : <2e-16          
                                          
                  Kappa : 0.6001          
 Mcnemar's Test P-Value : 1               
                                          
            Sensitivity : 0.7748          
            Specificity : 0.8248          
         Pos Pred Value : 0.7818          
         Neg Pred Value : 0.8188          
             Prevalence : 0.4476          
         Detection Rate : 0.3468          
   Detection Prevalence : 0.4435          
      Balanced Accuracy : 0.7998          
                                          
       'Positive' Class : Weak            
                                          
> ### weaves
> 
> ## Processing for flights data.
> 
> ## Following the caret vignette.
> 
> ###################################################
> ### code chunk number 1: loadLibs
> ###################################################
> library(MASS)
> library(caret)
> library(mlbench)
> library(pROC)
> library(pls)
> 
> library(doMC)
> registerDoMC(cores = 4)
> 
> options(useFancyQuotes = FALSE) 
> 
> # Accounting info.
> getInfo <- function(what = "Suggests")
+ {
+   text <- packageDescription("caret")[what][[1]]
+   text <- gsub("\n", ", ", text, fixed = TRUE)
+   text <- gsub(">=", "$\\\\ge$", text, fixed = TRUE)
+   eachPkg <- strsplit(text, ", ", fixed = TRUE)[[1]]
+   eachPkg <- gsub(",", "", eachPkg, fixed = TRUE)
+   # out <- paste("\\\\pkg{", eachPkg[order(tolower(eachPkg))], "}", sep = "")
+   # paste(out, collapse = ", ")
+   length(eachPkg)
+ }
> 
> ### project-specific: begin
> ## Set-seed, load original CSV file, order it
> ## and do some simple-cleaning
> ## Various datasets 
> 
> seed.mine = 107
> set.seed(seed.mine)                     # helpful for testing
> 
> flight <- read.csv("../bak/flight.csv")
> flight <- flight[order(flight$D00),]
> 
> # Backup
> flight.raw <- flight
> 
> # To check adjustment, there is test code in flight-nb.R
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"
> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"
> 
> # And some deletions
> 
> t.cols <- colnames(flight)
> 
> t.drops <- t.cols[grep("^RANK*", t.cols)]
> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])
> t.drops <- c(t.drops, "D80THPCTL")
> 
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR
> flight$xHNGR <- flight$xDURN < 0
> 
> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+ }
> 
> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))
> 
> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE
> t.cols <- colnames(flight)
> 
> t.drops <- c("SARRHR", "xDURN")
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Backup
> 
> flight00 <- flight
> 
> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]
> 
> paste("samples in use: ", dim(flight)[1])
[1] "samples in use:  320"
> 
> ## Data insights
> 
> ## *Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> flight <- flight1
> 
> ### Numeric variables
> 
> ### Try and impute the AVG, it might have more information than the
> ### bucket.
> 
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))
Error in `$<-.data.frame`(`*tmp*`, "xAVAILBUCKET", value = numeric(0)) : 
  replacement has 0 rows, data has 320
> 
> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1
> 
> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]
Error in `[.data.frame`(flight, , c("AVGSKDAVAIL", "xAVAILBUCKET")) : 
  undefined columns selected
> 
> preProcValues <- preProcess(flight.na, method = c("knnImpute"))
> flight.na1 <- predict(preProcValues, flight.na)
> 
> ## I'll add the new imputed value and drop the others
> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL
> flight$AVGSKDAVAIL <- NULL
> flight$xAVAILBUCKET <- NULL
> flight$AVAILBUCKET <- NULL
> 
> flight$xHNGR <- NULL
> 
> ## Check some more numeric correlations, I haven't scaled everything yet.
> ## I'd cut correlations above 0.65 to 0.75 because of overfitting.
> 
> x1 <- as.data.frame(as.matrix(sapply(flight, class)))
> 
> flight.num <- flight[,names(x1[which(x1$V1 %in% c("numeric", "integer")),])]
> 
> flight.nzv <- nearZeroVar(flight.num, saveMetrics = TRUE)
> flight.nzv
             freqRatio percentUnique zeroVar   nzv
SDEPHR        1.038462        5.9375   FALSE FALSE
SKDEPS        1.000000       19.0625   FALSE FALSE
D00           1.166667       75.3125   FALSE FALSE
AVGSQ         6.333333       82.8125   FALSE FALSE
AVGLOFATC     1.000000       78.4375   FALSE FALSE
xDURN2        1.428571        2.5000   FALSE FALSE
xAVGSKDAVAIL 18.500000       87.8125   FALSE FALSE
> 
> # annoying NA should be gone.
> flight.cor <- cor(flight.num, use = "pairwise.complete.obs")
> 
> descrCorr <- findCorrelation(flight.cor, cutoff = .65, verbose=TRUE)
Considering row	 4 column	 1 value	 0.956 
  Flagging column	 4 
Considering row	 1 column	 3 value	 0.43 
Considering row	 1 column	 7 value	 0.053 
Considering row	 1 column	 6 value	 0.204 
Considering row	 1 column	 5 value	 0.131 
Considering row	 1 column	 2 value	 0.054 
Considering row	 3 column	 7 value	 0.401 
Considering row	 3 column	 6 value	 0.071 
Considering row	 3 column	 5 value	 0.114 
Considering row	 3 column	 2 value	 0.006 
Considering row	 7 column	 6 value	 0.019 
Considering row	 7 column	 5 value	 0.07 
Considering row	 7 column	 2 value	 0.113 
Considering row	 6 column	 5 value	 0.137 
Considering row	 6 column	 2 value	 0.005 
Considering row	 5 column	 2 value	 0.041 
> 
> colnames(flight.num)[descrCorr]
[1] "AVGSQ"
> 
> ## And I'll leave the centered and scale values in for now.
> ## and delete the troublesome ones
> 
> ## Re-classing
> ## Check warnings to see it adjustment has taken place.
> ## We want the proportion in the training class to be about 0.55 0.45
> ## Strong to Weak
> ## I've achieved this heuristically
> src.adjust <- TRUE
> source(file = "flight1.R")
Warning message:
In eval(expr, envir, enclos) : adjusting
> flight1 <- flight
> 
> ## This should be deleted, leave it in and the results
> ## are ideal because it defines LEGTYPE.
> flight$D00 <- NULL
> 
> ## Keep the results but don't change the order.
> outcomes.flight <- flight$LEGTYPE
> 
> flight$LEGTYPE <- NULL
> 
> ## If you know your factors are definitely factors, you don't need this
> ##  asNumeric <- function(x) as.numeric(as.character(x))
> 
> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))
> 
> flight.num0 <- factors.numeric(flight)
> 
> flight.scl0 <- scale(flight.num0)
> 
> ## Now split the samples
> ## we need at least 60 to test with, p at 0.77 gives about 75.
> ## Difficulty here is the bias in the table
> ## Because we only have [3.1, 4.4] the proportion of Weak is higher.
> ## see prop.table(results)
> 
> set.seed(seed.mine)
> inTrain <- createDataPartition(outcomes.flight, p = 0.77, list = FALSE)
> 
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> 
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> 
> prop.table(table(trainClass))
trainClass
   Strong      Weak 
0.5524194 0.4475806 
> dim(trainDescr)
[1] 248  19
> 
> prop.table(table(testClass))
testClass
   Strong      Weak 
0.5555556 0.4444444 
> dim(testDescr)
[1] 72 19
> 
> ## Check Near-zero variance
> 
> nzv <- nearZeroVar(trainDescr, saveMetrics= TRUE)
> stopifnot( all(nzv$nzv == FALSE) )
> 
> # It's imputed and behaves well, no need for this.
> # descrCorr <- cor(scale(trainDescr), use = "pairwise.complete.obs")
> 
> descrCorr <- cor(scale(trainDescr))
> 
> ## This cut-off should be under src.adjust control.
> ## I'm under Git, so I can tinker with it.
> highCorr <- findCorrelation(descrCorr, cutoff = .95, verbose = TRUE)
Considering row	 17 column	 16 value	 0.85 
Considering row	 17 column	 10 value	 0.671 
Considering row	 17 column	 1 value	 0.279 
Considering row	 17 column	 11 value	 0.277 
Considering row	 17 column	 6 value	 0.22 
Considering row	 17 column	 12 value	 0.226 
Considering row	 17 column	 2 value	 0.298 
Considering row	 17 column	 9 value	 0.586 
Considering row	 17 column	 14 value	 0.226 
Considering row	 17 column	 13 value	 0.23 
Considering row	 17 column	 8 value	 0.541 
Considering row	 17 column	 3 value	 0.346 
Considering row	 17 column	 18 value	 0.261 
Considering row	 17 column	 19 value	 0.138 
Considering row	 17 column	 15 value	 0.057 
Considering row	 17 column	 4 value	 0.067 
Considering row	 17 column	 7 value	 0.034 
Considering row	 17 column	 5 value	 0.018 
Considering row	 16 column	 10 value	 0.568 
Considering row	 16 column	 1 value	 0.236 
Considering row	 16 column	 11 value	 0.231 
Considering row	 16 column	 6 value	 0.189 
Considering row	 16 column	 12 value	 0.19 
Considering row	 16 column	 2 value	 0.333 
Considering row	 16 column	 9 value	 0.671 
Considering row	 16 column	 14 value	 0.242 
Considering row	 16 column	 13 value	 0.208 
Considering row	 16 column	 8 value	 0.6 
Considering row	 16 column	 3 value	 0.318 
Considering row	 16 column	 18 value	 0.279 
Considering row	 16 column	 19 value	 0.213 
Considering row	 16 column	 15 value	 0.083 
Considering row	 16 column	 4 value	 0.02 
Considering row	 16 column	 7 value	 0.009 
Considering row	 16 column	 5 value	 0.005 
Considering row	 10 column	 1 value	 0.281 
Considering row	 10 column	 11 value	 0.275 
Considering row	 10 column	 6 value	 0.298 
Considering row	 10 column	 12 value	 0.255 
Considering row	 10 column	 2 value	 0.286 
Considering row	 10 column	 9 value	 0.404 
Considering row	 10 column	 14 value	 0.224 
Considering row	 10 column	 13 value	 0.199 
Considering row	 10 column	 8 value	 0.366 
Considering row	 10 column	 3 value	 0.462 
Considering row	 10 column	 18 value	 0.226 
Considering row	 10 column	 19 value	 0.103 
Considering row	 10 column	 15 value	 0.274 
Considering row	 10 column	 4 value	 0.018 
Considering row	 10 column	 7 value	 0.127 
Considering row	 10 column	 5 value	 0.096 
Considering row	 1 column	 11 value	 0.988 
  Flagging column	 1 
Considering row	 11 column	 6 value	 0.945 
Considering row	 11 column	 12 value	 0.889 
Considering row	 11 column	 2 value	 0.165 
Considering row	 11 column	 9 value	 0.139 
Considering row	 11 column	 14 value	 0.171 
Considering row	 11 column	 13 value	 0.156 
Considering row	 11 column	 8 value	 0.145 
Considering row	 11 column	 3 value	 0.073 
Considering row	 11 column	 18 value	 0.183 
Considering row	 11 column	 19 value	 0.053 
Considering row	 11 column	 15 value	 0.142 
Considering row	 11 column	 4 value	 0.037 
Considering row	 11 column	 7 value	 0.053 
Considering row	 11 column	 5 value	 0.03 
Considering row	 6 column	 12 value	 0.883 
Considering row	 6 column	 2 value	 0.151 
Considering row	 6 column	 9 value	 0.04 
Considering row	 6 column	 14 value	 0.188 
Considering row	 6 column	 13 value	 0.161 
Considering row	 6 column	 8 value	 0.063 
Considering row	 6 column	 3 value	 0.083 
Considering row	 6 column	 18 value	 0.197 
Considering row	 6 column	 19 value	 0.114 
Considering row	 6 column	 15 value	 0.159 
Considering row	 6 column	 4 value	 0.01 
Considering row	 6 column	 7 value	 0.027 
Considering row	 6 column	 5 value	 0.039 
Considering row	 12 column	 2 value	 0.121 
Considering row	 12 column	 9 value	 0.128 
Considering row	 12 column	 14 value	 0.092 
Considering row	 12 column	 13 value	 0.105 
Considering row	 12 column	 8 value	 0.071 
Considering row	 12 column	 3 value	 0.093 
Considering row	 12 column	 18 value	 0.126 
Considering row	 12 column	 19 value	 0.171 
Considering row	 12 column	 15 value	 0.13 
Considering row	 12 column	 4 value	 0.01 
Considering row	 12 column	 7 value	 0.043 
Considering row	 12 column	 5 value	 0.017 
Considering row	 2 column	 9 value	 0.423 
Considering row	 2 column	 14 value	 0.574 
Considering row	 2 column	 13 value	 0.557 
Considering row	 2 column	 8 value	 0.165 
Considering row	 2 column	 3 value	 0.263 
Considering row	 2 column	 18 value	 0.128 
Considering row	 2 column	 19 value	 0.089 
Considering row	 2 column	 15 value	 0.069 
Considering row	 2 column	 4 value	 0.27 
Considering row	 2 column	 7 value	 0.045 
Considering row	 2 column	 5 value	 0.024 
Considering row	 9 column	 14 value	 0.147 
Considering row	 9 column	 13 value	 0.125 
Considering row	 9 column	 8 value	 0.449 
Considering row	 9 column	 3 value	 0.322 
Considering row	 9 column	 18 value	 0.018 
Considering row	 9 column	 19 value	 0.141 
Considering row	 9 column	 15 value	 0.073 
Considering row	 9 column	 4 value	 0.006 
Considering row	 9 column	 7 value	 0.136 
Considering row	 9 column	 5 value	 0.123 
Considering row	 14 column	 13 value	 0.659 
Considering row	 14 column	 8 value	 0.097 
Considering row	 14 column	 3 value	 0.106 
Considering row	 14 column	 18 value	 0.361 
Considering row	 14 column	 19 value	 0.092 
Considering row	 14 column	 15 value	 0.084 
Considering row	 14 column	 4 value	 0.263 
Considering row	 14 column	 7 value	 0.139 
Considering row	 14 column	 5 value	 0.031 
Considering row	 13 column	 8 value	 0.097 
Considering row	 13 column	 3 value	 0.167 
Considering row	 13 column	 18 value	 0.18 
Considering row	 13 column	 19 value	 0.131 
Considering row	 13 column	 15 value	 0.137 
Considering row	 13 column	 4 value	 0.24 
Considering row	 13 column	 7 value	 0.085 
Considering row	 13 column	 5 value	 0.027 
Considering row	 8 column	 3 value	 0.224 
Considering row	 8 column	 18 value	 0.173 
Considering row	 8 column	 19 value	 0.235 
Considering row	 8 column	 15 value	 0.07 
Considering row	 8 column	 4 value	 0.02 
Considering row	 8 column	 7 value	 0.085 
Considering row	 8 column	 5 value	 0.004 
Considering row	 3 column	 18 value	 0.028 
Considering row	 3 column	 19 value	 0.027 
Considering row	 3 column	 15 value	 0.017 
Considering row	 3 column	 4 value	 0.094 
Considering row	 3 column	 7 value	 0.095 
Considering row	 3 column	 5 value	 0.097 
Considering row	 18 column	 19 value	 0.019 
Considering row	 18 column	 15 value	 0.12 
Considering row	 18 column	 4 value	 0.086 
Considering row	 18 column	 7 value	 0.132 
Considering row	 18 column	 5 value	 0.002 
Considering row	 19 column	 15 value	 0.019 
Considering row	 19 column	 4 value	 0.032 
Considering row	 19 column	 7 value	 0.056 
Considering row	 19 column	 5 value	 0.075 
Considering row	 15 column	 4 value	 0.043 
Considering row	 15 column	 7 value	 0.061 
Considering row	 15 column	 5 value	 0.08 
Considering row	 4 column	 7 value	 0.005 
Considering row	 4 column	 5 value	 0.213 
Considering row	 7 column	 5 value	 0.008 
> 
> colnames(trainDescr)[highCorr]
[1] "SDEPHR"
> 
> descr.ncol0 <- ncol(trainDescr)
> 
> # I've switched off the correlation remover and the results are better.
> if (sum(highCorr) > 0) {
+     warning("overfitting: correlations: err.trainDescr: ", paste(colnames(trainDescr)[highCorr], collapse = ", ") )
+     err.trainDescr <- trainDescr
+     trainDescr <- trainDescr[,-highCorr]
+ }
Warning message:
overfitting: correlations: err.trainDescr: SDEPHR 
> 
> descr.ncol1 <- ncol(trainDescr)
> 
> paste("Dropped: ", as.character(descr.ncol0 - descr.ncol1))
[1] "Dropped:  1"
> 
> descrCorr <- cor(trainDescr)
> summary(descrCorr[upper.tri(descrCorr)])
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
-0.85020 -0.13860 -0.01766  0.01577  0.11970  0.94490 
> 
> ## Dominant correlations
> ## At 0.9, there are some big ones that might need re-thinking.
> 
> table.descrCorr <- as.data.frame(as.table(descrCorr))
> table.descrCorr <- table.descrCorr[which(table.descrCorr$Var1 != table.descrCorr$Var2),]
> table.descrCorr[order(abs(table.descrCorr$Freq), decreasing = TRUE),]
              Var1           Var2         Freq
82       DEPBUCKET          AVGSQ  0.944870657
167          AVGSQ      DEPBUCKET  0.944870657
173      ARRBUCKET      DEPBUCKET  0.889095737
190      DEPBUCKET      ARRBUCKET  0.889095737
83       ARRBUCKET          AVGSQ  0.882590635
185          AVGSQ      ARRBUCKET  0.882590635
268       ARRSPOKE       DEPSPOKE -0.850165355
285       DEPSPOKE       ARRSPOKE -0.850165355
141       DEPSPOKE   DEPSTAATCIMP  0.671264566
260   DEPSTAATCIMP       DEPSPOKE  0.671264566
160       ARRSPOKE DOWNLINEATCIMP  0.671009330
279 DOWNLINEATCIMP       ARRSPOKE  0.671009330
211     TRNRANKGRP     DEPRANKGRP  0.658724662
228     DEPRANKGRP     TRNRANKGRP  0.658724662
123       DEPSPOKE   UPLINEATCIMP -0.600008252
259   UPLINEATCIMP       DEPSPOKE -0.600008252
142       ARRSPOKE   DEPSTAATCIMP -0.586442959
278   DEPSTAATCIMP       ARRSPOKE -0.586442959
13      TRNRANKGRP      SKDDEPSTA  0.574035134
217      SKDDEPSTA     TRNRANKGRP  0.574035134
159       DEPSPOKE DOWNLINEATCIMP -0.567682494
261 DOWNLINEATCIMP       DEPSPOKE -0.567682494
12      DEPRANKGRP      SKDDEPSTA  0.557399203
199      SKDDEPSTA     DEPRANKGRP  0.557399203
124       ARRSPOKE   UPLINEATCIMP  0.540734833
277   UPLINEATCIMP       ARRSPOKE  0.540734833
27  DOWNLINEATCIMP      SKDARRSTA  0.462378131
146      SKDARRSTA DOWNLINEATCIMP  0.462378131
116   DEPSTAATCIMP   UPLINEATCIMP -0.449249986
133   UPLINEATCIMP   DEPSTAATCIMP -0.449249986
8     DEPSTAATCIMP      SKDDEPSTA  0.423425796
127      SKDDEPSTA   DEPSTAATCIMP  0.423425796
135 DOWNLINEATCIMP   DEPSTAATCIMP -0.403695561
152   DEPSTAATCIMP DOWNLINEATCIMP -0.403695561
117 DOWNLINEATCIMP   UPLINEATCIMP  0.365833687
151   UPLINEATCIMP DOWNLINEATCIMP  0.365833687
233         xDURN2     TRNRANKGRP  0.361347207
301     TRNRANKGRP         xDURN2  0.361347207
34        ARRSPOKE      SKDARRSTA  0.345987375
272      SKDARRSTA       ARRSPOKE  0.345987375
15        DEPSPOKE      SKDDEPSTA  0.332823310
253      SKDDEPSTA       DEPSPOKE  0.332823310
26    DEPSTAATCIMP      SKDARRSTA -0.322204878
128      SKDARRSTA   DEPSTAATCIMP -0.322204878
33        DEPSPOKE      SKDARRSTA -0.318093195
254      SKDARRSTA       DEPSPOKE -0.318093195
81  DOWNLINEATCIMP          AVGSQ  0.298096458
149          AVGSQ DOWNLINEATCIMP  0.298096458
16        ARRSPOKE      SKDDEPSTA -0.298036487
271      SKDDEPSTA       ARRSPOKE -0.298036487
9   DOWNLINEATCIMP      SKDDEPSTA -0.285911992
145      SKDDEPSTA DOWNLINEATCIMP -0.285911992
269         xDURN2       DEPSPOKE  0.279030910
303       DEPSPOKE         xDURN2  0.279030910
178       ARRSPOKE      DEPBUCKET  0.276615722
280      DEPBUCKET       ARRSPOKE  0.276615722
154      DEPBUCKET DOWNLINEATCIMP  0.275167866
171 DOWNLINEATCIMP      DEPBUCKET  0.275167866
158     ARRRANKGRP DOWNLINEATCIMP -0.274110143
243 DOWNLINEATCIMP     ARRRANKGRP -0.274110143
3           SKDEQP      SKDDEPSTA  0.270065872
37       SKDDEPSTA         SKDEQP  0.270065872
2        SKDARRSTA      SKDDEPSTA -0.263453106
19       SKDDEPSTA      SKDARRSTA -0.263453106
49      TRNRANKGRP         SKDEQP  0.262837233
219         SKDEQP     TRNRANKGRP  0.262837233
287         xDURN2       ARRSPOKE -0.261107447
304       ARRSPOKE         xDURN2 -0.261107447
155      ARRBUCKET DOWNLINEATCIMP  0.255480148
189 DOWNLINEATCIMP      ARRBUCKET  0.255480148
231       DEPSPOKE     TRNRANKGRP  0.242138220
265     TRNRANKGRP       DEPSPOKE  0.242138220
48      DEPRANKGRP         SKDEQP  0.239915140
201         SKDEQP     DEPRANKGRP  0.239915140
126   xAVGSKDAVAIL   UPLINEATCIMP  0.234867014
313   UPLINEATCIMP   xAVGSKDAVAIL  0.234867014
177       DEPSPOKE      DEPBUCKET -0.231298301
262      DEPBUCKET       DEPSPOKE -0.231298301
214       ARRSPOKE     DEPRANKGRP -0.229640758
282     DEPRANKGRP       ARRSPOKE -0.229640758
161         xDURN2 DOWNLINEATCIMP -0.226093423
297 DOWNLINEATCIMP         xDURN2 -0.226093423
196       ARRSPOKE      ARRBUCKET  0.225890655
281      ARRBUCKET       ARRSPOKE  0.225890655
232       ARRSPOKE     TRNRANKGRP -0.225591539
283     TRNRANKGRP       ARRSPOKE -0.225591539
157     TRNRANKGRP DOWNLINEATCIMP -0.224193213
225 DOWNLINEATCIMP     TRNRANKGRP -0.224193213
25    UPLINEATCIMP      SKDARRSTA  0.223824406
110      SKDARRSTA   UPLINEATCIMP  0.223824406
88        ARRSPOKE          AVGSQ  0.219975654
275          AVGSQ       ARRSPOKE  0.219975654
270   xAVGSKDAVAIL       DEPSPOKE -0.212821518
321       DEPSPOKE   xAVGSKDAVAIL -0.212821518
40          SKDEPS         SKDEQP  0.212586898
57          SKDEQP         SKDEPS  0.212586898
213       DEPSPOKE     DEPRANKGRP  0.208188512
264     DEPRANKGRP       DEPSPOKE  0.208188512
156     DEPRANKGRP DOWNLINEATCIMP -0.199411990
207 DOWNLINEATCIMP     DEPRANKGRP -0.199411990
89          xDURN2          AVGSQ -0.197447957
293          AVGSQ         xDURN2 -0.197447957
195       DEPSPOKE      ARRBUCKET -0.189934966
263      ARRBUCKET       DEPSPOKE -0.189934966
87        DEPSPOKE          AVGSQ -0.188666787
257          AVGSQ       DEPSPOKE -0.188666787
85      TRNRANKGRP          AVGSQ -0.188226304
221          AVGSQ     TRNRANKGRP -0.188226304
179         xDURN2      DEPBUCKET -0.183349624
298      DEPBUCKET         xDURN2 -0.183349624
215         xDURN2     DEPRANKGRP  0.180043357
300     DEPRANKGRP         xDURN2  0.180043357
125         xDURN2   UPLINEATCIMP -0.173240320
295   UPLINEATCIMP         xDURN2 -0.173240320
198   xAVGSKDAVAIL      ARRBUCKET -0.170644257
317      ARRBUCKET   xAVGSKDAVAIL -0.170644257
175     TRNRANKGRP      DEPBUCKET -0.170618431
226      DEPBUCKET     TRNRANKGRP -0.170618431
30      DEPRANKGRP      SKDARRSTA -0.167375913
200      SKDARRSTA     DEPRANKGRP -0.167375913
10       DEPBUCKET      SKDDEPSTA -0.165029385
163      SKDDEPSTA      DEPBUCKET -0.165029385
7     UPLINEATCIMP      SKDDEPSTA -0.164964952
109      SKDDEPSTA   UPLINEATCIMP -0.164964952
84      DEPRANKGRP          AVGSQ -0.161451853
203          AVGSQ     DEPRANKGRP -0.161451853
86      ARRRANKGRP          AVGSQ -0.159135469
239          AVGSQ     ARRRANKGRP -0.159135469
174     DEPRANKGRP      DEPBUCKET -0.155547085
208      DEPBUCKET     DEPRANKGRP -0.155547085
5            AVGSQ      SKDDEPSTA -0.150522366
73       SKDDEPSTA          AVGSQ -0.150522366
139     TRNRANKGRP   DEPSTAATCIMP -0.147409309
224   DEPSTAATCIMP     TRNRANKGRP -0.147409309
118      DEPBUCKET   UPLINEATCIMP  0.144940797
169   UPLINEATCIMP      DEPBUCKET  0.144940797
176     ARRRANKGRP      DEPBUCKET -0.142348062
244      DEPBUCKET     ARRRANKGRP -0.142348062
144   xAVGSKDAVAIL   DEPSTAATCIMP -0.141077194
314   DEPSTAATCIMP   xAVGSKDAVAIL -0.141077194
103     TRNRANKGRP      AVGLOFATC  0.139184315
222      AVGLOFATC     TRNRANKGRP  0.139184315
136      DEPBUCKET   DEPSTAATCIMP -0.138581846
170   DEPSTAATCIMP      DEPBUCKET -0.138581846
288   xAVGSKDAVAIL       ARRSPOKE  0.137677242
322       ARRSPOKE   xAVGSKDAVAIL  0.137677242
212     ARRRANKGRP     DEPRANKGRP  0.136562948
246     DEPRANKGRP     ARRRANKGRP  0.136562948
98    DEPSTAATCIMP      AVGLOFATC -0.135778614
132      AVGLOFATC   DEPSTAATCIMP -0.135778614
107         xDURN2      AVGLOFATC -0.132084629
294      AVGLOFATC         xDURN2 -0.132084629
216   xAVGSKDAVAIL     DEPRANKGRP  0.130574789
318     DEPRANKGRP   xAVGSKDAVAIL  0.130574789
194     ARRRANKGRP      ARRBUCKET -0.129698517
245      ARRBUCKET     ARRRANKGRP -0.129698517
137      ARRBUCKET   DEPSTAATCIMP -0.127726148
188   DEPSTAATCIMP      ARRBUCKET -0.127726148
17          xDURN2      SKDDEPSTA  0.127598189
289      SKDDEPSTA         xDURN2  0.127598189
99  DOWNLINEATCIMP      AVGLOFATC -0.126763572
150      AVGLOFATC DOWNLINEATCIMP -0.126763572
197         xDURN2      ARRBUCKET -0.125836459
299      ARRBUCKET         xDURN2 -0.125836459
138     DEPRANKGRP   DEPSTAATCIMP  0.124672682
206   DEPSTAATCIMP     DEPRANKGRP  0.124672682
62    DEPSTAATCIMP         SKDEPS -0.123445793
130         SKDEPS   DEPSTAATCIMP -0.123445793
11       ARRBUCKET      SKDDEPSTA -0.120728212
181      SKDDEPSTA      ARRBUCKET -0.120728212
251         xDURN2     ARRRANKGRP  0.119675180
302     ARRRANKGRP         xDURN2  0.119675180
90    xAVGSKDAVAIL          AVGSQ -0.113720147
311          AVGSQ   xAVGSKDAVAIL -0.113720147
31      TRNRANKGRP      SKDARRSTA -0.105802023
218      SKDARRSTA     TRNRANKGRP -0.105802023
192     DEPRANKGRP      ARRBUCKET -0.105057984
209      ARRBUCKET     DEPRANKGRP -0.105057984
162   xAVGSKDAVAIL DOWNLINEATCIMP  0.102577364
315 DOWNLINEATCIMP   xAVGSKDAVAIL  0.102577364
120     DEPRANKGRP   UPLINEATCIMP -0.097218129
205   UPLINEATCIMP     DEPRANKGRP -0.097218129
121     TRNRANKGRP   UPLINEATCIMP -0.097037814
223   UPLINEATCIMP     TRNRANKGRP -0.097037814
22          SKDEPS      SKDARRSTA -0.096699169
56       SKDARRSTA         SKDEPS -0.096699169
63  DOWNLINEATCIMP         SKDEPS -0.095568613
148         SKDEPS DOWNLINEATCIMP -0.095568613
24       AVGLOFATC      SKDARRSTA -0.095234466
92       SKDARRSTA      AVGLOFATC -0.095234466
21          SKDEQP      SKDARRSTA  0.094073459
38       SKDARRSTA         SKDEQP  0.094073459
29       ARRBUCKET      SKDARRSTA  0.092625400
182      SKDARRSTA      ARRBUCKET  0.092625400
193     TRNRANKGRP      ARRBUCKET -0.092415252
227      ARRBUCKET     TRNRANKGRP -0.092415252
234   xAVGSKDAVAIL     TRNRANKGRP  0.092011501
319     TRNRANKGRP   xAVGSKDAVAIL  0.092011501
18    xAVGSKDAVAIL      SKDDEPSTA  0.088580325
307      SKDDEPSTA   xAVGSKDAVAIL  0.088580325
53          xDURN2         SKDEQP  0.086170070
291         SKDEQP         xDURN2  0.086170070
102     DEPRANKGRP      AVGLOFATC  0.085474019
204      AVGLOFATC     DEPRANKGRP  0.085474019
97    UPLINEATCIMP      AVGLOFATC -0.085180887
114      AVGLOFATC   UPLINEATCIMP -0.085180887
230     ARRRANKGRP     TRNRANKGRP  0.083906762
247     TRNRANKGRP     ARRRANKGRP  0.083906762
249       DEPSPOKE     ARRRANKGRP  0.083162083
266     ARRRANKGRP       DEPSPOKE  0.083162083
23           AVGSQ      SKDARRSTA  0.082898864
74       SKDARRSTA          AVGSQ  0.082898864
68      ARRRANKGRP         SKDEPS  0.080398834
238         SKDEPS     ARRRANKGRP  0.080398834
72    xAVGSKDAVAIL         SKDEPS  0.075169577
310         SKDEPS   xAVGSKDAVAIL  0.075169577
140     ARRRANKGRP   DEPSTAATCIMP  0.073371196
242   DEPSTAATCIMP     ARRRANKGRP  0.073371196
28       DEPBUCKET      SKDARRSTA  0.072910977
164      SKDARRSTA      DEPBUCKET  0.072910977
119      ARRBUCKET   UPLINEATCIMP  0.071409699
187   UPLINEATCIMP      ARRBUCKET  0.071409699
122     ARRRANKGRP   UPLINEATCIMP -0.069790367
241   UPLINEATCIMP     ARRRANKGRP -0.069790367
14      ARRRANKGRP      SKDDEPSTA  0.068927801
235      SKDDEPSTA     ARRRANKGRP  0.068927801
52        ARRSPOKE         SKDEQP  0.066579707
273         SKDEQP       ARRSPOKE  0.066579707
79    UPLINEATCIMP          AVGSQ  0.062631172
113          AVGSQ   UPLINEATCIMP  0.062631172
104     ARRRANKGRP      AVGLOFATC -0.061491190
240      AVGLOFATC     ARRRANKGRP -0.061491190
250       ARRSPOKE     ARRRANKGRP -0.057002549
284     ARRRANKGRP       ARRSPOKE -0.057002549
108   xAVGSKDAVAIL      AVGLOFATC -0.056264979
312      AVGLOFATC   xAVGSKDAVAIL -0.056264979
100      DEPBUCKET      AVGLOFATC -0.053357134
168      AVGLOFATC      DEPBUCKET -0.053357134
180   xAVGSKDAVAIL      DEPBUCKET -0.053125467
316      DEPBUCKET   xAVGSKDAVAIL -0.053125467
6        AVGLOFATC      SKDDEPSTA -0.044946507
91       SKDDEPSTA      AVGLOFATC -0.044946507
101      ARRBUCKET      AVGLOFATC -0.043093769
186      AVGLOFATC      ARRBUCKET -0.043093769
50      ARRRANKGRP         SKDEQP -0.042512956
237         SKDEQP     ARRRANKGRP -0.042512956
80    DEPSTAATCIMP          AVGSQ -0.040428658
131          AVGSQ   DEPSTAATCIMP -0.040428658
59           AVGSQ         SKDEPS -0.038820886
76          SKDEPS          AVGSQ -0.038820886
46       DEPBUCKET         SKDEQP  0.037125178
165         SKDEQP      DEPBUCKET  0.037125178
106       ARRSPOKE      AVGLOFATC -0.034402462
276      AVGLOFATC       ARRSPOKE -0.034402462
54    xAVGSKDAVAIL         SKDEQP  0.031863410
309         SKDEQP   xAVGSKDAVAIL  0.031863410
67      TRNRANKGRP         SKDEPS  0.030883560
220         SKDEPS     TRNRANKGRP  0.030883560
64       DEPBUCKET         SKDEPS -0.030101407
166         SKDEPS      DEPBUCKET -0.030101407
35          xDURN2      SKDARRSTA  0.027576751
290      SKDARRSTA         xDURN2  0.027576751
78       AVGLOFATC          AVGSQ -0.027382453
95           AVGSQ      AVGLOFATC -0.027382453
36    xAVGSKDAVAIL      SKDARRSTA  0.027225219
308      SKDARRSTA   xAVGSKDAVAIL  0.027225219
66      DEPRANKGRP         SKDEPS  0.027025501
202         SKDEPS     DEPRANKGRP  0.027025501
4           SKDEPS      SKDDEPSTA -0.024267794
55       SKDDEPSTA         SKDEPS -0.024267794
43    UPLINEATCIMP         SKDEQP -0.019807499
111         SKDEQP   UPLINEATCIMP -0.019807499
51        DEPSPOKE         SKDEQP  0.019755644
255         SKDEQP       DEPSPOKE  0.019755644
306   xAVGSKDAVAIL         xDURN2 -0.019255572
323         xDURN2   xAVGSKDAVAIL -0.019255572
252   xAVGSKDAVAIL     ARRRANKGRP -0.018743432
320     ARRRANKGRP   xAVGSKDAVAIL -0.018743432
143         xDURN2   DEPSTAATCIMP -0.017999758
296   DEPSTAATCIMP         xDURN2 -0.017999758
45  DOWNLINEATCIMP         SKDEQP -0.017658860
147         SKDEQP DOWNLINEATCIMP -0.017658860
70        ARRSPOKE         SKDEPS  0.017573485
274         SKDEPS       ARRSPOKE  0.017573485
65       ARRBUCKET         SKDEPS  0.017414895
184         SKDEPS      ARRBUCKET  0.017414895
32      ARRRANKGRP      SKDARRSTA  0.016733374
236      SKDARRSTA     ARRRANKGRP  0.016733374
41           AVGSQ         SKDEQP  0.010218807
75          SKDEQP          AVGSQ  0.010218807
47       ARRBUCKET         SKDEQP  0.009926479
183         SKDEQP      ARRBUCKET  0.009926479
105       DEPSPOKE      AVGLOFATC -0.008540402
258      AVGLOFATC       DEPSPOKE -0.008540402
60       AVGLOFATC         SKDEPS  0.008240563
94          SKDEPS      AVGLOFATC  0.008240563
44    DEPSTAATCIMP         SKDEQP -0.005922601
129         SKDEQP   DEPSTAATCIMP -0.005922601
42       AVGLOFATC         SKDEQP -0.004889040
93          SKDEQP      AVGLOFATC -0.004889040
69        DEPSPOKE         SKDEPS -0.004617067
256         SKDEPS       DEPSPOKE -0.004617067
61    UPLINEATCIMP         SKDEPS  0.004016263
112         SKDEPS   UPLINEATCIMP  0.004016263
71          xDURN2         SKDEPS  0.001748012
292         SKDEPS         xDURN2  0.001748012
> 
> ### Models
> 
> ## Try GBM (gradient boosting). Works well for mixed data.
> ## And there is a tutorial for it with caret.
> 
> ## Training controller and big grid
> ## Check the ROC (my preferred.)
> 
> fitControl <- trainControl(## 10-fold CV
+     method = "repeatedcv",
+     number = 10,
+     ## repeated ten times
+     repeats = 10,
+     classProbs = 10,
+     summaryFunction = twoClassSummary)
> 
> ## Some trial and error with variables to branch and boost.
> ## I'm just going to try the airports and the planes and the duration
> ## of the flight. There may be some distance relationship there that
> ## air traffic control use.
> 
> ## Annoying because I drop variables, this needs to be looked up.
> 
> tr.cols <- colnames(trainDescr)
> tr.cols
 [1] "SKDDEPSTA"      "SKDARRSTA"      "SKDEQP"         "SKDEPS"        
 [5] "AVGSQ"          "AVGLOFATC"      "UPLINEATCIMP"   "DEPSTAATCIMP"  
 [9] "DOWNLINEATCIMP" "DEPBUCKET"      "ARRBUCKET"      "DEPRANKGRP"    
[13] "TRNRANKGRP"     "ARRRANKGRP"     "DEPSPOKE"       "ARRSPOKE"      
[17] "xDURN2"         "xAVGSKDAVAIL"  
> tr.icols <- grep("((STA|EQP)$)|(^xD)", tr.cols)
> tr.icols <- rev(tr.icols)
> 
> gbmGrid <- expand.grid(interaction.depth = tr.icols,
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.1,
+                         n.minobsinnode = 20)
> 
> set.seed(seed.mine)
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "ROC",
+                  verbose = FALSE)
> gbmFit1
Stochastic Gradient Boosting 

248 samples
 18 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 222, 223, 223, 224, 223, 223, ... 

Resampling results across tuning parameters:

  interaction.depth  n.trees  ROC        Sens       Spec       ROC SD    
   1                   90     0.7879491  0.7452198  0.6902273  0.08345969
   1                  180     0.7885760  0.7449451  0.6990909  0.08298156
   1                  270     0.7838066  0.7509341  0.6956061  0.08540577
   1                  360     0.7783183  0.7396154  0.6912121  0.09268667
   1                  450     0.7746091  0.7425275  0.6918939  0.08790756
   1                  540     0.7711946  0.7439560  0.6831061  0.08968519
   1                  630     0.7717383  0.7308242  0.6850000  0.09259339
   1                  720     0.7693906  0.7351099  0.6734091  0.09238540
   1                  810     0.7629562  0.7299451  0.6752273  0.10558373
   1                  900     0.7647602  0.7364835  0.6718182  0.09336401
   1                  990     0.7596907  0.7356593  0.6718939  0.10582980
   1                 1080     0.7594164  0.7314835  0.6769697  0.09897609
   1                 1170     0.7558854  0.7336813  0.6734848  0.10680608
   1                 1260     0.7571379  0.7323077  0.6688636  0.10710117
   1                 1350     0.7565185  0.7301099  0.6672727  0.10451553
   1                 1440     0.7560340  0.7286264  0.6716667  0.10541723
   1                 1530     0.7574983  0.7228022  0.6744697  0.10109491
   1                 1620     0.7549242  0.7286264  0.6689394  0.10138704
   1                 1710     0.7548281  0.7213187  0.6681818  0.10106840
   1                 1800     0.7540768  0.7235714  0.6636364  0.10277582
   1                 1890     0.7544227  0.7241209  0.6634848  0.10071951
   1                 1980     0.7506315  0.7219231  0.6652273  0.10461606
   1                 2070     0.7501582  0.7254945  0.6564394  0.10681343
   1                 2160     0.7514993  0.7261538  0.6601515  0.10101754
   1                 2250     0.7500549  0.7267582  0.6592424  0.10222365
   1                 2340     0.7505286  0.7241209  0.6637879  0.10134503
   1                 2430     0.7517120  0.7225275  0.6629545  0.10050724
   1                 2520     0.7523872  0.7210989  0.6663636  0.10132468
   1                 2610     0.7517424  0.7216484  0.6662879  0.10073231
   1                 2700     0.7505332  0.7267582  0.6635606  0.09986549
   2                   90     0.7794888  0.7620330  0.6714394  0.09956587
   2                  180     0.7720026  0.7360989  0.6678030  0.09071462
   2                  270     0.7685419  0.7381319  0.6632576  0.09547601
   2                  360     0.7666034  0.7361538  0.6561364  0.09034456
   2                  450     0.7703114  0.7368132  0.6640152  0.09047581
   2                  540     0.7694381  0.7394505  0.6590152  0.09004537
   2                  630     0.7687071  0.7352198  0.6578788  0.09452169
   2                  720     0.7660843  0.7343956  0.6617424  0.09464958
   2                  810     0.7658121  0.7365934  0.6600000  0.09187750
   2                  900     0.7631677  0.7381319  0.6598485  0.09923718
   2                  990     0.7608229  0.7379670  0.6662121  0.09824384
   2                 1080     0.7620950  0.7416484  0.6598485  0.09620877
   2                 1170     0.7605594  0.7373077  0.6606061  0.09705033
   2                 1260     0.7616692  0.7415934  0.6571212  0.09700197
   2                 1350     0.7583941  0.7357692  0.6642424  0.09678388
   2                 1440     0.7605457  0.7342308  0.6604545  0.09651400
   2                 1530     0.7581710  0.7395055  0.6577273  0.09820703
   2                 1620     0.7554292  0.7379670  0.6615909  0.09843684
   2                 1710     0.7576132  0.7351099  0.6551515  0.09564101
   2                 1800     0.7553609  0.7351648  0.6577273  0.09963545
   2                 1890     0.7544709  0.7358242  0.6577273  0.09852255
   2                 1980     0.7552393  0.7365385  0.6542424  0.09848962
   2                 2070     0.7549788  0.7321429  0.6532576  0.10059452
   2                 2160     0.7551702  0.7321429  0.6568939  0.10085288
   2                 2250     0.7532030  0.7315385  0.6579545  0.10201481
   2                 2340     0.7532413  0.7359341  0.6569697  0.10134297
   2                 2430     0.7526357  0.7323077  0.6606818  0.10237595
   2                 2520     0.7540331  0.7329670  0.6633333  0.10156955
   2                 2610     0.7539257  0.7292857  0.6569697  0.10036349
   2                 2700     0.7536422  0.7322527  0.6614394  0.09968022
   3                   90     0.7809649  0.7532418  0.6744697  0.08944807
   3                  180     0.7680124  0.7354396  0.6586364  0.09805716
   3                  270     0.7641779  0.7324725  0.6642424  0.09631284
   3                  360     0.7592703  0.7310440  0.6607576  0.10184928
   3                  450     0.7600595  0.7279670  0.6633333  0.09895190
   3                  540     0.7615289  0.7360440  0.6544697  0.09850614
   3                  630     0.7584361  0.7315385  0.6651515  0.10102431
   3                  720     0.7570667  0.7254396  0.6597727  0.10001957
   3                  810     0.7563187  0.7342857  0.6543182  0.09920683
   3                  900     0.7556822  0.7379121  0.6550758  0.10095781
   3                  990     0.7557501  0.7329121  0.6561364  0.10117253
   3                 1080     0.7548947  0.7328571  0.6587121  0.09961402
   3                 1170     0.7529554  0.7321978  0.6596970  0.09980002
   3                 1260     0.7554146  0.7313736  0.6550758  0.09693011
   3                 1350     0.7544172  0.7268681  0.6570455  0.09634874
   3                 1440     0.7547199  0.7341758  0.6490152  0.09451462
   3                 1530     0.7554146  0.7348901  0.6552273  0.09573349
   3                 1620     0.7556485  0.7306044  0.6533333  0.09566592
   3                 1710     0.7522336  0.7357143  0.6543939  0.09869253
   3                 1800     0.7543373  0.7336813  0.6534091  0.09618145
   3                 1890     0.7535198  0.7308242  0.6515909  0.09593895
   3                 1980     0.7535852  0.7336813  0.6489394  0.09679518
   3                 2070     0.7542274  0.7344505  0.6461364  0.09589355
   3                 2160     0.7536813  0.7345604  0.6471212  0.09729710
   3                 2250     0.7523751  0.7352198  0.6461364  0.10059613
   3                 2340     0.7538453  0.7323077  0.6461364  0.09692337
   3                 2430     0.7520067  0.7351648  0.6453030  0.10074658
   3                 2520     0.7522428  0.7358791  0.6452273  0.09973834
   3                 2610     0.7530952  0.7358791  0.6452273  0.09993601
   3                 2700     0.7538499  0.7366484  0.6488636  0.09937930
  17                   90     0.7813374  0.7504945  0.6685606  0.09352588
  17                  180     0.7674638  0.7376374  0.6570455  0.09666832
  17                  270     0.7627539  0.7339560  0.6641667  0.10055278
  17                  360     0.7606356  0.7347802  0.6669697  0.10072323
  17                  450     0.7598418  0.7342308  0.6568939  0.10042217
  17                  540     0.7587962  0.7310989  0.6522727  0.10358313
  17                  630     0.7571553  0.7332418  0.6559091  0.10293809
  17                  720     0.7561780  0.7337912  0.6560606  0.10534310
  17                  810     0.7547007  0.7368681  0.6559848  0.10393607
  17                  900     0.7564677  0.7338462  0.6541667  0.10317809
  17                  990     0.7521553  0.7293956  0.6531818  0.10215498
  17                 1080     0.7537109  0.7323626  0.6504545  0.10139951
  17                 1170     0.7516746  0.7302198  0.6541667  0.10305150
  17                 1260     0.7533708  0.7302747  0.6496212  0.10162754
  17                 1350     0.7533516  0.7270330  0.6496212  0.09983549
  17                 1440     0.7529287  0.7270879  0.6540152  0.10094332
  17                 1530     0.7526303  0.7292308  0.6496212  0.09991100
  17                 1620     0.7519060  0.7248901  0.6504545  0.10330200
  17                 1710     0.7529516  0.7226923  0.6477273  0.10011735
  17                 1800     0.7530020  0.7313736  0.6496212  0.09941220
  17                 1890     0.7519893  0.7307143  0.6450000  0.09876161
  17                 1980     0.7535823  0.7300000  0.6441667  0.09785203
  17                 2070     0.7527373  0.7292308  0.6440909  0.09844337
  17                 2160     0.7521358  0.7292857  0.6459848  0.09705755
  17                 2250     0.7519993  0.7293407  0.6450758  0.09660374
  17                 2340     0.7526486  0.7285165  0.6414394  0.09678128
  17                 2430     0.7515281  0.7292308  0.6423485  0.10101136
  17                 2520     0.7514806  0.7286264  0.6424242  0.10069621
  17                 2610     0.7512883  0.7277473  0.6387879  0.10045968
  17                 2700     0.7501124  0.7314286  0.6388636  0.10156281
  Sens SD    Spec SD  
  0.1088099  0.1348971
  0.1191595  0.1287049
  0.1117695  0.1251530
  0.1151899  0.1326664
  0.1210959  0.1335459
  0.1144759  0.1334547
  0.1233526  0.1411646
  0.1187342  0.1393988
  0.1203643  0.1377874
  0.1236302  0.1424918
  0.1212542  0.1333532
  0.1182745  0.1319628
  0.1194796  0.1347836
  0.1281101  0.1293170
  0.1219273  0.1330921
  0.1223532  0.1318252
  0.1247754  0.1365228
  0.1238273  0.1334740
  0.1195782  0.1399140
  0.1252835  0.1372915
  0.1277245  0.1359599
  0.1252012  0.1383670
  0.1241766  0.1487753
  0.1231775  0.1455475
  0.1212289  0.1422968
  0.1197622  0.1460714
  0.1189836  0.1471340
  0.1196445  0.1439612
  0.1231837  0.1443170
  0.1250452  0.1413243
  0.1170487  0.1298956
  0.1164683  0.1214337
  0.1128425  0.1356107
  0.1145610  0.1250534
  0.1187424  0.1376263
  0.1119580  0.1398705
  0.1164610  0.1383336
  0.1168389  0.1424409
  0.1121284  0.1431955
  0.1131717  0.1416333
  0.1145975  0.1418023
  0.1146674  0.1344736
  0.1125055  0.1356433
  0.1139645  0.1362685
  0.1144734  0.1420721
  0.1094693  0.1344903
  0.1141827  0.1403293
  0.1136945  0.1371735
  0.1101238  0.1346674
  0.1123870  0.1450103
  0.1153190  0.1421965
  0.1118495  0.1380601
  0.1150428  0.1445196
  0.1185725  0.1395210
  0.1201631  0.1389092
  0.1153590  0.1391832
  0.1148404  0.1344770
  0.1157316  0.1334689
  0.1194040  0.1335764
  0.1154807  0.1364516
  0.1179063  0.1380556
  0.1226606  0.1401740
  0.1261592  0.1401081
  0.1279632  0.1421035
  0.1147326  0.1424488
  0.1193506  0.1383469
  0.1171407  0.1344585
  0.1179900  0.1378145
  0.1155906  0.1329089
  0.1138923  0.1318131
  0.1114084  0.1332758
  0.1104569  0.1313413
  0.1122176  0.1292156
  0.1129524  0.1274074
  0.1163657  0.1301818
  0.1116842  0.1333678
  0.1131587  0.1324669
  0.1125699  0.1330678
  0.1133851  0.1338093
  0.1118524  0.1361184
  0.1093769  0.1359442
  0.1105360  0.1350574
  0.1071220  0.1400726
  0.1101083  0.1342738
  0.1094722  0.1376680
  0.1086989  0.1388755
  0.1110770  0.1388091
  0.1116336  0.1398355
  0.1116336  0.1410244
  0.1111325  0.1407459
  0.1147528  0.1381434
  0.1178476  0.1312021
  0.1107393  0.1341480
  0.1174393  0.1311803
  0.1210698  0.1364966
  0.1250670  0.1323881
  0.1150349  0.1316930
  0.1176948  0.1319166
  0.1214728  0.1328017
  0.1223194  0.1306287
  0.1198795  0.1366337
  0.1205363  0.1347945
  0.1236489  0.1340110
  0.1226326  0.1379124
  0.1167753  0.1378157
  0.1187772  0.1361639
  0.1177122  0.1393343
  0.1211544  0.1357331
  0.1212229  0.1371035
  0.1184915  0.1365012
  0.1186242  0.1356775
  0.1167705  0.1375339
  0.1159477  0.1354250
  0.1167152  0.1374175
  0.1158702  0.1383866
  0.1159767  0.1385694
  0.1158056  0.1382312
  0.1149169  0.1390078
  0.1143116  0.1397186
  0.1164966  0.1412708

Tuning parameter 'shrinkage' was held constant at a value of 0.1

Tuning parameter 'n.minobsinnode' was held constant at a value of 20
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 180, interaction.depth =
 1, shrinkage = 0.1 and n.minobsinnode = 20. 
> 
> ## The acid test is dissapointing, but I've seen worse.
> 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
  Accuracy      Kappa 
 0.4305556 -0.1567398 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     20   21
    Weak       20   11
                                          
               Accuracy : 0.4306          
                 95% CI : (0.3143, 0.5527)
    No Information Rate : 0.5556          
    P-Value [Acc > NIR] : 0.9876          
                                          
                  Kappa : -0.1567         
 Mcnemar's Test P-Value : 1.0000          
                                          
            Sensitivity : 0.3438          
            Specificity : 0.5000          
         Pos Pred Value : 0.3548          
         Neg Pred Value : 0.4878          
             Prevalence : 0.4444          
         Detection Rate : 0.1528          
   Detection Prevalence : 0.4306          
      Balanced Accuracy : 0.4219          
                                          
       'Positive' Class : Weak            
                                          
> 
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
 Accuracy     Kappa 
0.8145161 0.6261878 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    112   21
    Weak       25   90
                                          
               Accuracy : 0.8145          
                 95% CI : (0.7605, 0.8609)
    No Information Rate : 0.5524          
    P-Value [Acc > NIR] : <2e-16          
                                          
                  Kappa : 0.6262          
 Mcnemar's Test P-Value : 0.6583          
                                          
            Sensitivity : 0.8108          
            Specificity : 0.8175          
         Pos Pred Value : 0.7826          
         Neg Pred Value : 0.8421          
             Prevalence : 0.4476          
         Detection Rate : 0.3629          
   Detection Prevalence : 0.4637          
      Balanced Accuracy : 0.8142          
                                          
       'Positive' Class : Weak            
                                          
> ### weaves
> 
> ## Processing for flights data.
> 
> ## Following the caret vignette.
> 
> ###################################################
> ### code chunk number 1: loadLibs
> ###################################################
> library(MASS)
> library(caret)
> library(mlbench)
> library(pROC)
> library(pls)
> 
> library(doMC)
> registerDoMC(cores = 4)
> 
> options(useFancyQuotes = FALSE) 
> 
> # Accounting info.
> getInfo <- function(what = "Suggests")
+ {
+   text <- packageDescription("caret")[what][[1]]
+   text <- gsub("\n", ", ", text, fixed = TRUE)
+   text <- gsub(">=", "$\\\\ge$", text, fixed = TRUE)
+   eachPkg <- strsplit(text, ", ", fixed = TRUE)[[1]]
+   eachPkg <- gsub(",", "", eachPkg, fixed = TRUE)
+   # out <- paste("\\\\pkg{", eachPkg[order(tolower(eachPkg))], "}", sep = "")
+   # paste(out, collapse = ", ")
+   length(eachPkg)
+ }
> 
> ### project-specific: begin
> ## Set-seed, load original CSV file, order it
> ## and do some simple-cleaning
> ## Various datasets 
> 
> seed.mine = 107
> set.seed(seed.mine)                     # helpful for testing
> 
> flight <- read.csv("../bak/flight.csv")
> flight <- flight[order(flight$D00),]
> 
> # Backup
> flight.raw <- flight
> 
> # To check adjustment, there is test code in flight-nb.R
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"
> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"
> 
> # And some deletions
> 
> t.cols <- colnames(flight)
> 
> t.drops <- t.cols[grep("^RANK*", t.cols)]
> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])
> t.drops <- c(t.drops, "D80THPCTL")
> 
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR
> flight$xHNGR <- flight$xDURN < 0
> 
> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+ }
> 
> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))
> 
> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE
> t.cols <- colnames(flight)
> 
> t.drops <- c("SARRHR", "xDURN")
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Backup
> 
> flight00 <- flight
> 
> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]
> 
> paste("samples in use: ", dim(flight)[1])
[1] "samples in use:  320"
> 
> ## Data insights
> 
> ## *Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> flight <- flight1
> 
> ### Numeric variables
> 
> ### Try and impute the AVG, it might have more information than the
> ### bucket.
> 
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))
Error in `$<-.data.frame`(`*tmp*`, "xAVAILBUCKET", value = numeric(0)) : 
  replacement has 0 rows, data has 320
> 
> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1
> 
> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]
Error in `[.data.frame`(flight, , c("AVGSKDAVAIL", "xAVAILBUCKET")) : 
  undefined columns selected
> 
> preProcValues <- preProcess(flight.na, method = c("knnImpute"))
> flight.na1 <- predict(preProcValues, flight.na)
> 
> ## I'll add the new imputed value and drop the others
> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL
> flight$AVGSKDAVAIL <- NULL
> flight$xAVAILBUCKET <- NULL
> flight$AVAILBUCKET <- NULL
> 
> flight$xHNGR <- NULL
> 
> ## Check some more numeric correlations, I haven't scaled everything yet.
> ## I'd cut correlations above 0.65 to 0.75 because of overfitting.
> 
> x1 <- as.data.frame(as.matrix(sapply(flight, class)))
> 
> flight.num <- flight[,names(x1[which(x1$V1 %in% c("numeric", "integer")),])]
> 
> flight.nzv <- nearZeroVar(flight.num, saveMetrics = TRUE)
> flight.nzv
             freqRatio percentUnique zeroVar   nzv
SDEPHR        1.038462        5.9375   FALSE FALSE
SKDEPS        1.000000       19.0625   FALSE FALSE
D00           1.166667       75.3125   FALSE FALSE
AVGSQ         6.333333       82.8125   FALSE FALSE
AVGLOFATC     1.000000       78.4375   FALSE FALSE
xDURN2        1.428571        2.5000   FALSE FALSE
xAVGSKDAVAIL 18.500000       87.8125   FALSE FALSE
> 
> # annoying NA should be gone.
> flight.cor <- cor(flight.num, use = "pairwise.complete.obs")
> 
> descrCorr <- findCorrelation(flight.cor, cutoff = .65, verbose=TRUE)
Considering row	 4 column	 1 value	 0.956 
  Flagging column	 4 
Considering row	 1 column	 3 value	 0.43 
Considering row	 1 column	 7 value	 0.053 
Considering row	 1 column	 6 value	 0.204 
Considering row	 1 column	 5 value	 0.131 
Considering row	 1 column	 2 value	 0.054 
Considering row	 3 column	 7 value	 0.401 
Considering row	 3 column	 6 value	 0.071 
Considering row	 3 column	 5 value	 0.114 
Considering row	 3 column	 2 value	 0.006 
Considering row	 7 column	 6 value	 0.019 
Considering row	 7 column	 5 value	 0.07 
Considering row	 7 column	 2 value	 0.113 
Considering row	 6 column	 5 value	 0.137 
Considering row	 6 column	 2 value	 0.005 
Considering row	 5 column	 2 value	 0.041 
> 
> colnames(flight.num)[descrCorr]
[1] "AVGSQ"
> 
> ## And I'll leave the centered and scale values in for now.
> ## and delete the troublesome ones
> 
> ## Re-classing
> ## Check warnings to see it adjustment has taken place.
> ## We want the proportion in the training class to be about 0.55 0.45
> ## Strong to Weak
> ## I've achieved this heuristically
> src.adjust <- TRUE
> source(file = "flight1.R")
Warning message:
In eval(expr, envir, enclos) : adjusting
> flight1 <- flight
> 
> ## This should be deleted, leave it in and the results
> ## are ideal because it defines LEGTYPE.
> flight$D00 <- NULL
> 
> ## Keep the results but don't change the order.
> outcomes.flight <- flight$LEGTYPE
> 
> flight$LEGTYPE <- NULL
> 
> ## If you know your factors are definitely factors, you don't need this
> ##  asNumeric <- function(x) as.numeric(as.character(x))
> 
> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))
> 
> flight.num0 <- factors.numeric(flight)
> 
> flight.scl0 <- scale(flight.num0)
> 
> ## Now split the samples
> ## we need at least 60 to test with, p at 0.77 gives about 75.
> ## Difficulty here is the bias in the table
> ## Because we only have [3.1, 4.4] the proportion of Weak is higher.
> ## see prop.table(results)
> 
> set.seed(seed.mine)
> inTrain <- createDataPartition(outcomes.flight, p = 0.77, list = FALSE)
> 
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> 
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> 
> prop.table(table(trainClass))
trainClass
   Strong      Weak 
0.5524194 0.4475806 
> dim(trainDescr)
[1] 248  19
> 
> prop.table(table(testClass))
testClass
   Strong      Weak 
0.5555556 0.4444444 
> dim(testDescr)
[1] 72 19
> 
> ## Check Near-zero variance
> 
> nzv <- nearZeroVar(trainDescr, saveMetrics= TRUE)
> stopifnot( all(nzv$nzv == FALSE) )
> 
> # It's imputed and behaves well, no need for this.
> # descrCorr <- cor(scale(trainDescr), use = "pairwise.complete.obs")
> 
> descrCorr <- cor(scale(trainDescr))
> 
> ## This cut-off should be under src.adjust control.
> ## I'm under Git, so I can tinker with it.
> highCorr <- findCorrelation(descrCorr, cutoff = .80, verbose = TRUE)
Considering row	 17 column	 16 value	 0.85 
  Flagging column	 17 
Considering row	 16 column	 10 value	 0.568 
Considering row	 16 column	 1 value	 0.236 
Considering row	 16 column	 11 value	 0.231 
Considering row	 16 column	 6 value	 0.189 
Considering row	 16 column	 12 value	 0.19 
Considering row	 16 column	 2 value	 0.333 
Considering row	 16 column	 9 value	 0.671 
Considering row	 16 column	 14 value	 0.242 
Considering row	 16 column	 13 value	 0.208 
Considering row	 16 column	 8 value	 0.6 
Considering row	 16 column	 3 value	 0.318 
Considering row	 16 column	 18 value	 0.279 
Considering row	 16 column	 19 value	 0.213 
Considering row	 16 column	 15 value	 0.083 
Considering row	 16 column	 4 value	 0.02 
Considering row	 16 column	 7 value	 0.009 
Considering row	 16 column	 5 value	 0.005 
Considering row	 10 column	 1 value	 0.281 
Considering row	 10 column	 11 value	 0.275 
Considering row	 10 column	 6 value	 0.298 
Considering row	 10 column	 12 value	 0.255 
Considering row	 10 column	 2 value	 0.286 
Considering row	 10 column	 9 value	 0.404 
Considering row	 10 column	 14 value	 0.224 
Considering row	 10 column	 13 value	 0.199 
Considering row	 10 column	 8 value	 0.366 
Considering row	 10 column	 3 value	 0.462 
Considering row	 10 column	 18 value	 0.226 
Considering row	 10 column	 19 value	 0.103 
Considering row	 10 column	 15 value	 0.274 
Considering row	 10 column	 4 value	 0.018 
Considering row	 10 column	 7 value	 0.127 
Considering row	 10 column	 5 value	 0.096 
Considering row	 1 column	 11 value	 0.988 
  Flagging column	 1 
Considering row	 11 column	 6 value	 0.945 
  Flagging column	 11 
Considering row	 6 column	 12 value	 0.883 
  Flagging column	 6 
Considering row	 12 column	 2 value	 0.121 
Considering row	 12 column	 9 value	 0.128 
Considering row	 12 column	 14 value	 0.092 
Considering row	 12 column	 13 value	 0.105 
Considering row	 12 column	 8 value	 0.071 
Considering row	 12 column	 3 value	 0.093 
Considering row	 12 column	 18 value	 0.126 
Considering row	 12 column	 19 value	 0.171 
Considering row	 12 column	 15 value	 0.13 
Considering row	 12 column	 4 value	 0.01 
Considering row	 12 column	 7 value	 0.043 
Considering row	 12 column	 5 value	 0.017 
Considering row	 2 column	 9 value	 0.423 
Considering row	 2 column	 14 value	 0.574 
Considering row	 2 column	 13 value	 0.557 
Considering row	 2 column	 8 value	 0.165 
Considering row	 2 column	 3 value	 0.263 
Considering row	 2 column	 18 value	 0.128 
Considering row	 2 column	 19 value	 0.089 
Considering row	 2 column	 15 value	 0.069 
Considering row	 2 column	 4 value	 0.27 
Considering row	 2 column	 7 value	 0.045 
Considering row	 2 column	 5 value	 0.024 
Considering row	 9 column	 14 value	 0.147 
Considering row	 9 column	 13 value	 0.125 
Considering row	 9 column	 8 value	 0.449 
Considering row	 9 column	 3 value	 0.322 
Considering row	 9 column	 18 value	 0.018 
Considering row	 9 column	 19 value	 0.141 
Considering row	 9 column	 15 value	 0.073 
Considering row	 9 column	 4 value	 0.006 
Considering row	 9 column	 7 value	 0.136 
Considering row	 9 column	 5 value	 0.123 
Considering row	 14 column	 13 value	 0.659 
Considering row	 14 column	 8 value	 0.097 
Considering row	 14 column	 3 value	 0.106 
Considering row	 14 column	 18 value	 0.361 
Considering row	 14 column	 19 value	 0.092 
Considering row	 14 column	 15 value	 0.084 
Considering row	 14 column	 4 value	 0.263 
Considering row	 14 column	 7 value	 0.139 
Considering row	 14 column	 5 value	 0.031 
Considering row	 13 column	 8 value	 0.097 
Considering row	 13 column	 3 value	 0.167 
Considering row	 13 column	 18 value	 0.18 
Considering row	 13 column	 19 value	 0.131 
Considering row	 13 column	 15 value	 0.137 
Considering row	 13 column	 4 value	 0.24 
Considering row	 13 column	 7 value	 0.085 
Considering row	 13 column	 5 value	 0.027 
Considering row	 8 column	 3 value	 0.224 
Considering row	 8 column	 18 value	 0.173 
Considering row	 8 column	 19 value	 0.235 
Considering row	 8 column	 15 value	 0.07 
Considering row	 8 column	 4 value	 0.02 
Considering row	 8 column	 7 value	 0.085 
Considering row	 8 column	 5 value	 0.004 
Considering row	 3 column	 18 value	 0.028 
Considering row	 3 column	 19 value	 0.027 
Considering row	 3 column	 15 value	 0.017 
Considering row	 3 column	 4 value	 0.094 
Considering row	 3 column	 7 value	 0.095 
Considering row	 3 column	 5 value	 0.097 
Considering row	 18 column	 19 value	 0.019 
Considering row	 18 column	 15 value	 0.12 
Considering row	 18 column	 4 value	 0.086 
Considering row	 18 column	 7 value	 0.132 
Considering row	 18 column	 5 value	 0.002 
Considering row	 19 column	 15 value	 0.019 
Considering row	 19 column	 4 value	 0.032 
Considering row	 19 column	 7 value	 0.056 
Considering row	 19 column	 5 value	 0.075 
Considering row	 15 column	 4 value	 0.043 
Considering row	 15 column	 7 value	 0.061 
Considering row	 15 column	 5 value	 0.08 
Considering row	 4 column	 7 value	 0.005 
Considering row	 4 column	 5 value	 0.213 
Considering row	 7 column	 5 value	 0.008 
> 
> colnames(trainDescr)[highCorr]
[1] "ARRSPOKE"  "SDEPHR"    "DEPBUCKET" "AVGSQ"    
> 
> descr.ncol0 <- ncol(trainDescr)
> 
> # I've switched off the correlation remover and the results are better.
> if (sum(highCorr) > 0) {
+     warning("overfitting: correlations: err.trainDescr: ", paste(colnames(trainDescr)[highCorr], collapse = ", ") )
+     err.trainDescr <- trainDescr
+     trainDescr <- trainDescr[,-highCorr]
+ }
Warning message:
overfitting: correlations: err.trainDescr: ARRSPOKE, SDEPHR, DEPBUCKET, AVGSQ 
> 
> descr.ncol1 <- ncol(trainDescr)
> 
> paste("Dropped: ", as.character(descr.ncol0 - descr.ncol1))
[1] "Dropped:  4"
> 
> descrCorr <- cor(trainDescr)
> summary(descrCorr[upper.tri(descrCorr)])
     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
-0.600000 -0.123400 -0.004617  0.012770  0.102600  0.671300 
> 
> ## Dominant correlations
> ## At 0.9, there are some big ones that might need re-thinking.
> 
> table.descrCorr <- as.data.frame(as.table(descrCorr))
> table.descrCorr <- table.descrCorr[which(table.descrCorr$Var1 != table.descrCorr$Var2),]
> table.descrCorr[order(abs(table.descrCorr$Freq), decreasing = TRUE),]
              Var1           Var2         Freq
103       DEPSPOKE   DEPSTAATCIMP  0.671264566
187   DEPSTAATCIMP       DEPSPOKE  0.671264566
146     TRNRANKGRP     DEPRANKGRP  0.658724662
160     DEPRANKGRP     TRNRANKGRP  0.658724662
88        DEPSPOKE   UPLINEATCIMP -0.600008252
186   UPLINEATCIMP       DEPSPOKE -0.600008252
11      TRNRANKGRP      SKDDEPSTA  0.574035134
151      SKDDEPSTA     TRNRANKGRP  0.574035134
118       DEPSPOKE DOWNLINEATCIMP -0.567682494
188 DOWNLINEATCIMP       DEPSPOKE -0.567682494
10      DEPRANKGRP      SKDDEPSTA  0.557399203
136      SKDDEPSTA     DEPRANKGRP  0.557399203
23  DOWNLINEATCIMP      SKDARRSTA  0.462378131
107      SKDARRSTA DOWNLINEATCIMP  0.462378131
82    DEPSTAATCIMP   UPLINEATCIMP -0.449249986
96    UPLINEATCIMP   DEPSTAATCIMP -0.449249986
7     DEPSTAATCIMP      SKDDEPSTA  0.423425796
91       SKDDEPSTA   DEPSTAATCIMP  0.423425796
98  DOWNLINEATCIMP   DEPSTAATCIMP -0.403695561
112   DEPSTAATCIMP DOWNLINEATCIMP -0.403695561
83  DOWNLINEATCIMP   UPLINEATCIMP  0.365833687
111   UPLINEATCIMP DOWNLINEATCIMP  0.365833687
164         xDURN2     TRNRANKGRP  0.361347207
206     TRNRANKGRP         xDURN2  0.361347207
13        DEPSPOKE      SKDDEPSTA  0.332823310
181      SKDDEPSTA       DEPSPOKE  0.332823310
22    DEPSTAATCIMP      SKDARRSTA -0.322204878
92       SKDARRSTA   DEPSTAATCIMP -0.322204878
28        DEPSPOKE      SKDARRSTA -0.318093195
182      SKDARRSTA       DEPSPOKE -0.318093195
8   DOWNLINEATCIMP      SKDDEPSTA -0.285911992
106      SKDDEPSTA DOWNLINEATCIMP -0.285911992
194         xDURN2       DEPSPOKE  0.279030910
208       DEPSPOKE         xDURN2  0.279030910
117     ARRRANKGRP DOWNLINEATCIMP -0.274110143
173 DOWNLINEATCIMP     ARRRANKGRP -0.274110143
3           SKDEQP      SKDDEPSTA  0.270065872
31       SKDDEPSTA         SKDEQP  0.270065872
2        SKDARRSTA      SKDDEPSTA -0.263453106
16       SKDDEPSTA      SKDARRSTA -0.263453106
41      TRNRANKGRP         SKDEQP  0.262837233
153         SKDEQP     TRNRANKGRP  0.262837233
114      ARRBUCKET DOWNLINEATCIMP  0.255480148
128 DOWNLINEATCIMP      ARRBUCKET  0.255480148
163       DEPSPOKE     TRNRANKGRP  0.242138220
191     TRNRANKGRP       DEPSPOKE  0.242138220
40      DEPRANKGRP         SKDEQP  0.239915140
138         SKDEQP     DEPRANKGRP  0.239915140
90    xAVGSKDAVAIL   UPLINEATCIMP  0.234867014
216   UPLINEATCIMP   xAVGSKDAVAIL  0.234867014
119         xDURN2 DOWNLINEATCIMP -0.226093423
203 DOWNLINEATCIMP         xDURN2 -0.226093423
116     TRNRANKGRP DOWNLINEATCIMP -0.224193213
158 DOWNLINEATCIMP     TRNRANKGRP -0.224193213
21    UPLINEATCIMP      SKDARRSTA  0.223824406
77       SKDARRSTA   UPLINEATCIMP  0.223824406
195   xAVGSKDAVAIL       DEPSPOKE -0.212821518
223       DEPSPOKE   xAVGSKDAVAIL -0.212821518
34          SKDEPS         SKDEQP  0.212586898
48          SKDEQP         SKDEPS  0.212586898
148       DEPSPOKE     DEPRANKGRP  0.208188512
190     DEPRANKGRP       DEPSPOKE  0.208188512
115     DEPRANKGRP DOWNLINEATCIMP -0.199411990
143 DOWNLINEATCIMP     DEPRANKGRP -0.199411990
133       DEPSPOKE      ARRBUCKET -0.189934966
189      ARRBUCKET       DEPSPOKE -0.189934966
149         xDURN2     DEPRANKGRP  0.180043357
205     DEPRANKGRP         xDURN2  0.180043357
89          xDURN2   UPLINEATCIMP -0.173240320
201   UPLINEATCIMP         xDURN2 -0.173240320
135   xAVGSKDAVAIL      ARRBUCKET -0.170644257
219      ARRBUCKET   xAVGSKDAVAIL -0.170644257
25      DEPRANKGRP      SKDARRSTA -0.167375913
137      SKDARRSTA     DEPRANKGRP -0.167375913
6     UPLINEATCIMP      SKDDEPSTA -0.164964952
76       SKDDEPSTA   UPLINEATCIMP -0.164964952
101     TRNRANKGRP   DEPSTAATCIMP -0.147409309
157   DEPSTAATCIMP     TRNRANKGRP -0.147409309
105   xAVGSKDAVAIL   DEPSTAATCIMP -0.141077194
217   DEPSTAATCIMP   xAVGSKDAVAIL -0.141077194
71      TRNRANKGRP      AVGLOFATC  0.139184315
155      AVGLOFATC     TRNRANKGRP  0.139184315
147     ARRRANKGRP     DEPRANKGRP  0.136562948
175     DEPRANKGRP     ARRRANKGRP  0.136562948
67    DEPSTAATCIMP      AVGLOFATC -0.135778614
95       AVGLOFATC   DEPSTAATCIMP -0.135778614
74          xDURN2      AVGLOFATC -0.132084629
200      AVGLOFATC         xDURN2 -0.132084629
150   xAVGSKDAVAIL     DEPRANKGRP  0.130574789
220     DEPRANKGRP   xAVGSKDAVAIL  0.130574789
132     ARRRANKGRP      ARRBUCKET -0.129698517
174      ARRBUCKET     ARRRANKGRP -0.129698517
99       ARRBUCKET   DEPSTAATCIMP -0.127726148
127   DEPSTAATCIMP      ARRBUCKET -0.127726148
14          xDURN2      SKDDEPSTA  0.127598189
196      SKDDEPSTA         xDURN2  0.127598189
68  DOWNLINEATCIMP      AVGLOFATC -0.126763572
110      AVGLOFATC DOWNLINEATCIMP -0.126763572
134         xDURN2      ARRBUCKET -0.125836459
204      ARRBUCKET         xDURN2 -0.125836459
100     DEPRANKGRP   DEPSTAATCIMP  0.124672682
142   DEPSTAATCIMP     DEPRANKGRP  0.124672682
52    DEPSTAATCIMP         SKDEPS -0.123445793
94          SKDEPS   DEPSTAATCIMP -0.123445793
9        ARRBUCKET      SKDDEPSTA -0.120728212
121      SKDDEPSTA      ARRBUCKET -0.120728212
179         xDURN2     ARRRANKGRP  0.119675180
207     ARRRANKGRP         xDURN2  0.119675180
26      TRNRANKGRP      SKDARRSTA -0.105802023
152      SKDARRSTA     TRNRANKGRP -0.105802023
130     DEPRANKGRP      ARRBUCKET -0.105057984
144      ARRBUCKET     DEPRANKGRP -0.105057984
120   xAVGSKDAVAIL DOWNLINEATCIMP  0.102577364
218 DOWNLINEATCIMP   xAVGSKDAVAIL  0.102577364
85      DEPRANKGRP   UPLINEATCIMP -0.097218129
141   UPLINEATCIMP     DEPRANKGRP -0.097218129
86      TRNRANKGRP   UPLINEATCIMP -0.097037814
156   UPLINEATCIMP     TRNRANKGRP -0.097037814
19          SKDEPS      SKDARRSTA -0.096699169
47       SKDARRSTA         SKDEPS -0.096699169
53  DOWNLINEATCIMP         SKDEPS -0.095568613
109         SKDEPS DOWNLINEATCIMP -0.095568613
20       AVGLOFATC      SKDARRSTA -0.095234466
62       SKDARRSTA      AVGLOFATC -0.095234466
18          SKDEQP      SKDARRSTA  0.094073459
32       SKDARRSTA         SKDEQP  0.094073459
24       ARRBUCKET      SKDARRSTA  0.092625400
122      SKDARRSTA      ARRBUCKET  0.092625400
131     TRNRANKGRP      ARRBUCKET -0.092415252
159      ARRBUCKET     TRNRANKGRP -0.092415252
165   xAVGSKDAVAIL     TRNRANKGRP  0.092011501
221     TRNRANKGRP   xAVGSKDAVAIL  0.092011501
15    xAVGSKDAVAIL      SKDDEPSTA  0.088580325
211      SKDDEPSTA   xAVGSKDAVAIL  0.088580325
44          xDURN2         SKDEQP  0.086170070
198         SKDEQP         xDURN2  0.086170070
70      DEPRANKGRP      AVGLOFATC  0.085474019
140      AVGLOFATC     DEPRANKGRP  0.085474019
66    UPLINEATCIMP      AVGLOFATC -0.085180887
80       AVGLOFATC   UPLINEATCIMP -0.085180887
162     ARRRANKGRP     TRNRANKGRP  0.083906762
176     TRNRANKGRP     ARRRANKGRP  0.083906762
178       DEPSPOKE     ARRRANKGRP  0.083162083
192     ARRRANKGRP       DEPSPOKE  0.083162083
57      ARRRANKGRP         SKDEPS  0.080398834
169         SKDEPS     ARRRANKGRP  0.080398834
60    xAVGSKDAVAIL         SKDEPS  0.075169577
214         SKDEPS   xAVGSKDAVAIL  0.075169577
102     ARRRANKGRP   DEPSTAATCIMP  0.073371196
172   DEPSTAATCIMP     ARRRANKGRP  0.073371196
84       ARRBUCKET   UPLINEATCIMP  0.071409699
126   UPLINEATCIMP      ARRBUCKET  0.071409699
87      ARRRANKGRP   UPLINEATCIMP -0.069790367
171   UPLINEATCIMP     ARRRANKGRP -0.069790367
12      ARRRANKGRP      SKDDEPSTA  0.068927801
166      SKDDEPSTA     ARRRANKGRP  0.068927801
72      ARRRANKGRP      AVGLOFATC -0.061491190
170      AVGLOFATC     ARRRANKGRP -0.061491190
75    xAVGSKDAVAIL      AVGLOFATC -0.056264979
215      AVGLOFATC   xAVGSKDAVAIL -0.056264979
5        AVGLOFATC      SKDDEPSTA -0.044946507
61       SKDDEPSTA      AVGLOFATC -0.044946507
69       ARRBUCKET      AVGLOFATC -0.043093769
125      AVGLOFATC      ARRBUCKET -0.043093769
42      ARRRANKGRP         SKDEQP -0.042512956
168         SKDEQP     ARRRANKGRP -0.042512956
45    xAVGSKDAVAIL         SKDEQP  0.031863410
213         SKDEQP   xAVGSKDAVAIL  0.031863410
56      TRNRANKGRP         SKDEPS  0.030883560
154         SKDEPS     TRNRANKGRP  0.030883560
29          xDURN2      SKDARRSTA  0.027576751
197      SKDARRSTA         xDURN2  0.027576751
30    xAVGSKDAVAIL      SKDARRSTA  0.027225219
212      SKDARRSTA   xAVGSKDAVAIL  0.027225219
55      DEPRANKGRP         SKDEPS  0.027025501
139         SKDEPS     DEPRANKGRP  0.027025501
4           SKDEPS      SKDDEPSTA -0.024267794
46       SKDDEPSTA         SKDEPS -0.024267794
36    UPLINEATCIMP         SKDEQP -0.019807499
78          SKDEQP   UPLINEATCIMP -0.019807499
43        DEPSPOKE         SKDEQP  0.019755644
183         SKDEQP       DEPSPOKE  0.019755644
210   xAVGSKDAVAIL         xDURN2 -0.019255572
224         xDURN2   xAVGSKDAVAIL -0.019255572
180   xAVGSKDAVAIL     ARRRANKGRP -0.018743432
222     ARRRANKGRP   xAVGSKDAVAIL -0.018743432
104         xDURN2   DEPSTAATCIMP -0.017999758
202   DEPSTAATCIMP         xDURN2 -0.017999758
38  DOWNLINEATCIMP         SKDEQP -0.017658860
108         SKDEQP DOWNLINEATCIMP -0.017658860
54       ARRBUCKET         SKDEPS  0.017414895
124         SKDEPS      ARRBUCKET  0.017414895
27      ARRRANKGRP      SKDARRSTA  0.016733374
167      SKDARRSTA     ARRRANKGRP  0.016733374
39       ARRBUCKET         SKDEQP  0.009926479
123         SKDEQP      ARRBUCKET  0.009926479
73        DEPSPOKE      AVGLOFATC -0.008540402
185      AVGLOFATC       DEPSPOKE -0.008540402
50       AVGLOFATC         SKDEPS  0.008240563
64          SKDEPS      AVGLOFATC  0.008240563
37    DEPSTAATCIMP         SKDEQP -0.005922601
93          SKDEQP   DEPSTAATCIMP -0.005922601
35       AVGLOFATC         SKDEQP -0.004889040
63          SKDEQP      AVGLOFATC -0.004889040
58        DEPSPOKE         SKDEPS -0.004617067
184         SKDEPS       DEPSPOKE -0.004617067
51    UPLINEATCIMP         SKDEPS  0.004016263
79          SKDEPS   UPLINEATCIMP  0.004016263
59          xDURN2         SKDEPS  0.001748012
199         SKDEPS         xDURN2  0.001748012
> 
> ### Models
> 
> ## Try GBM (gradient boosting). Works well for mixed data.
> ## And there is a tutorial for it with caret.
> 
> ## Training controller and big grid
> ## Check the ROC (my preferred.)
> 
> fitControl <- trainControl(## 10-fold CV
+     method = "repeatedcv",
+     number = 10,
+     ## repeated ten times
+     repeats = 10,
+     classProbs = 10,
+     summaryFunction = twoClassSummary)
> 
> ## Some trial and error with variables to branch and boost.
> ## I'm just going to try the airports and the planes and the duration
> ## of the flight. There may be some distance relationship there that
> ## air traffic control use.
> 
> ## Annoying because I drop variables, this needs to be looked up.
> 
> tr.cols <- colnames(trainDescr)
> tr.cols
 [1] "SKDDEPSTA"      "SKDARRSTA"      "SKDEQP"         "SKDEPS"        
 [5] "AVGLOFATC"      "UPLINEATCIMP"   "DEPSTAATCIMP"   "DOWNLINEATCIMP"
 [9] "ARRBUCKET"      "DEPRANKGRP"     "TRNRANKGRP"     "ARRRANKGRP"    
[13] "DEPSPOKE"       "xDURN2"         "xAVGSKDAVAIL"  
> tr.icols <- grep("((STA|EQP)$)|(^xD)", tr.cols)
> tr.icols <- rev(tr.icols)
> 
> gbmGrid <- expand.grid(interaction.depth = tr.icols,
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.1,
+                         n.minobsinnode = 20)
> 
> set.seed(seed.mine)
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "ROC",
+                  verbose = FALSE)
> gbmFit1
Stochastic Gradient Boosting 

248 samples
 15 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 222, 223, 223, 224, 223, 223, ... 

Resampling results across tuning parameters:

  interaction.depth  n.trees  ROC        Sens       Spec       ROC SD    
   1                   90     0.7608134  0.7308242  0.6666667  0.08528903
   1                  180     0.7581040  0.7191209  0.6685606  0.08888061
   1                  270     0.7483383  0.7135165  0.6579545  0.10227168
   1                  360     0.7454741  0.7140659  0.6531061  0.09316827
   1                  450     0.7398427  0.7053846  0.6456818  0.09430292
   1                  540     0.7366896  0.7060440  0.6435606  0.09590752
   1                  630     0.7290310  0.7011538  0.6354545  0.09486196
   1                  720     0.7217466  0.6987912  0.6293182  0.10658674
   1                  810     0.7130007  0.6938462  0.6138636  0.10905376
   1                  900     0.7170055  0.6866484  0.6220455  0.10466077
   1                  990     0.7154970  0.6930220  0.6187121  0.10216373
   1                 1080     0.7122082  0.6812637  0.6106818  0.09996696
   1                 1170     0.7084840  0.6827473  0.6087879  0.10099357
   1                 1260     0.7037209  0.6769780  0.6178030  0.10059819
   1                 1350     0.7006631  0.6792308  0.6122727  0.10326174
   1                 1440     0.6997040  0.6854396  0.6079545  0.10738311
   1                 1530     0.6943352  0.6789560  0.6061364  0.11176525
   1                 1620     0.6886039  0.6782967  0.6034091  0.11772213
   1                 1710     0.6860614  0.6701099  0.5888636  0.11683333
   1                 1800     0.6853222  0.6722527  0.5897727  0.11367978
   1                 1890     0.6834653  0.6742308  0.5843939  0.11610953
   1                 1980     0.6812845  0.6714835  0.5896212  0.11131853
   1                 2070     0.6776990  0.6665934  0.5787121  0.11226081
   1                 2160     0.6793182  0.6612088  0.5868182  0.11092022
   1                 2250     0.6747253  0.6612088  0.5832576  0.11325426
   1                 2340     0.6748389  0.6590110  0.5821970  0.10827850
   1                 2430     0.6714827  0.6618681  0.5830303  0.11405812
   1                 2520     0.6693094  0.6612088  0.5771970  0.11175708
   1                 2610     0.6655723  0.6590659  0.5741667  0.11101618
   1                 2700     0.6646337  0.6589011  0.5688636  0.11181382
   2                   90     0.7494468  0.7379670  0.6518939  0.08808438
   2                  180     0.7344052  0.7123077  0.6472727  0.09819883
   2                  270     0.7254063  0.6986813  0.6363636  0.09747992
   2                  360     0.7208654  0.6943407  0.6231061  0.09743117
   2                  450     0.7133920  0.6876374  0.6231061  0.10407302
   2                  540     0.7127239  0.6848352  0.6256061  0.09771233
   2                  630     0.7086118  0.6900549  0.6203030  0.09779151
   2                  720     0.7054829  0.6826923  0.6203788  0.09397555
   2                  810     0.7047698  0.6847802  0.6237879  0.09858316
   2                  900     0.7023847  0.6847253  0.6156818  0.09622652
   2                  990     0.7018964  0.6876374  0.6131061  0.09611483
   2                 1080     0.7015222  0.6898352  0.6067424  0.09319562
   2                 1170     0.7007480  0.6832967  0.6130303  0.09411457
   2                 1260     0.6990460  0.6855495  0.6121212  0.09767265
   2                 1350     0.6965501  0.6818681  0.6140152  0.09763171
   2                 1440     0.6966059  0.6897802  0.6203030  0.09618589
   2                 1530     0.6965514  0.6897802  0.6140152  0.09705541
   2                 1620     0.6950154  0.6898352  0.6105303  0.09940930
   2                 1710     0.6941138  0.6907143  0.6131061  0.09647763
   2                 1800     0.6980578  0.6855495  0.6150000  0.09418892
   2                 1890     0.6962383  0.6863187  0.6112879  0.09200617
   2                 1980     0.6950741  0.6870330  0.6140152  0.09510145
   2                 2070     0.6939240  0.6876923  0.6140909  0.09407163
   2                 2160     0.6934873  0.6912637  0.6131061  0.09220100
   2                 2250     0.6924113  0.6890110  0.6122727  0.09151881
   2                 2340     0.6939577  0.6853846  0.6131818  0.09082191
   2                 2430     0.6928859  0.6831319  0.6059091  0.09308260
   2                 2520     0.6918856  0.6853846  0.6113636  0.09503211
   2                 2610     0.6910868  0.6831319  0.6086364  0.09488208
   2                 2700     0.6923164  0.6852747  0.6077273  0.09471774
   3                   90     0.7391321  0.7447802  0.6373485  0.10238084
   3                  180     0.7217287  0.7152747  0.6356818  0.10691962
   3                  270     0.7196416  0.6963736  0.6345455  0.10344959
   3                  360     0.7150516  0.6885714  0.6300000  0.10542557
   3                  450     0.7102876  0.6861538  0.6317424  0.10439041
   3                  540     0.7092116  0.6854396  0.6362121  0.10350879
   3                  630     0.7077152  0.6787912  0.6326515  0.10155532
   3                  720     0.7053971  0.6826374  0.6289394  0.10364986
   3                  810     0.7057592  0.6890110  0.6297727  0.10316869
   3                  900     0.7047107  0.6917582  0.6290152  0.10313758
   3                  990     0.7041163  0.6924725  0.6315909  0.10166629
   3                 1080     0.7050591  0.6926374  0.6307576  0.10111118
   3                 1170     0.7018694  0.6896154  0.6317424  0.10314280
   3                 1260     0.7029978  0.6903297  0.6272727  0.10322144
   3                 1350     0.7034241  0.6859341  0.6272727  0.09665546
   3                 1440     0.7018998  0.6905495  0.6227273  0.09891477
   3                 1530     0.7034657  0.6837912  0.6183333  0.09810286
   3                 1620     0.7025907  0.6874725  0.6191667  0.09867977
   3                 1710     0.7019701  0.6859890  0.6219697  0.09941961
   3                 1800     0.7010069  0.6844505  0.6219697  0.09696057
   3                 1890     0.6995983  0.6852747  0.6227273  0.09896983
   3                 1980     0.6989744  0.6864835  0.6254545  0.09845968
   3                 2070     0.6987225  0.6851648  0.6218182  0.09864225
   3                 2160     0.6976761  0.6852198  0.6218939  0.09797165
   3                 2250     0.6975175  0.6829670  0.6228030  0.09848312
   3                 2340     0.6979978  0.6859890  0.6209848  0.09833757
   3                 2430     0.6968806  0.6817033  0.6228788  0.09881093
   3                 2520     0.6971200  0.6874725  0.6219697  0.09793849
   3                 2610     0.6957942  0.6846703  0.6192424  0.09797821
   3                 2700     0.6963133  0.6890110  0.6191667  0.09765921
  14                   90     0.7368082  0.7308242  0.6336364  0.09345563
  14                  180     0.7216638  0.7044505  0.6217424  0.09978583
  14                  270     0.7149592  0.6900000  0.6157576  0.09403213
  14                  360     0.7124471  0.6878571  0.6229545  0.09508995
  14                  450     0.7066687  0.6832418  0.6203788  0.09957688
  14                  540     0.7065639  0.6815385  0.6185606  0.09521788
  14                  630     0.7063466  0.6826374  0.6178030  0.09839703
  14                  720     0.7046162  0.6868132  0.6211364  0.09879999
  14                  810     0.7030744  0.6832418  0.6219697  0.09627842
  14                  900     0.7003838  0.6796154  0.6275000  0.09660724
  14                  990     0.7011921  0.6793407  0.6274242  0.09732209
  14                 1080     0.6976328  0.6778571  0.6247727  0.09815227
  14                 1170     0.7017895  0.6807692  0.6238636  0.09634126
  14                 1260     0.6990052  0.6837363  0.6274242  0.10152573
  14                 1350     0.7016296  0.6836264  0.6228788  0.09568840
  14                 1440     0.6997690  0.6822527  0.6277273  0.09863891
  14                 1530     0.6998501  0.6829121  0.6212879  0.09608737
  14                 1620     0.6992707  0.6821978  0.6238636  0.09665598
  14                 1710     0.6989136  0.6858791  0.6257576  0.09665061
  14                 1800     0.6985177  0.6858791  0.6231818  0.09365536
  14                 1890     0.6963004  0.6844505  0.6185606  0.09556282
  14                 1980     0.6980216  0.6837363  0.6248485  0.09399410
  14                 2070     0.6980166  0.6844505  0.6221212  0.09524385
  14                 2160     0.6965926  0.6859890  0.6237879  0.09478445
  14                 2250     0.6963645  0.6843956  0.6238636  0.09416672
  14                 2340     0.6963062  0.6865934  0.6292424  0.09377603
  14                 2430     0.6948393  0.6909890  0.6220455  0.09376852
  14                 2520     0.6955582  0.6882418  0.6193182  0.09529417
  14                 2610     0.6953700  0.6873626  0.6184848  0.09396634
  14                 2700     0.6963882  0.6865385  0.6202273  0.09465725
  Sens SD    Spec SD  
  0.1198620  0.1248776
  0.1226106  0.1197851
  0.1214630  0.1342876
  0.1301384  0.1340669
  0.1313556  0.1381748
  0.1260305  0.1451940
  0.1303771  0.1476248
  0.1311665  0.1391047
  0.1313655  0.1300598
  0.1310434  0.1382505
  0.1324856  0.1377765
  0.1234539  0.1463930
  0.1332384  0.1372895
  0.1312267  0.1369379
  0.1346050  0.1379334
  0.1337267  0.1414075
  0.1332147  0.1478689
  0.1336423  0.1488687
  0.1312676  0.1389613
  0.1418017  0.1371579
  0.1377922  0.1492640
  0.1405422  0.1406704
  0.1350146  0.1370079
  0.1415086  0.1390054
  0.1261024  0.1436854
  0.1359576  0.1452699
  0.1362211  0.1439693
  0.1349160  0.1430109
  0.1302144  0.1458630
  0.1312764  0.1413694
  0.1236469  0.1444013
  0.1288777  0.1322735
  0.1292468  0.1305205
  0.1254172  0.1358541
  0.1269271  0.1326457
  0.1294868  0.1291371
  0.1239558  0.1249114
  0.1259261  0.1219554
  0.1257305  0.1304904
  0.1205325  0.1351931
  0.1269103  0.1340797
  0.1234980  0.1303832
  0.1238190  0.1230711
  0.1287152  0.1306759
  0.1322987  0.1280877
  0.1326185  0.1314247
  0.1261996  0.1305666
  0.1279417  0.1287726
  0.1276026  0.1293393
  0.1297675  0.1242604
  0.1284406  0.1257183
  0.1265025  0.1312044
  0.1270624  0.1249974
  0.1227210  0.1227153
  0.1257798  0.1212618
  0.1218455  0.1224674
  0.1276116  0.1235802
  0.1304560  0.1241396
  0.1288814  0.1260017
  0.1269817  0.1212962
  0.1276028  0.1297438
  0.1341320  0.1415088
  0.1303180  0.1260564
  0.1308511  0.1312192
  0.1315423  0.1312332
  0.1222597  0.1361636
  0.1232807  0.1310723
  0.1185126  0.1247103
  0.1216486  0.1383417
  0.1248393  0.1281062
  0.1214114  0.1304434
  0.1174573  0.1243502
  0.1163033  0.1258022
  0.1170456  0.1277416
  0.1183107  0.1275054
  0.1192687  0.1277643
  0.1188602  0.1309187
  0.1193208  0.1266287
  0.1212956  0.1300956
  0.1182606  0.1338904
  0.1209978  0.1304539
  0.1188305  0.1322997
  0.1196098  0.1347758
  0.1186494  0.1304365
  0.1173344  0.1346278
  0.1222098  0.1328818
  0.1250461  0.1342971
  0.1200444  0.1333654
  0.1235141  0.1364470
  0.1256828  0.1354459
  0.1237869  0.1444701
  0.1254042  0.1312171
  0.1262087  0.1202329
  0.1227285  0.1260276
  0.1263323  0.1369909
  0.1207906  0.1247354
  0.1285593  0.1253520
  0.1238226  0.1306115
  0.1257274  0.1284679
  0.1295296  0.1276556
  0.1308549  0.1254768
  0.1300862  0.1317251
  0.1292534  0.1308903
  0.1312314  0.1319622
  0.1262014  0.1318884
  0.1302465  0.1347730
  0.1279153  0.1357863
  0.1254976  0.1333170
  0.1288127  0.1300711
  0.1267316  0.1326380
  0.1276169  0.1313854
  0.1264311  0.1295687
  0.1266767  0.1289713
  0.1249293  0.1261442
  0.1245845  0.1309921
  0.1273697  0.1304708
  0.1248750  0.1327048
  0.1231500  0.1314295
  0.1278467  0.1300110
  0.1241163  0.1293052

Tuning parameter 'shrinkage' was held constant at a value of 0.1

Tuning parameter 'n.minobsinnode' was held constant at a value of 20
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 90, interaction.depth =
 1, shrinkage = 0.1 and n.minobsinnode = 20. 
> 
> ## The acid test is dissapointing, but I've seen worse.
> 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
     Accuracy         Kappa 
 5.416667e-01 -2.422305e-16 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     35   28
    Weak        5    4
                                        
               Accuracy : 0.5417        
                 95% CI : (0.42, 0.6598)
    No Information Rate : 0.5556        
    P-Value [Acc > NIR] : 0.6402955     
                                        
                  Kappa : 0             
 Mcnemar's Test P-Value : 0.0001283     
                                        
            Sensitivity : 0.12500       
            Specificity : 0.87500       
         Pos Pred Value : 0.44444       
         Neg Pred Value : 0.55556       
             Prevalence : 0.44444       
         Detection Rate : 0.05556       
   Detection Prevalence : 0.12500       
      Balanced Accuracy : 0.50000       
                                        
       'Positive' Class : Weak          
                                        
> 
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
 Accuracy     Kappa 
0.7943548 0.5844941 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    111   25
    Weak       26   86
                                          
               Accuracy : 0.7944          
                 95% CI : (0.7386, 0.8429)
    No Information Rate : 0.5524          
    P-Value [Acc > NIR] : 1.288e-15       
                                          
                  Kappa : 0.5845          
 Mcnemar's Test P-Value : 1               
                                          
            Sensitivity : 0.7748          
            Specificity : 0.8102          
         Pos Pred Value : 0.7679          
         Neg Pred Value : 0.8162          
             Prevalence : 0.4476          
         Detection Rate : 0.3468          
   Detection Prevalence : 0.4516          
      Balanced Accuracy : 0.7925          
                                          
       'Positive' Class : Weak            
                                          
> ### weaves
> 
> ## Processing for flights data.
> 
> ## Following the caret vignette.
> 
> ###################################################
> ### code chunk number 1: loadLibs
> ###################################################
> library(MASS)
> library(caret)
> library(mlbench)
> library(pROC)
> library(pls)
> 
> library(doMC)
> registerDoMC(cores = 4)
> 
> options(useFancyQuotes = FALSE) 
> 
> # Accounting info.
> getInfo <- function(what = "Suggests")
+ {
+   text <- packageDescription("caret")[what][[1]]
+   text <- gsub("\n", ", ", text, fixed = TRUE)
+   text <- gsub(">=", "$\\\\ge$", text, fixed = TRUE)
+   eachPkg <- strsplit(text, ", ", fixed = TRUE)[[1]]
+   eachPkg <- gsub(",", "", eachPkg, fixed = TRUE)
+   # out <- paste("\\\\pkg{", eachPkg[order(tolower(eachPkg))], "}", sep = "")
+   # paste(out, collapse = ", ")
+   length(eachPkg)
+ }
> 
> ### project-specific: begin
> ## Set-seed, load original CSV file, order it
> ## and do some simple-cleaning
> ## Various datasets 
> 
> seed.mine = 107
> set.seed(seed.mine)                     # helpful for testing
> 
> flight <- read.csv("../bak/flight.csv")
> flight <- flight[order(flight$D00),]
> 
> # Backup
> flight.raw <- flight
> 
> # To check adjustment, there is test code in flight-nb.R
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"
> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"
> 
> # And some deletions
> 
> t.cols <- colnames(flight)
> 
> t.drops <- t.cols[grep("^RANK*", t.cols)]
> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])
> t.drops <- c(t.drops, "D80THPCTL")
> 
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR
> flight$xHNGR <- flight$xDURN < 0
> 
> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+ }
> 
> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))
> 
> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE
> t.cols <- colnames(flight)
> 
> t.drops <- c("SARRHR", "xDURN")
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Backup
> 
> flight00 <- flight
> 
> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]
> 
> paste("samples in use: ", dim(flight)[1])
[1] "samples in use:  320"
> 
> ## Data insights
> 
> ## *Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> flight <- flight1
> 
> ### Numeric variables
> 
> ### Try and impute the AVG, it might have more information than the
> ### bucket.
> 
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))
Error in `$<-.data.frame`(`*tmp*`, "xAVAILBUCKET", value = numeric(0)) : 
  replacement has 0 rows, data has 320
> 
> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1
> 
> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]
Error in `[.data.frame`(flight, , c("AVGSKDAVAIL", "xAVAILBUCKET")) : 
  undefined columns selected
> 
> preProcValues <- preProcess(flight.na, method = c("knnImpute"))
> flight.na1 <- predict(preProcValues, flight.na)
> 
> ## I'll add the new imputed value and drop the others
> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL
> flight$AVGSKDAVAIL <- NULL
> flight$xAVAILBUCKET <- NULL
> flight$AVAILBUCKET <- NULL
> 
> flight$xHNGR <- NULL
> 
> ## Check some more numeric correlations, I haven't scaled everything yet.
> ## I'd cut correlations above 0.65 to 0.75 because of overfitting.
> 
> x1 <- as.data.frame(as.matrix(sapply(flight, class)))
> 
> flight.num <- flight[,names(x1[which(x1$V1 %in% c("numeric", "integer")),])]
> 
> flight.nzv <- nearZeroVar(flight.num, saveMetrics = TRUE)
> flight.nzv
             freqRatio percentUnique zeroVar   nzv
SDEPHR        1.038462        5.9375   FALSE FALSE
SKDEPS        1.000000       19.0625   FALSE FALSE
D00           1.166667       75.3125   FALSE FALSE
AVGSQ         6.333333       82.8125   FALSE FALSE
AVGLOFATC     1.000000       78.4375   FALSE FALSE
xDURN2        1.428571        2.5000   FALSE FALSE
xAVGSKDAVAIL 18.500000       87.8125   FALSE FALSE
> 
> # annoying NA should be gone.
> flight.cor <- cor(flight.num, use = "pairwise.complete.obs")
> 
> descrCorr <- findCorrelation(flight.cor, cutoff = .65, verbose=TRUE)
Considering row	 4 column	 1 value	 0.956 
  Flagging column	 4 
Considering row	 1 column	 3 value	 0.43 
Considering row	 1 column	 7 value	 0.053 
Considering row	 1 column	 6 value	 0.204 
Considering row	 1 column	 5 value	 0.131 
Considering row	 1 column	 2 value	 0.054 
Considering row	 3 column	 7 value	 0.401 
Considering row	 3 column	 6 value	 0.071 
Considering row	 3 column	 5 value	 0.114 
Considering row	 3 column	 2 value	 0.006 
Considering row	 7 column	 6 value	 0.019 
Considering row	 7 column	 5 value	 0.07 
Considering row	 7 column	 2 value	 0.113 
Considering row	 6 column	 5 value	 0.137 
Considering row	 6 column	 2 value	 0.005 
Considering row	 5 column	 2 value	 0.041 
> 
> colnames(flight.num)[descrCorr]
[1] "AVGSQ"
> 
> ## And I'll leave the centered and scale values in for now.
> ## and delete the troublesome ones
> 
> ## Re-classing
> ## Check warnings to see it adjustment has taken place.
> ## We want the proportion in the training class to be about 0.55 0.45
> ## Strong to Weak
> ## I've achieved this heuristically
> src.adjust <- TRUE
> source(file = "flight1.R")
Warning message:
In eval(expr, envir, enclos) : adjusting
> flight1 <- flight
> 
> ## This should be deleted, leave it in and the results
> ## are ideal because it defines LEGTYPE.
> flight$D00 <- NULL
> 
> ## Keep the results but don't change the order.
> outcomes.flight <- flight$LEGTYPE
> 
> flight$LEGTYPE <- NULL
> 
> ## If you know your factors are definitely factors, you don't need this
> ##  asNumeric <- function(x) as.numeric(as.character(x))
> 
> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))
> 
> flight.num0 <- factors.numeric(flight)
> 
> flight.scl0 <- scale(flight.num0)
> 
> ## Now split the samples
> ## we need at least 60 to test with, p at 0.77 gives about 75.
> ## Difficulty here is the bias in the table
> ## Because we only have [3.1, 4.4] the proportion of Weak is higher.
> ## see prop.table(results)
> 
> set.seed(seed.mine)
> inTrain <- createDataPartition(outcomes.flight, p = 0.77, list = FALSE)
> 
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> 
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> 
> prop.table(table(trainClass))
trainClass
   Strong      Weak 
0.5524194 0.4475806 
> dim(trainDescr)
[1] 248  19
> 
> prop.table(table(testClass))
testClass
   Strong      Weak 
0.5555556 0.4444444 
> dim(testDescr)
[1] 72 19
> 
> ## Check Near-zero variance
> 
> nzv <- nearZeroVar(trainDescr, saveMetrics= TRUE)
> stopifnot( all(nzv$nzv == FALSE) )
> 
> # It's imputed and behaves well, no need for this.
> # descrCorr <- cor(scale(trainDescr), use = "pairwise.complete.obs")
> 
> descrCorr <- cor(scale(trainDescr))
> 
> ## This cut-off should be under src.adjust control.
> ## I'm under Git, so I can tinker with it.
> highCorr <- findCorrelation(descrCorr, cutoff = .80, verbose = TRUE)
Considering row	 17 column	 16 value	 0.85 
  Flagging column	 17 
Considering row	 16 column	 10 value	 0.568 
Considering row	 16 column	 1 value	 0.236 
Considering row	 16 column	 11 value	 0.231 
Considering row	 16 column	 6 value	 0.189 
Considering row	 16 column	 12 value	 0.19 
Considering row	 16 column	 2 value	 0.333 
Considering row	 16 column	 9 value	 0.671 
Considering row	 16 column	 14 value	 0.242 
Considering row	 16 column	 13 value	 0.208 
Considering row	 16 column	 8 value	 0.6 
Considering row	 16 column	 3 value	 0.318 
Considering row	 16 column	 18 value	 0.279 
Considering row	 16 column	 19 value	 0.213 
Considering row	 16 column	 15 value	 0.083 
Considering row	 16 column	 4 value	 0.02 
Considering row	 16 column	 7 value	 0.009 
Considering row	 16 column	 5 value	 0.005 
Considering row	 10 column	 1 value	 0.281 
Considering row	 10 column	 11 value	 0.275 
Considering row	 10 column	 6 value	 0.298 
Considering row	 10 column	 12 value	 0.255 
Considering row	 10 column	 2 value	 0.286 
Considering row	 10 column	 9 value	 0.404 
Considering row	 10 column	 14 value	 0.224 
Considering row	 10 column	 13 value	 0.199 
Considering row	 10 column	 8 value	 0.366 
Considering row	 10 column	 3 value	 0.462 
Considering row	 10 column	 18 value	 0.226 
Considering row	 10 column	 19 value	 0.103 
Considering row	 10 column	 15 value	 0.274 
Considering row	 10 column	 4 value	 0.018 
Considering row	 10 column	 7 value	 0.127 
Considering row	 10 column	 5 value	 0.096 
Considering row	 1 column	 11 value	 0.988 
  Flagging column	 1 
Considering row	 11 column	 6 value	 0.945 
  Flagging column	 11 
Considering row	 6 column	 12 value	 0.883 
  Flagging column	 6 
Considering row	 12 column	 2 value	 0.121 
Considering row	 12 column	 9 value	 0.128 
Considering row	 12 column	 14 value	 0.092 
Considering row	 12 column	 13 value	 0.105 
Considering row	 12 column	 8 value	 0.071 
Considering row	 12 column	 3 value	 0.093 
Considering row	 12 column	 18 value	 0.126 
Considering row	 12 column	 19 value	 0.171 
Considering row	 12 column	 15 value	 0.13 
Considering row	 12 column	 4 value	 0.01 
Considering row	 12 column	 7 value	 0.043 
Considering row	 12 column	 5 value	 0.017 
Considering row	 2 column	 9 value	 0.423 
Considering row	 2 column	 14 value	 0.574 
Considering row	 2 column	 13 value	 0.557 
Considering row	 2 column	 8 value	 0.165 
Considering row	 2 column	 3 value	 0.263 
Considering row	 2 column	 18 value	 0.128 
Considering row	 2 column	 19 value	 0.089 
Considering row	 2 column	 15 value	 0.069 
Considering row	 2 column	 4 value	 0.27 
Considering row	 2 column	 7 value	 0.045 
Considering row	 2 column	 5 value	 0.024 
Considering row	 9 column	 14 value	 0.147 
Considering row	 9 column	 13 value	 0.125 
Considering row	 9 column	 8 value	 0.449 
Considering row	 9 column	 3 value	 0.322 
Considering row	 9 column	 18 value	 0.018 
Considering row	 9 column	 19 value	 0.141 
Considering row	 9 column	 15 value	 0.073 
Considering row	 9 column	 4 value	 0.006 
Considering row	 9 column	 7 value	 0.136 
Considering row	 9 column	 5 value	 0.123 
Considering row	 14 column	 13 value	 0.659 
Considering row	 14 column	 8 value	 0.097 
Considering row	 14 column	 3 value	 0.106 
Considering row	 14 column	 18 value	 0.361 
Considering row	 14 column	 19 value	 0.092 
Considering row	 14 column	 15 value	 0.084 
Considering row	 14 column	 4 value	 0.263 
Considering row	 14 column	 7 value	 0.139 
Considering row	 14 column	 5 value	 0.031 
Considering row	 13 column	 8 value	 0.097 
Considering row	 13 column	 3 value	 0.167 
Considering row	 13 column	 18 value	 0.18 
Considering row	 13 column	 19 value	 0.131 
Considering row	 13 column	 15 value	 0.137 
Considering row	 13 column	 4 value	 0.24 
Considering row	 13 column	 7 value	 0.085 
Considering row	 13 column	 5 value	 0.027 
Considering row	 8 column	 3 value	 0.224 
Considering row	 8 column	 18 value	 0.173 
Considering row	 8 column	 19 value	 0.235 
Considering row	 8 column	 15 value	 0.07 
Considering row	 8 column	 4 value	 0.02 
Considering row	 8 column	 7 value	 0.085 
Considering row	 8 column	 5 value	 0.004 
Considering row	 3 column	 18 value	 0.028 
Considering row	 3 column	 19 value	 0.027 
Considering row	 3 column	 15 value	 0.017 
Considering row	 3 column	 4 value	 0.094 
Considering row	 3 column	 7 value	 0.095 
Considering row	 3 column	 5 value	 0.097 
Considering row	 18 column	 19 value	 0.019 
Considering row	 18 column	 15 value	 0.12 
Considering row	 18 column	 4 value	 0.086 
Considering row	 18 column	 7 value	 0.132 
Considering row	 18 column	 5 value	 0.002 
Considering row	 19 column	 15 value	 0.019 
Considering row	 19 column	 4 value	 0.032 
Considering row	 19 column	 7 value	 0.056 
Considering row	 19 column	 5 value	 0.075 
Considering row	 15 column	 4 value	 0.043 
Considering row	 15 column	 7 value	 0.061 
Considering row	 15 column	 5 value	 0.08 
Considering row	 4 column	 7 value	 0.005 
Considering row	 4 column	 5 value	 0.213 
Considering row	 7 column	 5 value	 0.008 
> 
> colnames(trainDescr)[highCorr]
[1] "ARRSPOKE"  "SDEPHR"    "DEPBUCKET" "AVGSQ"    
> 
> descr.ncol0 <- ncol(trainDescr)
> 
> # I've switched off the correlation remover and the results are better.
> if (sum(highCorr) > 0) {
+     warning("overfitting: correlations: err.trainDescr: ", paste(colnames(trainDescr)[highCorr], collapse = ", ") )
+     err.trainDescr <- trainDescr
+     trainDescr <- trainDescr[,-highCorr]
+ }
Warning message:
overfitting: correlations: err.trainDescr: ARRSPOKE, SDEPHR, DEPBUCKET, AVGSQ 
> 
> descr.ncol1 <- ncol(trainDescr)
> 
> paste("Dropped: ", as.character(descr.ncol0 - descr.ncol1))
[1] "Dropped:  4"
> 
> descrCorr <- cor(trainDescr)
> summary(descrCorr[upper.tri(descrCorr)])
     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
-0.600000 -0.123400 -0.004617  0.012770  0.102600  0.671300 
> 
> ## Dominant correlations
> ## At 0.9, there are some big ones that might need re-thinking.
> 
> table.descrCorr <- as.data.frame(as.table(descrCorr))
> table.descrCorr <- table.descrCorr[which(table.descrCorr$Var1 != table.descrCorr$Var2),]
> table.descrCorr[order(abs(table.descrCorr$Freq), decreasing = TRUE),]
              Var1           Var2         Freq
103       DEPSPOKE   DEPSTAATCIMP  0.671264566
187   DEPSTAATCIMP       DEPSPOKE  0.671264566
146     TRNRANKGRP     DEPRANKGRP  0.658724662
160     DEPRANKGRP     TRNRANKGRP  0.658724662
88        DEPSPOKE   UPLINEATCIMP -0.600008252
186   UPLINEATCIMP       DEPSPOKE -0.600008252
11      TRNRANKGRP      SKDDEPSTA  0.574035134
151      SKDDEPSTA     TRNRANKGRP  0.574035134
118       DEPSPOKE DOWNLINEATCIMP -0.567682494
188 DOWNLINEATCIMP       DEPSPOKE -0.567682494
10      DEPRANKGRP      SKDDEPSTA  0.557399203
136      SKDDEPSTA     DEPRANKGRP  0.557399203
23  DOWNLINEATCIMP      SKDARRSTA  0.462378131
107      SKDARRSTA DOWNLINEATCIMP  0.462378131
82    DEPSTAATCIMP   UPLINEATCIMP -0.449249986
96    UPLINEATCIMP   DEPSTAATCIMP -0.449249986
7     DEPSTAATCIMP      SKDDEPSTA  0.423425796
91       SKDDEPSTA   DEPSTAATCIMP  0.423425796
98  DOWNLINEATCIMP   DEPSTAATCIMP -0.403695561
112   DEPSTAATCIMP DOWNLINEATCIMP -0.403695561
83  DOWNLINEATCIMP   UPLINEATCIMP  0.365833687
111   UPLINEATCIMP DOWNLINEATCIMP  0.365833687
164         xDURN2     TRNRANKGRP  0.361347207
206     TRNRANKGRP         xDURN2  0.361347207
13        DEPSPOKE      SKDDEPSTA  0.332823310
181      SKDDEPSTA       DEPSPOKE  0.332823310
22    DEPSTAATCIMP      SKDARRSTA -0.322204878
92       SKDARRSTA   DEPSTAATCIMP -0.322204878
28        DEPSPOKE      SKDARRSTA -0.318093195
182      SKDARRSTA       DEPSPOKE -0.318093195
8   DOWNLINEATCIMP      SKDDEPSTA -0.285911992
106      SKDDEPSTA DOWNLINEATCIMP -0.285911992
194         xDURN2       DEPSPOKE  0.279030910
208       DEPSPOKE         xDURN2  0.279030910
117     ARRRANKGRP DOWNLINEATCIMP -0.274110143
173 DOWNLINEATCIMP     ARRRANKGRP -0.274110143
3           SKDEQP      SKDDEPSTA  0.270065872
31       SKDDEPSTA         SKDEQP  0.270065872
2        SKDARRSTA      SKDDEPSTA -0.263453106
16       SKDDEPSTA      SKDARRSTA -0.263453106
41      TRNRANKGRP         SKDEQP  0.262837233
153         SKDEQP     TRNRANKGRP  0.262837233
114      ARRBUCKET DOWNLINEATCIMP  0.255480148
128 DOWNLINEATCIMP      ARRBUCKET  0.255480148
163       DEPSPOKE     TRNRANKGRP  0.242138220
191     TRNRANKGRP       DEPSPOKE  0.242138220
40      DEPRANKGRP         SKDEQP  0.239915140
138         SKDEQP     DEPRANKGRP  0.239915140
90    xAVGSKDAVAIL   UPLINEATCIMP  0.234867014
216   UPLINEATCIMP   xAVGSKDAVAIL  0.234867014
119         xDURN2 DOWNLINEATCIMP -0.226093423
203 DOWNLINEATCIMP         xDURN2 -0.226093423
116     TRNRANKGRP DOWNLINEATCIMP -0.224193213
158 DOWNLINEATCIMP     TRNRANKGRP -0.224193213
21    UPLINEATCIMP      SKDARRSTA  0.223824406
77       SKDARRSTA   UPLINEATCIMP  0.223824406
195   xAVGSKDAVAIL       DEPSPOKE -0.212821518
223       DEPSPOKE   xAVGSKDAVAIL -0.212821518
34          SKDEPS         SKDEQP  0.212586898
48          SKDEQP         SKDEPS  0.212586898
148       DEPSPOKE     DEPRANKGRP  0.208188512
190     DEPRANKGRP       DEPSPOKE  0.208188512
115     DEPRANKGRP DOWNLINEATCIMP -0.199411990
143 DOWNLINEATCIMP     DEPRANKGRP -0.199411990
133       DEPSPOKE      ARRBUCKET -0.189934966
189      ARRBUCKET       DEPSPOKE -0.189934966
149         xDURN2     DEPRANKGRP  0.180043357
205     DEPRANKGRP         xDURN2  0.180043357
89          xDURN2   UPLINEATCIMP -0.173240320
201   UPLINEATCIMP         xDURN2 -0.173240320
135   xAVGSKDAVAIL      ARRBUCKET -0.170644257
219      ARRBUCKET   xAVGSKDAVAIL -0.170644257
25      DEPRANKGRP      SKDARRSTA -0.167375913
137      SKDARRSTA     DEPRANKGRP -0.167375913
6     UPLINEATCIMP      SKDDEPSTA -0.164964952
76       SKDDEPSTA   UPLINEATCIMP -0.164964952
101     TRNRANKGRP   DEPSTAATCIMP -0.147409309
157   DEPSTAATCIMP     TRNRANKGRP -0.147409309
105   xAVGSKDAVAIL   DEPSTAATCIMP -0.141077194
217   DEPSTAATCIMP   xAVGSKDAVAIL -0.141077194
71      TRNRANKGRP      AVGLOFATC  0.139184315
155      AVGLOFATC     TRNRANKGRP  0.139184315
147     ARRRANKGRP     DEPRANKGRP  0.136562948
175     DEPRANKGRP     ARRRANKGRP  0.136562948
67    DEPSTAATCIMP      AVGLOFATC -0.135778614
95       AVGLOFATC   DEPSTAATCIMP -0.135778614
74          xDURN2      AVGLOFATC -0.132084629
200      AVGLOFATC         xDURN2 -0.132084629
150   xAVGSKDAVAIL     DEPRANKGRP  0.130574789
220     DEPRANKGRP   xAVGSKDAVAIL  0.130574789
132     ARRRANKGRP      ARRBUCKET -0.129698517
174      ARRBUCKET     ARRRANKGRP -0.129698517
99       ARRBUCKET   DEPSTAATCIMP -0.127726148
127   DEPSTAATCIMP      ARRBUCKET -0.127726148
14          xDURN2      SKDDEPSTA  0.127598189
196      SKDDEPSTA         xDURN2  0.127598189
68  DOWNLINEATCIMP      AVGLOFATC -0.126763572
110      AVGLOFATC DOWNLINEATCIMP -0.126763572
134         xDURN2      ARRBUCKET -0.125836459
204      ARRBUCKET         xDURN2 -0.125836459
100     DEPRANKGRP   DEPSTAATCIMP  0.124672682
142   DEPSTAATCIMP     DEPRANKGRP  0.124672682
52    DEPSTAATCIMP         SKDEPS -0.123445793
94          SKDEPS   DEPSTAATCIMP -0.123445793
9        ARRBUCKET      SKDDEPSTA -0.120728212
121      SKDDEPSTA      ARRBUCKET -0.120728212
179         xDURN2     ARRRANKGRP  0.119675180
207     ARRRANKGRP         xDURN2  0.119675180
26      TRNRANKGRP      SKDARRSTA -0.105802023
152      SKDARRSTA     TRNRANKGRP -0.105802023
130     DEPRANKGRP      ARRBUCKET -0.105057984
144      ARRBUCKET     DEPRANKGRP -0.105057984
120   xAVGSKDAVAIL DOWNLINEATCIMP  0.102577364
218 DOWNLINEATCIMP   xAVGSKDAVAIL  0.102577364
85      DEPRANKGRP   UPLINEATCIMP -0.097218129
141   UPLINEATCIMP     DEPRANKGRP -0.097218129
86      TRNRANKGRP   UPLINEATCIMP -0.097037814
156   UPLINEATCIMP     TRNRANKGRP -0.097037814
19          SKDEPS      SKDARRSTA -0.096699169
47       SKDARRSTA         SKDEPS -0.096699169
53  DOWNLINEATCIMP         SKDEPS -0.095568613
109         SKDEPS DOWNLINEATCIMP -0.095568613
20       AVGLOFATC      SKDARRSTA -0.095234466
62       SKDARRSTA      AVGLOFATC -0.095234466
18          SKDEQP      SKDARRSTA  0.094073459
32       SKDARRSTA         SKDEQP  0.094073459
24       ARRBUCKET      SKDARRSTA  0.092625400
122      SKDARRSTA      ARRBUCKET  0.092625400
131     TRNRANKGRP      ARRBUCKET -0.092415252
159      ARRBUCKET     TRNRANKGRP -0.092415252
165   xAVGSKDAVAIL     TRNRANKGRP  0.092011501
221     TRNRANKGRP   xAVGSKDAVAIL  0.092011501
15    xAVGSKDAVAIL      SKDDEPSTA  0.088580325
211      SKDDEPSTA   xAVGSKDAVAIL  0.088580325
44          xDURN2         SKDEQP  0.086170070
198         SKDEQP         xDURN2  0.086170070
70      DEPRANKGRP      AVGLOFATC  0.085474019
140      AVGLOFATC     DEPRANKGRP  0.085474019
66    UPLINEATCIMP      AVGLOFATC -0.085180887
80       AVGLOFATC   UPLINEATCIMP -0.085180887
162     ARRRANKGRP     TRNRANKGRP  0.083906762
176     TRNRANKGRP     ARRRANKGRP  0.083906762
178       DEPSPOKE     ARRRANKGRP  0.083162083
192     ARRRANKGRP       DEPSPOKE  0.083162083
57      ARRRANKGRP         SKDEPS  0.080398834
169         SKDEPS     ARRRANKGRP  0.080398834
60    xAVGSKDAVAIL         SKDEPS  0.075169577
214         SKDEPS   xAVGSKDAVAIL  0.075169577
102     ARRRANKGRP   DEPSTAATCIMP  0.073371196
172   DEPSTAATCIMP     ARRRANKGRP  0.073371196
84       ARRBUCKET   UPLINEATCIMP  0.071409699
126   UPLINEATCIMP      ARRBUCKET  0.071409699
87      ARRRANKGRP   UPLINEATCIMP -0.069790367
171   UPLINEATCIMP     ARRRANKGRP -0.069790367
12      ARRRANKGRP      SKDDEPSTA  0.068927801
166      SKDDEPSTA     ARRRANKGRP  0.068927801
72      ARRRANKGRP      AVGLOFATC -0.061491190
170      AVGLOFATC     ARRRANKGRP -0.061491190
75    xAVGSKDAVAIL      AVGLOFATC -0.056264979
215      AVGLOFATC   xAVGSKDAVAIL -0.056264979
5        AVGLOFATC      SKDDEPSTA -0.044946507
61       SKDDEPSTA      AVGLOFATC -0.044946507
69       ARRBUCKET      AVGLOFATC -0.043093769
125      AVGLOFATC      ARRBUCKET -0.043093769
42      ARRRANKGRP         SKDEQP -0.042512956
168         SKDEQP     ARRRANKGRP -0.042512956
45    xAVGSKDAVAIL         SKDEQP  0.031863410
213         SKDEQP   xAVGSKDAVAIL  0.031863410
56      TRNRANKGRP         SKDEPS  0.030883560
154         SKDEPS     TRNRANKGRP  0.030883560
29          xDURN2      SKDARRSTA  0.027576751
197      SKDARRSTA         xDURN2  0.027576751
30    xAVGSKDAVAIL      SKDARRSTA  0.027225219
212      SKDARRSTA   xAVGSKDAVAIL  0.027225219
55      DEPRANKGRP         SKDEPS  0.027025501
139         SKDEPS     DEPRANKGRP  0.027025501
4           SKDEPS      SKDDEPSTA -0.024267794
46       SKDDEPSTA         SKDEPS -0.024267794
36    UPLINEATCIMP         SKDEQP -0.019807499
78          SKDEQP   UPLINEATCIMP -0.019807499
43        DEPSPOKE         SKDEQP  0.019755644
183         SKDEQP       DEPSPOKE  0.019755644
210   xAVGSKDAVAIL         xDURN2 -0.019255572
224         xDURN2   xAVGSKDAVAIL -0.019255572
180   xAVGSKDAVAIL     ARRRANKGRP -0.018743432
222     ARRRANKGRP   xAVGSKDAVAIL -0.018743432
104         xDURN2   DEPSTAATCIMP -0.017999758
202   DEPSTAATCIMP         xDURN2 -0.017999758
38  DOWNLINEATCIMP         SKDEQP -0.017658860
108         SKDEQP DOWNLINEATCIMP -0.017658860
54       ARRBUCKET         SKDEPS  0.017414895
124         SKDEPS      ARRBUCKET  0.017414895
27      ARRRANKGRP      SKDARRSTA  0.016733374
167      SKDARRSTA     ARRRANKGRP  0.016733374
39       ARRBUCKET         SKDEQP  0.009926479
123         SKDEQP      ARRBUCKET  0.009926479
73        DEPSPOKE      AVGLOFATC -0.008540402
185      AVGLOFATC       DEPSPOKE -0.008540402
50       AVGLOFATC         SKDEPS  0.008240563
64          SKDEPS      AVGLOFATC  0.008240563
37    DEPSTAATCIMP         SKDEQP -0.005922601
93          SKDEQP   DEPSTAATCIMP -0.005922601
35       AVGLOFATC         SKDEQP -0.004889040
63          SKDEQP      AVGLOFATC -0.004889040
58        DEPSPOKE         SKDEPS -0.004617067
184         SKDEPS       DEPSPOKE -0.004617067
51    UPLINEATCIMP         SKDEPS  0.004016263
79          SKDEPS   UPLINEATCIMP  0.004016263
59          xDURN2         SKDEPS  0.001748012
199         SKDEPS         xDURN2  0.001748012
> 
> ### Models
> 
> ## Try GBM (gradient boosting). Works well for mixed data.
> ## And there is a tutorial for it with caret.
> 
> ## Training controller and big grid
> ## Check the ROC (my preferred.)
> 
> fitControl <- trainControl(## 10-fold CV
+     method = "repeatedcv",
+     number = 10,
+     ## repeated ten times
+     repeats = 10,
+     classProbs = 10,
+     summaryFunction = twoClassSummary)
> 
> ## Some trial and error with variables to branch and boost.
> ## I'm just going to try the airports and the planes and the duration
> ## of the flight. There may be some distance relationship there that
> ## air traffic control use.
> 
> ## Annoying because I drop variables, this needs to be looked up.
> 
> tr.cols <- colnames(trainDescr)
> tr.cols
 [1] "SKDDEPSTA"      "SKDARRSTA"      "SKDEQP"         "SKDEPS"        
 [5] "AVGLOFATC"      "UPLINEATCIMP"   "DEPSTAATCIMP"   "DOWNLINEATCIMP"
 [9] "ARRBUCKET"      "DEPRANKGRP"     "TRNRANKGRP"     "ARRRANKGRP"    
[13] "DEPSPOKE"       "xDURN2"         "xAVGSKDAVAIL"  
> tr.icols <- grep("((STA|EQP)$)|(^xD)", tr.cols)
> tr.icols <- rev(tr.icols)
> 
> gbmGrid <- expand.grid(interaction.depth = tr.icols,
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.1,
+                         n.minobsinnode = 10)
> 
> set.seed(seed.mine)
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "ROC",
+                  verbose = FALSE)
> gbmFit1
Stochastic Gradient Boosting 

248 samples
 15 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 222, 223, 223, 224, 223, 223, ... 

Resampling results across tuning parameters:

  interaction.depth  n.trees  ROC        Sens       Spec       ROC SD    
   1                   90     0.7677231  0.7398901  0.6799242  0.08864870
   1                  180     0.7610972  0.7217582  0.6837121  0.08615942
   1                  270     0.7547990  0.7066484  0.6713636  0.08826639
   1                  360     0.7490659  0.7046154  0.6616667  0.08911975
   1                  450     0.7411942  0.7037363  0.6671212  0.09714591
   1                  540     0.7425321  0.7007692  0.6696212  0.09214621
   1                  630     0.7390813  0.6979670  0.6596970  0.09051378
   1                  720     0.7302148  0.6978022  0.6454545  0.09653103
   1                  810     0.7306535  0.6971429  0.6514394  0.09023342
   1                  900     0.7263074  0.6940110  0.6441667  0.09628235
   1                  990     0.7268511  0.6934066  0.6385606  0.09451973
   1                 1080     0.7248223  0.6992857  0.6359091  0.09885554
   1                 1170     0.7274213  0.6984615  0.6369697  0.09091445
   1                 1260     0.7202589  0.6985714  0.6359091  0.09690223
   1                 1350     0.7195488  0.6969780  0.6296212  0.09562728
   1                 1440     0.7215193  0.6942308  0.6233333  0.08721151
   1                 1530     0.7220255  0.7006044  0.6269697  0.08521922
   1                 1620     0.7194522  0.6998352  0.6226515  0.08957879
   1                 1710     0.7166858  0.7015385  0.6190152  0.09290212
   1                 1800     0.7134857  0.7001099  0.6199242  0.09664418
   1                 1890     0.7146820  0.6932967  0.6180303  0.09315624
   1                 1980     0.7143411  0.6896154  0.6189394  0.09700888
   1                 2070     0.7137550  0.6869231  0.6189394  0.09364478
   1                 2160     0.7112142  0.6819231  0.6124242  0.09026121
   1                 2250     0.7124280  0.6832967  0.6153788  0.08631881
   1                 2340     0.7131369  0.6892308  0.6181061  0.08768030
   1                 2430     0.7104512  0.6840110  0.6081061  0.09245321
   1                 2520     0.7079341  0.6862088  0.6046212  0.08936012
   1                 2610     0.7054287  0.6815934  0.6037121  0.09035924
   1                 2700     0.7048839  0.6847253  0.6037121  0.08866508
   2                   90     0.7583550  0.7386813  0.6607576  0.08979727
   2                  180     0.7466446  0.7040110  0.6564394  0.08525493
   2                  270     0.7402165  0.6987912  0.6537121  0.08460258
   2                  360     0.7282309  0.6970330  0.6500000  0.08725596
   2                  450     0.7278621  0.6875275  0.6471970  0.08616747
   2                  540     0.7273593  0.6957143  0.6546212  0.08786936
   2                  630     0.7249363  0.7013187  0.6462879  0.08885501
   2                  720     0.7233492  0.6890110  0.6435606  0.08586067
   2                  810     0.7212363  0.6932967  0.6363636  0.08691476
   2                  900     0.7207480  0.6954396  0.6372727  0.08595932
   2                  990     0.7181868  0.6953846  0.6426515  0.08903953
   2                 1080     0.7192999  0.6975824  0.6353030  0.08725200
   2                 1170     0.7171233  0.6969780  0.6290152  0.08688539
   2                 1260     0.7160127  0.6911538  0.6378788  0.08682487
   2                 1350     0.7153813  0.6911538  0.6297727  0.08510084
   2                 1440     0.7143257  0.6919231  0.6306818  0.08747151
   2                 1530     0.7126586  0.6904945  0.6281818  0.08732367
   2                 1620     0.7129625  0.6877473  0.6322727  0.08730887
   2                 1710     0.7118577  0.6906044  0.6279545  0.08763391
   2                 1800     0.7125541  0.6891758  0.6254545  0.08676406
   2                 1890     0.7123298  0.6832418  0.6190909  0.08693598
   2                 1980     0.7110989  0.6860989  0.6190909  0.08545315
   2                 2070     0.7115876  0.6876923  0.6180303  0.08785329
   2                 2160     0.7109045  0.6861538  0.6153788  0.08540185
   2                 2250     0.7109357  0.6898901  0.6180303  0.08490375
   2                 2340     0.7111455  0.6891758  0.6163636  0.08497711
   2                 2430     0.7057418  0.6846703  0.6145455  0.09567045
   2                 2520     0.7089015  0.6818681  0.6207576  0.08532690
   2                 2610     0.7072378  0.6825824  0.6208333  0.09050809
   2                 2700     0.7099796  0.6863187  0.6162879  0.08456100
   3                   90     0.7464606  0.7162637  0.6610606  0.09853945
   3                  180     0.7313212  0.6985165  0.6539394  0.09232179
   3                  270     0.7250083  0.7065934  0.6424242  0.09374729
   3                  360     0.7252764  0.7023077  0.6376515  0.09523497
   3                  450     0.7189386  0.6971429  0.6440909  0.09994589
   3                  540     0.7242466  0.6993956  0.6476515  0.08907331
   3                  630     0.7219014  0.6942308  0.6388636  0.08964360
   3                  720     0.7177477  0.6963187  0.6296970  0.09445093
   3                  810     0.7185560  0.6934615  0.6432576  0.08646313
   3                  900     0.7188141  0.6962637  0.6350758  0.08678142
   3                  990     0.7150753  0.6941209  0.6349242  0.09576861
   3                 1080     0.7159853  0.6984615  0.6340152  0.09261452
   3                 1170     0.7137991  0.6934066  0.6278788  0.09139180
   3                 1260     0.7147365  0.6906593  0.6305303  0.09164253
   3                 1350     0.7122303  0.6942857  0.6304545  0.09099918
   3                 1440     0.7117707  0.6972527  0.6330303  0.09105649
   3                 1530     0.7130137  0.6934615  0.6266667  0.09132570
   3                 1620     0.7119052  0.6920330  0.6312879  0.09162907
   3                 1710     0.7119776  0.6949451  0.6294697  0.09206509
   3                 1800     0.7118036  0.6920330  0.6294697  0.09155344
   3                 1890     0.7113079  0.7001648  0.6312121  0.09220260
   3                 1980     0.7101111  0.6935714  0.6285606  0.09312267
   3                 2070     0.7093348  0.6943956  0.6322727  0.09245293
   3                 2160     0.7099879  0.6966484  0.6340909  0.09220474
   3                 2250     0.7107642  0.6965934  0.6296212  0.09031364
   3                 2340     0.7114998  0.6988462  0.6323485  0.08990709
   3                 2430     0.7127119  0.6958242  0.6314394  0.08933675
   3                 2520     0.7104283  0.6966484  0.6332576  0.08952722
   3                 2610     0.7099888  0.6951099  0.6341667  0.08896893
   3                 2700     0.7088395  0.6952198  0.6287121  0.09075389
  14                   90     0.7326236  0.7152747  0.6425000  0.10087146
  14                  180     0.7228746  0.7035165  0.6354545  0.09931368
  14                  270     0.7213462  0.7035165  0.6334848  0.09396458
  14                  360     0.7165659  0.6998352  0.6262121  0.10116195
  14                  450     0.7162845  0.6917582  0.6282576  0.09507166
  14                  540     0.7144668  0.6845055  0.6218939  0.09352347
  14                  630     0.7107443  0.6946154  0.6244697  0.09805865
  14                  720     0.7103280  0.6948901  0.6253788  0.09962236
  14                  810     0.7105149  0.7014835  0.6281818  0.09859145
  14                  900     0.7114332  0.7009890  0.6326515  0.09868955
  14                  990     0.7094302  0.6957143  0.6336364  0.10203480
  14                 1080     0.7080990  0.6979121  0.6353788  0.09936985
  14                 1170     0.7089061  0.6928022  0.6326515  0.10157800
  14                 1260     0.7101769  0.6949451  0.6300000  0.09989748
  14                 1350     0.7096491  0.6914286  0.6309091  0.10085309
  14                 1440     0.7115243  0.6921429  0.6272727  0.09726438
  14                 1530     0.7110910  0.6906044  0.6245455  0.09604735
  14                 1620     0.7108704  0.6936264  0.6254545  0.09625014
  14                 1710     0.7100210  0.6920879  0.6299242  0.09647862
  14                 1800     0.7128494  0.6930220  0.6315909  0.09366072
  14                 1890     0.7116873  0.6957692  0.6334091  0.09324457
  14                 1980     0.7120781  0.6965385  0.6307576  0.09414566
  14                 2070     0.7125814  0.6920879  0.6352273  0.09340483
  14                 2160     0.7126542  0.6951099  0.6315909  0.09310369
  14                 2250     0.7117260  0.6936813  0.6296970  0.09363284
  14                 2340     0.7127054  0.6936813  0.6315152  0.09404258
  14                 2430     0.7128998  0.6922527  0.6322727  0.09262044
  14                 2520     0.7129379  0.6937363  0.6314394  0.09292364
  14                 2610     0.7118115  0.6937363  0.6323485  0.09393908
  14                 2700     0.7120609  0.6958791  0.6305303  0.09393476
  Sens SD    Spec SD  
  0.1200163  0.1322693
  0.1204938  0.1278431
  0.1159157  0.1309806
  0.1214106  0.1339411
  0.1264995  0.1292925
  0.1311572  0.1372404
  0.1263904  0.1270256
  0.1220515  0.1441949
  0.1329145  0.1261041
  0.1288142  0.1261085
  0.1267627  0.1261813
  0.1238814  0.1244909
  0.1210513  0.1205440
  0.1310633  0.1264866
  0.1223594  0.1245983
  0.1220775  0.1227098
  0.1230779  0.1220373
  0.1239867  0.1255568
  0.1168119  0.1237598
  0.1215262  0.1123360
  0.1248365  0.1254435
  0.1260668  0.1278799
  0.1224307  0.1318396
  0.1264614  0.1346469
  0.1228671  0.1289379
  0.1206375  0.1304232
  0.1252465  0.1308614
  0.1199266  0.1257367
  0.1205264  0.1284597
  0.1213670  0.1278082
  0.1297662  0.1426410
  0.1244286  0.1402962
  0.1200726  0.1464896
  0.1174631  0.1382090
  0.1154299  0.1420573
  0.1192889  0.1347733
  0.1212582  0.1269207
  0.1114251  0.1256661
  0.1130158  0.1325260
  0.1173364  0.1281280
  0.1189728  0.1221177
  0.1191178  0.1273235
  0.1170739  0.1231878
  0.1220373  0.1295486
  0.1192518  0.1294620
  0.1180670  0.1252456
  0.1225703  0.1251219
  0.1155683  0.1298857
  0.1158914  0.1226239
  0.1172168  0.1280920
  0.1182583  0.1257339
  0.1178819  0.1315737
  0.1163956  0.1262129
  0.1153629  0.1298921
  0.1197419  0.1307609
  0.1143859  0.1333916
  0.1113865  0.1300322
  0.1104037  0.1350943
  0.1141981  0.1301263
  0.1087859  0.1297158
  0.1321073  0.1375725
  0.1314063  0.1329884
  0.1285970  0.1349362
  0.1195305  0.1338105
  0.1288346  0.1352023
  0.1208016  0.1349899
  0.1224815  0.1347860
  0.1264927  0.1364328
  0.1251632  0.1237167
  0.1264570  0.1275556
  0.1212722  0.1271944
  0.1242609  0.1281615
  0.1230667  0.1314423
  0.1229068  0.1279903
  0.1198671  0.1290940
  0.1269058  0.1311820
  0.1229708  0.1367884
  0.1220100  0.1272052
  0.1224045  0.1303609
  0.1215869  0.1290738
  0.1213079  0.1285508
  0.1222235  0.1280473
  0.1260941  0.1300150
  0.1234781  0.1274667
  0.1236417  0.1268302
  0.1216454  0.1285804
  0.1205520  0.1255922
  0.1279868  0.1256509
  0.1192089  0.1260020
  0.1180004  0.1251211
  0.1254919  0.1221872
  0.1315786  0.1264245
  0.1277641  0.1292744
  0.1295954  0.1340838
  0.1284202  0.1347482
  0.1232875  0.1351384
  0.1208039  0.1379035
  0.1181682  0.1324095
  0.1213802  0.1299404
  0.1268642  0.1280294
  0.1234002  0.1269244
  0.1230493  0.1272034
  0.1232947  0.1274803
  0.1233105  0.1261327
  0.1215401  0.1291187
  0.1214616  0.1256320
  0.1248642  0.1283632
  0.1226152  0.1248187
  0.1228905  0.1262781
  0.1197529  0.1235271
  0.1206333  0.1285644
  0.1209242  0.1273490
  0.1192816  0.1292412
  0.1197092  0.1310818
  0.1212503  0.1286743
  0.1198998  0.1350845
  0.1222675  0.1318525
  0.1205219  0.1313633
  0.1224895  0.1323442
  0.1183459  0.1316432

Tuning parameter 'shrinkage' was held constant at a value of 0.1

Tuning parameter 'n.minobsinnode' was held constant at a value of 10
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 90, interaction.depth =
 1, shrinkage = 0.1 and n.minobsinnode = 10. 
> 
> ## The acid test is dissapointing, but I've seen worse.
> 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
  Accuracy      Kappa 
0.56944444 0.05423729 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     37   28
    Weak        3    4
                                          
               Accuracy : 0.5694          
                 95% CI : (0.4473, 0.6857)
    No Information Rate : 0.5556          
    P-Value [Acc > NIR] : 0.4546          
                                          
                  Kappa : 0.0542          
 Mcnemar's Test P-Value : 1.629e-05       
                                          
            Sensitivity : 0.12500         
            Specificity : 0.92500         
         Pos Pred Value : 0.57143         
         Neg Pred Value : 0.56923         
             Prevalence : 0.44444         
         Detection Rate : 0.05556         
   Detection Prevalence : 0.09722         
      Balanced Accuracy : 0.52500         
                                          
       'Positive' Class : Weak            
                                          
> 
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
 Accuracy     Kappa 
0.7903226 0.5767085 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    110   25
    Weak       27   86
                                          
               Accuracy : 0.7903          
                 95% CI : (0.7343, 0.8393)
    No Information Rate : 0.5524          
    P-Value [Acc > NIR] : 3.997e-15       
                                          
                  Kappa : 0.5767          
 Mcnemar's Test P-Value : 0.8897          
                                          
            Sensitivity : 0.7748          
            Specificity : 0.8029          
         Pos Pred Value : 0.7611          
         Neg Pred Value : 0.8148          
             Prevalence : 0.4476          
         Detection Rate : 0.3468          
   Detection Prevalence : 0.4556          
      Balanced Accuracy : 0.7888          
                                          
       'Positive' Class : Weak            
                                          
> ### weaves
> 
> ## Processing for flights data.
> 
> ## Following the caret vignette.
> 
> ###################################################
> ### code chunk number 1: loadLibs
> ###################################################
> library(MASS)
> library(caret)
> library(mlbench)
> library(pROC)
> library(pls)
> 
> library(doMC)
> registerDoMC(cores = 4)
> 
> options(useFancyQuotes = FALSE) 
> 
> # Accounting info.
> getInfo <- function(what = "Suggests")
+ {
+   text <- packageDescription("caret")[what][[1]]
+   text <- gsub("\n", ", ", text, fixed = TRUE)
+   text <- gsub(">=", "$\\\\ge$", text, fixed = TRUE)
+   eachPkg <- strsplit(text, ", ", fixed = TRUE)[[1]]
+   eachPkg <- gsub(",", "", eachPkg, fixed = TRUE)
+   # out <- paste("\\\\pkg{", eachPkg[order(tolower(eachPkg))], "}", sep = "")
+   # paste(out, collapse = ", ")
+   length(eachPkg)
+ }
> 
> ### project-specific: begin
> ## Set-seed, load original CSV file, order it
> ## and do some simple-cleaning
> ## Various datasets 
> 
> seed.mine = 107
> set.seed(seed.mine)                     # helpful for testing
> 
> flight <- read.csv("../bak/flight.csv")
> flight <- flight[order(flight$D00),]
> 
> # Backup
> flight.raw <- flight
> 
> # To check adjustment, there is test code in flight-nb.R
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"
> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"
> 
> # And some deletions
> 
> t.cols <- colnames(flight)
> 
> t.drops <- t.cols[grep("^RANK*", t.cols)]
> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])
> t.drops <- c(t.drops, "D80THPCTL")
> 
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR
> flight$xHNGR <- flight$xDURN < 0
> 
> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+ }
> 
> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))
> 
> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE
> t.cols <- colnames(flight)
> 
> t.drops <- c("SARRHR", "xDURN")
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Backup
> 
> flight00 <- flight
> 
> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]
> 
> paste("samples in use: ", dim(flight)[1])
[1] "samples in use:  320"
> 
> ## Data insights
> 
> ## *Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> flight <- flight1
> 
> ### Numeric variables
> 
> ### Try and impute the AVG, it might have more information than the
> ### bucket.
> 
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))
Error in `$<-.data.frame`(`*tmp*`, "xAVAILBUCKET", value = numeric(0)) : 
  replacement has 0 rows, data has 320
> 
> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1
> 
> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]
Error in `[.data.frame`(flight, , c("AVGSKDAVAIL", "xAVAILBUCKET")) : 
  undefined columns selected
> 
> preProcValues <- preProcess(flight.na, method = c("knnImpute"))
> flight.na1 <- predict(preProcValues, flight.na)
> 
> ## I'll add the new imputed value and drop the others
> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL
> flight$AVGSKDAVAIL <- NULL
> flight$xAVAILBUCKET <- NULL
> flight$AVAILBUCKET <- NULL
> 
> flight$xHNGR <- NULL
> 
> ## Check some more numeric correlations, I haven't scaled everything yet.
> ## I'd cut correlations above 0.65 to 0.75 because of overfitting.
> 
> x1 <- as.data.frame(as.matrix(sapply(flight, class)))
> 
> flight.num <- flight[,names(x1[which(x1$V1 %in% c("numeric", "integer")),])]
> 
> flight.nzv <- nearZeroVar(flight.num, saveMetrics = TRUE)
> flight.nzv
             freqRatio percentUnique zeroVar   nzv
SDEPHR        1.038462        5.9375   FALSE FALSE
SKDEPS        1.000000       19.0625   FALSE FALSE
D00           1.166667       75.3125   FALSE FALSE
AVGSQ         6.333333       82.8125   FALSE FALSE
AVGLOFATC     1.000000       78.4375   FALSE FALSE
xDURN2        1.428571        2.5000   FALSE FALSE
xAVGSKDAVAIL 18.500000       87.8125   FALSE FALSE
> 
> # annoying NA should be gone.
> flight.cor <- cor(flight.num, use = "pairwise.complete.obs")
> 
> descrCorr <- findCorrelation(flight.cor, cutoff = .65, verbose=TRUE)
Considering row	 4 column	 1 value	 0.956 
  Flagging column	 4 
Considering row	 1 column	 3 value	 0.43 
Considering row	 1 column	 7 value	 0.053 
Considering row	 1 column	 6 value	 0.204 
Considering row	 1 column	 5 value	 0.131 
Considering row	 1 column	 2 value	 0.054 
Considering row	 3 column	 7 value	 0.401 
Considering row	 3 column	 6 value	 0.071 
Considering row	 3 column	 5 value	 0.114 
Considering row	 3 column	 2 value	 0.006 
Considering row	 7 column	 6 value	 0.019 
Considering row	 7 column	 5 value	 0.07 
Considering row	 7 column	 2 value	 0.113 
Considering row	 6 column	 5 value	 0.137 
Considering row	 6 column	 2 value	 0.005 
Considering row	 5 column	 2 value	 0.041 
> 
> colnames(flight.num)[descrCorr]
[1] "AVGSQ"
> 
> ## And I'll leave the centered and scale values in for now.
> ## and delete the troublesome ones
> 
> ## Re-classing
> ## Check warnings to see it adjustment has taken place.
> ## We want the proportion in the training class to be about 0.55 0.45
> ## Strong to Weak
> ## I've achieved this heuristically
> src.adjust <- TRUE
> source(file = "flight1.R")
Warning message:
In eval(expr, envir, enclos) : adjusting
> flight1 <- flight
> 
> ## This should be deleted, leave it in and the results
> ## are ideal because it defines LEGTYPE.
> flight$D00 <- NULL
> 
> ## Keep the results but don't change the order.
> outcomes.flight <- flight$LEGTYPE
> 
> flight$LEGTYPE <- NULL
> 
> ## If you know your factors are definitely factors, you don't need this
> ##  asNumeric <- function(x) as.numeric(as.character(x))
> 
> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))
> 
> flight.num0 <- factors.numeric(flight)
> 
> flight.scl0 <- scale(flight.num0)
> 
> ## Now split the samples
> ## we need at least 60 to test with, p at 0.77 gives about 75.
> ## Difficulty here is the bias in the table
> ## Because we only have [3.1, 4.4] the proportion of Weak is higher.
> ## see prop.table(results)
> 
> set.seed(seed.mine)
> inTrain <- createDataPartition(outcomes.flight, p = 0.77, list = FALSE)
> 
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> 
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> 
> prop.table(table(trainClass))
trainClass
   Strong      Weak 
0.5524194 0.4475806 
> dim(trainDescr)
[1] 248  19
> 
> prop.table(table(testClass))
testClass
   Strong      Weak 
0.5555556 0.4444444 
> dim(testDescr)
[1] 72 19
> 
> ## Check Near-zero variance
> 
> nzv <- nearZeroVar(trainDescr, saveMetrics= TRUE)
> stopifnot( all(nzv$nzv == FALSE) )
> 
> # It's imputed and behaves well, no need for this.
> # descrCorr <- cor(scale(trainDescr), use = "pairwise.complete.obs")
> 
> descrCorr <- cor(scale(trainDescr))
> 
> ## This cut-off should be under src.adjust control.
> ## I'm under Git, so I can tinker with it.
> highCorr <- findCorrelation(descrCorr, cutoff = .80, verbose = TRUE)
Considering row	 17 column	 16 value	 0.85 
  Flagging column	 17 
Considering row	 16 column	 10 value	 0.568 
Considering row	 16 column	 1 value	 0.236 
Considering row	 16 column	 11 value	 0.231 
Considering row	 16 column	 6 value	 0.189 
Considering row	 16 column	 12 value	 0.19 
Considering row	 16 column	 2 value	 0.333 
Considering row	 16 column	 9 value	 0.671 
Considering row	 16 column	 14 value	 0.242 
Considering row	 16 column	 13 value	 0.208 
Considering row	 16 column	 8 value	 0.6 
Considering row	 16 column	 3 value	 0.318 
Considering row	 16 column	 18 value	 0.279 
Considering row	 16 column	 19 value	 0.213 
Considering row	 16 column	 15 value	 0.083 
Considering row	 16 column	 4 value	 0.02 
Considering row	 16 column	 7 value	 0.009 
Considering row	 16 column	 5 value	 0.005 
Considering row	 10 column	 1 value	 0.281 
Considering row	 10 column	 11 value	 0.275 
Considering row	 10 column	 6 value	 0.298 
Considering row	 10 column	 12 value	 0.255 
Considering row	 10 column	 2 value	 0.286 
Considering row	 10 column	 9 value	 0.404 
Considering row	 10 column	 14 value	 0.224 
Considering row	 10 column	 13 value	 0.199 
Considering row	 10 column	 8 value	 0.366 
Considering row	 10 column	 3 value	 0.462 
Considering row	 10 column	 18 value	 0.226 
Considering row	 10 column	 19 value	 0.103 
Considering row	 10 column	 15 value	 0.274 
Considering row	 10 column	 4 value	 0.018 
Considering row	 10 column	 7 value	 0.127 
Considering row	 10 column	 5 value	 0.096 
Considering row	 1 column	 11 value	 0.988 
  Flagging column	 1 
Considering row	 11 column	 6 value	 0.945 
  Flagging column	 11 
Considering row	 6 column	 12 value	 0.883 
  Flagging column	 6 
Considering row	 12 column	 2 value	 0.121 
Considering row	 12 column	 9 value	 0.128 
Considering row	 12 column	 14 value	 0.092 
Considering row	 12 column	 13 value	 0.105 
Considering row	 12 column	 8 value	 0.071 
Considering row	 12 column	 3 value	 0.093 
Considering row	 12 column	 18 value	 0.126 
Considering row	 12 column	 19 value	 0.171 
Considering row	 12 column	 15 value	 0.13 
Considering row	 12 column	 4 value	 0.01 
Considering row	 12 column	 7 value	 0.043 
Considering row	 12 column	 5 value	 0.017 
Considering row	 2 column	 9 value	 0.423 
Considering row	 2 column	 14 value	 0.574 
Considering row	 2 column	 13 value	 0.557 
Considering row	 2 column	 8 value	 0.165 
Considering row	 2 column	 3 value	 0.263 
Considering row	 2 column	 18 value	 0.128 
Considering row	 2 column	 19 value	 0.089 
Considering row	 2 column	 15 value	 0.069 
Considering row	 2 column	 4 value	 0.27 
Considering row	 2 column	 7 value	 0.045 
Considering row	 2 column	 5 value	 0.024 
Considering row	 9 column	 14 value	 0.147 
Considering row	 9 column	 13 value	 0.125 
Considering row	 9 column	 8 value	 0.449 
Considering row	 9 column	 3 value	 0.322 
Considering row	 9 column	 18 value	 0.018 
Considering row	 9 column	 19 value	 0.141 
Considering row	 9 column	 15 value	 0.073 
Considering row	 9 column	 4 value	 0.006 
Considering row	 9 column	 7 value	 0.136 
Considering row	 9 column	 5 value	 0.123 
Considering row	 14 column	 13 value	 0.659 
Considering row	 14 column	 8 value	 0.097 
Considering row	 14 column	 3 value	 0.106 
Considering row	 14 column	 18 value	 0.361 
Considering row	 14 column	 19 value	 0.092 
Considering row	 14 column	 15 value	 0.084 
Considering row	 14 column	 4 value	 0.263 
Considering row	 14 column	 7 value	 0.139 
Considering row	 14 column	 5 value	 0.031 
Considering row	 13 column	 8 value	 0.097 
Considering row	 13 column	 3 value	 0.167 
Considering row	 13 column	 18 value	 0.18 
Considering row	 13 column	 19 value	 0.131 
Considering row	 13 column	 15 value	 0.137 
Considering row	 13 column	 4 value	 0.24 
Considering row	 13 column	 7 value	 0.085 
Considering row	 13 column	 5 value	 0.027 
Considering row	 8 column	 3 value	 0.224 
Considering row	 8 column	 18 value	 0.173 
Considering row	 8 column	 19 value	 0.235 
Considering row	 8 column	 15 value	 0.07 
Considering row	 8 column	 4 value	 0.02 
Considering row	 8 column	 7 value	 0.085 
Considering row	 8 column	 5 value	 0.004 
Considering row	 3 column	 18 value	 0.028 
Considering row	 3 column	 19 value	 0.027 
Considering row	 3 column	 15 value	 0.017 
Considering row	 3 column	 4 value	 0.094 
Considering row	 3 column	 7 value	 0.095 
Considering row	 3 column	 5 value	 0.097 
Considering row	 18 column	 19 value	 0.019 
Considering row	 18 column	 15 value	 0.12 
Considering row	 18 column	 4 value	 0.086 
Considering row	 18 column	 7 value	 0.132 
Considering row	 18 column	 5 value	 0.002 
Considering row	 19 column	 15 value	 0.019 
Considering row	 19 column	 4 value	 0.032 
Considering row	 19 column	 7 value	 0.056 
Considering row	 19 column	 5 value	 0.075 
Considering row	 15 column	 4 value	 0.043 
Considering row	 15 column	 7 value	 0.061 
Considering row	 15 column	 5 value	 0.08 
Considering row	 4 column	 7 value	 0.005 
Considering row	 4 column	 5 value	 0.213 
Considering row	 7 column	 5 value	 0.008 
> 
> colnames(trainDescr)[highCorr]
[1] "ARRSPOKE"  "SDEPHR"    "DEPBUCKET" "AVGSQ"    
> 
> descr.ncol0 <- ncol(trainDescr)
> 
> # I've switched off the correlation remover and the results are better.
> if (sum(highCorr) > 0) {
+     warning("overfitting: correlations: err.trainDescr: ", paste(colnames(trainDescr)[highCorr], collapse = ", ") )
+     err.trainDescr <- trainDescr
+     trainDescr <- trainDescr[,-highCorr]
+ }
Warning message:
overfitting: correlations: err.trainDescr: ARRSPOKE, SDEPHR, DEPBUCKET, AVGSQ 
> 
> descr.ncol1 <- ncol(trainDescr)
> 
> paste("Dropped: ", as.character(descr.ncol0 - descr.ncol1))
[1] "Dropped:  4"
> 
> descrCorr <- cor(trainDescr)
> summary(descrCorr[upper.tri(descrCorr)])
     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
-0.600000 -0.123400 -0.004617  0.012770  0.102600  0.671300 
> 
> ## Dominant correlations
> ## At 0.9, there are some big ones that might need re-thinking.
> 
> table.descrCorr <- as.data.frame(as.table(descrCorr))
> table.descrCorr <- table.descrCorr[which(table.descrCorr$Var1 != table.descrCorr$Var2),]
> table.descrCorr[order(abs(table.descrCorr$Freq), decreasing = TRUE),]
              Var1           Var2         Freq
103       DEPSPOKE   DEPSTAATCIMP  0.671264566
187   DEPSTAATCIMP       DEPSPOKE  0.671264566
146     TRNRANKGRP     DEPRANKGRP  0.658724662
160     DEPRANKGRP     TRNRANKGRP  0.658724662
88        DEPSPOKE   UPLINEATCIMP -0.600008252
186   UPLINEATCIMP       DEPSPOKE -0.600008252
11      TRNRANKGRP      SKDDEPSTA  0.574035134
151      SKDDEPSTA     TRNRANKGRP  0.574035134
118       DEPSPOKE DOWNLINEATCIMP -0.567682494
188 DOWNLINEATCIMP       DEPSPOKE -0.567682494
10      DEPRANKGRP      SKDDEPSTA  0.557399203
136      SKDDEPSTA     DEPRANKGRP  0.557399203
23  DOWNLINEATCIMP      SKDARRSTA  0.462378131
107      SKDARRSTA DOWNLINEATCIMP  0.462378131
82    DEPSTAATCIMP   UPLINEATCIMP -0.449249986
96    UPLINEATCIMP   DEPSTAATCIMP -0.449249986
7     DEPSTAATCIMP      SKDDEPSTA  0.423425796
91       SKDDEPSTA   DEPSTAATCIMP  0.423425796
98  DOWNLINEATCIMP   DEPSTAATCIMP -0.403695561
112   DEPSTAATCIMP DOWNLINEATCIMP -0.403695561
83  DOWNLINEATCIMP   UPLINEATCIMP  0.365833687
111   UPLINEATCIMP DOWNLINEATCIMP  0.365833687
164         xDURN2     TRNRANKGRP  0.361347207
206     TRNRANKGRP         xDURN2  0.361347207
13        DEPSPOKE      SKDDEPSTA  0.332823310
181      SKDDEPSTA       DEPSPOKE  0.332823310
22    DEPSTAATCIMP      SKDARRSTA -0.322204878
92       SKDARRSTA   DEPSTAATCIMP -0.322204878
28        DEPSPOKE      SKDARRSTA -0.318093195
182      SKDARRSTA       DEPSPOKE -0.318093195
8   DOWNLINEATCIMP      SKDDEPSTA -0.285911992
106      SKDDEPSTA DOWNLINEATCIMP -0.285911992
194         xDURN2       DEPSPOKE  0.279030910
208       DEPSPOKE         xDURN2  0.279030910
117     ARRRANKGRP DOWNLINEATCIMP -0.274110143
173 DOWNLINEATCIMP     ARRRANKGRP -0.274110143
3           SKDEQP      SKDDEPSTA  0.270065872
31       SKDDEPSTA         SKDEQP  0.270065872
2        SKDARRSTA      SKDDEPSTA -0.263453106
16       SKDDEPSTA      SKDARRSTA -0.263453106
41      TRNRANKGRP         SKDEQP  0.262837233
153         SKDEQP     TRNRANKGRP  0.262837233
114      ARRBUCKET DOWNLINEATCIMP  0.255480148
128 DOWNLINEATCIMP      ARRBUCKET  0.255480148
163       DEPSPOKE     TRNRANKGRP  0.242138220
191     TRNRANKGRP       DEPSPOKE  0.242138220
40      DEPRANKGRP         SKDEQP  0.239915140
138         SKDEQP     DEPRANKGRP  0.239915140
90    xAVGSKDAVAIL   UPLINEATCIMP  0.234867014
216   UPLINEATCIMP   xAVGSKDAVAIL  0.234867014
119         xDURN2 DOWNLINEATCIMP -0.226093423
203 DOWNLINEATCIMP         xDURN2 -0.226093423
116     TRNRANKGRP DOWNLINEATCIMP -0.224193213
158 DOWNLINEATCIMP     TRNRANKGRP -0.224193213
21    UPLINEATCIMP      SKDARRSTA  0.223824406
77       SKDARRSTA   UPLINEATCIMP  0.223824406
195   xAVGSKDAVAIL       DEPSPOKE -0.212821518
223       DEPSPOKE   xAVGSKDAVAIL -0.212821518
34          SKDEPS         SKDEQP  0.212586898
48          SKDEQP         SKDEPS  0.212586898
148       DEPSPOKE     DEPRANKGRP  0.208188512
190     DEPRANKGRP       DEPSPOKE  0.208188512
115     DEPRANKGRP DOWNLINEATCIMP -0.199411990
143 DOWNLINEATCIMP     DEPRANKGRP -0.199411990
133       DEPSPOKE      ARRBUCKET -0.189934966
189      ARRBUCKET       DEPSPOKE -0.189934966
149         xDURN2     DEPRANKGRP  0.180043357
205     DEPRANKGRP         xDURN2  0.180043357
89          xDURN2   UPLINEATCIMP -0.173240320
201   UPLINEATCIMP         xDURN2 -0.173240320
135   xAVGSKDAVAIL      ARRBUCKET -0.170644257
219      ARRBUCKET   xAVGSKDAVAIL -0.170644257
25      DEPRANKGRP      SKDARRSTA -0.167375913
137      SKDARRSTA     DEPRANKGRP -0.167375913
6     UPLINEATCIMP      SKDDEPSTA -0.164964952
76       SKDDEPSTA   UPLINEATCIMP -0.164964952
101     TRNRANKGRP   DEPSTAATCIMP -0.147409309
157   DEPSTAATCIMP     TRNRANKGRP -0.147409309
105   xAVGSKDAVAIL   DEPSTAATCIMP -0.141077194
217   DEPSTAATCIMP   xAVGSKDAVAIL -0.141077194
71      TRNRANKGRP      AVGLOFATC  0.139184315
155      AVGLOFATC     TRNRANKGRP  0.139184315
147     ARRRANKGRP     DEPRANKGRP  0.136562948
175     DEPRANKGRP     ARRRANKGRP  0.136562948
67    DEPSTAATCIMP      AVGLOFATC -0.135778614
95       AVGLOFATC   DEPSTAATCIMP -0.135778614
74          xDURN2      AVGLOFATC -0.132084629
200      AVGLOFATC         xDURN2 -0.132084629
150   xAVGSKDAVAIL     DEPRANKGRP  0.130574789
220     DEPRANKGRP   xAVGSKDAVAIL  0.130574789
132     ARRRANKGRP      ARRBUCKET -0.129698517
174      ARRBUCKET     ARRRANKGRP -0.129698517
99       ARRBUCKET   DEPSTAATCIMP -0.127726148
127   DEPSTAATCIMP      ARRBUCKET -0.127726148
14          xDURN2      SKDDEPSTA  0.127598189
196      SKDDEPSTA         xDURN2  0.127598189
68  DOWNLINEATCIMP      AVGLOFATC -0.126763572
110      AVGLOFATC DOWNLINEATCIMP -0.126763572
134         xDURN2      ARRBUCKET -0.125836459
204      ARRBUCKET         xDURN2 -0.125836459
100     DEPRANKGRP   DEPSTAATCIMP  0.124672682
142   DEPSTAATCIMP     DEPRANKGRP  0.124672682
52    DEPSTAATCIMP         SKDEPS -0.123445793
94          SKDEPS   DEPSTAATCIMP -0.123445793
9        ARRBUCKET      SKDDEPSTA -0.120728212
121      SKDDEPSTA      ARRBUCKET -0.120728212
179         xDURN2     ARRRANKGRP  0.119675180
207     ARRRANKGRP         xDURN2  0.119675180
26      TRNRANKGRP      SKDARRSTA -0.105802023
152      SKDARRSTA     TRNRANKGRP -0.105802023
130     DEPRANKGRP      ARRBUCKET -0.105057984
144      ARRBUCKET     DEPRANKGRP -0.105057984
120   xAVGSKDAVAIL DOWNLINEATCIMP  0.102577364
218 DOWNLINEATCIMP   xAVGSKDAVAIL  0.102577364
85      DEPRANKGRP   UPLINEATCIMP -0.097218129
141   UPLINEATCIMP     DEPRANKGRP -0.097218129
86      TRNRANKGRP   UPLINEATCIMP -0.097037814
156   UPLINEATCIMP     TRNRANKGRP -0.097037814
19          SKDEPS      SKDARRSTA -0.096699169
47       SKDARRSTA         SKDEPS -0.096699169
53  DOWNLINEATCIMP         SKDEPS -0.095568613
109         SKDEPS DOWNLINEATCIMP -0.095568613
20       AVGLOFATC      SKDARRSTA -0.095234466
62       SKDARRSTA      AVGLOFATC -0.095234466
18          SKDEQP      SKDARRSTA  0.094073459
32       SKDARRSTA         SKDEQP  0.094073459
24       ARRBUCKET      SKDARRSTA  0.092625400
122      SKDARRSTA      ARRBUCKET  0.092625400
131     TRNRANKGRP      ARRBUCKET -0.092415252
159      ARRBUCKET     TRNRANKGRP -0.092415252
165   xAVGSKDAVAIL     TRNRANKGRP  0.092011501
221     TRNRANKGRP   xAVGSKDAVAIL  0.092011501
15    xAVGSKDAVAIL      SKDDEPSTA  0.088580325
211      SKDDEPSTA   xAVGSKDAVAIL  0.088580325
44          xDURN2         SKDEQP  0.086170070
198         SKDEQP         xDURN2  0.086170070
70      DEPRANKGRP      AVGLOFATC  0.085474019
140      AVGLOFATC     DEPRANKGRP  0.085474019
66    UPLINEATCIMP      AVGLOFATC -0.085180887
80       AVGLOFATC   UPLINEATCIMP -0.085180887
162     ARRRANKGRP     TRNRANKGRP  0.083906762
176     TRNRANKGRP     ARRRANKGRP  0.083906762
178       DEPSPOKE     ARRRANKGRP  0.083162083
192     ARRRANKGRP       DEPSPOKE  0.083162083
57      ARRRANKGRP         SKDEPS  0.080398834
169         SKDEPS     ARRRANKGRP  0.080398834
60    xAVGSKDAVAIL         SKDEPS  0.075169577
214         SKDEPS   xAVGSKDAVAIL  0.075169577
102     ARRRANKGRP   DEPSTAATCIMP  0.073371196
172   DEPSTAATCIMP     ARRRANKGRP  0.073371196
84       ARRBUCKET   UPLINEATCIMP  0.071409699
126   UPLINEATCIMP      ARRBUCKET  0.071409699
87      ARRRANKGRP   UPLINEATCIMP -0.069790367
171   UPLINEATCIMP     ARRRANKGRP -0.069790367
12      ARRRANKGRP      SKDDEPSTA  0.068927801
166      SKDDEPSTA     ARRRANKGRP  0.068927801
72      ARRRANKGRP      AVGLOFATC -0.061491190
170      AVGLOFATC     ARRRANKGRP -0.061491190
75    xAVGSKDAVAIL      AVGLOFATC -0.056264979
215      AVGLOFATC   xAVGSKDAVAIL -0.056264979
5        AVGLOFATC      SKDDEPSTA -0.044946507
61       SKDDEPSTA      AVGLOFATC -0.044946507
69       ARRBUCKET      AVGLOFATC -0.043093769
125      AVGLOFATC      ARRBUCKET -0.043093769
42      ARRRANKGRP         SKDEQP -0.042512956
168         SKDEQP     ARRRANKGRP -0.042512956
45    xAVGSKDAVAIL         SKDEQP  0.031863410
213         SKDEQP   xAVGSKDAVAIL  0.031863410
56      TRNRANKGRP         SKDEPS  0.030883560
154         SKDEPS     TRNRANKGRP  0.030883560
29          xDURN2      SKDARRSTA  0.027576751
197      SKDARRSTA         xDURN2  0.027576751
30    xAVGSKDAVAIL      SKDARRSTA  0.027225219
212      SKDARRSTA   xAVGSKDAVAIL  0.027225219
55      DEPRANKGRP         SKDEPS  0.027025501
139         SKDEPS     DEPRANKGRP  0.027025501
4           SKDEPS      SKDDEPSTA -0.024267794
46       SKDDEPSTA         SKDEPS -0.024267794
36    UPLINEATCIMP         SKDEQP -0.019807499
78          SKDEQP   UPLINEATCIMP -0.019807499
43        DEPSPOKE         SKDEQP  0.019755644
183         SKDEQP       DEPSPOKE  0.019755644
210   xAVGSKDAVAIL         xDURN2 -0.019255572
224         xDURN2   xAVGSKDAVAIL -0.019255572
180   xAVGSKDAVAIL     ARRRANKGRP -0.018743432
222     ARRRANKGRP   xAVGSKDAVAIL -0.018743432
104         xDURN2   DEPSTAATCIMP -0.017999758
202   DEPSTAATCIMP         xDURN2 -0.017999758
38  DOWNLINEATCIMP         SKDEQP -0.017658860
108         SKDEQP DOWNLINEATCIMP -0.017658860
54       ARRBUCKET         SKDEPS  0.017414895
124         SKDEPS      ARRBUCKET  0.017414895
27      ARRRANKGRP      SKDARRSTA  0.016733374
167      SKDARRSTA     ARRRANKGRP  0.016733374
39       ARRBUCKET         SKDEQP  0.009926479
123         SKDEQP      ARRBUCKET  0.009926479
73        DEPSPOKE      AVGLOFATC -0.008540402
185      AVGLOFATC       DEPSPOKE -0.008540402
50       AVGLOFATC         SKDEPS  0.008240563
64          SKDEPS      AVGLOFATC  0.008240563
37    DEPSTAATCIMP         SKDEQP -0.005922601
93          SKDEQP   DEPSTAATCIMP -0.005922601
35       AVGLOFATC         SKDEQP -0.004889040
63          SKDEQP      AVGLOFATC -0.004889040
58        DEPSPOKE         SKDEPS -0.004617067
184         SKDEPS       DEPSPOKE -0.004617067
51    UPLINEATCIMP         SKDEPS  0.004016263
79          SKDEPS   UPLINEATCIMP  0.004016263
59          xDURN2         SKDEPS  0.001748012
199         SKDEPS         xDURN2  0.001748012
> 
> ### Models
> 
> ## Try GBM (gradient boosting). Works well for mixed data.
> ## And there is a tutorial for it with caret.
> 
> ## Training controller and big grid
> ## Check the ROC (my preferred.)
> 
> fitControl <- trainControl(## 10-fold CV
+     method = "repeatedcv",
+     number = 10,
+     ## repeated ten times
+     repeats = 10,
+     classProbs = 10,
+     summaryFunction = twoClassSummary)
> 
> ## Some trial and error with variables to branch and boost.
> ## I'm just going to try the airports and the planes and the duration
> ## of the flight. There may be some distance relationship there that
> ## air traffic control use.
> 
> ## Annoying because I drop variables, this needs to be looked up.
> 
> gbmGrid <- expand.grid(interaction.depth = c(1 2)
Error: unexpected numeric constant in "gbmGrid <- expand.grid(interaction.depth = c(1 2"
>                         n.trees = (1:30)*90,
Error: unexpected ',' in "                        n.trees = (1:30)*90,"
>                         shrinkage = 0.1,
Error: unexpected ',' in "                        shrinkage = 0.1,"
>                         n.minobsinnode = 20)
Error: unexpected ')' in "                        n.minobsinnode = 20)"
> 
> set.seed(seed.mine)
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "ROC",
+                  verbose = FALSE)
> gbmFit1
Stochastic Gradient Boosting 

248 samples
 15 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 222, 223, 223, 224, 223, 223, ... 

Resampling results across tuning parameters:

  interaction.depth  n.trees  ROC        Sens       Spec       ROC SD    
   1                   90     0.7643219  0.7415934  0.6851515  0.09342386
   1                  180     0.7621312  0.7221429  0.6730303  0.08681063
   1                  270     0.7574455  0.7093956  0.6800758  0.08724882
   1                  360     0.7474384  0.7067033  0.6775000  0.08827890
   1                  450     0.7438653  0.7044505  0.6748485  0.08808005
   1                  540     0.7422365  0.7101648  0.6812121  0.09091612
   1                  630     0.7364419  0.6993407  0.6651515  0.09203596
   1                  720     0.7320296  0.7036813  0.6641667  0.09451950
   1                  810     0.7301186  0.7014286  0.6596970  0.10201694
   1                  900     0.7292803  0.7043407  0.6460606  0.09889909
   1                  990     0.7289590  0.7041758  0.6478030  0.09745426
   1                 1080     0.7279587  0.6948352  0.6398485  0.08993976
   1                 1170     0.7196961  0.6947253  0.6433333  0.09978941
   1                 1260     0.7227631  0.7015385  0.6434091  0.09658595
   1                 1350     0.7222561  0.6971429  0.6480303  0.09412147
   1                 1440     0.7203159  0.6971978  0.6326515  0.09701813
   1                 1530     0.7205340  0.6949451  0.6344697  0.09430612
   1                 1620     0.7146787  0.6955495  0.6291667  0.10185174
   1                 1710     0.7172715  0.6978571  0.6272727  0.09554985
   1                 1800     0.7153484  0.7001099  0.6209848  0.09479830
   1                 1890     0.7160273  0.6948352  0.6255303  0.09431954
   1                 1980     0.7126940  0.6970879  0.6300000  0.09162042
   1                 2070     0.7155511  0.6948352  0.6255303  0.09180913
   1                 2160     0.7128318  0.6992857  0.6201515  0.08979713
   1                 2250     0.7112646  0.6971429  0.6153788  0.09182898
   1                 2340     0.7106843  0.6939011  0.6172727  0.09010350
   1                 2430     0.7084686  0.6954945  0.6146970  0.09232105
   1                 2520     0.7094709  0.6934066  0.6137121  0.09174979
   1                 2610     0.7057630  0.6876923  0.6110606  0.09489330
   1                 2700     0.7050079  0.6875275  0.6028788  0.09240526
   2                   90     0.7555057  0.7284066  0.6612121  0.09742733
   2                  180     0.7432900  0.7146154  0.6621970  0.09627458
   2                  270     0.7382526  0.6970330  0.6612879  0.09269873
   2                  360     0.7389785  0.6976923  0.6459848  0.08805561
   2                  450     0.7319439  0.6960989  0.6434091  0.09106913
   2                  540     0.7282026  0.6947253  0.6478788  0.09325268
   2                  630     0.7276819  0.6974725  0.6478788  0.08959146
   2                  720     0.7280270  0.6976374  0.6479545  0.08814763
   2                  810     0.7263894  0.7011538  0.6496212  0.09003344
   2                  900     0.7253151  0.6982418  0.6451515  0.08962388
   2                  990     0.7247856  0.6982418  0.6471212  0.08992613
   2                 1080     0.7216525  0.6997802  0.6418182  0.09042069
   2                 1170     0.7213245  0.6998352  0.6460606  0.09002499
   2                 1260     0.7198764  0.7012088  0.6426515  0.08851996
   2                 1350     0.7217287  0.6988462  0.6416667  0.08767276
   2                 1440     0.7201952  0.6960989  0.6362879  0.08836134
   2                 1530     0.7201490  0.6967582  0.6389394  0.08826530
   2                 1620     0.7195625  0.6966484  0.6307576  0.08711394
   2                 1710     0.7176107  0.6998352  0.6371212  0.08778549
   2                 1800     0.7169897  0.7005495  0.6343182  0.08632816
   2                 1890     0.7165639  0.6961538  0.6334848  0.08704274
   2                 1980     0.7155811  0.6996703  0.6308333  0.08728547
   2                 2070     0.7119639  0.7012088  0.6300758  0.09176820
   2                 2160     0.7120009  0.6975275  0.6300758  0.09360318
   2                 2250     0.7119963  0.7012088  0.6307576  0.09334071
   2                 2340     0.7131981  0.6982418  0.6272727  0.09352486
   2                 2430     0.7141384  0.6982967  0.6289394  0.08852563
   2                 2520     0.7140097  0.6975275  0.6333333  0.08796251
   2                 2610     0.7121591  0.6967582  0.6278788  0.09179107
   2                 2700     0.7090530  0.7004945  0.6241667  0.09701723
   3                   90     0.7511326  0.7183516  0.6675000  0.09262565
   3                  180     0.7413337  0.7036264  0.6531061  0.08773302
   3                  270     0.7335286  0.6998352  0.6441667  0.08802735
   3                  360     0.7319360  0.7007692  0.6521970  0.08888756
   3                  450     0.7291263  0.6935165  0.6375758  0.09026878
   3                  540     0.7271133  0.6870879  0.6502273  0.09299101
   3                  630     0.7242928  0.6942308  0.6458333  0.09081019
   3                  720     0.7222969  0.6944505  0.6423485  0.09012386
   3                  810     0.7166146  0.6941758  0.6485606  0.09537938
   3                  900     0.7159844  0.6943407  0.6440909  0.09754953
   3                  990     0.7150216  0.6901099  0.6412121  0.09707864
   3                 1080     0.7154808  0.6945055  0.6421212  0.09618932
   3                 1170     0.7152485  0.6898352  0.6376515  0.09612013
   3                 1260     0.7192208  0.6965385  0.6386364  0.08911705
   3                 1350     0.7146437  0.6921978  0.6403788  0.09418981
   3                 1440     0.7129033  0.6964835  0.6378788  0.09511030
   3                 1530     0.7126424  0.6965385  0.6359091  0.09493077
   3                 1620     0.7136056  0.7031868  0.6351515  0.09208612
   3                 1710     0.7136001  0.7001099  0.6368939  0.09155745
   3                 1800     0.7138399  0.6993956  0.6315152  0.08826725
   3                 1890     0.7132717  0.6973077  0.6378788  0.08608774
   3                 1980     0.7122086  0.6913736  0.6324242  0.09128655
   3                 2070     0.7113070  0.6966484  0.6315152  0.09117192
   3                 2160     0.7108512  0.6958242  0.6396970  0.09230643
   3                 2250     0.7104054  0.6994505  0.6324242  0.09370241
   3                 2340     0.7098477  0.6981319  0.6351515  0.09348064
   3                 2430     0.7097461  0.6966484  0.6359848  0.09349421
   3                 2520     0.7091159  0.6958791  0.6315909  0.09353454
   3                 2610     0.7094277  0.6958242  0.6378788  0.09300681
   3                 2700     0.7103850  0.6942857  0.6369697  0.09290170
  14                   90     0.7342075  0.7001648  0.6443939  0.09447364
  14                  180     0.7267100  0.6935714  0.6453788  0.08492706
  14                  270     0.7231027  0.6950549  0.6346970  0.09268773
  14                  360     0.7249051  0.6828022  0.6363636  0.09382124
  14                  450     0.7222765  0.6878571  0.6363636  0.09012556
  14                  540     0.7182900  0.6833516  0.6327273  0.09138839
  14                  630     0.7162492  0.6884066  0.6315909  0.09461709
  14                  720     0.7110872  0.6877473  0.6280303  0.09868732
  14                  810     0.7114998  0.6818681  0.6359848  0.09989133
  14                  900     0.7151486  0.6796703  0.6385606  0.09348598
  14                  990     0.7161605  0.6825824  0.6342424  0.09020401
  14                 1080     0.7140947  0.6812637  0.6332576  0.09418398
  14                 1170     0.7149671  0.6804396  0.6332576  0.09393224
  14                 1260     0.7143606  0.6825824  0.6332576  0.09443271
  14                 1350     0.7155524  0.6782967  0.6350758  0.09137243
  14                 1440     0.7159445  0.6789560  0.6386364  0.09184871
  14                 1530     0.7151432  0.6806044  0.6296212  0.09165875
  14                 1620     0.7142562  0.6784066  0.6341667  0.09256640
  14                 1710     0.7124867  0.6791209  0.6332576  0.09761728
  14                 1800     0.7142412  0.6783516  0.6332576  0.09387682
  14                 1890     0.7147072  0.6791209  0.6324242  0.09287353
  14                 1980     0.7149224  0.6792308  0.6341667  0.09235821
  14                 2070     0.7125427  0.6804396  0.6297727  0.09797209
  14                 2160     0.7126147  0.6834066  0.6325000  0.09610759
  14                 2250     0.7121218  0.6826374  0.6342424  0.09765399
  14                 2340     0.7120573  0.6825275  0.6315909  0.09710126
  14                 2430     0.7151168  0.6825824  0.6342424  0.09185722
  14                 2520     0.7147392  0.6855495  0.6351515  0.09220735
  14                 2610     0.7145831  0.6854396  0.6333333  0.09573773
  14                 2700     0.7145336  0.6876374  0.6351515  0.09545807
  Sens SD    Spec SD  
  0.1197499  0.1269327
  0.1193182  0.1363327
  0.1175406  0.1351588
  0.1237925  0.1324702
  0.1257005  0.1349134
  0.1299026  0.1252701
  0.1262736  0.1292664
  0.1303523  0.1363214
  0.1352591  0.1250107
  0.1288592  0.1250543
  0.1282663  0.1185304
  0.1260642  0.1172713
  0.1217472  0.1196606
  0.1230342  0.1235111
  0.1295050  0.1290843
  0.1321705  0.1272436
  0.1276318  0.1313898
  0.1228537  0.1406552
  0.1314848  0.1396776
  0.1225905  0.1367688
  0.1158197  0.1306637
  0.1220957  0.1258935
  0.1232856  0.1379245
  0.1213596  0.1354167
  0.1177671  0.1377041
  0.1168391  0.1466722
  0.1197568  0.1424761
  0.1185792  0.1366757
  0.1230586  0.1412797
  0.1213667  0.1373429
  0.1249485  0.1378313
  0.1343216  0.1387786
  0.1292923  0.1378490
  0.1208412  0.1359756
  0.1217631  0.1366789
  0.1219499  0.1453142
  0.1242279  0.1405237
  0.1209231  0.1414734
  0.1175951  0.1383950
  0.1196536  0.1287393
  0.1207849  0.1291505
  0.1219054  0.1269270
  0.1256043  0.1252673
  0.1171921  0.1171211
  0.1205752  0.1197953
  0.1211178  0.1268786
  0.1180940  0.1247858
  0.1207966  0.1279756
  0.1174284  0.1215298
  0.1163426  0.1276819
  0.1195971  0.1289376
  0.1173701  0.1263079
  0.1196462  0.1288174
  0.1165597  0.1320178
  0.1192147  0.1317302
  0.1156412  0.1257381
  0.1146411  0.1258026
  0.1185416  0.1288891
  0.1196205  0.1303706
  0.1221826  0.1348283
  0.1161620  0.1357026
  0.1227114  0.1260848
  0.1237700  0.1267688
  0.1238163  0.1260839
  0.1204180  0.1253489
  0.1155243  0.1264051
  0.1116530  0.1263974
  0.1135931  0.1256519
  0.1172843  0.1264915
  0.1197504  0.1215464
  0.1188515  0.1300734
  0.1166946  0.1277693
  0.1203871  0.1241002
  0.1130656  0.1224564
  0.1135557  0.1191108
  0.1136259  0.1218180
  0.1132300  0.1201786
  0.1128716  0.1179923
  0.1123793  0.1154119
  0.1149259  0.1206970
  0.1168985  0.1238568
  0.1154997  0.1251442
  0.1153656  0.1267690
  0.1193138  0.1197073
  0.1134658  0.1244753
  0.1123784  0.1207892
  0.1136371  0.1200220
  0.1139990  0.1211244
  0.1149319  0.1265241
  0.1133798  0.1242012
  0.1134221  0.1283023
  0.1261402  0.1340643
  0.1186319  0.1337391
  0.1260435  0.1268627
  0.1193040  0.1286911
  0.1189199  0.1352944
  0.1198971  0.1307497
  0.1219042  0.1327598
  0.1235156  0.1309346
  0.1209812  0.1320277
  0.1185377  0.1280637
  0.1207011  0.1284119
  0.1171399  0.1257847
  0.1157576  0.1322549
  0.1150243  0.1300714
  0.1157797  0.1257404
  0.1170147  0.1292569
  0.1176354  0.1310183
  0.1166136  0.1267900
  0.1155904  0.1227760
  0.1162417  0.1269471
  0.1194141  0.1284444
  0.1161150  0.1269113
  0.1184088  0.1206200
  0.1194660  0.1243337
  0.1162275  0.1243363
  0.1134372  0.1256693
  0.1165452  0.1212873
  0.1195662  0.1219417
  0.1167061  0.1212873

Tuning parameter 'shrinkage' was held constant at a value of 0.1

Tuning parameter 'n.minobsinnode' was held constant at a value of 10
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 90, interaction.depth =
 1, shrinkage = 0.1 and n.minobsinnode = 10. 
> 
> ## The acid test is dissapointing, but I've seen worse.
> 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
  Accuracy      Kappa 
0.56944444 0.05423729 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     37   28
    Weak        3    4
                                          
               Accuracy : 0.5694          
                 95% CI : (0.4473, 0.6857)
    No Information Rate : 0.5556          
    P-Value [Acc > NIR] : 0.4546          
                                          
                  Kappa : 0.0542          
 Mcnemar's Test P-Value : 1.629e-05       
                                          
            Sensitivity : 0.12500         
            Specificity : 0.92500         
         Pos Pred Value : 0.57143         
         Neg Pred Value : 0.56923         
             Prevalence : 0.44444         
         Detection Rate : 0.05556         
   Detection Prevalence : 0.09722         
      Balanced Accuracy : 0.52500         
                                          
       'Positive' Class : Weak            
                                          
> 
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
 Accuracy     Kappa 
0.7903226 0.5767085 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    110   25
    Weak       27   86
                                          
               Accuracy : 0.7903          
                 95% CI : (0.7343, 0.8393)
    No Information Rate : 0.5524          
    P-Value [Acc > NIR] : 3.997e-15       
                                          
                  Kappa : 0.5767          
 Mcnemar's Test P-Value : 0.8897          
                                          
            Sensitivity : 0.7748          
            Specificity : 0.8029          
         Pos Pred Value : 0.7611          
         Neg Pred Value : 0.8148          
             Prevalence : 0.4476          
         Detection Rate : 0.3468          
   Detection Prevalence : 0.4556          
      Balanced Accuracy : 0.7888          
                                          
       'Positive' Class : Weak            
                                          
> gbmGrid <- expand.grid(interaction.depth = 1,
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.1,
+                         n.minobsinnode = 20)
> ### weaves
> 
> ## Processing for flights data.
> 
> ## Following the caret vignette.
> 
> ###################################################
> ### code chunk number 1: loadLibs
> ###################################################
> library(MASS)
> library(caret)
> library(mlbench)
> library(pROC)
> library(pls)
> 
> library(doMC)
> registerDoMC(cores = 4)
> 
> options(useFancyQuotes = FALSE) 
> 
> # Accounting info.
> getInfo <- function(what = "Suggests")
+ {
+   text <- packageDescription("caret")[what][[1]]
+   text <- gsub("\n", ", ", text, fixed = TRUE)
+   text <- gsub(">=", "$\\\\ge$", text, fixed = TRUE)
+   eachPkg <- strsplit(text, ", ", fixed = TRUE)[[1]]
+   eachPkg <- gsub(",", "", eachPkg, fixed = TRUE)
+   # out <- paste("\\\\pkg{", eachPkg[order(tolower(eachPkg))], "}", sep = "")
+   # paste(out, collapse = ", ")
+   length(eachPkg)
+ }
> 
> ### project-specific: begin
> ## Set-seed, load original CSV file, order it
> ## and do some simple-cleaning
> ## Various datasets 
> 
> seed.mine = 107
> set.seed(seed.mine)                     # helpful for testing
> 
> flight <- read.csv("../bak/flight.csv")
> flight <- flight[order(flight$D00),]
> 
> # Backup
> flight.raw <- flight
> 
> # To check adjustment, there is test code in flight-nb.R
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"
> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"
> 
> # And some deletions
> 
> t.cols <- colnames(flight)
> 
> t.drops <- t.cols[grep("^RANK*", t.cols)]
> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])
> t.drops <- c(t.drops, "D80THPCTL")
> 
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR
> flight$xHNGR <- flight$xDURN < 0
> 
> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+ }
> 
> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))
> 
> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE
> t.cols <- colnames(flight)
> 
> t.drops <- c("SARRHR", "xDURN")
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Backup
> 
> flight00 <- flight
> 
> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]
> 
> paste("samples in use: ", dim(flight)[1])
[1] "samples in use:  320"
> 
> ## Data insights
> 
> ## *Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> flight <- flight1
> 
> ### Numeric variables
> 
> ### Try and impute the AVG, it might have more information than the
> ### bucket.
> 
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))
Error in `$<-.data.frame`(`*tmp*`, "xAVAILBUCKET", value = numeric(0)) : 
  replacement has 0 rows, data has 320
> 
> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1
> 
> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]
Error in `[.data.frame`(flight, , c("AVGSKDAVAIL", "xAVAILBUCKET")) : 
  undefined columns selected
> 
> preProcValues <- preProcess(flight.na, method = c("knnImpute"))
> flight.na1 <- predict(preProcValues, flight.na)
> 
> ## I'll add the new imputed value and drop the others
> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL
> flight$AVGSKDAVAIL <- NULL
> flight$xAVAILBUCKET <- NULL
> flight$AVAILBUCKET <- NULL
> 
> flight$xHNGR <- NULL
> 
> ## Check some more numeric correlations, I haven't scaled everything yet.
> ## I'd cut correlations above 0.65 to 0.75 because of overfitting.
> 
> x1 <- as.data.frame(as.matrix(sapply(flight, class)))
> 
> flight.num <- flight[,names(x1[which(x1$V1 %in% c("numeric", "integer")),])]
> 
> flight.nzv <- nearZeroVar(flight.num, saveMetrics = TRUE)
> flight.nzv
             freqRatio percentUnique zeroVar   nzv
SDEPHR        1.038462        5.9375   FALSE FALSE
SKDEPS        1.000000       19.0625   FALSE FALSE
D00           1.166667       75.3125   FALSE FALSE
AVGSQ         6.333333       82.8125   FALSE FALSE
AVGLOFATC     1.000000       78.4375   FALSE FALSE
xDURN2        1.428571        2.5000   FALSE FALSE
xAVGSKDAVAIL 18.500000       87.8125   FALSE FALSE
> 
> # annoying NA should be gone.
> flight.cor <- cor(flight.num, use = "pairwise.complete.obs")
> 
> descrCorr <- findCorrelation(flight.cor, cutoff = .65, verbose=TRUE)
Considering row	 4 column	 1 value	 0.956 
  Flagging column	 4 
Considering row	 1 column	 3 value	 0.43 
Considering row	 1 column	 7 value	 0.053 
Considering row	 1 column	 6 value	 0.204 
Considering row	 1 column	 5 value	 0.131 
Considering row	 1 column	 2 value	 0.054 
Considering row	 3 column	 7 value	 0.401 
Considering row	 3 column	 6 value	 0.071 
Considering row	 3 column	 5 value	 0.114 
Considering row	 3 column	 2 value	 0.006 
Considering row	 7 column	 6 value	 0.019 
Considering row	 7 column	 5 value	 0.07 
Considering row	 7 column	 2 value	 0.113 
Considering row	 6 column	 5 value	 0.137 
Considering row	 6 column	 2 value	 0.005 
Considering row	 5 column	 2 value	 0.041 
> 
> colnames(flight.num)[descrCorr]
[1] "AVGSQ"
> 
> ## And I'll leave the centered and scale values in for now.
> ## and delete the troublesome ones
> 
> ## Re-classing
> ## Check warnings to see it adjustment has taken place.
> ## We want the proportion in the training class to be about 0.55 0.45
> ## Strong to Weak
> ## I've achieved this heuristically
> src.adjust <- TRUE
> source(file = "flight1.R")
Warning message:
In eval(expr, envir, enclos) : adjusting
> flight1 <- flight
> 
> ## This should be deleted, leave it in and the results
> ## are ideal because it defines LEGTYPE.
> flight$D00 <- NULL
> 
> ## Keep the results but don't change the order.
> outcomes.flight <- flight$LEGTYPE
> 
> flight$LEGTYPE <- NULL
> 
> ## If you know your factors are definitely factors, you don't need this
> ##  asNumeric <- function(x) as.numeric(as.character(x))
> 
> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))
> 
> flight.num0 <- factors.numeric(flight)
> 
> flight.scl0 <- scale(flight.num0)
> 
> ## Now split the samples
> ## we need at least 60 to test with, p at 0.77 gives about 75.
> ## Difficulty here is the bias in the table
> ## Because we only have [3.1, 4.4] the proportion of Weak is higher.
> ## see prop.table(results)
> 
> set.seed(seed.mine)
> inTrain <- createDataPartition(outcomes.flight, p = 0.77, list = FALSE)
> 
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> 
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> 
> prop.table(table(trainClass))
trainClass
   Strong      Weak 
0.5524194 0.4475806 
> dim(trainDescr)
[1] 248  19
> 
> prop.table(table(testClass))
testClass
   Strong      Weak 
0.5555556 0.4444444 
> dim(testDescr)
[1] 72 19
> 
> ## Check Near-zero variance
> 
> nzv <- nearZeroVar(trainDescr, saveMetrics= TRUE)
> stopifnot( all(nzv$nzv == FALSE) )
> 
> # It's imputed and behaves well, no need for this.
> # descrCorr <- cor(scale(trainDescr), use = "pairwise.complete.obs")
> 
> descrCorr <- cor(scale(trainDescr))
> 
> ## This cut-off should be under src.adjust control.
> ## I'm under Git, so I can tinker with it.
> highCorr <- findCorrelation(descrCorr, cutoff = .95, verbose = TRUE)
Considering row	 17 column	 16 value	 0.85 
Considering row	 17 column	 10 value	 0.671 
Considering row	 17 column	 1 value	 0.279 
Considering row	 17 column	 11 value	 0.277 
Considering row	 17 column	 6 value	 0.22 
Considering row	 17 column	 12 value	 0.226 
Considering row	 17 column	 2 value	 0.298 
Considering row	 17 column	 9 value	 0.586 
Considering row	 17 column	 14 value	 0.226 
Considering row	 17 column	 13 value	 0.23 
Considering row	 17 column	 8 value	 0.541 
Considering row	 17 column	 3 value	 0.346 
Considering row	 17 column	 18 value	 0.261 
Considering row	 17 column	 19 value	 0.138 
Considering row	 17 column	 15 value	 0.057 
Considering row	 17 column	 4 value	 0.067 
Considering row	 17 column	 7 value	 0.034 
Considering row	 17 column	 5 value	 0.018 
Considering row	 16 column	 10 value	 0.568 
Considering row	 16 column	 1 value	 0.236 
Considering row	 16 column	 11 value	 0.231 
Considering row	 16 column	 6 value	 0.189 
Considering row	 16 column	 12 value	 0.19 
Considering row	 16 column	 2 value	 0.333 
Considering row	 16 column	 9 value	 0.671 
Considering row	 16 column	 14 value	 0.242 
Considering row	 16 column	 13 value	 0.208 
Considering row	 16 column	 8 value	 0.6 
Considering row	 16 column	 3 value	 0.318 
Considering row	 16 column	 18 value	 0.279 
Considering row	 16 column	 19 value	 0.213 
Considering row	 16 column	 15 value	 0.083 
Considering row	 16 column	 4 value	 0.02 
Considering row	 16 column	 7 value	 0.009 
Considering row	 16 column	 5 value	 0.005 
Considering row	 10 column	 1 value	 0.281 
Considering row	 10 column	 11 value	 0.275 
Considering row	 10 column	 6 value	 0.298 
Considering row	 10 column	 12 value	 0.255 
Considering row	 10 column	 2 value	 0.286 
Considering row	 10 column	 9 value	 0.404 
Considering row	 10 column	 14 value	 0.224 
Considering row	 10 column	 13 value	 0.199 
Considering row	 10 column	 8 value	 0.366 
Considering row	 10 column	 3 value	 0.462 
Considering row	 10 column	 18 value	 0.226 
Considering row	 10 column	 19 value	 0.103 
Considering row	 10 column	 15 value	 0.274 
Considering row	 10 column	 4 value	 0.018 
Considering row	 10 column	 7 value	 0.127 
Considering row	 10 column	 5 value	 0.096 
Considering row	 1 column	 11 value	 0.988 
  Flagging column	 1 
Considering row	 11 column	 6 value	 0.945 
Considering row	 11 column	 12 value	 0.889 
Considering row	 11 column	 2 value	 0.165 
Considering row	 11 column	 9 value	 0.139 
Considering row	 11 column	 14 value	 0.171 
Considering row	 11 column	 13 value	 0.156 
Considering row	 11 column	 8 value	 0.145 
Considering row	 11 column	 3 value	 0.073 
Considering row	 11 column	 18 value	 0.183 
Considering row	 11 column	 19 value	 0.053 
Considering row	 11 column	 15 value	 0.142 
Considering row	 11 column	 4 value	 0.037 
Considering row	 11 column	 7 value	 0.053 
Considering row	 11 column	 5 value	 0.03 
Considering row	 6 column	 12 value	 0.883 
Considering row	 6 column	 2 value	 0.151 
Considering row	 6 column	 9 value	 0.04 
Considering row	 6 column	 14 value	 0.188 
Considering row	 6 column	 13 value	 0.161 
Considering row	 6 column	 8 value	 0.063 
Considering row	 6 column	 3 value	 0.083 
Considering row	 6 column	 18 value	 0.197 
Considering row	 6 column	 19 value	 0.114 
Considering row	 6 column	 15 value	 0.159 
Considering row	 6 column	 4 value	 0.01 
Considering row	 6 column	 7 value	 0.027 
Considering row	 6 column	 5 value	 0.039 
Considering row	 12 column	 2 value	 0.121 
Considering row	 12 column	 9 value	 0.128 
Considering row	 12 column	 14 value	 0.092 
Considering row	 12 column	 13 value	 0.105 
Considering row	 12 column	 8 value	 0.071 
Considering row	 12 column	 3 value	 0.093 
Considering row	 12 column	 18 value	 0.126 
Considering row	 12 column	 19 value	 0.171 
Considering row	 12 column	 15 value	 0.13 
Considering row	 12 column	 4 value	 0.01 
Considering row	 12 column	 7 value	 0.043 
Considering row	 12 column	 5 value	 0.017 
Considering row	 2 column	 9 value	 0.423 
Considering row	 2 column	 14 value	 0.574 
Considering row	 2 column	 13 value	 0.557 
Considering row	 2 column	 8 value	 0.165 
Considering row	 2 column	 3 value	 0.263 
Considering row	 2 column	 18 value	 0.128 
Considering row	 2 column	 19 value	 0.089 
Considering row	 2 column	 15 value	 0.069 
Considering row	 2 column	 4 value	 0.27 
Considering row	 2 column	 7 value	 0.045 
Considering row	 2 column	 5 value	 0.024 
Considering row	 9 column	 14 value	 0.147 
Considering row	 9 column	 13 value	 0.125 
Considering row	 9 column	 8 value	 0.449 
Considering row	 9 column	 3 value	 0.322 
Considering row	 9 column	 18 value	 0.018 
Considering row	 9 column	 19 value	 0.141 
Considering row	 9 column	 15 value	 0.073 
Considering row	 9 column	 4 value	 0.006 
Considering row	 9 column	 7 value	 0.136 
Considering row	 9 column	 5 value	 0.123 
Considering row	 14 column	 13 value	 0.659 
Considering row	 14 column	 8 value	 0.097 
Considering row	 14 column	 3 value	 0.106 
Considering row	 14 column	 18 value	 0.361 
Considering row	 14 column	 19 value	 0.092 
Considering row	 14 column	 15 value	 0.084 
Considering row	 14 column	 4 value	 0.263 
Considering row	 14 column	 7 value	 0.139 
Considering row	 14 column	 5 value	 0.031 
Considering row	 13 column	 8 value	 0.097 
Considering row	 13 column	 3 value	 0.167 
Considering row	 13 column	 18 value	 0.18 
Considering row	 13 column	 19 value	 0.131 
Considering row	 13 column	 15 value	 0.137 
Considering row	 13 column	 4 value	 0.24 
Considering row	 13 column	 7 value	 0.085 
Considering row	 13 column	 5 value	 0.027 
Considering row	 8 column	 3 value	 0.224 
Considering row	 8 column	 18 value	 0.173 
Considering row	 8 column	 19 value	 0.235 
Considering row	 8 column	 15 value	 0.07 
Considering row	 8 column	 4 value	 0.02 
Considering row	 8 column	 7 value	 0.085 
Considering row	 8 column	 5 value	 0.004 
Considering row	 3 column	 18 value	 0.028 
Considering row	 3 column	 19 value	 0.027 
Considering row	 3 column	 15 value	 0.017 
Considering row	 3 column	 4 value	 0.094 
Considering row	 3 column	 7 value	 0.095 
Considering row	 3 column	 5 value	 0.097 
Considering row	 18 column	 19 value	 0.019 
Considering row	 18 column	 15 value	 0.12 
Considering row	 18 column	 4 value	 0.086 
Considering row	 18 column	 7 value	 0.132 
Considering row	 18 column	 5 value	 0.002 
Considering row	 19 column	 15 value	 0.019 
Considering row	 19 column	 4 value	 0.032 
Considering row	 19 column	 7 value	 0.056 
Considering row	 19 column	 5 value	 0.075 
Considering row	 15 column	 4 value	 0.043 
Considering row	 15 column	 7 value	 0.061 
Considering row	 15 column	 5 value	 0.08 
Considering row	 4 column	 7 value	 0.005 
Considering row	 4 column	 5 value	 0.213 
Considering row	 7 column	 5 value	 0.008 
> 
> colnames(trainDescr)[highCorr]
[1] "SDEPHR"
> 
> descr.ncol0 <- ncol(trainDescr)
> 
> # I've switched off the correlation remover and the results are better.
> if (sum(highCorr) > 0) {
+     warning("overfitting: correlations: err.trainDescr: ", paste(colnames(trainDescr)[highCorr], collapse = ", ") )
+     err.trainDescr <- trainDescr
+     trainDescr <- trainDescr[,-highCorr]
+ }
Warning message:
overfitting: correlations: err.trainDescr: SDEPHR 
> 
> descr.ncol1 <- ncol(trainDescr)
> 
> paste("Dropped: ", as.character(descr.ncol0 - descr.ncol1))
[1] "Dropped:  1"
> 
> descrCorr <- cor(trainDescr)
> summary(descrCorr[upper.tri(descrCorr)])
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
-0.85020 -0.13860 -0.01766  0.01577  0.11970  0.94490 
> 
> ## Dominant correlations
> ## At 0.9, there are some big ones that might need re-thinking.
> 
> table.descrCorr <- as.data.frame(as.table(descrCorr))
> table.descrCorr <- table.descrCorr[which(table.descrCorr$Var1 != table.descrCorr$Var2),]
> table.descrCorr[order(abs(table.descrCorr$Freq), decreasing = TRUE),]
              Var1           Var2         Freq
82       DEPBUCKET          AVGSQ  0.944870657
167          AVGSQ      DEPBUCKET  0.944870657
173      ARRBUCKET      DEPBUCKET  0.889095737
190      DEPBUCKET      ARRBUCKET  0.889095737
83       ARRBUCKET          AVGSQ  0.882590635
185          AVGSQ      ARRBUCKET  0.882590635
268       ARRSPOKE       DEPSPOKE -0.850165355
285       DEPSPOKE       ARRSPOKE -0.850165355
141       DEPSPOKE   DEPSTAATCIMP  0.671264566
260   DEPSTAATCIMP       DEPSPOKE  0.671264566
160       ARRSPOKE DOWNLINEATCIMP  0.671009330
279 DOWNLINEATCIMP       ARRSPOKE  0.671009330
211     TRNRANKGRP     DEPRANKGRP  0.658724662
228     DEPRANKGRP     TRNRANKGRP  0.658724662
123       DEPSPOKE   UPLINEATCIMP -0.600008252
259   UPLINEATCIMP       DEPSPOKE -0.600008252
142       ARRSPOKE   DEPSTAATCIMP -0.586442959
278   DEPSTAATCIMP       ARRSPOKE -0.586442959
13      TRNRANKGRP      SKDDEPSTA  0.574035134
217      SKDDEPSTA     TRNRANKGRP  0.574035134
159       DEPSPOKE DOWNLINEATCIMP -0.567682494
261 DOWNLINEATCIMP       DEPSPOKE -0.567682494
12      DEPRANKGRP      SKDDEPSTA  0.557399203
199      SKDDEPSTA     DEPRANKGRP  0.557399203
124       ARRSPOKE   UPLINEATCIMP  0.540734833
277   UPLINEATCIMP       ARRSPOKE  0.540734833
27  DOWNLINEATCIMP      SKDARRSTA  0.462378131
146      SKDARRSTA DOWNLINEATCIMP  0.462378131
116   DEPSTAATCIMP   UPLINEATCIMP -0.449249986
133   UPLINEATCIMP   DEPSTAATCIMP -0.449249986
8     DEPSTAATCIMP      SKDDEPSTA  0.423425796
127      SKDDEPSTA   DEPSTAATCIMP  0.423425796
135 DOWNLINEATCIMP   DEPSTAATCIMP -0.403695561
152   DEPSTAATCIMP DOWNLINEATCIMP -0.403695561
117 DOWNLINEATCIMP   UPLINEATCIMP  0.365833687
151   UPLINEATCIMP DOWNLINEATCIMP  0.365833687
233         xDURN2     TRNRANKGRP  0.361347207
301     TRNRANKGRP         xDURN2  0.361347207
34        ARRSPOKE      SKDARRSTA  0.345987375
272      SKDARRSTA       ARRSPOKE  0.345987375
15        DEPSPOKE      SKDDEPSTA  0.332823310
253      SKDDEPSTA       DEPSPOKE  0.332823310
26    DEPSTAATCIMP      SKDARRSTA -0.322204878
128      SKDARRSTA   DEPSTAATCIMP -0.322204878
33        DEPSPOKE      SKDARRSTA -0.318093195
254      SKDARRSTA       DEPSPOKE -0.318093195
81  DOWNLINEATCIMP          AVGSQ  0.298096458
149          AVGSQ DOWNLINEATCIMP  0.298096458
16        ARRSPOKE      SKDDEPSTA -0.298036487
271      SKDDEPSTA       ARRSPOKE -0.298036487
9   DOWNLINEATCIMP      SKDDEPSTA -0.285911992
145      SKDDEPSTA DOWNLINEATCIMP -0.285911992
269         xDURN2       DEPSPOKE  0.279030910
303       DEPSPOKE         xDURN2  0.279030910
178       ARRSPOKE      DEPBUCKET  0.276615722
280      DEPBUCKET       ARRSPOKE  0.276615722
154      DEPBUCKET DOWNLINEATCIMP  0.275167866
171 DOWNLINEATCIMP      DEPBUCKET  0.275167866
158     ARRRANKGRP DOWNLINEATCIMP -0.274110143
243 DOWNLINEATCIMP     ARRRANKGRP -0.274110143
3           SKDEQP      SKDDEPSTA  0.270065872
37       SKDDEPSTA         SKDEQP  0.270065872
2        SKDARRSTA      SKDDEPSTA -0.263453106
19       SKDDEPSTA      SKDARRSTA -0.263453106
49      TRNRANKGRP         SKDEQP  0.262837233
219         SKDEQP     TRNRANKGRP  0.262837233
287         xDURN2       ARRSPOKE -0.261107447
304       ARRSPOKE         xDURN2 -0.261107447
155      ARRBUCKET DOWNLINEATCIMP  0.255480148
189 DOWNLINEATCIMP      ARRBUCKET  0.255480148
231       DEPSPOKE     TRNRANKGRP  0.242138220
265     TRNRANKGRP       DEPSPOKE  0.242138220
48      DEPRANKGRP         SKDEQP  0.239915140
201         SKDEQP     DEPRANKGRP  0.239915140
126   xAVGSKDAVAIL   UPLINEATCIMP  0.234867014
313   UPLINEATCIMP   xAVGSKDAVAIL  0.234867014
177       DEPSPOKE      DEPBUCKET -0.231298301
262      DEPBUCKET       DEPSPOKE -0.231298301
214       ARRSPOKE     DEPRANKGRP -0.229640758
282     DEPRANKGRP       ARRSPOKE -0.229640758
161         xDURN2 DOWNLINEATCIMP -0.226093423
297 DOWNLINEATCIMP         xDURN2 -0.226093423
196       ARRSPOKE      ARRBUCKET  0.225890655
281      ARRBUCKET       ARRSPOKE  0.225890655
232       ARRSPOKE     TRNRANKGRP -0.225591539
283     TRNRANKGRP       ARRSPOKE -0.225591539
157     TRNRANKGRP DOWNLINEATCIMP -0.224193213
225 DOWNLINEATCIMP     TRNRANKGRP -0.224193213
25    UPLINEATCIMP      SKDARRSTA  0.223824406
110      SKDARRSTA   UPLINEATCIMP  0.223824406
88        ARRSPOKE          AVGSQ  0.219975654
275          AVGSQ       ARRSPOKE  0.219975654
270   xAVGSKDAVAIL       DEPSPOKE -0.212821518
321       DEPSPOKE   xAVGSKDAVAIL -0.212821518
40          SKDEPS         SKDEQP  0.212586898
57          SKDEQP         SKDEPS  0.212586898
213       DEPSPOKE     DEPRANKGRP  0.208188512
264     DEPRANKGRP       DEPSPOKE  0.208188512
156     DEPRANKGRP DOWNLINEATCIMP -0.199411990
207 DOWNLINEATCIMP     DEPRANKGRP -0.199411990
89          xDURN2          AVGSQ -0.197447957
293          AVGSQ         xDURN2 -0.197447957
195       DEPSPOKE      ARRBUCKET -0.189934966
263      ARRBUCKET       DEPSPOKE -0.189934966
87        DEPSPOKE          AVGSQ -0.188666787
257          AVGSQ       DEPSPOKE -0.188666787
85      TRNRANKGRP          AVGSQ -0.188226304
221          AVGSQ     TRNRANKGRP -0.188226304
179         xDURN2      DEPBUCKET -0.183349624
298      DEPBUCKET         xDURN2 -0.183349624
215         xDURN2     DEPRANKGRP  0.180043357
300     DEPRANKGRP         xDURN2  0.180043357
125         xDURN2   UPLINEATCIMP -0.173240320
295   UPLINEATCIMP         xDURN2 -0.173240320
198   xAVGSKDAVAIL      ARRBUCKET -0.170644257
317      ARRBUCKET   xAVGSKDAVAIL -0.170644257
175     TRNRANKGRP      DEPBUCKET -0.170618431
226      DEPBUCKET     TRNRANKGRP -0.170618431
30      DEPRANKGRP      SKDARRSTA -0.167375913
200      SKDARRSTA     DEPRANKGRP -0.167375913
10       DEPBUCKET      SKDDEPSTA -0.165029385
163      SKDDEPSTA      DEPBUCKET -0.165029385
7     UPLINEATCIMP      SKDDEPSTA -0.164964952
109      SKDDEPSTA   UPLINEATCIMP -0.164964952
84      DEPRANKGRP          AVGSQ -0.161451853
203          AVGSQ     DEPRANKGRP -0.161451853
86      ARRRANKGRP          AVGSQ -0.159135469
239          AVGSQ     ARRRANKGRP -0.159135469
174     DEPRANKGRP      DEPBUCKET -0.155547085
208      DEPBUCKET     DEPRANKGRP -0.155547085
5            AVGSQ      SKDDEPSTA -0.150522366
73       SKDDEPSTA          AVGSQ -0.150522366
139     TRNRANKGRP   DEPSTAATCIMP -0.147409309
224   DEPSTAATCIMP     TRNRANKGRP -0.147409309
118      DEPBUCKET   UPLINEATCIMP  0.144940797
169   UPLINEATCIMP      DEPBUCKET  0.144940797
176     ARRRANKGRP      DEPBUCKET -0.142348062
244      DEPBUCKET     ARRRANKGRP -0.142348062
144   xAVGSKDAVAIL   DEPSTAATCIMP -0.141077194
314   DEPSTAATCIMP   xAVGSKDAVAIL -0.141077194
103     TRNRANKGRP      AVGLOFATC  0.139184315
222      AVGLOFATC     TRNRANKGRP  0.139184315
136      DEPBUCKET   DEPSTAATCIMP -0.138581846
170   DEPSTAATCIMP      DEPBUCKET -0.138581846
288   xAVGSKDAVAIL       ARRSPOKE  0.137677242
322       ARRSPOKE   xAVGSKDAVAIL  0.137677242
212     ARRRANKGRP     DEPRANKGRP  0.136562948
246     DEPRANKGRP     ARRRANKGRP  0.136562948
98    DEPSTAATCIMP      AVGLOFATC -0.135778614
132      AVGLOFATC   DEPSTAATCIMP -0.135778614
107         xDURN2      AVGLOFATC -0.132084629
294      AVGLOFATC         xDURN2 -0.132084629
216   xAVGSKDAVAIL     DEPRANKGRP  0.130574789
318     DEPRANKGRP   xAVGSKDAVAIL  0.130574789
194     ARRRANKGRP      ARRBUCKET -0.129698517
245      ARRBUCKET     ARRRANKGRP -0.129698517
137      ARRBUCKET   DEPSTAATCIMP -0.127726148
188   DEPSTAATCIMP      ARRBUCKET -0.127726148
17          xDURN2      SKDDEPSTA  0.127598189
289      SKDDEPSTA         xDURN2  0.127598189
99  DOWNLINEATCIMP      AVGLOFATC -0.126763572
150      AVGLOFATC DOWNLINEATCIMP -0.126763572
197         xDURN2      ARRBUCKET -0.125836459
299      ARRBUCKET         xDURN2 -0.125836459
138     DEPRANKGRP   DEPSTAATCIMP  0.124672682
206   DEPSTAATCIMP     DEPRANKGRP  0.124672682
62    DEPSTAATCIMP         SKDEPS -0.123445793
130         SKDEPS   DEPSTAATCIMP -0.123445793
11       ARRBUCKET      SKDDEPSTA -0.120728212
181      SKDDEPSTA      ARRBUCKET -0.120728212
251         xDURN2     ARRRANKGRP  0.119675180
302     ARRRANKGRP         xDURN2  0.119675180
90    xAVGSKDAVAIL          AVGSQ -0.113720147
311          AVGSQ   xAVGSKDAVAIL -0.113720147
31      TRNRANKGRP      SKDARRSTA -0.105802023
218      SKDARRSTA     TRNRANKGRP -0.105802023
192     DEPRANKGRP      ARRBUCKET -0.105057984
209      ARRBUCKET     DEPRANKGRP -0.105057984
162   xAVGSKDAVAIL DOWNLINEATCIMP  0.102577364
315 DOWNLINEATCIMP   xAVGSKDAVAIL  0.102577364
120     DEPRANKGRP   UPLINEATCIMP -0.097218129
205   UPLINEATCIMP     DEPRANKGRP -0.097218129
121     TRNRANKGRP   UPLINEATCIMP -0.097037814
223   UPLINEATCIMP     TRNRANKGRP -0.097037814
22          SKDEPS      SKDARRSTA -0.096699169
56       SKDARRSTA         SKDEPS -0.096699169
63  DOWNLINEATCIMP         SKDEPS -0.095568613
148         SKDEPS DOWNLINEATCIMP -0.095568613
24       AVGLOFATC      SKDARRSTA -0.095234466
92       SKDARRSTA      AVGLOFATC -0.095234466
21          SKDEQP      SKDARRSTA  0.094073459
38       SKDARRSTA         SKDEQP  0.094073459
29       ARRBUCKET      SKDARRSTA  0.092625400
182      SKDARRSTA      ARRBUCKET  0.092625400
193     TRNRANKGRP      ARRBUCKET -0.092415252
227      ARRBUCKET     TRNRANKGRP -0.092415252
234   xAVGSKDAVAIL     TRNRANKGRP  0.092011501
319     TRNRANKGRP   xAVGSKDAVAIL  0.092011501
18    xAVGSKDAVAIL      SKDDEPSTA  0.088580325
307      SKDDEPSTA   xAVGSKDAVAIL  0.088580325
53          xDURN2         SKDEQP  0.086170070
291         SKDEQP         xDURN2  0.086170070
102     DEPRANKGRP      AVGLOFATC  0.085474019
204      AVGLOFATC     DEPRANKGRP  0.085474019
97    UPLINEATCIMP      AVGLOFATC -0.085180887
114      AVGLOFATC   UPLINEATCIMP -0.085180887
230     ARRRANKGRP     TRNRANKGRP  0.083906762
247     TRNRANKGRP     ARRRANKGRP  0.083906762
249       DEPSPOKE     ARRRANKGRP  0.083162083
266     ARRRANKGRP       DEPSPOKE  0.083162083
23           AVGSQ      SKDARRSTA  0.082898864
74       SKDARRSTA          AVGSQ  0.082898864
68      ARRRANKGRP         SKDEPS  0.080398834
238         SKDEPS     ARRRANKGRP  0.080398834
72    xAVGSKDAVAIL         SKDEPS  0.075169577
310         SKDEPS   xAVGSKDAVAIL  0.075169577
140     ARRRANKGRP   DEPSTAATCIMP  0.073371196
242   DEPSTAATCIMP     ARRRANKGRP  0.073371196
28       DEPBUCKET      SKDARRSTA  0.072910977
164      SKDARRSTA      DEPBUCKET  0.072910977
119      ARRBUCKET   UPLINEATCIMP  0.071409699
187   UPLINEATCIMP      ARRBUCKET  0.071409699
122     ARRRANKGRP   UPLINEATCIMP -0.069790367
241   UPLINEATCIMP     ARRRANKGRP -0.069790367
14      ARRRANKGRP      SKDDEPSTA  0.068927801
235      SKDDEPSTA     ARRRANKGRP  0.068927801
52        ARRSPOKE         SKDEQP  0.066579707
273         SKDEQP       ARRSPOKE  0.066579707
79    UPLINEATCIMP          AVGSQ  0.062631172
113          AVGSQ   UPLINEATCIMP  0.062631172
104     ARRRANKGRP      AVGLOFATC -0.061491190
240      AVGLOFATC     ARRRANKGRP -0.061491190
250       ARRSPOKE     ARRRANKGRP -0.057002549
284     ARRRANKGRP       ARRSPOKE -0.057002549
108   xAVGSKDAVAIL      AVGLOFATC -0.056264979
312      AVGLOFATC   xAVGSKDAVAIL -0.056264979
100      DEPBUCKET      AVGLOFATC -0.053357134
168      AVGLOFATC      DEPBUCKET -0.053357134
180   xAVGSKDAVAIL      DEPBUCKET -0.053125467
316      DEPBUCKET   xAVGSKDAVAIL -0.053125467
6        AVGLOFATC      SKDDEPSTA -0.044946507
91       SKDDEPSTA      AVGLOFATC -0.044946507
101      ARRBUCKET      AVGLOFATC -0.043093769
186      AVGLOFATC      ARRBUCKET -0.043093769
50      ARRRANKGRP         SKDEQP -0.042512956
237         SKDEQP     ARRRANKGRP -0.042512956
80    DEPSTAATCIMP          AVGSQ -0.040428658
131          AVGSQ   DEPSTAATCIMP -0.040428658
59           AVGSQ         SKDEPS -0.038820886
76          SKDEPS          AVGSQ -0.038820886
46       DEPBUCKET         SKDEQP  0.037125178
165         SKDEQP      DEPBUCKET  0.037125178
106       ARRSPOKE      AVGLOFATC -0.034402462
276      AVGLOFATC       ARRSPOKE -0.034402462
54    xAVGSKDAVAIL         SKDEQP  0.031863410
309         SKDEQP   xAVGSKDAVAIL  0.031863410
67      TRNRANKGRP         SKDEPS  0.030883560
220         SKDEPS     TRNRANKGRP  0.030883560
64       DEPBUCKET         SKDEPS -0.030101407
166         SKDEPS      DEPBUCKET -0.030101407
35          xDURN2      SKDARRSTA  0.027576751
290      SKDARRSTA         xDURN2  0.027576751
78       AVGLOFATC          AVGSQ -0.027382453
95           AVGSQ      AVGLOFATC -0.027382453
36    xAVGSKDAVAIL      SKDARRSTA  0.027225219
308      SKDARRSTA   xAVGSKDAVAIL  0.027225219
66      DEPRANKGRP         SKDEPS  0.027025501
202         SKDEPS     DEPRANKGRP  0.027025501
4           SKDEPS      SKDDEPSTA -0.024267794
55       SKDDEPSTA         SKDEPS -0.024267794
43    UPLINEATCIMP         SKDEQP -0.019807499
111         SKDEQP   UPLINEATCIMP -0.019807499
51        DEPSPOKE         SKDEQP  0.019755644
255         SKDEQP       DEPSPOKE  0.019755644
306   xAVGSKDAVAIL         xDURN2 -0.019255572
323         xDURN2   xAVGSKDAVAIL -0.019255572
252   xAVGSKDAVAIL     ARRRANKGRP -0.018743432
320     ARRRANKGRP   xAVGSKDAVAIL -0.018743432
143         xDURN2   DEPSTAATCIMP -0.017999758
296   DEPSTAATCIMP         xDURN2 -0.017999758
45  DOWNLINEATCIMP         SKDEQP -0.017658860
147         SKDEQP DOWNLINEATCIMP -0.017658860
70        ARRSPOKE         SKDEPS  0.017573485
274         SKDEPS       ARRSPOKE  0.017573485
65       ARRBUCKET         SKDEPS  0.017414895
184         SKDEPS      ARRBUCKET  0.017414895
32      ARRRANKGRP      SKDARRSTA  0.016733374
236      SKDARRSTA     ARRRANKGRP  0.016733374
41           AVGSQ         SKDEQP  0.010218807
75          SKDEQP          AVGSQ  0.010218807
47       ARRBUCKET         SKDEQP  0.009926479
183         SKDEQP      ARRBUCKET  0.009926479
105       DEPSPOKE      AVGLOFATC -0.008540402
258      AVGLOFATC       DEPSPOKE -0.008540402
60       AVGLOFATC         SKDEPS  0.008240563
94          SKDEPS      AVGLOFATC  0.008240563
44    DEPSTAATCIMP         SKDEQP -0.005922601
129         SKDEQP   DEPSTAATCIMP -0.005922601
42       AVGLOFATC         SKDEQP -0.004889040
93          SKDEQP      AVGLOFATC -0.004889040
69        DEPSPOKE         SKDEPS -0.004617067
256         SKDEPS       DEPSPOKE -0.004617067
61    UPLINEATCIMP         SKDEPS  0.004016263
112         SKDEPS   UPLINEATCIMP  0.004016263
71          xDURN2         SKDEPS  0.001748012
292         SKDEPS         xDURN2  0.001748012
> 
> ### Models
> 
> ## Try GBM (gradient boosting). Works well for mixed data.
> ## And there is a tutorial for it with caret.
> 
> ## Training controller and big grid
> ## Check the ROC (my preferred.)
> 
> fitControl <- trainControl(## 10-fold CV
+     method = "repeatedcv",
+     number = 10,
+     ## repeated ten times
+     repeats = 10,
+     classProbs = 10,
+     summaryFunction = twoClassSummary)
> 
> ## Some trial and error with variables to branch and boost.
> ## I'm just going to try the airports and the planes and the duration
> ## of the flight. There may be some distance relationship there that
> ## air traffic control use.
> 
> ## Annoying because I drop variables, this needs to be looked up.
> 
> gbmGrid <- expand.grid(interaction.depth = 1,
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.1,
+                         n.minobsinnode = 20)
> 
> set.seed(seed.mine)
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "ROC",
+                  verbose = FALSE)
> gbmFit1
Stochastic Gradient Boosting 

248 samples
 18 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 222, 223, 223, 224, 223, 223, ... 

Resampling results across tuning parameters:

  n.trees  ROC        Sens       Spec       ROC SD      Sens SD    Spec SD  
    90     0.7844102  0.7505495  0.6935606  0.08847171  0.1190335  0.1317291
   180     0.7831976  0.7453846  0.6975000  0.08451674  0.1182630  0.1225073
   270     0.7791309  0.7382418  0.6912121  0.08776850  0.1206330  0.1307651
   360     0.7770009  0.7302198  0.6930303  0.08929870  0.1224096  0.1238216
   450     0.7735823  0.7332418  0.6902273  0.09255786  0.1258849  0.1329274
   540     0.7694439  0.7284066  0.6815152  0.09414443  0.1298319  0.1378895
   630     0.7677031  0.7340110  0.6868182  0.09790919  0.1276882  0.1403286
   720     0.7670850  0.7404945  0.6806061  0.09774108  0.1278213  0.1381281
   810     0.7658100  0.7405495  0.6797727  0.09936719  0.1276439  0.1414463
   900     0.7679795  0.7337912  0.6861364  0.09723653  0.1257080  0.1391089
   990     0.7655782  0.7360989  0.6843182  0.09691749  0.1283251  0.1395367
  1080     0.7625583  0.7344505  0.6840909  0.09621306  0.1221041  0.1330739
  1170     0.7615047  0.7283516  0.6815909  0.09698535  0.1147800  0.1353072
  1260     0.7613320  0.7335714  0.6824242  0.09691666  0.1223547  0.1322531
  1350     0.7593032  0.7307143  0.6771212  0.09452328  0.1195945  0.1396310
  1440     0.7609220  0.7291758  0.6743182  0.09793313  0.1267634  0.1366206
  1530     0.7607085  0.7283516  0.6706061  0.09566874  0.1250268  0.1286707
  1620     0.7597490  0.7254945  0.6699242  0.09295570  0.1214075  0.1384363
  1710     0.7598818  0.7227473  0.6844697  0.09409905  0.1247682  0.1409311
  1800     0.7580478  0.7225824  0.6787879  0.09569533  0.1170195  0.1372746
  1890     0.7579308  0.7232418  0.6753030  0.09587510  0.1205423  0.1364105
  1980     0.7584923  0.7268681  0.6743939  0.09608456  0.1195991  0.1411761
  2070     0.7562729  0.7269780  0.6745455  0.09374598  0.1160256  0.1432426
  2160     0.7565335  0.7224725  0.6779545  0.09404268  0.1179669  0.1392182
  2250     0.7558650  0.7234066  0.6769697  0.09470526  0.1167083  0.1346675
  2340     0.7529920  0.7195604  0.6743182  0.09543368  0.1220863  0.1434189
  2430     0.7540368  0.7174176  0.6779545  0.09539278  0.1248069  0.1350543
  2520     0.7538561  0.7211538  0.6716667  0.09548279  0.1222447  0.1329114
  2610     0.7525191  0.7188462  0.6690909  0.09501851  0.1220392  0.1413070
  2700     0.7510456  0.7159341  0.6726515  0.09865087  0.1213060  0.1392715

Tuning parameter 'interaction.depth' was held constant at a value of 1

Tuning parameter 'shrinkage' was held constant at a value of 0.1

Tuning parameter 'n.minobsinnode' was held constant at a value of 20
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 90, interaction.depth =
 1, shrinkage = 0.1 and n.minobsinnode = 20. 
> 
> ## The acid test is dissapointing, but I've seen worse.
> 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
   Accuracy       Kappa 
 0.48611111 -0.06389776 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     25   22
    Weak       15   10
                                          
               Accuracy : 0.4861          
                 95% CI : (0.3665, 0.6069)
    No Information Rate : 0.5556          
    P-Value [Acc > NIR] : 0.9036          
                                          
                  Kappa : -0.0639         
 Mcnemar's Test P-Value : 0.3239          
                                          
            Sensitivity : 0.3125          
            Specificity : 0.6250          
         Pos Pred Value : 0.4000          
         Neg Pred Value : 0.5319          
             Prevalence : 0.4444          
         Detection Rate : 0.1389          
   Detection Prevalence : 0.3472          
      Balanced Accuracy : 0.4688          
                                          
       'Positive' Class : Weak            
                                          
> 
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
 Accuracy     Kappa 
0.8064516 0.6072583 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    115   26
    Weak       22   85
                                          
               Accuracy : 0.8065          
                 95% CI : (0.7517, 0.8537)
    No Information Rate : 0.5524          
    P-Value [Acc > NIR] : <2e-16          
                                          
                  Kappa : 0.6073          
 Mcnemar's Test P-Value : 0.665           
                                          
            Sensitivity : 0.7658          
            Specificity : 0.8394          
         Pos Pred Value : 0.7944          
         Neg Pred Value : 0.8156          
             Prevalence : 0.4476          
         Detection Rate : 0.3427          
   Detection Prevalence : 0.4315          
      Balanced Accuracy : 0.8026          
                                          
       'Positive' Class : Weak            
                                          
> ### weaves
> 
> ## Processing for flights data.
> 
> ## Following the caret vignette.
> 
> ###################################################
> ### code chunk number 1: loadLibs
> ###################################################
> library(MASS)
> library(caret)
> library(mlbench)
> library(pROC)
> library(pls)
> 
> library(doMC)
> registerDoMC(cores = 4)
> 
> options(useFancyQuotes = FALSE) 
> 
> # Accounting info.
> getInfo <- function(what = "Suggests")
+ {
+   text <- packageDescription("caret")[what][[1]]
+   text <- gsub("\n", ", ", text, fixed = TRUE)
+   text <- gsub(">=", "$\\\\ge$", text, fixed = TRUE)
+   eachPkg <- strsplit(text, ", ", fixed = TRUE)[[1]]
+   eachPkg <- gsub(",", "", eachPkg, fixed = TRUE)
+   # out <- paste("\\\\pkg{", eachPkg[order(tolower(eachPkg))], "}", sep = "")
+   # paste(out, collapse = ", ")
+   length(eachPkg)
+ }
> 
> ### project-specific: begin
> ## Set-seed, load original CSV file, order it
> ## and do some simple-cleaning
> ## Various datasets 
> 
> seed.mine = 107
> set.seed(seed.mine)                     # helpful for testing
> 
> flight <- read.csv("../bak/flight.csv")
> flight <- flight[order(flight$D00),]
> 
> # Backup
> flight.raw <- flight
> 
> # To check adjustment, there is test code in flight-nb.R
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"
> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"
> 
> # And some deletions
> 
> t.cols <- colnames(flight)
> 
> t.drops <- t.cols[grep("^RANK*", t.cols)]
> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])
> t.drops <- c(t.drops, "D80THPCTL")
> 
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR
> flight$xHNGR <- flight$xDURN < 0
> 
> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+ }
> 
> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))
> 
> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE
> t.cols <- colnames(flight)
> 
> t.drops <- c("SARRHR", "xDURN")
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Backup
> 
> flight00 <- flight
> 
> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]
> 
> paste("samples in use: ", dim(flight)[1])
[1] "samples in use:  320"
> 
> ## Data insights
> 
> ## *Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> flight <- flight1
> 
> ### Numeric variables
> 
> ### Try and impute the AVG, it might have more information than the
> ### bucket.
> 
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))
Error in `$<-.data.frame`(`*tmp*`, "xAVAILBUCKET", value = numeric(0)) : 
  replacement has 0 rows, data has 320
> 
> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1
> 
> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]
Error in `[.data.frame`(flight, , c("AVGSKDAVAIL", "xAVAILBUCKET")) : 
  undefined columns selected
> 
> preProcValues <- preProcess(flight.na, method = c("knnImpute"))
> flight.na1 <- predict(preProcValues, flight.na)
> 
> ## I'll add the new imputed value and drop the others
> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL
> flight$AVGSKDAVAIL <- NULL
> flight$xAVAILBUCKET <- NULL
> flight$AVAILBUCKET <- NULL
> 
> flight$xHNGR <- NULL
> 
> ## Check some more numeric correlations, I haven't scaled everything yet.
> ## I'd cut correlations above 0.65 to 0.75 because of overfitting.
> 
> x1 <- as.data.frame(as.matrix(sapply(flight, class)))
> 
> flight.num <- flight[,names(x1[which(x1$V1 %in% c("numeric", "integer")),])]
> 
> flight.nzv <- nearZeroVar(flight.num, saveMetrics = TRUE)
> flight.nzv
             freqRatio percentUnique zeroVar   nzv
SDEPHR        1.038462        5.9375   FALSE FALSE
SKDEPS        1.000000       19.0625   FALSE FALSE
D00           1.166667       75.3125   FALSE FALSE
AVGSQ         6.333333       82.8125   FALSE FALSE
AVGLOFATC     1.000000       78.4375   FALSE FALSE
xDURN2        1.428571        2.5000   FALSE FALSE
xAVGSKDAVAIL 18.500000       87.8125   FALSE FALSE
> 
> # annoying NA should be gone.
> flight.cor <- cor(flight.num, use = "pairwise.complete.obs")
> 
> descrCorr <- findCorrelation(flight.cor, cutoff = .65, verbose=TRUE)
Considering row	 4 column	 1 value	 0.956 
  Flagging column	 4 
Considering row	 1 column	 3 value	 0.43 
Considering row	 1 column	 7 value	 0.053 
Considering row	 1 column	 6 value	 0.204 
Considering row	 1 column	 5 value	 0.131 
Considering row	 1 column	 2 value	 0.054 
Considering row	 3 column	 7 value	 0.401 
Considering row	 3 column	 6 value	 0.071 
Considering row	 3 column	 5 value	 0.114 
Considering row	 3 column	 2 value	 0.006 
Considering row	 7 column	 6 value	 0.019 
Considering row	 7 column	 5 value	 0.07 
Considering row	 7 column	 2 value	 0.113 
Considering row	 6 column	 5 value	 0.137 
Considering row	 6 column	 2 value	 0.005 
Considering row	 5 column	 2 value	 0.041 
> 
> colnames(flight.num)[descrCorr]
[1] "AVGSQ"
> 
> ## And I'll leave the centered and scale values in for now.
> ## and delete the troublesome ones
> 
> ## Re-classing
> ## Check warnings to see it adjustment has taken place.
> ## We want the proportion in the training class to be about 0.55 0.45
> ## Strong to Weak
> ## I've achieved this heuristically
> src.adjust <- TRUE
> source(file = "flight1.R")
Warning message:
In eval(expr, envir, enclos) : adjusting
> flight1 <- flight
> 
> ## This should be deleted, leave it in and the results
> ## are ideal because it defines LEGTYPE.
> flight$D00 <- NULL
> 
> ## Keep the results but don't change the order.
> outcomes.flight <- flight$LEGTYPE
> 
> flight$LEGTYPE <- NULL
> 
> ## If you know your factors are definitely factors, you don't need this
> ##  asNumeric <- function(x) as.numeric(as.character(x))
> 
> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))
> 
> flight.num0 <- factors.numeric(flight)
> 
> flight.scl0 <- scale(flight.num0)
> 
> ## Now split the samples
> ## we need at least 60 to test with, p at 0.77 gives about 75.
> ## Difficulty here is the bias in the table
> ## Because we only have [3.1, 4.4] the proportion of Weak is higher.
> ## see prop.table(results)
> 
> set.seed(seed.mine)
> inTrain <- createDataPartition(outcomes.flight, p = 0.77, list = FALSE)
> 
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> 
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> 
> prop.table(table(trainClass))
trainClass
   Strong      Weak 
0.5524194 0.4475806 
> dim(trainDescr)
[1] 248  19
> 
> prop.table(table(testClass))
testClass
   Strong      Weak 
0.5555556 0.4444444 
> dim(testDescr)
[1] 72 19
> 
> ## Check Near-zero variance
> 
> nzv <- nearZeroVar(trainDescr, saveMetrics= TRUE)
> stopifnot( all(nzv$nzv == FALSE) )
> 
> # It's imputed and behaves well, no need for this.
> # descrCorr <- cor(scale(trainDescr), use = "pairwise.complete.obs")
> 
> descrCorr <- cor(scale(trainDescr))
> 
> ## This cut-off should be under src.adjust control.
> ## I'm under Git, so I can tinker with it.
> highCorr <- findCorrelation(descrCorr, cutoff = .95, verbose = TRUE)
Considering row	 17 column	 16 value	 0.85 
Considering row	 17 column	 10 value	 0.671 
Considering row	 17 column	 1 value	 0.279 
Considering row	 17 column	 11 value	 0.277 
Considering row	 17 column	 6 value	 0.22 
Considering row	 17 column	 12 value	 0.226 
Considering row	 17 column	 2 value	 0.298 
Considering row	 17 column	 9 value	 0.586 
Considering row	 17 column	 14 value	 0.226 
Considering row	 17 column	 13 value	 0.23 
Considering row	 17 column	 8 value	 0.541 
Considering row	 17 column	 3 value	 0.346 
Considering row	 17 column	 18 value	 0.261 
Considering row	 17 column	 19 value	 0.138 
Considering row	 17 column	 15 value	 0.057 
Considering row	 17 column	 4 value	 0.067 
Considering row	 17 column	 7 value	 0.034 
Considering row	 17 column	 5 value	 0.018 
Considering row	 16 column	 10 value	 0.568 
Considering row	 16 column	 1 value	 0.236 
Considering row	 16 column	 11 value	 0.231 
Considering row	 16 column	 6 value	 0.189 
Considering row	 16 column	 12 value	 0.19 
Considering row	 16 column	 2 value	 0.333 
Considering row	 16 column	 9 value	 0.671 
Considering row	 16 column	 14 value	 0.242 
Considering row	 16 column	 13 value	 0.208 
Considering row	 16 column	 8 value	 0.6 
Considering row	 16 column	 3 value	 0.318 
Considering row	 16 column	 18 value	 0.279 
Considering row	 16 column	 19 value	 0.213 
Considering row	 16 column	 15 value	 0.083 
Considering row	 16 column	 4 value	 0.02 
Considering row	 16 column	 7 value	 0.009 
Considering row	 16 column	 5 value	 0.005 
Considering row	 10 column	 1 value	 0.281 
Considering row	 10 column	 11 value	 0.275 
Considering row	 10 column	 6 value	 0.298 
Considering row	 10 column	 12 value	 0.255 
Considering row	 10 column	 2 value	 0.286 
Considering row	 10 column	 9 value	 0.404 
Considering row	 10 column	 14 value	 0.224 
Considering row	 10 column	 13 value	 0.199 
Considering row	 10 column	 8 value	 0.366 
Considering row	 10 column	 3 value	 0.462 
Considering row	 10 column	 18 value	 0.226 
Considering row	 10 column	 19 value	 0.103 
Considering row	 10 column	 15 value	 0.274 
Considering row	 10 column	 4 value	 0.018 
Considering row	 10 column	 7 value	 0.127 
Considering row	 10 column	 5 value	 0.096 
Considering row	 1 column	 11 value	 0.988 
  Flagging column	 1 
Considering row	 11 column	 6 value	 0.945 
Considering row	 11 column	 12 value	 0.889 
Considering row	 11 column	 2 value	 0.165 
Considering row	 11 column	 9 value	 0.139 
Considering row	 11 column	 14 value	 0.171 
Considering row	 11 column	 13 value	 0.156 
Considering row	 11 column	 8 value	 0.145 
Considering row	 11 column	 3 value	 0.073 
Considering row	 11 column	 18 value	 0.183 
Considering row	 11 column	 19 value	 0.053 
Considering row	 11 column	 15 value	 0.142 
Considering row	 11 column	 4 value	 0.037 
Considering row	 11 column	 7 value	 0.053 
Considering row	 11 column	 5 value	 0.03 
Considering row	 6 column	 12 value	 0.883 
Considering row	 6 column	 2 value	 0.151 
Considering row	 6 column	 9 value	 0.04 
Considering row	 6 column	 14 value	 0.188 
Considering row	 6 column	 13 value	 0.161 
Considering row	 6 column	 8 value	 0.063 
Considering row	 6 column	 3 value	 0.083 
Considering row	 6 column	 18 value	 0.197 
Considering row	 6 column	 19 value	 0.114 
Considering row	 6 column	 15 value	 0.159 
Considering row	 6 column	 4 value	 0.01 
Considering row	 6 column	 7 value	 0.027 
Considering row	 6 column	 5 value	 0.039 
Considering row	 12 column	 2 value	 0.121 
Considering row	 12 column	 9 value	 0.128 
Considering row	 12 column	 14 value	 0.092 
Considering row	 12 column	 13 value	 0.105 
Considering row	 12 column	 8 value	 0.071 
Considering row	 12 column	 3 value	 0.093 
Considering row	 12 column	 18 value	 0.126 
Considering row	 12 column	 19 value	 0.171 
Considering row	 12 column	 15 value	 0.13 
Considering row	 12 column	 4 value	 0.01 
Considering row	 12 column	 7 value	 0.043 
Considering row	 12 column	 5 value	 0.017 
Considering row	 2 column	 9 value	 0.423 
Considering row	 2 column	 14 value	 0.574 
Considering row	 2 column	 13 value	 0.557 
Considering row	 2 column	 8 value	 0.165 
Considering row	 2 column	 3 value	 0.263 
Considering row	 2 column	 18 value	 0.128 
Considering row	 2 column	 19 value	 0.089 
Considering row	 2 column	 15 value	 0.069 
Considering row	 2 column	 4 value	 0.27 
Considering row	 2 column	 7 value	 0.045 
Considering row	 2 column	 5 value	 0.024 
Considering row	 9 column	 14 value	 0.147 
Considering row	 9 column	 13 value	 0.125 
Considering row	 9 column	 8 value	 0.449 
Considering row	 9 column	 3 value	 0.322 
Considering row	 9 column	 18 value	 0.018 
Considering row	 9 column	 19 value	 0.141 
Considering row	 9 column	 15 value	 0.073 
Considering row	 9 column	 4 value	 0.006 
Considering row	 9 column	 7 value	 0.136 
Considering row	 9 column	 5 value	 0.123 
Considering row	 14 column	 13 value	 0.659 
Considering row	 14 column	 8 value	 0.097 
Considering row	 14 column	 3 value	 0.106 
Considering row	 14 column	 18 value	 0.361 
Considering row	 14 column	 19 value	 0.092 
Considering row	 14 column	 15 value	 0.084 
Considering row	 14 column	 4 value	 0.263 
Considering row	 14 column	 7 value	 0.139 
Considering row	 14 column	 5 value	 0.031 
Considering row	 13 column	 8 value	 0.097 
Considering row	 13 column	 3 value	 0.167 
Considering row	 13 column	 18 value	 0.18 
Considering row	 13 column	 19 value	 0.131 
Considering row	 13 column	 15 value	 0.137 
Considering row	 13 column	 4 value	 0.24 
Considering row	 13 column	 7 value	 0.085 
Considering row	 13 column	 5 value	 0.027 
Considering row	 8 column	 3 value	 0.224 
Considering row	 8 column	 18 value	 0.173 
Considering row	 8 column	 19 value	 0.235 
Considering row	 8 column	 15 value	 0.07 
Considering row	 8 column	 4 value	 0.02 
Considering row	 8 column	 7 value	 0.085 
Considering row	 8 column	 5 value	 0.004 
Considering row	 3 column	 18 value	 0.028 
Considering row	 3 column	 19 value	 0.027 
Considering row	 3 column	 15 value	 0.017 
Considering row	 3 column	 4 value	 0.094 
Considering row	 3 column	 7 value	 0.095 
Considering row	 3 column	 5 value	 0.097 
Considering row	 18 column	 19 value	 0.019 
Considering row	 18 column	 15 value	 0.12 
Considering row	 18 column	 4 value	 0.086 
Considering row	 18 column	 7 value	 0.132 
Considering row	 18 column	 5 value	 0.002 
Considering row	 19 column	 15 value	 0.019 
Considering row	 19 column	 4 value	 0.032 
Considering row	 19 column	 7 value	 0.056 
Considering row	 19 column	 5 value	 0.075 
Considering row	 15 column	 4 value	 0.043 
Considering row	 15 column	 7 value	 0.061 
Considering row	 15 column	 5 value	 0.08 
Considering row	 4 column	 7 value	 0.005 
Considering row	 4 column	 5 value	 0.213 
Considering row	 7 column	 5 value	 0.008 
> 
> colnames(trainDescr)[highCorr]
[1] "SDEPHR"
> 
> descr.ncol0 <- ncol(trainDescr)
> 
> # I've switched off the correlation remover and the results are better.
> if (sum(highCorr) > 0) {
+     warning("overfitting: correlations: err.trainDescr: ", paste(colnames(trainDescr)[highCorr], collapse = ", ") )
+     err.trainDescr <- trainDescr
+     trainDescr <- trainDescr[,-highCorr]
+ }
Warning message:
overfitting: correlations: err.trainDescr: SDEPHR 
> 
> descr.ncol1 <- ncol(trainDescr)
> 
> paste("Dropped: ", as.character(descr.ncol0 - descr.ncol1))
[1] "Dropped:  1"
> 
> descrCorr <- cor(trainDescr)
> summary(descrCorr[upper.tri(descrCorr)])
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
-0.85020 -0.13860 -0.01766  0.01577  0.11970  0.94490 
> 
> ## Dominant correlations
> ## At 0.9, there are some big ones that might need re-thinking.
> 
> table.descrCorr <- as.data.frame(as.table(descrCorr))
> table.descrCorr <- table.descrCorr[which(table.descrCorr$Var1 != table.descrCorr$Var2),]
> table.descrCorr[order(abs(table.descrCorr$Freq), decreasing = TRUE),]
              Var1           Var2         Freq
82       DEPBUCKET          AVGSQ  0.944870657
167          AVGSQ      DEPBUCKET  0.944870657
173      ARRBUCKET      DEPBUCKET  0.889095737
190      DEPBUCKET      ARRBUCKET  0.889095737
83       ARRBUCKET          AVGSQ  0.882590635
185          AVGSQ      ARRBUCKET  0.882590635
268       ARRSPOKE       DEPSPOKE -0.850165355
285       DEPSPOKE       ARRSPOKE -0.850165355
141       DEPSPOKE   DEPSTAATCIMP  0.671264566
260   DEPSTAATCIMP       DEPSPOKE  0.671264566
160       ARRSPOKE DOWNLINEATCIMP  0.671009330
279 DOWNLINEATCIMP       ARRSPOKE  0.671009330
211     TRNRANKGRP     DEPRANKGRP  0.658724662
228     DEPRANKGRP     TRNRANKGRP  0.658724662
123       DEPSPOKE   UPLINEATCIMP -0.600008252
259   UPLINEATCIMP       DEPSPOKE -0.600008252
142       ARRSPOKE   DEPSTAATCIMP -0.586442959
278   DEPSTAATCIMP       ARRSPOKE -0.586442959
13      TRNRANKGRP      SKDDEPSTA  0.574035134
217      SKDDEPSTA     TRNRANKGRP  0.574035134
159       DEPSPOKE DOWNLINEATCIMP -0.567682494
261 DOWNLINEATCIMP       DEPSPOKE -0.567682494
12      DEPRANKGRP      SKDDEPSTA  0.557399203
199      SKDDEPSTA     DEPRANKGRP  0.557399203
124       ARRSPOKE   UPLINEATCIMP  0.540734833
277   UPLINEATCIMP       ARRSPOKE  0.540734833
27  DOWNLINEATCIMP      SKDARRSTA  0.462378131
146      SKDARRSTA DOWNLINEATCIMP  0.462378131
116   DEPSTAATCIMP   UPLINEATCIMP -0.449249986
133   UPLINEATCIMP   DEPSTAATCIMP -0.449249986
8     DEPSTAATCIMP      SKDDEPSTA  0.423425796
127      SKDDEPSTA   DEPSTAATCIMP  0.423425796
135 DOWNLINEATCIMP   DEPSTAATCIMP -0.403695561
152   DEPSTAATCIMP DOWNLINEATCIMP -0.403695561
117 DOWNLINEATCIMP   UPLINEATCIMP  0.365833687
151   UPLINEATCIMP DOWNLINEATCIMP  0.365833687
233         xDURN2     TRNRANKGRP  0.361347207
301     TRNRANKGRP         xDURN2  0.361347207
34        ARRSPOKE      SKDARRSTA  0.345987375
272      SKDARRSTA       ARRSPOKE  0.345987375
15        DEPSPOKE      SKDDEPSTA  0.332823310
253      SKDDEPSTA       DEPSPOKE  0.332823310
26    DEPSTAATCIMP      SKDARRSTA -0.322204878
128      SKDARRSTA   DEPSTAATCIMP -0.322204878
33        DEPSPOKE      SKDARRSTA -0.318093195
254      SKDARRSTA       DEPSPOKE -0.318093195
81  DOWNLINEATCIMP          AVGSQ  0.298096458
149          AVGSQ DOWNLINEATCIMP  0.298096458
16        ARRSPOKE      SKDDEPSTA -0.298036487
271      SKDDEPSTA       ARRSPOKE -0.298036487
9   DOWNLINEATCIMP      SKDDEPSTA -0.285911992
145      SKDDEPSTA DOWNLINEATCIMP -0.285911992
269         xDURN2       DEPSPOKE  0.279030910
303       DEPSPOKE         xDURN2  0.279030910
178       ARRSPOKE      DEPBUCKET  0.276615722
280      DEPBUCKET       ARRSPOKE  0.276615722
154      DEPBUCKET DOWNLINEATCIMP  0.275167866
171 DOWNLINEATCIMP      DEPBUCKET  0.275167866
158     ARRRANKGRP DOWNLINEATCIMP -0.274110143
243 DOWNLINEATCIMP     ARRRANKGRP -0.274110143
3           SKDEQP      SKDDEPSTA  0.270065872
37       SKDDEPSTA         SKDEQP  0.270065872
2        SKDARRSTA      SKDDEPSTA -0.263453106
19       SKDDEPSTA      SKDARRSTA -0.263453106
49      TRNRANKGRP         SKDEQP  0.262837233
219         SKDEQP     TRNRANKGRP  0.262837233
287         xDURN2       ARRSPOKE -0.261107447
304       ARRSPOKE         xDURN2 -0.261107447
155      ARRBUCKET DOWNLINEATCIMP  0.255480148
189 DOWNLINEATCIMP      ARRBUCKET  0.255480148
231       DEPSPOKE     TRNRANKGRP  0.242138220
265     TRNRANKGRP       DEPSPOKE  0.242138220
48      DEPRANKGRP         SKDEQP  0.239915140
201         SKDEQP     DEPRANKGRP  0.239915140
126   xAVGSKDAVAIL   UPLINEATCIMP  0.234867014
313   UPLINEATCIMP   xAVGSKDAVAIL  0.234867014
177       DEPSPOKE      DEPBUCKET -0.231298301
262      DEPBUCKET       DEPSPOKE -0.231298301
214       ARRSPOKE     DEPRANKGRP -0.229640758
282     DEPRANKGRP       ARRSPOKE -0.229640758
161         xDURN2 DOWNLINEATCIMP -0.226093423
297 DOWNLINEATCIMP         xDURN2 -0.226093423
196       ARRSPOKE      ARRBUCKET  0.225890655
281      ARRBUCKET       ARRSPOKE  0.225890655
232       ARRSPOKE     TRNRANKGRP -0.225591539
283     TRNRANKGRP       ARRSPOKE -0.225591539
157     TRNRANKGRP DOWNLINEATCIMP -0.224193213
225 DOWNLINEATCIMP     TRNRANKGRP -0.224193213
25    UPLINEATCIMP      SKDARRSTA  0.223824406
110      SKDARRSTA   UPLINEATCIMP  0.223824406
88        ARRSPOKE          AVGSQ  0.219975654
275          AVGSQ       ARRSPOKE  0.219975654
270   xAVGSKDAVAIL       DEPSPOKE -0.212821518
321       DEPSPOKE   xAVGSKDAVAIL -0.212821518
40          SKDEPS         SKDEQP  0.212586898
57          SKDEQP         SKDEPS  0.212586898
213       DEPSPOKE     DEPRANKGRP  0.208188512
264     DEPRANKGRP       DEPSPOKE  0.208188512
156     DEPRANKGRP DOWNLINEATCIMP -0.199411990
207 DOWNLINEATCIMP     DEPRANKGRP -0.199411990
89          xDURN2          AVGSQ -0.197447957
293          AVGSQ         xDURN2 -0.197447957
195       DEPSPOKE      ARRBUCKET -0.189934966
263      ARRBUCKET       DEPSPOKE -0.189934966
87        DEPSPOKE          AVGSQ -0.188666787
257          AVGSQ       DEPSPOKE -0.188666787
85      TRNRANKGRP          AVGSQ -0.188226304
221          AVGSQ     TRNRANKGRP -0.188226304
179         xDURN2      DEPBUCKET -0.183349624
298      DEPBUCKET         xDURN2 -0.183349624
215         xDURN2     DEPRANKGRP  0.180043357
300     DEPRANKGRP         xDURN2  0.180043357
125         xDURN2   UPLINEATCIMP -0.173240320
295   UPLINEATCIMP         xDURN2 -0.173240320
198   xAVGSKDAVAIL      ARRBUCKET -0.170644257
317      ARRBUCKET   xAVGSKDAVAIL -0.170644257
175     TRNRANKGRP      DEPBUCKET -0.170618431
226      DEPBUCKET     TRNRANKGRP -0.170618431
30      DEPRANKGRP      SKDARRSTA -0.167375913
200      SKDARRSTA     DEPRANKGRP -0.167375913
10       DEPBUCKET      SKDDEPSTA -0.165029385
163      SKDDEPSTA      DEPBUCKET -0.165029385
7     UPLINEATCIMP      SKDDEPSTA -0.164964952
109      SKDDEPSTA   UPLINEATCIMP -0.164964952
84      DEPRANKGRP          AVGSQ -0.161451853
203          AVGSQ     DEPRANKGRP -0.161451853
86      ARRRANKGRP          AVGSQ -0.159135469
239          AVGSQ     ARRRANKGRP -0.159135469
174     DEPRANKGRP      DEPBUCKET -0.155547085
208      DEPBUCKET     DEPRANKGRP -0.155547085
5            AVGSQ      SKDDEPSTA -0.150522366
73       SKDDEPSTA          AVGSQ -0.150522366
139     TRNRANKGRP   DEPSTAATCIMP -0.147409309
224   DEPSTAATCIMP     TRNRANKGRP -0.147409309
118      DEPBUCKET   UPLINEATCIMP  0.144940797
169   UPLINEATCIMP      DEPBUCKET  0.144940797
176     ARRRANKGRP      DEPBUCKET -0.142348062
244      DEPBUCKET     ARRRANKGRP -0.142348062
144   xAVGSKDAVAIL   DEPSTAATCIMP -0.141077194
314   DEPSTAATCIMP   xAVGSKDAVAIL -0.141077194
103     TRNRANKGRP      AVGLOFATC  0.139184315
222      AVGLOFATC     TRNRANKGRP  0.139184315
136      DEPBUCKET   DEPSTAATCIMP -0.138581846
170   DEPSTAATCIMP      DEPBUCKET -0.138581846
288   xAVGSKDAVAIL       ARRSPOKE  0.137677242
322       ARRSPOKE   xAVGSKDAVAIL  0.137677242
212     ARRRANKGRP     DEPRANKGRP  0.136562948
246     DEPRANKGRP     ARRRANKGRP  0.136562948
98    DEPSTAATCIMP      AVGLOFATC -0.135778614
132      AVGLOFATC   DEPSTAATCIMP -0.135778614
107         xDURN2      AVGLOFATC -0.132084629
294      AVGLOFATC         xDURN2 -0.132084629
216   xAVGSKDAVAIL     DEPRANKGRP  0.130574789
318     DEPRANKGRP   xAVGSKDAVAIL  0.130574789
194     ARRRANKGRP      ARRBUCKET -0.129698517
245      ARRBUCKET     ARRRANKGRP -0.129698517
137      ARRBUCKET   DEPSTAATCIMP -0.127726148
188   DEPSTAATCIMP      ARRBUCKET -0.127726148
17          xDURN2      SKDDEPSTA  0.127598189
289      SKDDEPSTA         xDURN2  0.127598189
99  DOWNLINEATCIMP      AVGLOFATC -0.126763572
150      AVGLOFATC DOWNLINEATCIMP -0.126763572
197         xDURN2      ARRBUCKET -0.125836459
299      ARRBUCKET         xDURN2 -0.125836459
138     DEPRANKGRP   DEPSTAATCIMP  0.124672682
206   DEPSTAATCIMP     DEPRANKGRP  0.124672682
62    DEPSTAATCIMP         SKDEPS -0.123445793
130         SKDEPS   DEPSTAATCIMP -0.123445793
11       ARRBUCKET      SKDDEPSTA -0.120728212
181      SKDDEPSTA      ARRBUCKET -0.120728212
251         xDURN2     ARRRANKGRP  0.119675180
302     ARRRANKGRP         xDURN2  0.119675180
90    xAVGSKDAVAIL          AVGSQ -0.113720147
311          AVGSQ   xAVGSKDAVAIL -0.113720147
31      TRNRANKGRP      SKDARRSTA -0.105802023
218      SKDARRSTA     TRNRANKGRP -0.105802023
192     DEPRANKGRP      ARRBUCKET -0.105057984
209      ARRBUCKET     DEPRANKGRP -0.105057984
162   xAVGSKDAVAIL DOWNLINEATCIMP  0.102577364
315 DOWNLINEATCIMP   xAVGSKDAVAIL  0.102577364
120     DEPRANKGRP   UPLINEATCIMP -0.097218129
205   UPLINEATCIMP     DEPRANKGRP -0.097218129
121     TRNRANKGRP   UPLINEATCIMP -0.097037814
223   UPLINEATCIMP     TRNRANKGRP -0.097037814
22          SKDEPS      SKDARRSTA -0.096699169
56       SKDARRSTA         SKDEPS -0.096699169
63  DOWNLINEATCIMP         SKDEPS -0.095568613
148         SKDEPS DOWNLINEATCIMP -0.095568613
24       AVGLOFATC      SKDARRSTA -0.095234466
92       SKDARRSTA      AVGLOFATC -0.095234466
21          SKDEQP      SKDARRSTA  0.094073459
38       SKDARRSTA         SKDEQP  0.094073459
29       ARRBUCKET      SKDARRSTA  0.092625400
182      SKDARRSTA      ARRBUCKET  0.092625400
193     TRNRANKGRP      ARRBUCKET -0.092415252
227      ARRBUCKET     TRNRANKGRP -0.092415252
234   xAVGSKDAVAIL     TRNRANKGRP  0.092011501
319     TRNRANKGRP   xAVGSKDAVAIL  0.092011501
18    xAVGSKDAVAIL      SKDDEPSTA  0.088580325
307      SKDDEPSTA   xAVGSKDAVAIL  0.088580325
53          xDURN2         SKDEQP  0.086170070
291         SKDEQP         xDURN2  0.086170070
102     DEPRANKGRP      AVGLOFATC  0.085474019
204      AVGLOFATC     DEPRANKGRP  0.085474019
97    UPLINEATCIMP      AVGLOFATC -0.085180887
114      AVGLOFATC   UPLINEATCIMP -0.085180887
230     ARRRANKGRP     TRNRANKGRP  0.083906762
247     TRNRANKGRP     ARRRANKGRP  0.083906762
249       DEPSPOKE     ARRRANKGRP  0.083162083
266     ARRRANKGRP       DEPSPOKE  0.083162083
23           AVGSQ      SKDARRSTA  0.082898864
74       SKDARRSTA          AVGSQ  0.082898864
68      ARRRANKGRP         SKDEPS  0.080398834
238         SKDEPS     ARRRANKGRP  0.080398834
72    xAVGSKDAVAIL         SKDEPS  0.075169577
310         SKDEPS   xAVGSKDAVAIL  0.075169577
140     ARRRANKGRP   DEPSTAATCIMP  0.073371196
242   DEPSTAATCIMP     ARRRANKGRP  0.073371196
28       DEPBUCKET      SKDARRSTA  0.072910977
164      SKDARRSTA      DEPBUCKET  0.072910977
119      ARRBUCKET   UPLINEATCIMP  0.071409699
187   UPLINEATCIMP      ARRBUCKET  0.071409699
122     ARRRANKGRP   UPLINEATCIMP -0.069790367
241   UPLINEATCIMP     ARRRANKGRP -0.069790367
14      ARRRANKGRP      SKDDEPSTA  0.068927801
235      SKDDEPSTA     ARRRANKGRP  0.068927801
52        ARRSPOKE         SKDEQP  0.066579707
273         SKDEQP       ARRSPOKE  0.066579707
79    UPLINEATCIMP          AVGSQ  0.062631172
113          AVGSQ   UPLINEATCIMP  0.062631172
104     ARRRANKGRP      AVGLOFATC -0.061491190
240      AVGLOFATC     ARRRANKGRP -0.061491190
250       ARRSPOKE     ARRRANKGRP -0.057002549
284     ARRRANKGRP       ARRSPOKE -0.057002549
108   xAVGSKDAVAIL      AVGLOFATC -0.056264979
312      AVGLOFATC   xAVGSKDAVAIL -0.056264979
100      DEPBUCKET      AVGLOFATC -0.053357134
168      AVGLOFATC      DEPBUCKET -0.053357134
180   xAVGSKDAVAIL      DEPBUCKET -0.053125467
316      DEPBUCKET   xAVGSKDAVAIL -0.053125467
6        AVGLOFATC      SKDDEPSTA -0.044946507
91       SKDDEPSTA      AVGLOFATC -0.044946507
101      ARRBUCKET      AVGLOFATC -0.043093769
186      AVGLOFATC      ARRBUCKET -0.043093769
50      ARRRANKGRP         SKDEQP -0.042512956
237         SKDEQP     ARRRANKGRP -0.042512956
80    DEPSTAATCIMP          AVGSQ -0.040428658
131          AVGSQ   DEPSTAATCIMP -0.040428658
59           AVGSQ         SKDEPS -0.038820886
76          SKDEPS          AVGSQ -0.038820886
46       DEPBUCKET         SKDEQP  0.037125178
165         SKDEQP      DEPBUCKET  0.037125178
106       ARRSPOKE      AVGLOFATC -0.034402462
276      AVGLOFATC       ARRSPOKE -0.034402462
54    xAVGSKDAVAIL         SKDEQP  0.031863410
309         SKDEQP   xAVGSKDAVAIL  0.031863410
67      TRNRANKGRP         SKDEPS  0.030883560
220         SKDEPS     TRNRANKGRP  0.030883560
64       DEPBUCKET         SKDEPS -0.030101407
166         SKDEPS      DEPBUCKET -0.030101407
35          xDURN2      SKDARRSTA  0.027576751
290      SKDARRSTA         xDURN2  0.027576751
78       AVGLOFATC          AVGSQ -0.027382453
95           AVGSQ      AVGLOFATC -0.027382453
36    xAVGSKDAVAIL      SKDARRSTA  0.027225219
308      SKDARRSTA   xAVGSKDAVAIL  0.027225219
66      DEPRANKGRP         SKDEPS  0.027025501
202         SKDEPS     DEPRANKGRP  0.027025501
4           SKDEPS      SKDDEPSTA -0.024267794
55       SKDDEPSTA         SKDEPS -0.024267794
43    UPLINEATCIMP         SKDEQP -0.019807499
111         SKDEQP   UPLINEATCIMP -0.019807499
51        DEPSPOKE         SKDEQP  0.019755644
255         SKDEQP       DEPSPOKE  0.019755644
306   xAVGSKDAVAIL         xDURN2 -0.019255572
323         xDURN2   xAVGSKDAVAIL -0.019255572
252   xAVGSKDAVAIL     ARRRANKGRP -0.018743432
320     ARRRANKGRP   xAVGSKDAVAIL -0.018743432
143         xDURN2   DEPSTAATCIMP -0.017999758
296   DEPSTAATCIMP         xDURN2 -0.017999758
45  DOWNLINEATCIMP         SKDEQP -0.017658860
147         SKDEQP DOWNLINEATCIMP -0.017658860
70        ARRSPOKE         SKDEPS  0.017573485
274         SKDEPS       ARRSPOKE  0.017573485
65       ARRBUCKET         SKDEPS  0.017414895
184         SKDEPS      ARRBUCKET  0.017414895
32      ARRRANKGRP      SKDARRSTA  0.016733374
236      SKDARRSTA     ARRRANKGRP  0.016733374
41           AVGSQ         SKDEQP  0.010218807
75          SKDEQP          AVGSQ  0.010218807
47       ARRBUCKET         SKDEQP  0.009926479
183         SKDEQP      ARRBUCKET  0.009926479
105       DEPSPOKE      AVGLOFATC -0.008540402
258      AVGLOFATC       DEPSPOKE -0.008540402
60       AVGLOFATC         SKDEPS  0.008240563
94          SKDEPS      AVGLOFATC  0.008240563
44    DEPSTAATCIMP         SKDEQP -0.005922601
129         SKDEQP   DEPSTAATCIMP -0.005922601
42       AVGLOFATC         SKDEQP -0.004889040
93          SKDEQP      AVGLOFATC -0.004889040
69        DEPSPOKE         SKDEPS -0.004617067
256         SKDEPS       DEPSPOKE -0.004617067
61    UPLINEATCIMP         SKDEPS  0.004016263
112         SKDEPS   UPLINEATCIMP  0.004016263
71          xDURN2         SKDEPS  0.001748012
292         SKDEPS         xDURN2  0.001748012
> 
> ### Models
> 
> ## Try GBM (gradient boosting). Works well for mixed data.
> ## And there is a tutorial for it with caret.
> 
> ## Training controller and big grid
> ## Check the ROC (my preferred.)
> 
> fitControl <- trainControl(## 10-fold CV
+     method = "repeatedcv",
+     number = 10,
+     ## repeated ten times
+     repeats = 10,
+     classProbs = 10,
+     summaryFunction = twoClassSummary)
> 
> ## Some trial and error with variables to branch and boost.
> ## I'm just going to try the airports and the planes and the duration
> ## of the flight. There may be some distance relationship there that
> ## air traffic control use.
> 
> ## Annoying because I drop variables, this needs to be looked up.
> 
> gbmGrid <- expand.grid(interaction.depth = 2,
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.1,
+                         n.minobsinnode = 20)
> 
> set.seed(seed.mine)
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "ROC",
+                  verbose = FALSE)
> gbmFit1
Stochastic Gradient Boosting 

248 samples
 18 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 222, 223, 223, 224, 223, 223, ... 

Resampling results across tuning parameters:

  n.trees  ROC        Sens       Spec       ROC SD      Sens SD    Spec SD  
    90     0.7822915  0.7507143  0.6725000  0.09137101  0.1061285  0.1435900
   180     0.7747140  0.7460989  0.6616667  0.08909268  0.1102787  0.1261074
   270     0.7661001  0.7369231  0.6571212  0.09212498  0.1188497  0.1385760
   360     0.7632905  0.7281319  0.6470455  0.08954675  0.1190015  0.1333463
   450     0.7614444  0.7293956  0.6480303  0.09394805  0.1182351  0.1297562
   540     0.7591721  0.7258242  0.6490152  0.09889833  0.1225465  0.1323862
   630     0.7630836  0.7264286  0.6462121  0.09746957  0.1136371  0.1291609
   720     0.7633167  0.7281319  0.6490152  0.09743381  0.1156986  0.1345880
   810     0.7559253  0.7286264  0.6490152  0.10629149  0.1154359  0.1313222
   900     0.7597261  0.7328571  0.6463636  0.09829762  0.1181742  0.1291671
   990     0.7592116  0.7299451  0.6515152  0.09868320  0.1205694  0.1325348
  1080     0.7576457  0.7270879  0.6490152  0.09777156  0.1271256  0.1305829
  1170     0.7580515  0.7307692  0.6507576  0.09743648  0.1113511  0.1302114
  1260     0.7591184  0.7328022  0.6506818  0.09785857  0.1149693  0.1323724
  1350     0.7580524  0.7358242  0.6487121  0.09860054  0.1125867  0.1347284
  1440     0.7574954  0.7358242  0.6524242  0.09796655  0.1188917  0.1282637
  1530     0.7577818  0.7328571  0.6524242  0.09666708  0.1148662  0.1370729
  1620     0.7574255  0.7379670  0.6506818  0.09676412  0.1125461  0.1265694
  1710     0.7569639  0.7307143  0.6551515  0.09946488  0.1157039  0.1295105
  1800     0.7601070  0.7320879  0.6542424  0.09362212  0.1178184  0.1299620
  1890     0.7587379  0.7335714  0.6543939  0.09418349  0.1180495  0.1307281
  1980     0.7593452  0.7379121  0.6526515  0.09258016  0.1175785  0.1297381
  2070     0.7595937  0.7315385  0.6561364  0.09305182  0.1191642  0.1300796
  2160     0.7591434  0.7313736  0.6526515  0.09639211  0.1134803  0.1310187
  2250     0.7589394  0.7364835  0.6561364  0.09522135  0.1203176  0.1319908
  2340     0.7556185  0.7336264  0.6552273  0.10315509  0.1168239  0.1345167
  2430     0.7582451  0.7335165  0.6561364  0.09893856  0.1164815  0.1328227
  2520     0.7565705  0.7342857  0.6561364  0.10298670  0.1210770  0.1344969
  2610     0.7550670  0.7336264  0.6534091  0.10328632  0.1143092  0.1333170
  2700     0.7542075  0.7335714  0.6471212  0.10372574  0.1170326  0.1402334

Tuning parameter 'interaction.depth' was held constant at a value of 2

Tuning parameter 'shrinkage' was held constant at a value of 0.1

Tuning parameter 'n.minobsinnode' was held constant at a value of 20
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 90, interaction.depth =
 2, shrinkage = 0.1 and n.minobsinnode = 20. 
> 
> ## The acid test is dissapointing, but I've seen worse.
> 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
  Accuracy      Kappa 
 0.4444444 -0.1250000 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     20   20
    Weak       20   12
                                          
               Accuracy : 0.4444          
                 95% CI : (0.3272, 0.5664)
    No Information Rate : 0.5556          
    P-Value [Acc > NIR] : 0.9778          
                                          
                  Kappa : -0.125          
 Mcnemar's Test P-Value : 1.0000          
                                          
            Sensitivity : 0.3750          
            Specificity : 0.5000          
         Pos Pred Value : 0.3750          
         Neg Pred Value : 0.5000          
             Prevalence : 0.4444          
         Detection Rate : 0.1667          
   Detection Prevalence : 0.4444          
      Balanced Accuracy : 0.4375          
                                          
       'Positive' Class : Weak            
                                          
> 
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
 Accuracy     Kappa 
0.8346774 0.6642451 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    119   23
    Weak       18   88
                                          
               Accuracy : 0.8347          
                 95% CI : (0.7825, 0.8787)
    No Information Rate : 0.5524          
    P-Value [Acc > NIR] : <2e-16          
                                          
                  Kappa : 0.6642          
 Mcnemar's Test P-Value : 0.5322          
                                          
            Sensitivity : 0.7928          
            Specificity : 0.8686          
         Pos Pred Value : 0.8302          
         Neg Pred Value : 0.8380          
             Prevalence : 0.4476          
         Detection Rate : 0.3548          
   Detection Prevalence : 0.4274          
      Balanced Accuracy : 0.8307          
                                          
       'Positive' Class : Weak            
                                          
> ### weaves
> 
> ## Processing for flights data.
> 
> ## Following the caret vignette.
> 
> ###################################################
> ### code chunk number 1: loadLibs
> ###################################################
> library(MASS)
> library(caret)
> library(mlbench)
> library(pROC)
> library(pls)
> 
> library(doMC)
> registerDoMC(cores = 4)
> 
> options(useFancyQuotes = FALSE) 
> 
> # Accounting info.
> getInfo <- function(what = "Suggests")
+ {
+   text <- packageDescription("caret")[what][[1]]
+   text <- gsub("\n", ", ", text, fixed = TRUE)
+   text <- gsub(">=", "$\\\\ge$", text, fixed = TRUE)
+   eachPkg <- strsplit(text, ", ", fixed = TRUE)[[1]]
+   eachPkg <- gsub(",", "", eachPkg, fixed = TRUE)
+   # out <- paste("\\\\pkg{", eachPkg[order(tolower(eachPkg))], "}", sep = "")
+   # paste(out, collapse = ", ")
+   length(eachPkg)
+ }
> 
> ### project-specific: begin
> ## Set-seed, load original CSV file, order it
> ## and do some simple-cleaning
> ## Various datasets 
> 
> seed.mine = 107
> set.seed(seed.mine)                     # helpful for testing
> 
> flight <- read.csv("../bak/flight.csv")
> flight <- flight[order(flight$D00),]
> 
> # Backup
> flight.raw <- flight
> 
> # To check adjustment, there is test code in flight-nb.R
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"
> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"
> 
> # And some deletions
> 
> t.cols <- colnames(flight)
> 
> t.drops <- t.cols[grep("^RANK*", t.cols)]
> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])
> t.drops <- c(t.drops, "D80THPCTL")
> 
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR
> flight$xHNGR <- flight$xDURN < 0
> 
> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+ }
> 
> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))
> 
> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE
> t.cols <- colnames(flight)
> 
> t.drops <- c("SARRHR", "xDURN")
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Backup
> 
> flight00 <- flight
> 
> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]
> 
> paste("samples in use: ", dim(flight)[1])
[1] "samples in use:  320"
> 
> ## Data insights
> 
> ## *Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> flight <- flight1
> 
> ### Numeric variables
> 
> ### Try and impute the AVG, it might have more information than the
> ### bucket.
> 
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))
Error in `$<-.data.frame`(`*tmp*`, "xAVAILBUCKET", value = numeric(0)) : 
  replacement has 0 rows, data has 320
> 
> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1
> 
> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]
Error in `[.data.frame`(flight, , c("AVGSKDAVAIL", "xAVAILBUCKET")) : 
  undefined columns selected
> 
> preProcValues <- preProcess(flight.na, method = c("knnImpute"))
> flight.na1 <- predict(preProcValues, flight.na)
> 
> ## I'll add the new imputed value and drop the others
> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL
> flight$AVGSKDAVAIL <- NULL
> flight$xAVAILBUCKET <- NULL
> flight$AVAILBUCKET <- NULL
> 
> flight$xHNGR <- NULL
> 
> ## Check some more numeric correlations, I haven't scaled everything yet.
> ## I'd cut correlations above 0.65 to 0.75 because of overfitting.
> 
> x1 <- as.data.frame(as.matrix(sapply(flight, class)))
> 
> flight.num <- flight[,names(x1[which(x1$V1 %in% c("numeric", "integer")),])]
> 
> flight.nzv <- nearZeroVar(flight.num, saveMetrics = TRUE)
> flight.nzv
             freqRatio percentUnique zeroVar   nzv
SDEPHR        1.038462        5.9375   FALSE FALSE
SKDEPS        1.000000       19.0625   FALSE FALSE
D00           1.166667       75.3125   FALSE FALSE
AVGSQ         6.333333       82.8125   FALSE FALSE
AVGLOFATC     1.000000       78.4375   FALSE FALSE
xDURN2        1.428571        2.5000   FALSE FALSE
xAVGSKDAVAIL 18.500000       87.8125   FALSE FALSE
> 
> # annoying NA should be gone.
> flight.cor <- cor(flight.num, use = "pairwise.complete.obs")
> 
> descrCorr <- findCorrelation(flight.cor, cutoff = .65, verbose=TRUE)
Considering row	 4 column	 1 value	 0.956 
  Flagging column	 4 
Considering row	 1 column	 3 value	 0.43 
Considering row	 1 column	 7 value	 0.053 
Considering row	 1 column	 6 value	 0.204 
Considering row	 1 column	 5 value	 0.131 
Considering row	 1 column	 2 value	 0.054 
Considering row	 3 column	 7 value	 0.401 
Considering row	 3 column	 6 value	 0.071 
Considering row	 3 column	 5 value	 0.114 
Considering row	 3 column	 2 value	 0.006 
Considering row	 7 column	 6 value	 0.019 
Considering row	 7 column	 5 value	 0.07 
Considering row	 7 column	 2 value	 0.113 
Considering row	 6 column	 5 value	 0.137 
Considering row	 6 column	 2 value	 0.005 
Considering row	 5 column	 2 value	 0.041 
> 
> colnames(flight.num)[descrCorr]
[1] "AVGSQ"
> 
> ## And I'll leave the centered and scale values in for now.
> ## and delete the troublesome ones
> 
> ## Re-classing
> ## Check warnings to see it adjustment has taken place.
> ## We want the proportion in the training class to be about 0.55 0.45
> ## Strong to Weak
> ## I've achieved this heuristically
> src.adjust <- TRUE
> source(file = "flight1.R")
Warning message:
In eval(expr, envir, enclos) : adjusting
> flight1 <- flight
> 
> ## This should be deleted, leave it in and the results
> ## are ideal because it defines LEGTYPE.
> flight$D00 <- NULL
> 
> ## Keep the results but don't change the order.
> outcomes.flight <- flight$LEGTYPE
> 
> flight$LEGTYPE <- NULL
> 
> ## If you know your factors are definitely factors, you don't need this
> ##  asNumeric <- function(x) as.numeric(as.character(x))
> 
> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))
> 
> flight.num0 <- factors.numeric(flight)
> 
> flight.scl0 <- scale(flight.num0)
> 
> ## Now split the samples
> ## we need at least 60 to test with, p at 0.77 gives about 75.
> ## Difficulty here is the bias in the table
> ## Because we only have [3.1, 4.4] the proportion of Weak is higher.
> ## see prop.table(results)
> 
> set.seed(seed.mine)
> inTrain <- createDataPartition(outcomes.flight, p = 0.77, list = FALSE)
> 
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> 
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> 
> prop.table(table(trainClass))
trainClass
   Strong      Weak 
0.5524194 0.4475806 
> dim(trainDescr)
[1] 248  19
> 
> prop.table(table(testClass))
testClass
   Strong      Weak 
0.5555556 0.4444444 
> dim(testDescr)
[1] 72 19
> 
> ## Check Near-zero variance
> 
> nzv <- nearZeroVar(trainDescr, saveMetrics= TRUE)
> stopifnot( all(nzv$nzv == FALSE) )
> 
> # It's imputed and behaves well, no need for this.
> # descrCorr <- cor(scale(trainDescr), use = "pairwise.complete.obs")
> 
> descrCorr <- cor(scale(trainDescr))
> 
> ## This cut-off should be under src.adjust control.
> ## I'm under Git, so I can tinker with it.
> highCorr <- findCorrelation(descrCorr, cutoff = .95, verbose = TRUE)
Considering row	 17 column	 16 value	 0.85 
Considering row	 17 column	 10 value	 0.671 
Considering row	 17 column	 1 value	 0.279 
Considering row	 17 column	 11 value	 0.277 
Considering row	 17 column	 6 value	 0.22 
Considering row	 17 column	 12 value	 0.226 
Considering row	 17 column	 2 value	 0.298 
Considering row	 17 column	 9 value	 0.586 
Considering row	 17 column	 14 value	 0.226 
Considering row	 17 column	 13 value	 0.23 
Considering row	 17 column	 8 value	 0.541 
Considering row	 17 column	 3 value	 0.346 
Considering row	 17 column	 18 value	 0.261 
Considering row	 17 column	 19 value	 0.138 
Considering row	 17 column	 15 value	 0.057 
Considering row	 17 column	 4 value	 0.067 
Considering row	 17 column	 7 value	 0.034 
Considering row	 17 column	 5 value	 0.018 
Considering row	 16 column	 10 value	 0.568 
Considering row	 16 column	 1 value	 0.236 
Considering row	 16 column	 11 value	 0.231 
Considering row	 16 column	 6 value	 0.189 
Considering row	 16 column	 12 value	 0.19 
Considering row	 16 column	 2 value	 0.333 
Considering row	 16 column	 9 value	 0.671 
Considering row	 16 column	 14 value	 0.242 
Considering row	 16 column	 13 value	 0.208 
Considering row	 16 column	 8 value	 0.6 
Considering row	 16 column	 3 value	 0.318 
Considering row	 16 column	 18 value	 0.279 
Considering row	 16 column	 19 value	 0.213 
Considering row	 16 column	 15 value	 0.083 
Considering row	 16 column	 4 value	 0.02 
Considering row	 16 column	 7 value	 0.009 
Considering row	 16 column	 5 value	 0.005 
Considering row	 10 column	 1 value	 0.281 
Considering row	 10 column	 11 value	 0.275 
Considering row	 10 column	 6 value	 0.298 
Considering row	 10 column	 12 value	 0.255 
Considering row	 10 column	 2 value	 0.286 
Considering row	 10 column	 9 value	 0.404 
Considering row	 10 column	 14 value	 0.224 
Considering row	 10 column	 13 value	 0.199 
Considering row	 10 column	 8 value	 0.366 
Considering row	 10 column	 3 value	 0.462 
Considering row	 10 column	 18 value	 0.226 
Considering row	 10 column	 19 value	 0.103 
Considering row	 10 column	 15 value	 0.274 
Considering row	 10 column	 4 value	 0.018 
Considering row	 10 column	 7 value	 0.127 
Considering row	 10 column	 5 value	 0.096 
Considering row	 1 column	 11 value	 0.988 
  Flagging column	 1 
Considering row	 11 column	 6 value	 0.945 
Considering row	 11 column	 12 value	 0.889 
Considering row	 11 column	 2 value	 0.165 
Considering row	 11 column	 9 value	 0.139 
Considering row	 11 column	 14 value	 0.171 
Considering row	 11 column	 13 value	 0.156 
Considering row	 11 column	 8 value	 0.145 
Considering row	 11 column	 3 value	 0.073 
Considering row	 11 column	 18 value	 0.183 
Considering row	 11 column	 19 value	 0.053 
Considering row	 11 column	 15 value	 0.142 
Considering row	 11 column	 4 value	 0.037 
Considering row	 11 column	 7 value	 0.053 
Considering row	 11 column	 5 value	 0.03 
Considering row	 6 column	 12 value	 0.883 
Considering row	 6 column	 2 value	 0.151 
Considering row	 6 column	 9 value	 0.04 
Considering row	 6 column	 14 value	 0.188 
Considering row	 6 column	 13 value	 0.161 
Considering row	 6 column	 8 value	 0.063 
Considering row	 6 column	 3 value	 0.083 
Considering row	 6 column	 18 value	 0.197 
Considering row	 6 column	 19 value	 0.114 
Considering row	 6 column	 15 value	 0.159 
Considering row	 6 column	 4 value	 0.01 
Considering row	 6 column	 7 value	 0.027 
Considering row	 6 column	 5 value	 0.039 
Considering row	 12 column	 2 value	 0.121 
Considering row	 12 column	 9 value	 0.128 
Considering row	 12 column	 14 value	 0.092 
Considering row	 12 column	 13 value	 0.105 
Considering row	 12 column	 8 value	 0.071 
Considering row	 12 column	 3 value	 0.093 
Considering row	 12 column	 18 value	 0.126 
Considering row	 12 column	 19 value	 0.171 
Considering row	 12 column	 15 value	 0.13 
Considering row	 12 column	 4 value	 0.01 
Considering row	 12 column	 7 value	 0.043 
Considering row	 12 column	 5 value	 0.017 
Considering row	 2 column	 9 value	 0.423 
Considering row	 2 column	 14 value	 0.574 
Considering row	 2 column	 13 value	 0.557 
Considering row	 2 column	 8 value	 0.165 
Considering row	 2 column	 3 value	 0.263 
Considering row	 2 column	 18 value	 0.128 
Considering row	 2 column	 19 value	 0.089 
Considering row	 2 column	 15 value	 0.069 
Considering row	 2 column	 4 value	 0.27 
Considering row	 2 column	 7 value	 0.045 
Considering row	 2 column	 5 value	 0.024 
Considering row	 9 column	 14 value	 0.147 
Considering row	 9 column	 13 value	 0.125 
Considering row	 9 column	 8 value	 0.449 
Considering row	 9 column	 3 value	 0.322 
Considering row	 9 column	 18 value	 0.018 
Considering row	 9 column	 19 value	 0.141 
Considering row	 9 column	 15 value	 0.073 
Considering row	 9 column	 4 value	 0.006 
Considering row	 9 column	 7 value	 0.136 
Considering row	 9 column	 5 value	 0.123 
Considering row	 14 column	 13 value	 0.659 
Considering row	 14 column	 8 value	 0.097 
Considering row	 14 column	 3 value	 0.106 
Considering row	 14 column	 18 value	 0.361 
Considering row	 14 column	 19 value	 0.092 
Considering row	 14 column	 15 value	 0.084 
Considering row	 14 column	 4 value	 0.263 
Considering row	 14 column	 7 value	 0.139 
Considering row	 14 column	 5 value	 0.031 
Considering row	 13 column	 8 value	 0.097 
Considering row	 13 column	 3 value	 0.167 
Considering row	 13 column	 18 value	 0.18 
Considering row	 13 column	 19 value	 0.131 
Considering row	 13 column	 15 value	 0.137 
Considering row	 13 column	 4 value	 0.24 
Considering row	 13 column	 7 value	 0.085 
Considering row	 13 column	 5 value	 0.027 
Considering row	 8 column	 3 value	 0.224 
Considering row	 8 column	 18 value	 0.173 
Considering row	 8 column	 19 value	 0.235 
Considering row	 8 column	 15 value	 0.07 
Considering row	 8 column	 4 value	 0.02 
Considering row	 8 column	 7 value	 0.085 
Considering row	 8 column	 5 value	 0.004 
Considering row	 3 column	 18 value	 0.028 
Considering row	 3 column	 19 value	 0.027 
Considering row	 3 column	 15 value	 0.017 
Considering row	 3 column	 4 value	 0.094 
Considering row	 3 column	 7 value	 0.095 
Considering row	 3 column	 5 value	 0.097 
Considering row	 18 column	 19 value	 0.019 
Considering row	 18 column	 15 value	 0.12 
Considering row	 18 column	 4 value	 0.086 
Considering row	 18 column	 7 value	 0.132 
Considering row	 18 column	 5 value	 0.002 
Considering row	 19 column	 15 value	 0.019 
Considering row	 19 column	 4 value	 0.032 
Considering row	 19 column	 7 value	 0.056 
Considering row	 19 column	 5 value	 0.075 
Considering row	 15 column	 4 value	 0.043 
Considering row	 15 column	 7 value	 0.061 
Considering row	 15 column	 5 value	 0.08 
Considering row	 4 column	 7 value	 0.005 
Considering row	 4 column	 5 value	 0.213 
Considering row	 7 column	 5 value	 0.008 
> 
> colnames(trainDescr)[highCorr]
[1] "SDEPHR"
> 
> descr.ncol0 <- ncol(trainDescr)
> 
> # I've switched off the correlation remover and the results are better.
> if (sum(highCorr) > 0) {
+     warning("overfitting: correlations: err.trainDescr: ", paste(colnames(trainDescr)[highCorr], collapse = ", ") )
+     err.trainDescr <- trainDescr
+     trainDescr <- trainDescr[,-highCorr]
+ }
Warning message:
overfitting: correlations: err.trainDescr: SDEPHR 
> 
> descr.ncol1 <- ncol(trainDescr)
> 
> paste("Dropped: ", as.character(descr.ncol0 - descr.ncol1))
[1] "Dropped:  1"
> 
> descrCorr <- cor(trainDescr)
> summary(descrCorr[upper.tri(descrCorr)])
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
-0.85020 -0.13860 -0.01766  0.01577  0.11970  0.94490 
> 
> ## Dominant correlations
> ## At 0.9, there are some big ones that might need re-thinking.
> 
> table.descrCorr <- as.data.frame(as.table(descrCorr))
> table.descrCorr <- table.descrCorr[which(table.descrCorr$Var1 != table.descrCorr$Var2),]
> table.descrCorr[order(abs(table.descrCorr$Freq), decreasing = TRUE),]
              Var1           Var2         Freq
82       DEPBUCKET          AVGSQ  0.944870657
167          AVGSQ      DEPBUCKET  0.944870657
173      ARRBUCKET      DEPBUCKET  0.889095737
190      DEPBUCKET      ARRBUCKET  0.889095737
83       ARRBUCKET          AVGSQ  0.882590635
185          AVGSQ      ARRBUCKET  0.882590635
268       ARRSPOKE       DEPSPOKE -0.850165355
285       DEPSPOKE       ARRSPOKE -0.850165355
141       DEPSPOKE   DEPSTAATCIMP  0.671264566
260   DEPSTAATCIMP       DEPSPOKE  0.671264566
160       ARRSPOKE DOWNLINEATCIMP  0.671009330
279 DOWNLINEATCIMP       ARRSPOKE  0.671009330
211     TRNRANKGRP     DEPRANKGRP  0.658724662
228     DEPRANKGRP     TRNRANKGRP  0.658724662
123       DEPSPOKE   UPLINEATCIMP -0.600008252
259   UPLINEATCIMP       DEPSPOKE -0.600008252
142       ARRSPOKE   DEPSTAATCIMP -0.586442959
278   DEPSTAATCIMP       ARRSPOKE -0.586442959
13      TRNRANKGRP      SKDDEPSTA  0.574035134
217      SKDDEPSTA     TRNRANKGRP  0.574035134
159       DEPSPOKE DOWNLINEATCIMP -0.567682494
261 DOWNLINEATCIMP       DEPSPOKE -0.567682494
12      DEPRANKGRP      SKDDEPSTA  0.557399203
199      SKDDEPSTA     DEPRANKGRP  0.557399203
124       ARRSPOKE   UPLINEATCIMP  0.540734833
277   UPLINEATCIMP       ARRSPOKE  0.540734833
27  DOWNLINEATCIMP      SKDARRSTA  0.462378131
146      SKDARRSTA DOWNLINEATCIMP  0.462378131
116   DEPSTAATCIMP   UPLINEATCIMP -0.449249986
133   UPLINEATCIMP   DEPSTAATCIMP -0.449249986
8     DEPSTAATCIMP      SKDDEPSTA  0.423425796
127      SKDDEPSTA   DEPSTAATCIMP  0.423425796
135 DOWNLINEATCIMP   DEPSTAATCIMP -0.403695561
152   DEPSTAATCIMP DOWNLINEATCIMP -0.403695561
117 DOWNLINEATCIMP   UPLINEATCIMP  0.365833687
151   UPLINEATCIMP DOWNLINEATCIMP  0.365833687
233         xDURN2     TRNRANKGRP  0.361347207
301     TRNRANKGRP         xDURN2  0.361347207
34        ARRSPOKE      SKDARRSTA  0.345987375
272      SKDARRSTA       ARRSPOKE  0.345987375
15        DEPSPOKE      SKDDEPSTA  0.332823310
253      SKDDEPSTA       DEPSPOKE  0.332823310
26    DEPSTAATCIMP      SKDARRSTA -0.322204878
128      SKDARRSTA   DEPSTAATCIMP -0.322204878
33        DEPSPOKE      SKDARRSTA -0.318093195
254      SKDARRSTA       DEPSPOKE -0.318093195
81  DOWNLINEATCIMP          AVGSQ  0.298096458
149          AVGSQ DOWNLINEATCIMP  0.298096458
16        ARRSPOKE      SKDDEPSTA -0.298036487
271      SKDDEPSTA       ARRSPOKE -0.298036487
9   DOWNLINEATCIMP      SKDDEPSTA -0.285911992
145      SKDDEPSTA DOWNLINEATCIMP -0.285911992
269         xDURN2       DEPSPOKE  0.279030910
303       DEPSPOKE         xDURN2  0.279030910
178       ARRSPOKE      DEPBUCKET  0.276615722
280      DEPBUCKET       ARRSPOKE  0.276615722
154      DEPBUCKET DOWNLINEATCIMP  0.275167866
171 DOWNLINEATCIMP      DEPBUCKET  0.275167866
158     ARRRANKGRP DOWNLINEATCIMP -0.274110143
243 DOWNLINEATCIMP     ARRRANKGRP -0.274110143
3           SKDEQP      SKDDEPSTA  0.270065872
37       SKDDEPSTA         SKDEQP  0.270065872
2        SKDARRSTA      SKDDEPSTA -0.263453106
19       SKDDEPSTA      SKDARRSTA -0.263453106
49      TRNRANKGRP         SKDEQP  0.262837233
219         SKDEQP     TRNRANKGRP  0.262837233
287         xDURN2       ARRSPOKE -0.261107447
304       ARRSPOKE         xDURN2 -0.261107447
155      ARRBUCKET DOWNLINEATCIMP  0.255480148
189 DOWNLINEATCIMP      ARRBUCKET  0.255480148
231       DEPSPOKE     TRNRANKGRP  0.242138220
265     TRNRANKGRP       DEPSPOKE  0.242138220
48      DEPRANKGRP         SKDEQP  0.239915140
201         SKDEQP     DEPRANKGRP  0.239915140
126   xAVGSKDAVAIL   UPLINEATCIMP  0.234867014
313   UPLINEATCIMP   xAVGSKDAVAIL  0.234867014
177       DEPSPOKE      DEPBUCKET -0.231298301
262      DEPBUCKET       DEPSPOKE -0.231298301
214       ARRSPOKE     DEPRANKGRP -0.229640758
282     DEPRANKGRP       ARRSPOKE -0.229640758
161         xDURN2 DOWNLINEATCIMP -0.226093423
297 DOWNLINEATCIMP         xDURN2 -0.226093423
196       ARRSPOKE      ARRBUCKET  0.225890655
281      ARRBUCKET       ARRSPOKE  0.225890655
232       ARRSPOKE     TRNRANKGRP -0.225591539
283     TRNRANKGRP       ARRSPOKE -0.225591539
157     TRNRANKGRP DOWNLINEATCIMP -0.224193213
225 DOWNLINEATCIMP     TRNRANKGRP -0.224193213
25    UPLINEATCIMP      SKDARRSTA  0.223824406
110      SKDARRSTA   UPLINEATCIMP  0.223824406
88        ARRSPOKE          AVGSQ  0.219975654
275          AVGSQ       ARRSPOKE  0.219975654
270   xAVGSKDAVAIL       DEPSPOKE -0.212821518
321       DEPSPOKE   xAVGSKDAVAIL -0.212821518
40          SKDEPS         SKDEQP  0.212586898
57          SKDEQP         SKDEPS  0.212586898
213       DEPSPOKE     DEPRANKGRP  0.208188512
264     DEPRANKGRP       DEPSPOKE  0.208188512
156     DEPRANKGRP DOWNLINEATCIMP -0.199411990
207 DOWNLINEATCIMP     DEPRANKGRP -0.199411990
89          xDURN2          AVGSQ -0.197447957
293          AVGSQ         xDURN2 -0.197447957
195       DEPSPOKE      ARRBUCKET -0.189934966
263      ARRBUCKET       DEPSPOKE -0.189934966
87        DEPSPOKE          AVGSQ -0.188666787
257          AVGSQ       DEPSPOKE -0.188666787
85      TRNRANKGRP          AVGSQ -0.188226304
221          AVGSQ     TRNRANKGRP -0.188226304
179         xDURN2      DEPBUCKET -0.183349624
298      DEPBUCKET         xDURN2 -0.183349624
215         xDURN2     DEPRANKGRP  0.180043357
300     DEPRANKGRP         xDURN2  0.180043357
125         xDURN2   UPLINEATCIMP -0.173240320
295   UPLINEATCIMP         xDURN2 -0.173240320
198   xAVGSKDAVAIL      ARRBUCKET -0.170644257
317      ARRBUCKET   xAVGSKDAVAIL -0.170644257
175     TRNRANKGRP      DEPBUCKET -0.170618431
226      DEPBUCKET     TRNRANKGRP -0.170618431
30      DEPRANKGRP      SKDARRSTA -0.167375913
200      SKDARRSTA     DEPRANKGRP -0.167375913
10       DEPBUCKET      SKDDEPSTA -0.165029385
163      SKDDEPSTA      DEPBUCKET -0.165029385
7     UPLINEATCIMP      SKDDEPSTA -0.164964952
109      SKDDEPSTA   UPLINEATCIMP -0.164964952
84      DEPRANKGRP          AVGSQ -0.161451853
203          AVGSQ     DEPRANKGRP -0.161451853
86      ARRRANKGRP          AVGSQ -0.159135469
239          AVGSQ     ARRRANKGRP -0.159135469
174     DEPRANKGRP      DEPBUCKET -0.155547085
208      DEPBUCKET     DEPRANKGRP -0.155547085
5            AVGSQ      SKDDEPSTA -0.150522366
73       SKDDEPSTA          AVGSQ -0.150522366
139     TRNRANKGRP   DEPSTAATCIMP -0.147409309
224   DEPSTAATCIMP     TRNRANKGRP -0.147409309
118      DEPBUCKET   UPLINEATCIMP  0.144940797
169   UPLINEATCIMP      DEPBUCKET  0.144940797
176     ARRRANKGRP      DEPBUCKET -0.142348062
244      DEPBUCKET     ARRRANKGRP -0.142348062
144   xAVGSKDAVAIL   DEPSTAATCIMP -0.141077194
314   DEPSTAATCIMP   xAVGSKDAVAIL -0.141077194
103     TRNRANKGRP      AVGLOFATC  0.139184315
222      AVGLOFATC     TRNRANKGRP  0.139184315
136      DEPBUCKET   DEPSTAATCIMP -0.138581846
170   DEPSTAATCIMP      DEPBUCKET -0.138581846
288   xAVGSKDAVAIL       ARRSPOKE  0.137677242
322       ARRSPOKE   xAVGSKDAVAIL  0.137677242
212     ARRRANKGRP     DEPRANKGRP  0.136562948
246     DEPRANKGRP     ARRRANKGRP  0.136562948
98    DEPSTAATCIMP      AVGLOFATC -0.135778614
132      AVGLOFATC   DEPSTAATCIMP -0.135778614
107         xDURN2      AVGLOFATC -0.132084629
294      AVGLOFATC         xDURN2 -0.132084629
216   xAVGSKDAVAIL     DEPRANKGRP  0.130574789
318     DEPRANKGRP   xAVGSKDAVAIL  0.130574789
194     ARRRANKGRP      ARRBUCKET -0.129698517
245      ARRBUCKET     ARRRANKGRP -0.129698517
137      ARRBUCKET   DEPSTAATCIMP -0.127726148
188   DEPSTAATCIMP      ARRBUCKET -0.127726148
17          xDURN2      SKDDEPSTA  0.127598189
289      SKDDEPSTA         xDURN2  0.127598189
99  DOWNLINEATCIMP      AVGLOFATC -0.126763572
150      AVGLOFATC DOWNLINEATCIMP -0.126763572
197         xDURN2      ARRBUCKET -0.125836459
299      ARRBUCKET         xDURN2 -0.125836459
138     DEPRANKGRP   DEPSTAATCIMP  0.124672682
206   DEPSTAATCIMP     DEPRANKGRP  0.124672682
62    DEPSTAATCIMP         SKDEPS -0.123445793
130         SKDEPS   DEPSTAATCIMP -0.123445793
11       ARRBUCKET      SKDDEPSTA -0.120728212
181      SKDDEPSTA      ARRBUCKET -0.120728212
251         xDURN2     ARRRANKGRP  0.119675180
302     ARRRANKGRP         xDURN2  0.119675180
90    xAVGSKDAVAIL          AVGSQ -0.113720147
311          AVGSQ   xAVGSKDAVAIL -0.113720147
31      TRNRANKGRP      SKDARRSTA -0.105802023
218      SKDARRSTA     TRNRANKGRP -0.105802023
192     DEPRANKGRP      ARRBUCKET -0.105057984
209      ARRBUCKET     DEPRANKGRP -0.105057984
162   xAVGSKDAVAIL DOWNLINEATCIMP  0.102577364
315 DOWNLINEATCIMP   xAVGSKDAVAIL  0.102577364
120     DEPRANKGRP   UPLINEATCIMP -0.097218129
205   UPLINEATCIMP     DEPRANKGRP -0.097218129
121     TRNRANKGRP   UPLINEATCIMP -0.097037814
223   UPLINEATCIMP     TRNRANKGRP -0.097037814
22          SKDEPS      SKDARRSTA -0.096699169
56       SKDARRSTA         SKDEPS -0.096699169
63  DOWNLINEATCIMP         SKDEPS -0.095568613
148         SKDEPS DOWNLINEATCIMP -0.095568613
24       AVGLOFATC      SKDARRSTA -0.095234466
92       SKDARRSTA      AVGLOFATC -0.095234466
21          SKDEQP      SKDARRSTA  0.094073459
38       SKDARRSTA         SKDEQP  0.094073459
29       ARRBUCKET      SKDARRSTA  0.092625400
182      SKDARRSTA      ARRBUCKET  0.092625400
193     TRNRANKGRP      ARRBUCKET -0.092415252
227      ARRBUCKET     TRNRANKGRP -0.092415252
234   xAVGSKDAVAIL     TRNRANKGRP  0.092011501
319     TRNRANKGRP   xAVGSKDAVAIL  0.092011501
18    xAVGSKDAVAIL      SKDDEPSTA  0.088580325
307      SKDDEPSTA   xAVGSKDAVAIL  0.088580325
53          xDURN2         SKDEQP  0.086170070
291         SKDEQP         xDURN2  0.086170070
102     DEPRANKGRP      AVGLOFATC  0.085474019
204      AVGLOFATC     DEPRANKGRP  0.085474019
97    UPLINEATCIMP      AVGLOFATC -0.085180887
114      AVGLOFATC   UPLINEATCIMP -0.085180887
230     ARRRANKGRP     TRNRANKGRP  0.083906762
247     TRNRANKGRP     ARRRANKGRP  0.083906762
249       DEPSPOKE     ARRRANKGRP  0.083162083
266     ARRRANKGRP       DEPSPOKE  0.083162083
23           AVGSQ      SKDARRSTA  0.082898864
74       SKDARRSTA          AVGSQ  0.082898864
68      ARRRANKGRP         SKDEPS  0.080398834
238         SKDEPS     ARRRANKGRP  0.080398834
72    xAVGSKDAVAIL         SKDEPS  0.075169577
310         SKDEPS   xAVGSKDAVAIL  0.075169577
140     ARRRANKGRP   DEPSTAATCIMP  0.073371196
242   DEPSTAATCIMP     ARRRANKGRP  0.073371196
28       DEPBUCKET      SKDARRSTA  0.072910977
164      SKDARRSTA      DEPBUCKET  0.072910977
119      ARRBUCKET   UPLINEATCIMP  0.071409699
187   UPLINEATCIMP      ARRBUCKET  0.071409699
122     ARRRANKGRP   UPLINEATCIMP -0.069790367
241   UPLINEATCIMP     ARRRANKGRP -0.069790367
14      ARRRANKGRP      SKDDEPSTA  0.068927801
235      SKDDEPSTA     ARRRANKGRP  0.068927801
52        ARRSPOKE         SKDEQP  0.066579707
273         SKDEQP       ARRSPOKE  0.066579707
79    UPLINEATCIMP          AVGSQ  0.062631172
113          AVGSQ   UPLINEATCIMP  0.062631172
104     ARRRANKGRP      AVGLOFATC -0.061491190
240      AVGLOFATC     ARRRANKGRP -0.061491190
250       ARRSPOKE     ARRRANKGRP -0.057002549
284     ARRRANKGRP       ARRSPOKE -0.057002549
108   xAVGSKDAVAIL      AVGLOFATC -0.056264979
312      AVGLOFATC   xAVGSKDAVAIL -0.056264979
100      DEPBUCKET      AVGLOFATC -0.053357134
168      AVGLOFATC      DEPBUCKET -0.053357134
180   xAVGSKDAVAIL      DEPBUCKET -0.053125467
316      DEPBUCKET   xAVGSKDAVAIL -0.053125467
6        AVGLOFATC      SKDDEPSTA -0.044946507
91       SKDDEPSTA      AVGLOFATC -0.044946507
101      ARRBUCKET      AVGLOFATC -0.043093769
186      AVGLOFATC      ARRBUCKET -0.043093769
50      ARRRANKGRP         SKDEQP -0.042512956
237         SKDEQP     ARRRANKGRP -0.042512956
80    DEPSTAATCIMP          AVGSQ -0.040428658
131          AVGSQ   DEPSTAATCIMP -0.040428658
59           AVGSQ         SKDEPS -0.038820886
76          SKDEPS          AVGSQ -0.038820886
46       DEPBUCKET         SKDEQP  0.037125178
165         SKDEQP      DEPBUCKET  0.037125178
106       ARRSPOKE      AVGLOFATC -0.034402462
276      AVGLOFATC       ARRSPOKE -0.034402462
54    xAVGSKDAVAIL         SKDEQP  0.031863410
309         SKDEQP   xAVGSKDAVAIL  0.031863410
67      TRNRANKGRP         SKDEPS  0.030883560
220         SKDEPS     TRNRANKGRP  0.030883560
64       DEPBUCKET         SKDEPS -0.030101407
166         SKDEPS      DEPBUCKET -0.030101407
35          xDURN2      SKDARRSTA  0.027576751
290      SKDARRSTA         xDURN2  0.027576751
78       AVGLOFATC          AVGSQ -0.027382453
95           AVGSQ      AVGLOFATC -0.027382453
36    xAVGSKDAVAIL      SKDARRSTA  0.027225219
308      SKDARRSTA   xAVGSKDAVAIL  0.027225219
66      DEPRANKGRP         SKDEPS  0.027025501
202         SKDEPS     DEPRANKGRP  0.027025501
4           SKDEPS      SKDDEPSTA -0.024267794
55       SKDDEPSTA         SKDEPS -0.024267794
43    UPLINEATCIMP         SKDEQP -0.019807499
111         SKDEQP   UPLINEATCIMP -0.019807499
51        DEPSPOKE         SKDEQP  0.019755644
255         SKDEQP       DEPSPOKE  0.019755644
306   xAVGSKDAVAIL         xDURN2 -0.019255572
323         xDURN2   xAVGSKDAVAIL -0.019255572
252   xAVGSKDAVAIL     ARRRANKGRP -0.018743432
320     ARRRANKGRP   xAVGSKDAVAIL -0.018743432
143         xDURN2   DEPSTAATCIMP -0.017999758
296   DEPSTAATCIMP         xDURN2 -0.017999758
45  DOWNLINEATCIMP         SKDEQP -0.017658860
147         SKDEQP DOWNLINEATCIMP -0.017658860
70        ARRSPOKE         SKDEPS  0.017573485
274         SKDEPS       ARRSPOKE  0.017573485
65       ARRBUCKET         SKDEPS  0.017414895
184         SKDEPS      ARRBUCKET  0.017414895
32      ARRRANKGRP      SKDARRSTA  0.016733374
236      SKDARRSTA     ARRRANKGRP  0.016733374
41           AVGSQ         SKDEQP  0.010218807
75          SKDEQP          AVGSQ  0.010218807
47       ARRBUCKET         SKDEQP  0.009926479
183         SKDEQP      ARRBUCKET  0.009926479
105       DEPSPOKE      AVGLOFATC -0.008540402
258      AVGLOFATC       DEPSPOKE -0.008540402
60       AVGLOFATC         SKDEPS  0.008240563
94          SKDEPS      AVGLOFATC  0.008240563
44    DEPSTAATCIMP         SKDEQP -0.005922601
129         SKDEQP   DEPSTAATCIMP -0.005922601
42       AVGLOFATC         SKDEQP -0.004889040
93          SKDEQP      AVGLOFATC -0.004889040
69        DEPSPOKE         SKDEPS -0.004617067
256         SKDEPS       DEPSPOKE -0.004617067
61    UPLINEATCIMP         SKDEPS  0.004016263
112         SKDEPS   UPLINEATCIMP  0.004016263
71          xDURN2         SKDEPS  0.001748012
292         SKDEPS         xDURN2  0.001748012
> 
> ### Models
> 
> ## Try GBM (gradient boosting). Works well for mixed data.
> ## And there is a tutorial for it with caret.
> 
> ## Training controller and big grid
> ## Check the ROC (my preferred.)
> 
> # I'm not using this at the moment.
> 
> tr.cols <- colnames(trainDescr)
> tr.cols
 [1] "SKDDEPSTA"      "SKDARRSTA"      "SKDEQP"         "SKDEPS"        
 [5] "AVGSQ"          "AVGLOFATC"      "UPLINEATCIMP"   "DEPSTAATCIMP"  
 [9] "DOWNLINEATCIMP" "DEPBUCKET"      "ARRBUCKET"      "DEPRANKGRP"    
[13] "TRNRANKGRP"     "ARRRANKGRP"     "DEPSPOKE"       "ARRSPOKE"      
[17] "xDURN2"         "xAVGSKDAVAIL"  
> tr.icols <- grep("((STA|EQP)$)|(^xD)", tr.cols)
> tr.icols <- rev(tr.icols)
> 
> fitControl <- trainControl(## 10-fold CV
+     method = "repeatedcv",
+     number = 10,
+     ## repeated ten times
+     repeats = 10,
+     classProbs = 10,
+     summaryFunction = twoClassSummary)
> 
> ## Some trial and error with variables to branch and boost.
> ## I'm just going to try the airports and the planes and the duration
> ## of the flight. There may be some distance relationship there that
> ## air traffic control use.
> 
> ## Annoying because I drop variables, this needs to be looked up.
> 
> gbmGrid <- expand.grid(interaction.depth = c(1 2 3),
Error: unexpected numeric constant in "gbmGrid <- expand.grid(interaction.depth = c(1 2"
>                         n.trees = (1:30)*90,
Error: unexpected ',' in "                        n.trees = (1:30)*90,"
>                         shrinkage = 0.1,
Error: unexpected ',' in "                        shrinkage = 0.1,"
>                         n.minobsinnode = 20)
Error: unexpected ')' in "                        n.minobsinnode = 20)"
> 
> set.seed(seed.mine)
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "ROC",
+                  verbose = FALSE)
> gbmFit1
Stochastic Gradient Boosting 

248 samples
 18 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 222, 223, 223, 224, 223, 223, ... 

Resampling results across tuning parameters:

  n.trees  ROC        Sens       Spec       ROC SD      Sens SD    Spec SD  
    90     0.7812671  0.7548352  0.6721212  0.09224463  0.1063642  0.1395160
   180     0.7707934  0.7352747  0.6703788  0.08807498  0.1232063  0.1261087
   270     0.7674317  0.7250549  0.6615152  0.09243293  0.1243827  0.1263309
   360     0.7657218  0.7206593  0.6533333  0.09217592  0.1197734  0.1290919
   450     0.7649509  0.7281319  0.6534091  0.09198453  0.1220952  0.1260024
   540     0.7616529  0.7265385  0.6577273  0.09655198  0.1261813  0.1268553
   630     0.7597527  0.7215385  0.6552273  0.09826901  0.1207627  0.1316812
   720     0.7572299  0.7302198  0.6578030  0.09869070  0.1175473  0.1305119
   810     0.7581893  0.7352747  0.6633333  0.09937807  0.1186727  0.1333690
   900     0.7562313  0.7323077  0.6559091  0.10184582  0.1154311  0.1247391
   990     0.7563124  0.7321978  0.6612879  0.09990360  0.1211050  0.1258178
  1080     0.7574305  0.7344505  0.6631818  0.09991354  0.1148669  0.1231500
  1170     0.7565626  0.7307143  0.6524242  0.09785921  0.1130916  0.1268228
  1260     0.7567878  0.7321978  0.6678788  0.09836208  0.1175113  0.1277221
  1350     0.7575250  0.7286813  0.6607576  0.09245574  0.1143473  0.1331482
  1440     0.7574567  0.7346154  0.6598485  0.09413051  0.1159120  0.1241163
  1530     0.7555411  0.7337912  0.6580303  0.09833993  0.1164995  0.1234537
  1620     0.7549879  0.7351099  0.6571212  0.09906326  0.1113711  0.1336699
  1710     0.7582135  0.7352198  0.6543939  0.09459588  0.1154301  0.1299587
  1800     0.7582468  0.7352747  0.6534091  0.09362481  0.1176611  0.1324620
  1890     0.7564269  0.7345055  0.6571212  0.09342466  0.1185609  0.1279258
  1980     0.7563770  0.7343407  0.6543939  0.09436805  0.1196427  0.1318716
  2070     0.7578800  0.7321978  0.6525758  0.09285305  0.1145627  0.1333677
  2160     0.7572831  0.7300000  0.6562121  0.09280209  0.1185921  0.1270899
  2250     0.7546112  0.7322527  0.6509091  0.09951861  0.1196362  0.1334053
  2340     0.7549009  0.7360440  0.6518182  0.09715700  0.1170493  0.1329885
  2430     0.7553546  0.7345055  0.6561364  0.09696064  0.1150309  0.1338747
  2520     0.7559270  0.7346154  0.6534091  0.09667108  0.1197602  0.1333170
  2610     0.7559095  0.7317033  0.6561364  0.09669876  0.1149333  0.1320918
  2700     0.7553118  0.7359890  0.6569697  0.09673141  0.1123744  0.1341005

Tuning parameter 'interaction.depth' was held constant at a value of 2

Tuning parameter 'shrinkage' was held constant at a value of 0.1

Tuning parameter 'n.minobsinnode' was held constant at a value of 20
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 90, interaction.depth =
 2, shrinkage = 0.1 and n.minobsinnode = 20. 
> 
> ## The acid test is dissapointing, but I've seen worse.
> 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
  Accuracy      Kappa 
 0.4444444 -0.1250000 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     20   20
    Weak       20   12
                                          
               Accuracy : 0.4444          
                 95% CI : (0.3272, 0.5664)
    No Information Rate : 0.5556          
    P-Value [Acc > NIR] : 0.9778          
                                          
                  Kappa : -0.125          
 Mcnemar's Test P-Value : 1.0000          
                                          
            Sensitivity : 0.3750          
            Specificity : 0.5000          
         Pos Pred Value : 0.3750          
         Neg Pred Value : 0.5000          
             Prevalence : 0.4444          
         Detection Rate : 0.1667          
   Detection Prevalence : 0.4444          
      Balanced Accuracy : 0.4375          
                                          
       'Positive' Class : Weak            
                                          
> 
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
 Accuracy     Kappa 
0.8346774 0.6642451 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    119   23
    Weak       18   88
                                          
               Accuracy : 0.8347          
                 95% CI : (0.7825, 0.8787)
    No Information Rate : 0.5524          
    P-Value [Acc > NIR] : <2e-16          
                                          
                  Kappa : 0.6642          
 Mcnemar's Test P-Value : 0.5322          
                                          
            Sensitivity : 0.7928          
            Specificity : 0.8686          
         Pos Pred Value : 0.8302          
         Neg Pred Value : 0.8380          
             Prevalence : 0.4476          
         Detection Rate : 0.3548          
   Detection Prevalence : 0.4274          
      Balanced Accuracy : 0.8307          
                                          
       'Positive' Class : Weak            
                                          
> gbmGrid <- expand.grid(interaction.depth = 3,
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.1,
+                         n.minobsinnode = 20)
> c(1, 2, 3)
[1] 1 2 3
> c(1 2 3)
Error: unexpected numeric constant in "c(1 2"
> gbmGrid <- expand.grid(interaction.depth = c(1, 2, 3),
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.1,
+                         n.minobsinnode = 20)
> set.seed(seed.mine)
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "ROC",
+                  verbose = FALSE)
> gbmFit1
Stochastic Gradient Boosting 

248 samples
 18 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 222, 223, 223, 224, 223, 223, ... 

Resampling results across tuning parameters:

  interaction.depth  n.trees  ROC        Sens       Spec       ROC SD    
  1                    90     0.7884576  0.7396703  0.6985606  0.08426955
  1                   180     0.7837371  0.7315385  0.7010606  0.08641051
  1                   270     0.7829550  0.7352198  0.6970455  0.08749887
  1                   360     0.7792474  0.7278022  0.6853788  0.08790904
  1                   450     0.7763528  0.7255495  0.6887879  0.09431775
  1                   540     0.7693785  0.7250549  0.6824242  0.09408151
  1                   630     0.7708100  0.7342857  0.6787121  0.09190307
  1                   720     0.7674034  0.7264286  0.6816667  0.09597535
  1                   810     0.7632634  0.7323077  0.6772727  0.10397160
  1                   900     0.7615901  0.7241209  0.6853030  0.10554621
  1                   990     0.7638249  0.7287363  0.6861364  0.09635939
  1                  1080     0.7637687  0.7234615  0.6862121  0.09390176
  1                  1170     0.7603193  0.7219780  0.6800000  0.10047170
  1                  1260     0.7591367  0.7237363  0.6817424  0.09623999
  1                  1350     0.7587725  0.7236264  0.6781061  0.09524160
  1                  1440     0.7584932  0.7242308  0.6789394  0.09528317
  1                  1530     0.7573277  0.7191209  0.6752273  0.09188593
  1                  1620     0.7556926  0.7227473  0.6726515  0.09442162
  1                  1710     0.7547453  0.7190659  0.6779545  0.09214913
  1                  1800     0.7533379  0.7190110  0.6727273  0.09672924
  1                  1890     0.7549600  0.7198352  0.6718939  0.09417711
  1                  1980     0.7543119  0.7184066  0.6691667  0.09246356
  1                  2070     0.7543069  0.7198901  0.6682576  0.09154568
  1                  2160     0.7541675  0.7182418  0.6690909  0.09237110
  1                  2250     0.7523772  0.7204945  0.6609848  0.09145497
  1                  2340     0.7517341  0.7182967  0.6672727  0.09245953
  1                  2430     0.7515509  0.7174176  0.6654545  0.09300781
  1                  2520     0.7522748  0.7197802  0.6656061  0.09250117
  1                  2610     0.7516413  0.7139560  0.6637121  0.09227905
  1                  2700     0.7498452  0.7124725  0.6700758  0.09206161
  2                    90     0.7831015  0.7553297  0.6679545  0.08846377
  2                   180     0.7719277  0.7367582  0.6699242  0.09591411
  2                   270     0.7720617  0.7337363  0.6622727  0.08959718
  2                   360     0.7693944  0.7345604  0.6587879  0.09516084
  2                   450     0.7672053  0.7316484  0.6634091  0.09429541
  2                   540     0.7698031  0.7331319  0.6597727  0.09061729
  2                   630     0.7669959  0.7396703  0.6578788  0.09186321
  2                   720     0.7653276  0.7381319  0.6509091  0.09103059
  2                   810     0.7625025  0.7366484  0.6507576  0.09186555
  2                   900     0.7620059  0.7380769  0.6542424  0.09277290
  2                   990     0.7613162  0.7351648  0.6606061  0.09568592
  2                  1080     0.7643677  0.7379670  0.6606061  0.08918649
  2                  1170     0.7632251  0.7373077  0.6543182  0.08774121
  2                  1260     0.7634274  0.7365385  0.6532576  0.08961381
  2                  1350     0.7604050  0.7409341  0.6505303  0.09389487
  2                  1440     0.7615226  0.7351648  0.6587121  0.09076741
  2                  1530     0.7592603  0.7373077  0.6533333  0.09574901
  2                  1620     0.7585415  0.7367582  0.6506061  0.09676253
  2                  1710     0.7594043  0.7359890  0.6550758  0.09575892
  2                  1800     0.7572632  0.7396154  0.6551515  0.09581672
  2                  1890     0.7571200  0.7365934  0.6506061  0.09969354
  2                  1980     0.7567920  0.7329670  0.6543182  0.09964600
  2                  2070     0.7567075  0.7373626  0.6550758  0.09827377
  2                  2160     0.7561014  0.7371429  0.6596970  0.09935441
  2                  2250     0.7560102  0.7327473  0.6579545  0.10013138
  2                  2340     0.7561043  0.7371978  0.6588636  0.09998629
  2                  2430     0.7563274  0.7401648  0.6598485  0.09907720
  2                  2520     0.7557547  0.7348901  0.6571212  0.09866492
  2                  2610     0.7546100  0.7341758  0.6553788  0.10479888
  2                  2700     0.7541891  0.7371429  0.6544697  0.10389360
  3                    90     0.7773156  0.7541209  0.6578788  0.09220955
  3                   180     0.7687338  0.7353297  0.6606061  0.09341486
  3                   270     0.7640493  0.7278022  0.6507576  0.09756585
  3                   360     0.7629550  0.7286264  0.6471212  0.09372160
  3                   450     0.7602048  0.7264286  0.6497727  0.09289137
  3                   540     0.7582080  0.7249451  0.6514394  0.09730417
  3                   630     0.7581036  0.7285714  0.6497727  0.09506166
  3                   720     0.7612292  0.7234615  0.6496970  0.09289447
  3                   810     0.7582830  0.7256593  0.6478788  0.09771276
  3                   900     0.7587975  0.7263736  0.6461364  0.09651580
  3                   990     0.7565668  0.7342308  0.6427273  0.09764961
  3                  1080     0.7558770  0.7320879  0.6480303  0.09809879
  3                  1170     0.7562608  0.7282418  0.6525000  0.09634898
  3                  1260     0.7553488  0.7298901  0.6525758  0.09761670
  3                  1350     0.7547881  0.7319780  0.6500000  0.10125371
  3                  1440     0.7538029  0.7326923  0.6506818  0.10063492
  3                  1530     0.7553596  0.7276374  0.6481818  0.09606088
  3                  1620     0.7539877  0.7303297  0.6480303  0.10009023
  3                  1710     0.7561822  0.7319780  0.6490152  0.09564853
  3                  1800     0.7538341  0.7304945  0.6534091  0.09995180
  3                  1890     0.7539186  0.7304945  0.6541667  0.09953830
  3                  1980     0.7536222  0.7310989  0.6488636  0.09942213
  3                  2070     0.7550683  0.7303846  0.6478788  0.09511413
  3                  2160     0.7538037  0.7297802  0.6515152  0.09516317
  3                  2250     0.7552385  0.7276374  0.6525000  0.09464899
  3                  2340     0.7542999  0.7277473  0.6542424  0.09556787
  3                  2430     0.7524792  0.7297802  0.6542424  0.09952727
  3                  2520     0.7543652  0.7268681  0.6534091  0.09668183
  3                  2610     0.7547124  0.7290659  0.6534091  0.09625711
  3                  2700     0.7535773  0.7261538  0.6534091  0.09628289
  Sens SD    Spec SD  
  0.1071241  0.1373476
  0.1254181  0.1374072
  0.1235383  0.1319319
  0.1294700  0.1255464
  0.1229660  0.1418222
  0.1237855  0.1339344
  0.1206001  0.1417421
  0.1199555  0.1409254
  0.1178701  0.1371183
  0.1214210  0.1373524
  0.1247175  0.1386999
  0.1209322  0.1327759
  0.1170417  0.1332550
  0.1260126  0.1297297
  0.1250614  0.1321251
  0.1253614  0.1240569
  0.1220048  0.1305456
  0.1217574  0.1326148
  0.1200530  0.1362849
  0.1222713  0.1304183
  0.1159172  0.1354409
  0.1198235  0.1381672
  0.1171822  0.1374742
  0.1183374  0.1328793
  0.1195567  0.1329338
  0.1213747  0.1364133
  0.1210159  0.1355908
  0.1222762  0.1380412
  0.1241321  0.1350045
  0.1215735  0.1381518
  0.1120921  0.1355281
  0.1177640  0.1242225
  0.1162821  0.1361006
  0.1173219  0.1358607
  0.1113750  0.1327850
  0.1201459  0.1279370
  0.1212916  0.1383587
  0.1206979  0.1393563
  0.1161032  0.1279615
  0.1175825  0.1267096
  0.1152299  0.1239644
  0.1194062  0.1274963
  0.1218457  0.1274174
  0.1197522  0.1318324
  0.1165204  0.1337264
  0.1147100  0.1306775
  0.1185013  0.1312474
  0.1190005  0.1356616
  0.1189679  0.1359526
  0.1107192  0.1354101
  0.1147441  0.1287148
  0.1205128  0.1347542
  0.1158817  0.1380976
  0.1171842  0.1288787
  0.1146423  0.1349336
  0.1168332  0.1325980
  0.1102981  0.1298503
  0.1137393  0.1347153
  0.1130411  0.1377026
  0.1147306  0.1306754
  0.1089212  0.1353811
  0.1185356  0.1356176
  0.1192598  0.1304427
  0.1183808  0.1276698
  0.1118084  0.1333104
  0.1169552  0.1320549
  0.1130849  0.1306797
  0.1117177  0.1289032
  0.1110172  0.1316415
  0.1096234  0.1294156
  0.1102576  0.1352054
  0.1132334  0.1281513
  0.1156800  0.1291975
  0.1157678  0.1299196
  0.1120353  0.1335413
  0.1126076  0.1279089
  0.1144073  0.1355762
  0.1131110  0.1345077
  0.1144561  0.1347129
  0.1115300  0.1291963
  0.1139616  0.1302198
  0.1139467  0.1287513
  0.1110749  0.1315402
  0.1116230  0.1279456
  0.1162660  0.1315542
  0.1128051  0.1252786
  0.1131452  0.1279163
  0.1167555  0.1342660
  0.1163038  0.1311204
  0.1180682  0.1342660

Tuning parameter 'shrinkage' was held constant at a value of 0.1

Tuning parameter 'n.minobsinnode' was held constant at a value of 20
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 90, interaction.depth =
 1, shrinkage = 0.1 and n.minobsinnode = 20. 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
   Accuracy       Kappa 
 0.48611111 -0.06389776 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     25   22
    Weak       15   10
                                          
               Accuracy : 0.4861          
                 95% CI : (0.3665, 0.6069)
    No Information Rate : 0.5556          
    P-Value [Acc > NIR] : 0.9036          
                                          
                  Kappa : -0.0639         
 Mcnemar's Test P-Value : 0.3239          
                                          
            Sensitivity : 0.3125          
            Specificity : 0.6250          
         Pos Pred Value : 0.4000          
         Neg Pred Value : 0.5319          
             Prevalence : 0.4444          
         Detection Rate : 0.1389          
   Detection Prevalence : 0.3472          
      Balanced Accuracy : 0.4688          
                                          
       'Positive' Class : Weak            
                                          
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
 Accuracy     Kappa 
0.8064516 0.6072583 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    115   26
    Weak       22   85
                                          
               Accuracy : 0.8065          
                 95% CI : (0.7517, 0.8537)
    No Information Rate : 0.5524          
    P-Value [Acc > NIR] : <2e-16          
                                          
                  Kappa : 0.6073          
 Mcnemar's Test P-Value : 0.665           
                                          
            Sensitivity : 0.7658          
            Specificity : 0.8394          
         Pos Pred Value : 0.7944          
         Neg Pred Value : 0.8156          
             Prevalence : 0.4476          
         Detection Rate : 0.3427          
   Detection Prevalence : 0.4315          
      Balanced Accuracy : 0.8026          
\                                          
       'Positive' Class : Weak            
                                          
> gbmGrid <- expand.grid(interaction.depth = 2,
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.1,
+                         n.minobsinnode = 20)
> set.seed(seed.mine)
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "ROC",
+                  verbose = FALSE)
> gbmFit1
Stochastic Gradient Boosting 

248 samples
 18 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 222, 223, 223, 224, 223, 223, ... 

Resampling results across tuning parameters:

  n.trees  ROC        Sens       Spec       ROC SD      Sens SD    Spec SD  
    90     0.7839065  0.7556044  0.6878788  0.09130937  0.1231719  0.1365633
   180     0.7757035  0.7428571  0.6716667  0.10128691  0.1166868  0.1284125
   270     0.7708596  0.7398901  0.6654545  0.09979901  0.1237172  0.1292606
   360     0.7657401  0.7346703  0.6671970  0.09719710  0.1199352  0.1397824
   450     0.7616146  0.7311538  0.6606061  0.10630184  0.1240791  0.1291093
   540     0.7617420  0.7353297  0.6536364  0.10366027  0.1168723  0.1334896
   630     0.7628301  0.7376374  0.6526515  0.09843486  0.1141701  0.1386461
   720     0.7626369  0.7324176  0.6500000  0.10136035  0.1127108  0.1344370
   810     0.7615476  0.7331868  0.6525758  0.10056285  0.1136077  0.1362659
   900     0.7644426  0.7375275  0.6461364  0.09513307  0.1147973  0.1344512
   990     0.7628076  0.7412088  0.6562879  0.09960745  0.1136726  0.1306122
  1080     0.7592487  0.7405495  0.6490152  0.09932442  0.1191067  0.1389329
  1170     0.7616821  0.7396154  0.6534848  0.10070452  0.1205934  0.1357485
  1260     0.7596503  0.7389011  0.6571970  0.10002584  0.1192395  0.1320588
  1350     0.7610256  0.7432418  0.6545455  0.09982151  0.1190793  0.1385859
  1440     0.7603642  0.7389011  0.6535606  0.09970836  0.1175680  0.1360182
  1530     0.7603705  0.7409890  0.6571212  0.09992087  0.1159712  0.1360726
  1620     0.7605590  0.7366484  0.6597727  0.10006939  0.1189624  0.1362790
  1710     0.7578534  0.7367582  0.6571212  0.09978075  0.1173438  0.1339947
  1800     0.7583421  0.7396154  0.6642424  0.09970362  0.1186458  0.1366816
  1890     0.7571762  0.7374176  0.6606061  0.09863970  0.1150453  0.1361594
  1980     0.7580499  0.7358791  0.6607576  0.09953735  0.1168311  0.1370784
  2070     0.7572494  0.7359341  0.6625000  0.10211912  0.1166210  0.1361823
  2160     0.7575762  0.7380769  0.6570455  0.10182075  0.1128231  0.1401370
  2250     0.7569327  0.7409341  0.6588636  0.10134065  0.1146658  0.1401394
  2340     0.7572249  0.7336813  0.6607576  0.10122794  0.1177416  0.1352391
  2430     0.7558487  0.7364286  0.6597727  0.10265794  0.1174019  0.1405015
  2520     0.7572740  0.7350549  0.6596970  0.10190934  0.1130945  0.1403388
  2610     0.7564652  0.7350000  0.6570455  0.10020193  0.1148637  0.1368087
  2700     0.7552377  0.7387912  0.6571212  0.10508789  0.1121464  0.1394891

Tuning parameter 'interaction.depth' was held constant at a value of 2

Tuning parameter 'shrinkage' was held constant at a value of 0.1

Tuning parameter 'n.minobsinnode' was held constant at a value of 20
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 90, interaction.depth =
 2, shrinkage = 0.1 and n.minobsinnode = 20. 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
  Accuracy      Kappa 
 0.4444444 -0.1250000 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     20   20
    Weak       20   12
                                          
               Accuracy : 0.4444          
                 95% CI : (0.3272, 0.5664)
    No Information Rate : 0.5556          
    P-Value [Acc > NIR] : 0.9778          
                                          
                  Kappa : -0.125          
 Mcnemar's Test P-Value : 1.0000          
                                          
            Sensitivity : 0.3750          
            Specificity : 0.5000          
         Pos Pred Value : 0.3750          
         Neg Pred Value : 0.5000          
             Prevalence : 0.4444          
         Detection Rate : 0.1667          
   Detection Prevalence : 0.4444          
      Balanced Accuracy : 0.4375          
                                          
       'Positive' Class : Weak            
                                          
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
 Accuracy     Kappa 
0.8346774 0.6642451 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    119   23
    Weak       18   88
                                          
               Accuracy : 0.8347          
                 95% CI : (0.7825, 0.8787)
    No Information Rate : 0.5524          
    P-Value [Acc > NIR] : <2e-16          
                                          
                  Kappa : 0.6642          
 Mcnemar's Test P-Value : 0.5322          
                                          
            Sensitivity : 0.7928          
            Specificity : 0.8686          
         Pos Pred Value : 0.8302          
         Neg Pred Value : 0.8380          
             Prevalence : 0.4476          
         Detection Rate : 0.3548          
   Detection Prevalence : 0.4274          
      Balanced Accuracy : 0.8307          
                                          
       'Positive' Class : Weak            
                                          
> gbmGrid <- expand.grid(interaction.depth = 3,
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.1,
+                         n.minobsinnode = 20)
> set.seed(seed.mine)
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "ROC",
+                  verbose = FALSE)
> gbmFit1
Stochastic Gradient Boosting 

248 samples
 18 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 222, 223, 223, 224, 223, 223, ... 

Resampling results across tuning parameters:

  n.trees  ROC        Sens       Spec       ROC SD      Sens SD    Spec SD  
    90     0.7749088  0.7520330  0.6721212  0.08639089  0.1120545  0.1300759
   180     0.7677252  0.7373626  0.6659848  0.09057031  0.1156156  0.1262539
   270     0.7623697  0.7339011  0.6524242  0.09454844  0.1136397  0.1350105
   360     0.7610972  0.7359341  0.6513636  0.09464468  0.1200357  0.1311142
   450     0.7578251  0.7300549  0.6579545  0.09453007  0.1151045  0.1301975
   540     0.7582655  0.7344505  0.6541667  0.09455909  0.1143267  0.1259702
   630     0.7601677  0.7358791  0.6559091  0.09540056  0.1181290  0.1300853
   720     0.7587771  0.7352747  0.6568182  0.09520609  0.1111384  0.1271252
   810     0.7578476  0.7344505  0.6586364  0.09600605  0.1138751  0.1266057
   900     0.7548855  0.7359341  0.6558333  0.09771162  0.1128117  0.1269963
   990     0.7528388  0.7300549  0.6541667  0.09848604  0.1153189  0.1279428
  1080     0.7538129  0.7337912  0.6534091  0.09870284  0.1189499  0.1298140
  1170     0.7540672  0.7389560  0.6498485  0.09771982  0.1177262  0.1304253
  1260     0.7535244  0.7324176  0.6496970  0.09825006  0.1176848  0.1273649
  1350     0.7531198  0.7335714  0.6524242  0.10144717  0.1182766  0.1272700
  1440     0.7515072  0.7320879  0.6532576  0.10333582  0.1156107  0.1304577
  1530     0.7525033  0.7262088  0.6514394  0.10258618  0.1202545  0.1306825
  1620     0.7525387  0.7334066  0.6541667  0.10052958  0.1205621  0.1274207
  1710     0.7526815  0.7326923  0.6506818  0.10191458  0.1197573  0.1284561
  1800     0.7509953  0.7305495  0.6460606  0.10229674  0.1222561  0.1272782
  1890     0.7514744  0.7298352  0.6497727  0.10339366  0.1199422  0.1234529
  1980     0.7506548  0.7343407  0.6498485  0.10286757  0.1203466  0.1264213
  2070     0.7515609  0.7321978  0.6487879  0.10254208  0.1152263  0.1273667
  2160     0.7511547  0.7320879  0.6496970  0.10317758  0.1160556  0.1269454
  2250     0.7508433  0.7328571  0.6531818  0.10193746  0.1183135  0.1249406
  2340     0.7507176  0.7343407  0.6496970  0.10305181  0.1164288  0.1276014
  2430     0.7510331  0.7350549  0.6531818  0.10235190  0.1178429  0.1275853
  2520     0.7514989  0.7335714  0.6478030  0.10220345  0.1130916  0.1267278
  2610     0.7510127  0.7314835  0.6522727  0.10190844  0.1136891  0.1259523
  2700     0.7509366  0.7314835  0.6515152  0.10245961  0.1185706  0.1272915

Tuning parameter 'interaction.depth' was held constant at a value of 3

Tuning parameter 'shrinkage' was held constant at a value of 0.1

Tuning parameter 'n.minobsinnode' was held constant at a value of 20
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 90, interaction.depth =
 3, shrinkage = 0.1 and n.minobsinnode = 20. 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
  Accuracy      Kappa 
 0.4444444 -0.1180124 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     19   19
    Weak       21   13
                                          
               Accuracy : 0.4444          
                 95% CI : (0.3272, 0.5664)
    No Information Rate : 0.5556          
    P-Value [Acc > NIR] : 0.9778          
                                          
                  Kappa : -0.118          
 Mcnemar's Test P-Value : 0.8744          
                                          
            Sensitivity : 0.4062          
            Specificity : 0.4750          
         Pos Pred Value : 0.3824          
         Neg Pred Value : 0.5000          
             Prevalence : 0.4444          
         Detection Rate : 0.1806          
   Detection Prevalence : 0.4722          
      Balanced Accuracy : 0.4406          
                                          
       'Positive' Class : Weak            
                                          
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
 Accuracy     Kappa 
0.8750000 0.7452618 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    126   20
    Weak       11   91
                                          
               Accuracy : 0.875           
                 95% CI : (0.8273, 0.9135)
    No Information Rate : 0.5524          
    P-Value [Acc > NIR] : <2e-16          
                                          
                  Kappa : 0.7453          
 Mcnemar's Test P-Value : 0.1508          
                                          
            Sensitivity : 0.8198          
            Specificity : 0.9197          
         Pos Pred Value : 0.8922          
         Neg Pred Value : 0.8630          
             Prevalence : 0.4476          
         Detection Rate : 0.3669          
   Detection Prevalence : 0.4113          
      Balanced Accuracy : 0.8698          
                                          
       'Positive' Class : Weak            
                                          
> gbmGrid <- expand.grid(interaction.depth = 6,
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.1,
+                         n.minobsinnode = 20)
> set.seed(seed.mine)
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "ROC",
+                  verbose = FALSE)
> gbmFit1
Stochastic Gradient Boosting 

248 samples
 18 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 222, 223, 223, 224, 223, 223, ... 

Resampling results across tuning parameters:

  n.trees  ROC        Sens       Spec       ROC SD      Sens SD    Spec SD  
    90     0.7736630  0.7428571  0.6668939  0.08991901  0.1198251  0.1388804
   180     0.7639227  0.7316484  0.6569697  0.09701433  0.1227509  0.1399723
   270     0.7592449  0.7337363  0.6542424  0.09794185  0.1190167  0.1454101
   360     0.7574026  0.7328571  0.6553030  0.09451839  0.1076211  0.1407505
   450     0.7578909  0.7293407  0.6569697  0.09508374  0.1113528  0.1398770
   540     0.7534782  0.7228022  0.6551515  0.10048401  0.1119394  0.1365399
   630     0.7536401  0.7213736  0.6516667  0.09624702  0.1144793  0.1412213
   720     0.7552235  0.7181868  0.6578788  0.09720948  0.1146098  0.1388648
   810     0.7542195  0.7248352  0.6559848  0.10085892  0.1156280  0.1380541
   900     0.7530615  0.7284615  0.6568939  0.10172030  0.1136180  0.1406178
   990     0.7532443  0.7297802  0.6541667  0.10058717  0.1171026  0.1321290
  1080     0.7517786  0.7246703  0.6569697  0.10303519  0.1158367  0.1333505
  1170     0.7506369  0.7290659  0.6560606  0.10283490  0.1150570  0.1320176
  1260     0.7521512  0.7342308  0.6515909  0.09920390  0.1123318  0.1321822
  1350     0.7515322  0.7363736  0.6415909  0.10100246  0.1157737  0.1336008
  1440     0.7534786  0.7335165  0.6498485  0.09731074  0.1190553  0.1325592
  1530     0.7542886  0.7384615  0.6534091  0.09642905  0.1175253  0.1310187
  1620     0.7552106  0.7363736  0.6497727  0.09721996  0.1191948  0.1314449
  1710     0.7534703  0.7370879  0.6487879  0.09987815  0.1126996  0.1323050
  1800     0.7544635  0.7364286  0.6508333  0.09864806  0.1148998  0.1298798
  1890     0.7547007  0.7370330  0.6525758  0.09586640  0.1135720  0.1288352
  1980     0.7555919  0.7364286  0.6553030  0.09560508  0.1194388  0.1280294
  2070     0.7550358  0.7362637  0.6507576  0.09683383  0.1198632  0.1283008
  2160     0.7539373  0.7399451  0.6480303  0.09648032  0.1181130  0.1290079
  2250     0.7529233  0.7408242  0.6498485  0.09881112  0.1162733  0.1287252
  2340     0.7526344  0.7378022  0.6518182  0.09909933  0.1168907  0.1314496
  2430     0.7498227  0.7386264  0.6490152  0.10196282  0.1151723  0.1284433
  2520     0.7512363  0.7357143  0.6490909  0.09879517  0.1175629  0.1267707
  2610     0.7523685  0.7386264  0.6481061  0.09478483  0.1160638  0.1288548
  2700     0.7516987  0.7378571  0.6526515  0.10091181  0.1183818  0.1273751

Tuning parameter 'interaction.depth' was held constant at a value of 6

Tuning parameter 'shrinkage' was held constant at a value of 0.1

Tuning parameter 'n.minobsinnode' was held constant at a value of 20
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 90, interaction.depth =
 6, shrinkage = 0.1 and n.minobsinnode = 20. 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
  Accuracy      Kappa 
 0.4444444 -0.1320755 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     21   21
    Weak       19   11
                                          
               Accuracy : 0.4444          
                 95% CI : (0.3272, 0.5664)
    No Information Rate : 0.5556          
    P-Value [Acc > NIR] : 0.9778          
                                          
                  Kappa : -0.1321         
 Mcnemar's Test P-Value : 0.8744          
                                          
            Sensitivity : 0.3438          
            Specificity : 0.5250          
         Pos Pred Value : 0.3667          
         Neg Pred Value : 0.5000          
             Prevalence : 0.4444          
         Detection Rate : 0.1528          
   Detection Prevalence : 0.4167          
      Balanced Accuracy : 0.4344          
                                          
       'Positive' Class : Weak            
                                          
> 
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
 Accuracy     Kappa 
0.8951613 0.7865325 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    128   17
    Weak        9   94
                                          
               Accuracy : 0.8952          
                 95% CI : (0.8502, 0.9304)
    No Information Rate : 0.5524          
    P-Value [Acc > NIR] : <2e-16          
                                          
                  Kappa : 0.7865          
 Mcnemar's Test P-Value : 0.1698          
                                          
            Sensitivity : 0.8468          
            Specificity : 0.9343          
         Pos Pred Value : 0.9126          
         Neg Pred Value : 0.8828          
             Prevalence : 0.4476          
         Detection Rate : 0.3790          
   Detection Prevalence : 0.4153          
      Balanced Accuracy : 0.8906          
                                          
       'Positive' Class : Weak            
                                          
> (1:30)*90
 [1]   90  180  270  360  450  540  630  720  810  900  990 1080 1170 1260 1350
[16] 1440 1530 1620 1710 1800 1890 1980 2070 2160 2250 2340 2430 2520 2610 2700
> head(trainClass)
[1] Weak Weak Weak Weak Weak Weak
Levels: Strong Weak
> head(trainDescr)
    SKDDEPSTA  SKDARRSTA     SKDEQP      SKDEPS       AVGSQ  AVGLOFATC
2  -0.7928459  1.1225526  0.4194634 -1.53179509 -0.03921600 -1.0066428
5  -0.4321027  1.1225526  2.2805144  0.54675650 -0.22245695  0.5749037
14 -0.7928459 -1.0215176 -0.2784307  0.54675650 -0.01380709  0.7297372
18 -0.9371431 -0.8853861 -0.9763248  0.07908239  0.60429242  1.7048708
20  2.3095455 -0.8853861  0.4194634  1.48210471  0.72272822 -1.0138904
33  1.1190930  1.1225526  0.4194634 -1.53179509  0.46069669  0.8570454
   UPLINEATCIMP DEPSTAATCIMP DOWNLINEATCIMP  DEPBUCKET   ARRBUCKET DEPRANKGRP
2     0.4984977   -0.5427918     -0.6928036 -0.1734554  0.05705816 -0.8908684
5    -0.9516774    1.8365696     -0.6928036 -0.7901856 -0.55156221 -0.1055299
14    1.9486728   -0.5427918     -0.6928036  0.4432749  0.66567853 -0.8908684
18   -0.9516774   -0.5427918     -0.6928036  0.4432749  0.66567853 -0.1055299
20   -0.9516774    1.8365696     -0.6928036  0.4432749  0.66567853 -0.8908684
33   -0.9516774   -0.5427918     -0.6928036  0.4432749  0.66567853 -0.1055299
    TRNRANKGRP ARRRANKGRP   DEPSPOKE   ARRSPOKE      xDURN2 xAVGSKDAVAIL
2  -0.83083791  0.1473182 -0.8420257 -1.0173358  0.07890593   -0.7643289
5  -0.83083791  0.1473182  1.1839009 -1.0173358  0.07890593   -1.3308037
14 -0.83083791  0.1473182 -0.8420257  0.9798879  0.07890593   -0.3727810
18 -0.07337885  0.1473182  1.1839009 -1.0173358  0.07890593   -1.0658700
20 -0.83083791  0.1473182  1.1839009 -1.0173358 -0.97317308   -1.2671779
33  1.44153928  0.1473182  1.1839009 -1.0173358  1.13098493   -0.5036683
> ?getModelInfo
> getModelInfo("gbm")
$gbm
$gbm$label
[1] "Stochastic Gradient Boosting"

$gbm$library
[1] "gbm"  "plyr"

$gbm$type
[1] "Regression"     "Classification"

$gbm$parameters
          parameter   class                   label
1           n.trees numeric   # Boosting Iterations
2 interaction.depth numeric          Max Tree Depth
3         shrinkage numeric               Shrinkage
4    n.minobsinnode numeric Min. Terminal Node Size

$gbm$grid
function (x, y, len = NULL) 
expand.grid(interaction.depth = seq(1, len), n.trees = floor((1:len) * 
    50), shrinkage = 0.1, n.minobsinnode = 10)

$gbm$loop
function (grid) 
{
    loop <- ddply(grid, c("shrinkage", "interaction.depth", "n.minobsinnode"), 
        function(x) c(n.trees = max(x$n.trees)))
    submodels <- vector(mode = "list", length = nrow(loop))
    for (i in seq(along = loop$n.trees)) {
        index <- which(grid$interaction.depth == loop$interaction.depth[i] & 
            grid$shrinkage == loop$shrinkage[i] & grid$n.minobsinnode == 
            loop$n.minobsinnode[i])
        trees <- grid[index, "n.trees"]
        submodels[[i]] <- data.frame(n.trees = trees[trees != 
            loop$n.trees[i]])
    }
    list(loop = loop, submodels = submodels)
}

$gbm$fit
function (x, y, wts, param, lev, last, classProbs, ...) 
{
    theDots <- list(...)
    if (any(names(theDots) == "distribution")) {
        modDist <- theDots$distribution
        theDots$distribution <- NULL
    }
    else {
        if (is.numeric(y)) {
            modDist <- "gaussian"
        }
        else modDist <- if (length(lev) == 2) 
            "bernoulli"
        else "multinomial"
    }
    if (!is.null(wts)) 
        theDots$w <- wts
    if (is.factor(y) && length(lev) == 2) 
        y <- ifelse(y == lev[1], 1, 0)
    modArgs <- list(x = x, y = y, interaction.depth = param$interaction.depth, 
        n.trees = param$n.trees, shrinkage = param$shrinkage, 
        n.minobsinnode = param$n.minobsinnode, distribution = modDist)
    if (any(names(theDots) == "family")) 
        modArgs$distribution <- NULL
    if (length(theDots) > 0) 
        modArgs <- c(modArgs, theDots)
    do.call("gbm.fit", modArgs)
}

$gbm$predict
function (modelFit, newdata, submodels = NULL) 
{
    out <- predict(modelFit, newdata, type = "response", n.trees = modelFit$tuneValue$n.trees)
    out[is.nan(out)] <- NA
    out <- switch(modelFit$distribution$name, multinomial = {
        colnames(out[, , 1, drop = FALSE])[apply(out[, , 1, drop = FALSE], 
            1, which.max)]
    }, bernoulli = , adaboost = , huberized = {
        ifelse(out >= 0.5, modelFit$obsLevels[1], modelFit$obsLevels[2])
    }, gaussian = , laplace = , tdist = , poisson = {
        out
    })
    if (!is.null(submodels)) {
        tmp <- predict(modelFit, newdata, type = "response", 
            n.trees = submodels$n.trees)
        out <- switch(modelFit$distribution$name, multinomial = {
            lvl <- colnames(tmp[, , 1, drop = FALSE])
            tmp <- apply(tmp, 3, function(x) apply(x, 1, which.max))
            if (is.vector(tmp)) tmp <- matrix(tmp, nrow = 1)
            tmp <- t(apply(tmp, 1, function(x, lvl) lvl[x], lvl = lvl))
            if (nrow(tmp) == 1 & nrow(newdata) > 1) tmp <- t(tmp)
            tmp <- as.list(as.data.frame(tmp, stringsAsFactors = FALSE))
            c(list(out), tmp)
        }, bernoulli = , adaboost = , huberized = {
            tmp <- ifelse(tmp >= 0.5, modelFit$obsLevels[1], 
                modelFit$obsLevels[2])
            tmp <- as.list(as.data.frame(tmp, stringsAsFactors = FALSE))
            c(list(out), tmp)
        }, gaussian = , laplace = , tdist = , poisson = {
            tmp <- as.list(as.data.frame(tmp))
            c(list(out), tmp)
        })
    }
    out
}

$gbm$prob
function (modelFit, newdata, submodels = NULL) 
{
    out <- predict(modelFit, newdata, type = "response", n.trees = modelFit$tuneValue$n.trees)
    out[is.nan(out)] <- NA
    out <- switch(modelFit$distribution$name, multinomial = {
        out[, , 1]
    }, bernoulli = , adaboost = , huberized = {
        out <- cbind(out, 1 - out)
        colnames(out) <- modelFit$obsLevels
        out
    }, gaussian = , laplace = , tdist = , poisson = {
        out
    })
    if (!is.null(submodels)) {
        tmp <- predict(modelFit, newdata, type = "response", 
            n.trees = submodels$n.trees)
        tmp <- switch(modelFit$distribution$name, multinomial = {
            apply(tmp, 3, function(x) data.frame(x))
        }, bernoulli = , adaboost = , huberized = {
            tmp <- as.list(as.data.frame(tmp))
            lapply(tmp, function(x, lvl) {
                x <- cbind(x, 1 - x)
                colnames(x) <- lvl
                x
            }, lvl = modelFit$obsLevels)
        })
        out <- c(list(out), tmp)
    }
    out
}

$gbm$predictors
function (x, ...) 
{
    vi <- relative.influence(x, n.trees = x$tuneValue$n.trees)
    names(vi)[vi > 0]
}

$gbm$varImp
function (object, numTrees = NULL, ...) 
{
    if (is.null(numTrees)) 
        numTrees <- object$tuneValue$n.trees
    varImp <- relative.influence(object, n.trees = numTrees)
    out <- data.frame(varImp)
    colnames(out) <- "Overall"
    rownames(out) <- object$var.names
    out
}

$gbm$levels
function (x) 
{
    if (x$distribution$name %in% c("gaussian", "laplace", "tdist")) 
        return(NULL)
    if (is.null(x$classes)) {
        out <- if (any(names(x) == "obsLevels")) 
            x$obsLevels
        else NULL
    }
    else {
        out <- x$classes
    }
    out
}

$gbm$tags
[1] "Tree-Based Model"           "Boosting"                  
[3] "Ensemble Model"             "Implicit Feature Selection"

$gbm$sort
function (x) 
{
    x[order(x$n.trees, x$interaction.depth, x$shrinkage), ]
}


> floor((1:len) * 
    50)
floor((1:len) * 
+     50)
Error: object 'len' not found
> floor((1:10) * 50)
 [1]  50 100 150 200 250 300 350 400 450 500
> getModelInfo("gbm", regex = "trControl")
Error in if (regex) grepl(model, names(models), ...) else which(model ==  : 
  argument is not interpretable as logical
> modelLookup("gbm")
  model         parameter                   label forReg forClass probModel
1   gbm           n.trees   # Boosting Iterations   TRUE     TRUE      TRUE
2   gbm interaction.depth          Max Tree Depth   TRUE     TRUE      TRUE
3   gbm         shrinkage               Shrinkage   TRUE     TRUE      TRUE
4   gbm    n.minobsinnode Min. Terminal Node Size   TRUE     TRUE      TRUE
> getModelInfo("gbm")
$gbm
$gbm$label
[1] "Stochastic Gradient Boosting"

$gbm$library
[1] "gbm"  "plyr"

$gbm$type
[1] "Regression"     "Classification"

$gbm$parameters
          parameter   class                   label
1           n.trees numeric   # Boosting Iterations
2 interaction.depth numeric          Max Tree Depth
3         shrinkage numeric               Shrinkage
4    n.minobsinnode numeric Min. Terminal Node Size

$gbm$grid
function (x, y, len = NULL) 
expand.grid(interaction.depth = seq(1, len), n.trees = floor((1:len) * 
    50), shrinkage = 0.1, n.minobsinnode = 10)

$gbm$loop
function (grid) 
{
    loop <- ddply(grid, c("shrinkage", "interaction.depth", "n.minobsinnode"), 
        function(x) c(n.trees = max(x$n.trees)))
    submodels <- vector(mode = "list", length = nrow(loop))
    for (i in seq(along = loop$n.trees)) {
        index <- which(grid$interaction.depth == loop$interaction.depth[i] & 
            grid$shrinkage == loop$shrinkage[i] & grid$n.minobsinnode == 
            loop$n.minobsinnode[i])
        trees <- grid[index, "n.trees"]
        submodels[[i]] <- data.frame(n.trees = trees[trees != 
            loop$n.trees[i]])
    }
    list(loop = loop, submodels = submodels)
}

$gbm$fit
function (x, y, wts, param, lev, last, classProbs, ...) 
{
    theDots <- list(...)
    if (any(names(theDots) == "distribution")) {
        modDist <- theDots$distribution
        theDots$distribution <- NULL
    }
    else {
        if (is.numeric(y)) {
            modDist <- "gaussian"
        }
        else modDist <- if (length(lev) == 2) 
            "bernoulli"
        else "multinomial"
    }
    if (!is.null(wts)) 
        theDots$w <- wts
    if (is.factor(y) && length(lev) == 2) 
        y <- ifelse(y == lev[1], 1, 0)
    modArgs <- list(x = x, y = y, interaction.depth = param$interaction.depth, 
        n.trees = param$n.trees, shrinkage = param$shrinkage, 
        n.minobsinnode = param$n.minobsinnode, distribution = modDist)
    if (any(names(theDots) == "family")) 
        modArgs$distribution <- NULL
    if (length(theDots) > 0) 
        modArgs <- c(modArgs, theDots)
    do.call("gbm.fit", modArgs)
}

$gbm$predict
function (modelFit, newdata, submodels = NULL) 
{
    out <- predict(modelFit, newdata, type = "response", n.trees = modelFit$tuneValue$n.trees)
    out[is.nan(out)] <- NA
    out <- switch(modelFit$distribution$name, multinomial = {
        colnames(out[, , 1, drop = FALSE])[apply(out[, , 1, drop = FALSE], 
            1, which.max)]
    }, bernoulli = , adaboost = , huberized = {
        ifelse(out >= 0.5, modelFit$obsLevels[1], modelFit$obsLevels[2])
    }, gaussian = , laplace = , tdist = , poisson = {
        out
    })
    if (!is.null(submodels)) {
        tmp <- predict(modelFit, newdata, type = "response", 
            n.trees = submodels$n.trees)
        out <- switch(modelFit$distribution$name, multinomial = {
            lvl <- colnames(tmp[, , 1, drop = FALSE])
            tmp <- apply(tmp, 3, function(x) apply(x, 1, which.max))
            if (is.vector(tmp)) tmp <- matrix(tmp, nrow = 1)
            tmp <- t(apply(tmp, 1, function(x, lvl) lvl[x], lvl = lvl))
            if (nrow(tmp) == 1 & nrow(newdata) > 1) tmp <- t(tmp)
            tmp <- as.list(as.data.frame(tmp, stringsAsFactors = FALSE))
            c(list(out), tmp)
        }, bernoulli = , adaboost = , huberized = {
            tmp <- ifelse(tmp >= 0.5, modelFit$obsLevels[1], 
                modelFit$obsLevels[2])
            tmp <- as.list(as.data.frame(tmp, stringsAsFactors = FALSE))
            c(list(out), tmp)
        }, gaussian = , laplace = , tdist = , poisson = {
            tmp <- as.list(as.data.frame(tmp))
            c(list(out), tmp)
        })
    }
    out
}

$gbm$prob
function (modelFit, newdata, submodels = NULL) 
{
    out <- predict(modelFit, newdata, type = "response", n.trees = modelFit$tuneValue$n.trees)
    out[is.nan(out)] <- NA
    out <- switch(modelFit$distribution$name, multinomial = {
        out[, , 1]
    }, bernoulli = , adaboost = , huberized = {
        out <- cbind(out, 1 - out)
        colnames(out) <- modelFit$obsLevels
        out
    }, gaussian = , laplace = , tdist = , poisson = {
        out
    })
    if (!is.null(submodels)) {
        tmp <- predict(modelFit, newdata, type = "response", 
            n.trees = submodels$n.trees)
        tmp <- switch(modelFit$distribution$name, multinomial = {
            apply(tmp, 3, function(x) data.frame(x))
        }, bernoulli = , adaboost = , huberized = {
            tmp <- as.list(as.data.frame(tmp))
            lapply(tmp, function(x, lvl) {
                x <- cbind(x, 1 - x)
                colnames(x) <- lvl
                x
            }, lvl = modelFit$obsLevels)
        })
        out <- c(list(out), tmp)
    }
    out
}

$gbm$predictors
function (x, ...) 
{
    vi <- relative.influence(x, n.trees = x$tuneValue$n.trees)
    names(vi)[vi > 0]
}

$gbm$varImp
function (object, numTrees = NULL, ...) 
{
    if (is.null(numTrees)) 
        numTrees <- object$tuneValue$n.trees
    varImp <- relative.influence(object, n.trees = numTrees)
    out <- data.frame(varImp)
    colnames(out) <- "Overall"
    rownames(out) <- object$var.names
    out
}

$gbm$levels
function (x) 
{
    if (x$distribution$name %in% c("gaussian", "laplace", "tdist")) 
        return(NULL)
    if (is.null(x$classes)) {
        out <- if (any(names(x) == "obsLevels")) 
            x$obsLevels
        else NULL
    }
    else {
        out <- x$classes
    }
    out
}

$gbm$tags
[1] "Tree-Based Model"           "Boosting"                  
[3] "Ensemble Model"             "Implicit Feature Selection"

$gbm$sort
function (x) 
{
    x[order(x$n.trees, x$interaction.depth, x$shrinkage), ]
}


> seq(1, 10)
 [1]  1  2  3  4  5  6  7  8  9 10
> trainClass
  [1] Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak  
 [11] Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak  
 [21] Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak  
 [31] Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak  
 [41] Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak  
 [51] Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak  
 [61] Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak  
 [71] Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak  
 [81] Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak  
 [91] Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak  
[101] Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak  
[111] Weak   Strong Strong Strong Strong Strong Strong Strong Strong Strong
[121] Strong Strong Strong Strong Strong Strong Strong Strong Strong Strong
[131] Strong Strong Strong Strong Strong Strong Strong Strong Strong Strong
[141] Strong Strong Strong Strong Strong Strong Strong Strong Strong Strong
[151] Strong Strong Strong Strong Strong Strong Strong Strong Strong Strong
[161] Strong Strong Strong Strong Strong Strong Strong Strong Strong Strong
[171] Strong Strong Strong Strong Strong Strong Strong Strong Strong Strong
[181] Strong Strong Strong Strong Strong Strong Strong Strong Strong Strong
[191] Strong Strong Strong Strong Strong Strong Strong Strong Strong Strong
[201] Strong Strong Strong Strong Strong Strong Strong Strong Strong Strong
[211] Strong Strong Strong Strong Strong Strong Strong Strong Strong Strong
[221] Strong Strong Strong Strong Strong Strong Strong Strong Strong Strong
[231] Strong Strong Strong Strong Strong Strong Strong Strong Strong Strong
[241] Strong Strong Strong Strong Strong Strong Strong Strong
Levels: Strong Weak
> head(trainDescr)
    SKDDEPSTA  SKDARRSTA     SKDEQP      SKDEPS       AVGSQ  AVGLOFATC
2  -0.7928459  1.1225526  0.4194634 -1.53179509 -0.03921600 -1.0066428
5  -0.4321027  1.1225526  2.2805144  0.54675650 -0.22245695  0.5749037
14 -0.7928459 -1.0215176 -0.2784307  0.54675650 -0.01380709  0.7297372
18 -0.9371431 -0.8853861 -0.9763248  0.07908239  0.60429242  1.7048708
20  2.3095455 -0.8853861  0.4194634  1.48210471  0.72272822 -1.0138904
33  1.1190930  1.1225526  0.4194634 -1.53179509  0.46069669  0.8570454
   UPLINEATCIMP DEPSTAATCIMP DOWNLINEATCIMP  DEPBUCKET   ARRBUCKET DEPRANKGRP
2     0.4984977   -0.5427918     -0.6928036 -0.1734554  0.05705816 -0.8908684
5    -0.9516774    1.8365696     -0.6928036 -0.7901856 -0.55156221 -0.1055299
14    1.9486728   -0.5427918     -0.6928036  0.4432749  0.66567853 -0.8908684
18   -0.9516774   -0.5427918     -0.6928036  0.4432749  0.66567853 -0.1055299
20   -0.9516774    1.8365696     -0.6928036  0.4432749  0.66567853 -0.8908684
33   -0.9516774   -0.5427918     -0.6928036  0.4432749  0.66567853 -0.1055299
    TRNRANKGRP ARRRANKGRP   DEPSPOKE   ARRSPOKE      xDURN2 xAVGSKDAVAIL
2  -0.83083791  0.1473182 -0.8420257 -1.0173358  0.07890593   -0.7643289
5  -0.83083791  0.1473182  1.1839009 -1.0173358  0.07890593   -1.3308037
14 -0.83083791  0.1473182 -0.8420257  0.9798879  0.07890593   -0.3727810
18 -0.07337885  0.1473182  1.1839009 -1.0173358  0.07890593   -1.0658700
20 -0.83083791  0.1473182  1.1839009 -1.0173358 -0.97317308   -1.2671779
33  1.44153928  0.1473182  1.1839009 -1.0173358  1.13098493   -0.5036683
> colnames(trainDescr)
 [1] "SKDDEPSTA"      "SKDARRSTA"      "SKDEQP"         "SKDEPS"        
 [5] "AVGSQ"          "AVGLOFATC"      "UPLINEATCIMP"   "DEPSTAATCIMP"  
 [9] "DOWNLINEATCIMP" "DEPBUCKET"      "ARRBUCKET"      "DEPRANKGRP"    
[13] "TRNRANKGRP"     "ARRRANKGRP"     "DEPSPOKE"       "ARRSPOKE"      
[17] "xDURN2"         "xAVGSKDAVAIL"  
> gbmGrid <- expand.grid(interaction.depth = 18,
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.1,
+                         n.minobsinnode = 10)
> 
> set.seed(seed.mine)
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "ROC",
+                  verbose = FALSE)
> gbmFit1
Stochastic Gradient Boosting 

248 samples
 18 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 222, 223, 223, 224, 223, 223, ... 

Resampling results across tuning parameters:

  n.trees  ROC        Sens       Spec       ROC SD      Sens SD    Spec SD  
    90     0.7607380  0.7294505  0.6633333  0.09633827  0.1212019  0.1310450
   180     0.7573889  0.7225824  0.6581061  0.09349171  0.1142745  0.1341073
   270     0.7572657  0.7249451  0.6560606  0.09531503  0.1139012  0.1341261
   360     0.7564856  0.7253846  0.6641667  0.09310858  0.1148853  0.1248407
   450     0.7546895  0.7246703  0.6562121  0.09317680  0.1122401  0.1268022
   540     0.7510818  0.7239011  0.6552273  0.09531387  0.1142529  0.1264301
   630     0.7510931  0.7223626  0.6419697  0.09571706  0.1161536  0.1327036
   720     0.7530836  0.7216484  0.6500758  0.09403843  0.1183893  0.1319328
   810     0.7518648  0.7217582  0.6509091  0.09513639  0.1160514  0.1329308
   900     0.7482647  0.7225824  0.6499242  0.10036625  0.1150829  0.1345115
   990     0.7499538  0.7240110  0.6454545  0.09623516  0.1157918  0.1395364
  1080     0.7506131  0.7218681  0.6417424  0.09666115  0.1198092  0.1314468
  1170     0.7512279  0.7232967  0.6407576  0.09483032  0.1183412  0.1379074
  1260     0.7497011  0.7263187  0.6434848  0.09522896  0.1175115  0.1356553
  1350     0.7499301  0.7263187  0.6417424  0.09315827  0.1188199  0.1370434
  1440     0.7493352  0.7262088  0.6417424  0.09217068  0.1216864  0.1308102
  1530     0.7496512  0.7262637  0.6462121  0.09270893  0.1193671  0.1311121
  1620     0.7492603  0.7241209  0.6416667  0.09408202  0.1202095  0.1366715
  1710     0.7488212  0.7226374  0.6416667  0.09396845  0.1191397  0.1284859
  1800     0.7485952  0.7218681  0.6453030  0.09350350  0.1199466  0.1246378
  1890     0.7481976  0.7218132  0.6524242  0.09211850  0.1218306  0.1239751
  1980     0.7484665  0.7211538  0.6499242  0.09122054  0.1203415  0.1292453
  2070     0.7474371  0.7212088  0.6469697  0.09220048  0.1227084  0.1299463
  2160     0.7471666  0.7226374  0.6496970  0.09275828  0.1217751  0.1294731
  2250     0.7484332  0.7212637  0.6478788  0.09207953  0.1211282  0.1296492
  2340     0.7477622  0.7219780  0.6479545  0.09136728  0.1226994  0.1322784
  2430     0.7474355  0.7196703  0.6452273  0.09183027  0.1211739  0.1315427
  2520     0.7475219  0.7196154  0.6425000  0.09170132  0.1201388  0.1375897
  2610     0.7473724  0.7182418  0.6461364  0.09189474  0.1199474  0.1311598
  2700     0.7483419  0.7183516  0.6452273  0.09223746  0.1195209  0.1315427

Tuning parameter 'interaction.depth' was held constant at a value of 18

Tuning parameter 'shrinkage' was held constant at a value of 0.1

Tuning parameter 'n.minobsinnode' was held constant at a value of 10
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 90, interaction.depth =
 18, shrinkage = 0.1 and n.minobsinnode = 10. 
> 
> ## The acid test is dissapointing, but I've seen worse.
> 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
   Accuracy       Kappa 
 0.47222222 -0.08227848 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     23   21
    Weak       17   11
                                          
               Accuracy : 0.4722          
                 95% CI : (0.3533, 0.5935)
    No Information Rate : 0.5556          
    P-Value [Acc > NIR] : 0.9380          
                                          
                  Kappa : -0.0823         
 Mcnemar's Test P-Value : 0.6265          
                                          
            Sensitivity : 0.3438          
            Specificity : 0.5750          
         Pos Pred Value : 0.3929          
         Neg Pred Value : 0.5227          
             Prevalence : 0.4444          
         Detection Rate : 0.1528          
   Detection Prevalence : 0.3889          
      Balanced Accuracy : 0.4594          
                                          
       'Positive' Class : Weak            
                                          
> 
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
 Accuracy     Kappa 
0.9879032 0.9755167 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    136    2
    Weak        1  109
                                          
               Accuracy : 0.9879          
                 95% CI : (0.9651, 0.9975)
    No Information Rate : 0.5524          
    P-Value [Acc > NIR] : <2e-16          
                                          
                  Kappa : 0.9755          
 Mcnemar's Test P-Value : 1               
                                          
            Sensitivity : 0.9820          
            Specificity : 0.9927          
         Pos Pred Value : 0.9909          
         Neg Pred Value : 0.9855          
             Prevalence : 0.4476          
         Detection Rate : 0.4395          
   Detection Prevalence : 0.4435          
      Balanced Accuracy : 0.9873          
                                          
       'Positive' Class : Weak            
                                          
> gbmGrid <- expand.grid(interaction.depth = 18,
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.01,
+                         n.minobsinnode = 10)
> set.seed(seed.mine)
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "ROC",
+                  verbose = FALSE)
> gbmFit1
Stochastic Gradient Boosting 

248 samples
 18 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 222, 223, 223, 224, 223, 223, ... 

Resampling results across tuning parameters:

  n.trees  ROC        Sens       Spec       ROC SD      Sens SD    Spec SD  
    90     0.7795808  0.7811538  0.6001515  0.09034609  0.1003035  0.1399620
   180     0.7814223  0.7643407  0.6539394  0.08787991  0.1047496  0.1361887
   270     0.7797311  0.7563736  0.6755303  0.08775647  0.1156716  0.1322986
   360     0.7776915  0.7542308  0.6856818  0.08842340  0.1144275  0.1286482
   450     0.7767499  0.7446703  0.6884091  0.08910015  0.1181269  0.1265729
   540     0.7730390  0.7425275  0.6803030  0.09410220  0.1188105  0.1249148
   630     0.7727602  0.7410989  0.6837879  0.09446196  0.1197316  0.1245970
   720     0.7703201  0.7395604  0.6831818  0.09289349  0.1222563  0.1262368
   810     0.7693253  0.7373626  0.6787121  0.09391020  0.1191104  0.1284435
   900     0.7688391  0.7359890  0.6812879  0.09482597  0.1188294  0.1227201
   990     0.7687800  0.7358791  0.6805303  0.09294671  0.1234533  0.1240581
  1080     0.7676224  0.7352198  0.6787121  0.09323390  0.1208733  0.1299422
  1170     0.7667283  0.7344505  0.6813636  0.09259837  0.1213250  0.1217457
  1260     0.7651598  0.7323077  0.6831818  0.09351473  0.1198125  0.1217389
  1350     0.7656914  0.7300549  0.6777273  0.09334595  0.1206308  0.1257262
  1440     0.7633479  0.7279670  0.6750758  0.09307961  0.1222650  0.1212642
  1530     0.7634195  0.7279670  0.6759848  0.09356624  0.1212833  0.1233590
  1620     0.7632813  0.7286264  0.6741667  0.09251152  0.1223034  0.1252739
  1710     0.7626091  0.7278022  0.6740909  0.09272532  0.1209936  0.1242166
  1800     0.7625987  0.7285165  0.6724242  0.09196271  0.1210558  0.1248689
  1890     0.7613811  0.7291758  0.6724242  0.09265636  0.1229832  0.1255356
  1980     0.7618248  0.7291758  0.6696970  0.09211820  0.1231170  0.1272824
  2070     0.7620829  0.7276374  0.6732576  0.09210427  0.1242707  0.1231981
  2160     0.7618894  0.7299451  0.6751515  0.09355310  0.1241752  0.1235957
  2250     0.7611509  0.7284066  0.6715152  0.09379681  0.1222644  0.1246896
  2340     0.7606631  0.7247802  0.6715152  0.09312154  0.1253064  0.1266821
  2430     0.7611389  0.7262637  0.6697727  0.09367564  0.1234758  0.1252350
  2520     0.7605694  0.7247802  0.6697727  0.09353850  0.1214808  0.1245666
  2610     0.7599655  0.7240110  0.6706818  0.09367612  0.1240929  0.1236575
  2700     0.7592116  0.7277473  0.6698485  0.09363060  0.1213961  0.1233981

Tuning parameter 'interaction.depth' was held constant at a value of 18

Tuning parameter 'shrinkage' was held constant at a value of 0.01

Tuning parameter 'n.minobsinnode' was held constant at a value of 10
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 180, interaction.depth =
 18, shrinkage = 0.01 and n.minobsinnode = 10. 
> 
> ## The acid test is dissapointing, but I've seen worse.
> 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
  Accuracy      Kappa 
 0.4722222 -0.0754717 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     22   20
    Weak       18   12
                                          
               Accuracy : 0.4722          
                 95% CI : (0.3533, 0.5935)
    No Information Rate : 0.5556          
    P-Value [Acc > NIR] : 0.9380          
                                          
                  Kappa : -0.0755         
 Mcnemar's Test P-Value : 0.8711          
                                          
            Sensitivity : 0.3750          
            Specificity : 0.5500          
         Pos Pred Value : 0.4000          
         Neg Pred Value : 0.5238          
             Prevalence : 0.4444          
         Detection Rate : 0.1667          
   Detection Prevalence : 0.4167          
      Balanced Accuracy : 0.4625          
                                          
       'Positive' Class : Weak            
                                          
> 
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
 Accuracy     Kappa 
0.8669355 0.7297583 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    123   19
    Weak       14   92
                                          
               Accuracy : 0.8669          
                 95% CI : (0.8182, 0.9066)
    No Information Rate : 0.5524          
    P-Value [Acc > NIR] : <2e-16          
                                          
                  Kappa : 0.7298          
 Mcnemar's Test P-Value : 0.4862          
                                          
            Sensitivity : 0.8288          
            Specificity : 0.8978          
         Pos Pred Value : 0.8679          
         Neg Pred Value : 0.8662          
             Prevalence : 0.4476          
         Detection Rate : 0.3710          
   Detection Prevalence : 0.4274          
      Balanced Accuracy : 0.8633          
                                          
       'Positive' Class : Weak            
                                          
> length(colnames(trainDescr))
[1] 18
> gbmGrid <- expand.grid(interaction.depth = length(colnames(trainDescr)),
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.25,
+                         n.minobsinnode = 10)
> 
> set.seed(seed.mine)
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "ROC",
+                  verbose = FALSE)
> gbmFit1
Stochastic Gradient Boosting 

248 samples
 18 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 222, 223, 223, 224, 223, 223, ... 

Resampling results across tuning parameters:

  n.trees  ROC        Sens       Spec       ROC SD      Sens SD    Spec SD  
    90     0.7408462  0.7162088  0.6540152  0.10337233  0.1123120  0.1228041
   180     0.7449076  0.7147253  0.6527273  0.09278571  0.1133749  0.1252610
   270     0.7431989  0.7189560  0.6444697  0.09392998  0.1148200  0.1365771
   360     0.7430611  0.7145055  0.6453788  0.08954520  0.1178878  0.1326121
   450     0.7442249  0.7233516  0.6506818  0.09316778  0.1137125  0.1316654
   540     0.7444322  0.7185714  0.6470455  0.09261678  0.1158675  0.1310484
   630     0.7446966  0.7235165  0.6479545  0.08978835  0.1135931  0.1293670
   720     0.7447940  0.7155495  0.6440909  0.09102580  0.1091043  0.1332631
   810     0.7449946  0.7212637  0.6415909  0.09141212  0.1089813  0.1287122
   900     0.7449850  0.7196703  0.6478788  0.09164132  0.1144731  0.1180550
   990     0.7438247  0.7197802  0.6468939  0.09235815  0.1132627  0.1262943
  1080     0.7439943  0.7218681  0.6487121  0.09211967  0.1162464  0.1252237
  1170     0.7412821  0.7218132  0.6477273  0.09223615  0.1175244  0.1283234
  1260     0.7411499  0.7190110  0.6486364  0.09289223  0.1146143  0.1275725
  1350     0.7405122  0.7213187  0.6522727  0.09383608  0.1161684  0.1258741
  1440     0.7401265  0.7089011  0.6613636  0.09233790  0.1136926  0.1186282
  1530     0.7388437  0.6943956  0.6802273  0.09125669  0.1127332  0.1206911
  1620     0.7387053  0.6864286  0.6955303  0.09175569  0.1121623  0.1149460
  1710     0.7376694  0.6731868  0.7054545  0.09553672  0.1165652  0.1193531
  1800     0.7388618  0.6580769  0.7190152  0.09268307  0.1261426  0.1216232
  1890     0.7378349  0.6477473  0.7281061  0.09601403  0.1253229  0.1225860
  1980     0.7379385  0.6396703  0.7371212  0.09436576  0.1212825  0.1255513
  2070     0.7376028  0.6346703  0.7441667  0.09611099  0.1259119  0.1216792
  2160     0.7371083  0.6230220  0.7550758  0.09546404  0.1286560  0.1217135
  2250     0.7373212  0.6128571  0.7631061  0.09372938  0.1261972  0.1178848
  2340     0.7347667  0.6056593  0.7650758  0.09609040  0.1285089  0.1220771
  2430     0.7340045  0.6006044  0.7712879  0.09479688  0.1318420  0.1208418
  2520     0.7341873  0.5920879  0.7784091  0.09547900  0.1319909  0.1221050
  2610     0.7340890  0.5875275  0.7838636  0.09473968  0.1338245  0.1196499
  2700     0.7339675  0.5817033  0.7837879  0.09702368  0.1326719  0.1185007

Tuning parameter 'interaction.depth' was held constant at a value of 18

Tuning parameter 'shrinkage' was held constant at a value of 0.25

Tuning parameter 'n.minobsinnode' was held constant at a value of 10
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 810, interaction.depth =
 18, shrinkage = 0.25 and n.minobsinnode = 10. 
> 
> ## The acid test is dissapointing, but I've seen worse.
> 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
  Accuracy      Kappa 
 0.4027778 -0.2056075 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     18   21
    Weak       22   11
                                         
               Accuracy : 0.4028         
                 95% CI : (0.2888, 0.525)
    No Information Rate : 0.5556         
    P-Value [Acc > NIR] : 0.9967         
                                         
                  Kappa : -0.2056        
 Mcnemar's Test P-Value : 1.0000         
                                         
            Sensitivity : 0.3438         
            Specificity : 0.4500         
         Pos Pred Value : 0.3333         
         Neg Pred Value : 0.4615         
             Prevalence : 0.4444         
         Detection Rate : 0.1528         
   Detection Prevalence : 0.4583         
      Balanced Accuracy : 0.3969         
                                         
       'Positive' Class : Weak           
                                         
> 
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
Accuracy    Kappa 
       1        1 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    137    0
    Weak        0  111
                                     
               Accuracy : 1          
                 95% CI : (0.9852, 1)
    No Information Rate : 0.5524     
    P-Value [Acc > NIR] : < 2.2e-16  
                                     
                  Kappa : 1          
 Mcnemar's Test P-Value : NA         
                                     
            Sensitivity : 1.0000     
            Specificity : 1.0000     
         Pos Pred Value : 1.0000     
         Neg Pred Value : 1.0000     
             Prevalence : 0.4476     
         Detection Rate : 0.4476     
   Detection Prevalence : 0.4476     
      Balanced Accuracy : 1.0000     
                                     
       'Positive' Class : Weak       
                                     
> (1:30)*90
 [1]   90  180  270  360  450  540  630  720  810  900  990 1080 1170 1260 1350
[16] 1440 1530 1620 1710 1800 1890 1980 2070 2160 2250 2340 2430 2520 2610 2700
> trellis.par.set(caretTheme())
Warning message:
In trellis.par.set(caretTheme()) :
  Note: The default device has been opened to honour attempt to modify trellis settings
> plot(gbmFit1, metric = "ROC")
> trellis.par.set(caretTheme())
Warning message:
In trellis.par.set(caretTheme()) :
  Note: The default device has been opened to honour attempt to modify trellis settings
> plot(gbmFit1, metric = "ROC")
> gbmGrid <- expand.grid(interaction.depth = 
+                            c(length(colnames(trainDescr)), 1),
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.25,
+                         n.minobsinnode = 10)
> 
> set.seed(seed.mine)
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "ROC",
+                  verbose = FALSE)
> gbmFit1
Stochastic Gradient Boosting 

248 samples
 18 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 222, 223, 223, 224, 223, 223, ... 

Resampling results across tuning parameters:

  interaction.depth  n.trees  ROC        Sens       Spec       ROC SD    
   1                   90     0.7804104  0.7218681  0.6911364  0.07832596
   1                  180     0.7810531  0.7302198  0.6870455  0.07932143
   1                  270     0.7747074  0.7302198  0.6937879  0.08060127
   1                  360     0.7708450  0.7228571  0.6931818  0.08354888
   1                  450     0.7706518  0.7264286  0.6834091  0.08577309
   1                  540     0.7636380  0.7231319  0.6727273  0.09212232
   1                  630     0.7701107  0.7257143  0.6870455  0.08723413
   1                  720     0.7656256  0.7242857  0.6683333  0.08670269
   1                  810     0.7655270  0.7192857  0.6709848  0.08551294
   1                  900     0.7640818  0.7229121  0.6788636  0.08799933
   1                  990     0.7608641  0.7171429  0.6627273  0.08755741
   1                 1080     0.7603209  0.7185165  0.6743939  0.08233250
   1                 1170     0.7624992  0.7163736  0.6634091  0.08617785
   1                 1260     0.7607405  0.7191209  0.6625000  0.08569910
   1                 1350     0.7622956  0.7163736  0.6688636  0.08541178
   1                 1440     0.7606935  0.7161538  0.6589394  0.08577665
   1                 1530     0.7591650  0.7181319  0.6606818  0.08490881
   1                 1620     0.7554050  0.7139011  0.6599242  0.08571429
   1                 1710     0.7573693  0.7152747  0.6481818  0.08561805
   1                 1800     0.7554196  0.7190659  0.6518939  0.08743493
   1                 1890     0.7575121  0.7147253  0.6554545  0.08483606
   1                 1980     0.7571287  0.7153846  0.6563636  0.08628445
   1                 2070     0.7568186  0.7131319  0.6572727  0.08562998
   1                 2160     0.7570105  0.7085714  0.6563636  0.08406260
   1                 2250     0.7557347  0.7145055  0.6589394  0.08663021
   1                 2340     0.7561347  0.7195604  0.6600000  0.08518372
   1                 2430     0.7550520  0.7181868  0.6589394  0.09222111
   1                 2520     0.7574734  0.7168132  0.6517424  0.08543405
   1                 2610     0.7567291  0.7189011  0.6608333  0.08649137
   1                 2700     0.7565838  0.7160989  0.6534848  0.08600139
  18                   90     0.7520359  0.7229121  0.6715152  0.09832529
  18                  180     0.7451840  0.7155495  0.6579545  0.10171668
  18                  270     0.7479004  0.7119231  0.6607576  0.10185800
  18                  360     0.7425012  0.7088462  0.6428030  0.10567483
  18                  450     0.7420022  0.7137912  0.6489394  0.10472824
  18                  540     0.7427822  0.7187912  0.6489394  0.10280064
  18                  630     0.7431581  0.7187363  0.6490152  0.09891336
  18                  720     0.7444963  0.7179121  0.6508333  0.09729462
  18                  810     0.7449846  0.7165934  0.6446212  0.09672190
  18                  900     0.7447396  0.7181868  0.6480303  0.09435644
  18                  990     0.7464920  0.7144505  0.6487879  0.09638563
  18                 1080     0.7435396  0.7130769  0.6479545  0.09299423
  18                 1170     0.7416461  0.7123077  0.6441667  0.09253147
  18                 1260     0.7405149  0.7152198  0.6433333  0.09346087
  18                 1350     0.7411805  0.7122527  0.6434091  0.09443484
  18                 1440     0.7403103  0.7042308  0.6552273  0.09317144
  18                 1530     0.7406943  0.6984066  0.6741667  0.09152345
  18                 1620     0.7412856  0.6838462  0.6921970  0.09170479
  18                 1710     0.7404279  0.6729121  0.7121212  0.09348753
  18                 1800     0.7420340  0.6650549  0.7218939  0.09121783
  18                 1890     0.7409842  0.6518132  0.7354545  0.09521202
  18                 1980     0.7418725  0.6454396  0.7443182  0.09168774
  18                 2070     0.7390990  0.6352198  0.7514394  0.09460588
  18                 2160     0.7376334  0.6161538  0.7612879  0.09445496
  18                 2250     0.7358154  0.6133516  0.7612879  0.09766611
  18                 2340     0.7357753  0.6047802  0.7685606  0.09561827
  18                 2430     0.7362773  0.5990110  0.7730303  0.09625343
  18                 2520     0.7375568  0.5931319  0.7784848  0.09188117
  18                 2610     0.7372788  0.5852747  0.7875758  0.09094486
  18                 2700     0.7366086  0.5736264  0.7948485  0.09084880
  Sens SD    Spec SD  
  0.1123864  0.1238374
  0.1141838  0.1369478
  0.1107209  0.1363389
  0.1163369  0.1345038
  0.1224887  0.1398365
  0.1189718  0.1479101
  0.1153587  0.1373367
  0.1145248  0.1448911
  0.1148458  0.1414972
  0.1148117  0.1438403
  0.1163373  0.1583421
  0.1101281  0.1404887
  0.1087682  0.1458707
  0.1086911  0.1405975
  0.1082173  0.1365263
  0.1027727  0.1388909
  0.1087674  0.1391382
  0.1079365  0.1360738
  0.1101683  0.1394837
  0.1099058  0.1434265
  0.1065701  0.1398662
  0.1130012  0.1401314
  0.1130020  0.1431463
  0.1092693  0.1412235
  0.1134132  0.1359761
  0.1084598  0.1388629
  0.1106762  0.1337971
  0.1068266  0.1353029
  0.1051762  0.1325910
  0.1061152  0.1388852
  0.1105686  0.1394555
  0.1124354  0.1306332
  0.1064229  0.1351405
  0.1092570  0.1351611
  0.1139475  0.1304015
  0.1065550  0.1317020
  0.1058063  0.1235665
  0.1109732  0.1244968
  0.1106263  0.1297145
  0.1116965  0.1301666
  0.1124154  0.1249311
  0.1139514  0.1269698
  0.1123151  0.1284180
  0.1144867  0.1337352
  0.1158071  0.1291419
  0.1178467  0.1254219
  0.1160944  0.1232585
  0.1116258  0.1254319
  0.1180908  0.1237725
  0.1120553  0.1240686
  0.1114022  0.1210574
  0.1144531  0.1187839
  0.1146832  0.1190390
  0.1147154  0.1183150
  0.1209615  0.1152271
  0.1233594  0.1137734
  0.1252258  0.1154454
  0.1234733  0.1207335
  0.1252952  0.1171303
  0.1265316  0.1173961

Tuning parameter 'shrinkage' was held constant at a value of 0.25

Tuning parameter 'n.minobsinnode' was held constant at a value of 10
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 180, interaction.depth =
 1, shrinkage = 0.25 and n.minobsinnode = 10. 
> 
> ## The acid test is dissapointing, but I've seen worse.
> 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
  Accuracy      Kappa 
 0.4305556 -0.1284404 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     16   17
    Weak       24   15
                                          
               Accuracy : 0.4306          
                 95% CI : (0.3143, 0.5527)
    No Information Rate : 0.5556          
    P-Value [Acc > NIR] : 0.9876          
                                          
                  Kappa : -0.1284         
 Mcnemar's Test P-Value : 0.3487          
                                          
            Sensitivity : 0.4688          
            Specificity : 0.4000          
         Pos Pred Value : 0.3846          
         Neg Pred Value : 0.4848          
             Prevalence : 0.4444          
         Detection Rate : 0.2083          
   Detection Prevalence : 0.5417          
      Balanced Accuracy : 0.4344          
                                          
       'Positive' Class : Weak            
                                          
> 
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
 Accuracy     Kappa 
0.8709677 0.7399567 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    119   14
    Weak       18   97
                                        
               Accuracy : 0.871         
                 95% CI : (0.8228, 0.91)
    No Information Rate : 0.5524        
    P-Value [Acc > NIR] : <2e-16        
                                        
                  Kappa : 0.74          
 Mcnemar's Test P-Value : 0.5959        
                                        
            Sensitivity : 0.8739        
            Specificity : 0.8686        
         Pos Pred Value : 0.8435        
         Neg Pred Value : 0.8947        
             Prevalence : 0.4476        
         Detection Rate : 0.3911        
   Detection Prevalence : 0.4637        
      Balanced Accuracy : 0.8712        
                                        
       'Positive' Class : Weak          
                                        
> trellis.par.set(caretTheme())
Warning message:
In trellis.par.set(caretTheme()) :
  Note: The default device has been opened to honour attempt to modify trellis settings
> plot(gbmFit1, metric = "ROC")
> gbmGrid <- expand.grid(interaction.depth = 
+                            length(colnames(trainDescr)),
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.25,
+                         n.minobsinnode = 10)
> set.seed(seed.mine)
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "ROC",
+                  verbose = FALSE)
> gbmFit1
Stochastic Gradient Boosting 

248 samples
 18 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 222, 223, 223, 224, 223, 223, ... 

Resampling results across tuning parameters:

  n.trees  ROC        Sens       Spec       ROC SD      Sens SD    Spec SD  
    90     0.7476424  0.7284615  0.6410606  0.08970534  0.1006711  0.1346988
   180     0.7405907  0.7230220  0.6500758  0.09830114  0.1119250  0.1317041
   270     0.7409095  0.7189011  0.6552273  0.10067582  0.1127438  0.1331696
   360     0.7406285  0.7182418  0.6455303  0.10505560  0.1133383  0.1403744
   450     0.7397869  0.7124176  0.6398485  0.10585254  0.1163104  0.1347618
   540     0.7413928  0.7181319  0.6426515  0.10007091  0.1102738  0.1350524
   630     0.7402985  0.7102198  0.6489394  0.10367692  0.1096056  0.1334902
   720     0.7444277  0.7160989  0.6462121  0.10002520  0.1136204  0.1223096
   810     0.7425839  0.7117033  0.6470455  0.09432786  0.1139056  0.1262998
   900     0.7430155  0.7108791  0.6478788  0.09535208  0.1148582  0.1339552
   990     0.7420242  0.7086813  0.6496970  0.09496625  0.1146595  0.1315959
  1080     0.7424848  0.7108791  0.6453030  0.09450388  0.1153060  0.1270516
  1170     0.7418981  0.7145055  0.6461364  0.09008912  0.1151635  0.1218670
  1260     0.7408612  0.7174725  0.6469697  0.09009740  0.1160899  0.1204493
  1350     0.7406910  0.7154396  0.6460606  0.09385983  0.1175909  0.1205411
  1440     0.7397831  0.7087912  0.6542424  0.09177678  0.1187694  0.1195775
  1530     0.7392720  0.6985714  0.6703030  0.09154512  0.1223436  0.1265171
  1620     0.7390464  0.6884066  0.6912121  0.09204564  0.1224663  0.1273512
  1710     0.7398320  0.6767582  0.7020455  0.09372664  0.1222165  0.1303607
  1800     0.7380199  0.6673077  0.7156818  0.09575055  0.1235030  0.1300642
  1890     0.7389527  0.6584615  0.7337879  0.09656590  0.1221532  0.1261709
  1980     0.7395230  0.6468681  0.7381061  0.09600872  0.1171533  0.1274701
  2070     0.7383650  0.6411538  0.7489394  0.09686032  0.1183828  0.1209776
  2160     0.7377414  0.6295055  0.7615909  0.09587109  0.1272364  0.1267093
  2250     0.7369016  0.6227473  0.7661364  0.09553393  0.1270132  0.1237006
  2340     0.7341344  0.6205495  0.7732576  0.10010769  0.1258230  0.1189686
  2430     0.7361387  0.6131868  0.7821212  0.09611426  0.1289569  0.1259230
  2520     0.7357457  0.6024725  0.7830303  0.09573520  0.1296041  0.1191452
  2610     0.7348874  0.5987363  0.7865909  0.09582225  0.1308104  0.1229457
  2700     0.7365387  0.5898352  0.7875000  0.09419600  0.1291020  0.1200896

Tuning parameter 'interaction.depth' was held constant at a value of 18

Tuning parameter 'shrinkage' was held constant at a value of 0.25

Tuning parameter 'n.minobsinnode' was held constant at a value of 10
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 90, interaction.depth =
 18, shrinkage = 0.25 and n.minobsinnode = 10. 
> 
> ## The acid test is dissapointing, but I've seen worse.
> 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
  Accuracy      Kappa 
 0.3888889 -0.2222222 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     16   20
    Weak       24   12
                                          
               Accuracy : 0.3889          
                 95% CI : (0.2762, 0.5111)
    No Information Rate : 0.5556          
    P-Value [Acc > NIR] : 0.9984          
                                          
                  Kappa : -0.2222         
 Mcnemar's Test P-Value : 0.6511          
                                          
            Sensitivity : 0.3750          
            Specificity : 0.4000          
         Pos Pred Value : 0.3333          
         Neg Pred Value : 0.4444          
             Prevalence : 0.4444          
         Detection Rate : 0.1667          
   Detection Prevalence : 0.5000          
      Balanced Accuracy : 0.3875          
                                          
       'Positive' Class : Weak            
                                          
> 
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
Accuracy    Kappa 
       1        1 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    137    0
    Weak        0  111
                                     
               Accuracy : 1          
                 95% CI : (0.9852, 1)
    No Information Rate : 0.5524     
    P-Value [Acc > NIR] : < 2.2e-16  
                                     
                  Kappa : 1          
 Mcnemar's Test P-Value : NA         
                                     
            Sensitivity : 1.0000     
            Specificity : 1.0000     
         Pos Pred Value : 1.0000     
         Neg Pred Value : 1.0000     
             Prevalence : 0.4476     
         Detection Rate : 0.4476     
   Detection Prevalence : 0.4476     
      Balanced Accuracy : 1.0000     
                                     
       'Positive' Class : Weak       
                                     
> gbmGrid <- expand.grid(interaction.depth = 
+                            c(length(colnames(trainDescr), 2),
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.25,
+                         n.minobsinnode = 10)
+ set.seed(seed.mine)
Error: unexpected symbol in:
"                        n.minobsinnode = 10)
set.seed"
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "ROC",
+                  verbose = FALSE)
> gbmFit1
Stochastic Gradient Boosting 

248 samples
 18 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 223, 223, 224, 224, 224, 223, ... 

Resampling results across tuning parameters:

  n.trees  ROC        Sens       Spec       ROC SD      Sens SD    Spec SD  
    90     0.7431031  0.7053297  0.6428030  0.08494674  0.1234123  0.1392011
   180     0.7360223  0.7045055  0.6484848  0.08856902  0.1322666  0.1389411
   270     0.7387654  0.7057143  0.6581818  0.08619879  0.1270447  0.1288724
   360     0.7357493  0.7042857  0.6589394  0.08938111  0.1255672  0.1308442
   450     0.7394098  0.6979670  0.6562879  0.08890518  0.1249124  0.1319853
   540     0.7362467  0.7038462  0.6526515  0.09132044  0.1197678  0.1404408
   630     0.7368590  0.7036813  0.6490152  0.08878198  0.1235298  0.1371185
   720     0.7341779  0.7071978  0.6509091  0.09306399  0.1272293  0.1306478
   810     0.7343207  0.7109341  0.6497727  0.09294144  0.1259952  0.1305509
   900     0.7318423  0.7146154  0.6489394  0.09700991  0.1237951  0.1313450
   990     0.7341750  0.7131868  0.6462121  0.09125411  0.1237241  0.1349255
  1080     0.7346766  0.7109890  0.6408333  0.09248856  0.1245446  0.1356907
  1170     0.7352689  0.7137912  0.6472727  0.08891934  0.1193536  0.1397370
  1260     0.7316313  0.7070879  0.6454545  0.09431308  0.1224947  0.1398684
  1350     0.7337793  0.7043407  0.6463636  0.09005510  0.1225097  0.1395068
  1440     0.7321689  0.6976923  0.6554545  0.09042439  0.1260002  0.1348824
  1530     0.7319381  0.6926374  0.6698485  0.09241749  0.1286464  0.1368439
  1620     0.7308204  0.6743956  0.6960606  0.09263500  0.1282042  0.1394628
  1710     0.7304816  0.6656044  0.7068182  0.09377048  0.1279528  0.1302649
  1800     0.7318958  0.6545604  0.7247727  0.09267434  0.1278375  0.1234069
  1890     0.7338534  0.6463736  0.7372727  0.08699005  0.1333022  0.1224014
  1980     0.7322326  0.6304945  0.7426515  0.08932246  0.1266842  0.1242981
  2070     0.7323537  0.6197253  0.7525000  0.09430219  0.1258387  0.1249800
  2160     0.7313345  0.6137912  0.7542424  0.09404940  0.1229311  0.1273612
  2250     0.7322875  0.6029670  0.7632576  0.09434526  0.1228028  0.1244143
  2340     0.7306758  0.5920879  0.7703788  0.09394428  0.1213829  0.1251174
  2430     0.7310627  0.5854945  0.7740152  0.09254268  0.1254237  0.1196770
  2520     0.7318633  0.5832418  0.7737879  0.08673240  0.1259261  0.1192692
  2610     0.7325012  0.5817033  0.7784091  0.08647204  0.1264030  0.1190033
  2700     0.7323339  0.5737363  0.7829545  0.08687616  0.1261241  0.1151258

Tuning parameter 'interaction.depth' was held constant at a value of 18

Tuning parameter 'shrinkage' was held constant at a value of 0.25

Tuning parameter 'n.minobsinnode' was held constant at a value of 10
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 90, interaction.depth =
 18, shrinkage = 0.25 and n.minobsinnode = 10. 
> 
> ## The acid test is dissapointing, but I've seen worse.
> 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
  Accuracy      Kappa 
 0.3750000 -0.2616822 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     17   22
    Weak       23   10
                                         
               Accuracy : 0.375          
                 95% CI : (0.2636, 0.497)
    No Information Rate : 0.5556         
    P-Value [Acc > NIR] : 0.9993         
                                         
                  Kappa : -0.2617        
 Mcnemar's Test P-Value : 1.0000         
                                         
            Sensitivity : 0.3125         
            Specificity : 0.4250         
         Pos Pred Value : 0.3030         
         Neg Pred Value : 0.4359         
             Prevalence : 0.4444         
         Detection Rate : 0.1389         
   Detection Prevalence : 0.4583         
      Balanced Accuracy : 0.3688         
                                         
       'Positive' Class : Weak           
                                         
> 
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
Accuracy    Kappa 
       1        1 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    137    0
    Weak        0  111
                                     
               Accuracy : 1          
                 95% CI : (0.9852, 1)
    No Information Rate : 0.5524     
    P-Value [Acc > NIR] : < 2.2e-16  
                                     
                  Kappa : 1          
 Mcnemar's Test P-Value : NA         
                                     
            Sensitivity : 1.0000     
            Specificity : 1.0000     
         Pos Pred Value : 1.0000     
         Neg Pred Value : 1.0000     
             Prevalence : 0.4476     
         Detection Rate : 0.4476     
   Detection Prevalence : 0.4476     
      Balanced Accuracy : 1.0000     
                                     
       'Positive' Class : Weak       
                                     
> trellis.par.set(caretTheme())
Warning message:
In trellis.par.set(caretTheme()) :
  Note: The default device has been opened to honour attempt to modify trellis settings
> plot(gbmFit1, metric = "ROC")
> trellis.par.set(caretTheme())
Warning message:
In trellis.par.set(caretTheme()) :
  Note: The default device has been opened to honour attempt to modify trellis settings
> plot(gbmFit1, metric = "ROC")
> gbmGrid <- expand.grid(interaction.depth = 
+                            c(length(colnames(trainDescr), 2),
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.2,
+                         n.minobsinnode = 10)
+ 
+ set.seed(seed.mine)
Error: unexpected symbol in:
"
set.seed"
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "ROC",
+                  verbose = FALSE)
> gbmFit1
Stochastic Gradient Boosting 

248 samples
 18 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 223, 224, 224, 223, 223, 223, ... 

Resampling results across tuning parameters:

  n.trees  ROC        Sens       Spec       ROC SD      Sens SD    Spec SD  
    90     0.7512209  0.7249451  0.6700758  0.11079548  0.1175871  0.1369168
   180     0.7480145  0.7250549  0.6739394  0.11116952  0.1185970  0.1407028
   270     0.7491209  0.7173077  0.6668182  0.10256517  0.1263082  0.1467888
   360     0.7492054  0.7230769  0.6721212  0.10299868  0.1183553  0.1478360
   450     0.7460847  0.7208791  0.6717424  0.10620226  0.1221614  0.1466863
   540     0.7492724  0.7215934  0.6621970  0.10012537  0.1211464  0.1425293
   630     0.7467539  0.7214835  0.6603788  0.10480572  0.1258857  0.1445926
   720     0.7494266  0.7176923  0.6603788  0.10155515  0.1229447  0.1398976
   810     0.7451807  0.7206044  0.6649242  0.10670452  0.1212529  0.1422963
   900     0.7435872  0.7177473  0.6603788  0.10768689  0.1227880  0.1428501
   990     0.7422421  0.7250000  0.6648485  0.11180476  0.1276482  0.1429355
  1080     0.7384166  0.7272527  0.6640909  0.11604029  0.1240749  0.1396661
  1170     0.7436376  0.7264835  0.6685606  0.10761986  0.1200477  0.1385289
  1260     0.7447811  0.7284615  0.6640152  0.11035943  0.1174012  0.1385206
  1350     0.7439544  0.7263736  0.6640909  0.10891518  0.1181825  0.1365473
  1440     0.7428605  0.7235714  0.6739394  0.10917809  0.1223203  0.1342165
  1530     0.7431504  0.7147253  0.6874242  0.11184600  0.1275749  0.1328913
  1620     0.7446027  0.7016484  0.7045455  0.10652094  0.1226833  0.1314764
  1710     0.7483793  0.6855495  0.7163636  0.09880419  0.1242157  0.1215146
  1800     0.7470134  0.6745604  0.7351515  0.10240613  0.1195750  0.1197441
  1890     0.7470199  0.6641758  0.7414394  0.09818080  0.1274591  0.1174997
  1980     0.7476401  0.6555495  0.7523485  0.10227033  0.1276729  0.1163645
  2070     0.7457786  0.6445604  0.7630303  0.10396483  0.1300723  0.1215277
  2160     0.7459214  0.6380769  0.7676515  0.10287854  0.1306733  0.1168932
  2250     0.7480370  0.6284066  0.7731061  0.09873917  0.1306173  0.1111496
  2340     0.7489839  0.6181868  0.7784848  0.09688978  0.1301819  0.1117724
  2430     0.7472731  0.6153846  0.7856818  0.09569086  0.1297349  0.1068355
  2520     0.7470171  0.6058242  0.7893182  0.09552186  0.1305775  0.1039444
  2610     0.7482299  0.6023077  0.7972727  0.09627229  0.1302505  0.1070406
  2700     0.7480882  0.6000549  0.8034848  0.09522280  0.1329168  0.1043736

Tuning parameter 'interaction.depth' was held constant at a value of 18

Tuning parameter 'shrinkage' was held constant at a value of 0.25

Tuning parameter 'n.minobsinnode' was held constant at a value of 10
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 90, interaction.depth =
 18, shrinkage = 0.25 and n.minobsinnode = 10. 
> 
> ## The acid test is dissapointing, but I've seen worse.
> 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
  Accuracy      Kappa 
 0.4166667 -0.1812500 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     19   21
    Weak       21   11
                                          
               Accuracy : 0.4167          
                 95% CI : (0.3015, 0.5389)
    No Information Rate : 0.5556          
    P-Value [Acc > NIR] : 0.9935          
                                          
                  Kappa : -0.1813         
 Mcnemar's Test P-Value : 1.0000          
                                          
            Sensitivity : 0.3438          
            Specificity : 0.4750          
         Pos Pred Value : 0.3438          
         Neg Pred Value : 0.4750          
             Prevalence : 0.4444          
         Detection Rate : 0.1528          
   Detection Prevalence : 0.4444          
      Balanced Accuracy : 0.4094          
                                          
       'Positive' Class : Weak            
                                          
> 
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
Accuracy    Kappa 
       1        1 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    137    0
    Weak        0  111
                                     
               Accuracy : 1          
                 95% CI : (0.9852, 1)
    No Information Rate : 0.5524     
    P-Value [Acc > NIR] : < 2.2e-16  
                                     
                  Kappa : 1          
 Mcnemar's Test P-Value : NA         
                                     
            Sensitivity : 1.0000     
            Specificity : 1.0000     
         Pos Pred Value : 1.0000     
         Neg Pred Value : 1.0000     
             Prevalence : 0.4476     
         Detection Rate : 0.4476     
   Detection Prevalence : 0.4476     
      Balanced Accuracy : 1.0000     
                                     
       'Positive' Class : Weak       
                                     
> trellis.par.set(caretTheme())
Warning message:
In trellis.par.set(caretTheme()) :
  Note: The default device has been opened to honour attempt to modify trellis settings
> plot(gbmFit1, metric = "ROC")
> gbmGrid <- expand.grid(interaction.depth = 
+                            c(length(colnames(trainDescr), 8, 2),
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.2,
+                         n.minobsinnode = 10)
+ 
+ set.seed(seed.mine)
Error: unexpected symbol in:
"
set.seed"
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "ROC",
+                  verbose = FALSE)
> gbmFit1
Stochastic Gradient Boosting 

248 samples
 18 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 224, 224, 223, 222, 223, 223, ... 

Resampling results across tuning parameters:

  n.trees  ROC        Sens       Spec       ROC SD      Sens SD    Spec SD  
    90     0.7442982  0.7158242  0.6470455  0.10018518  0.1249969  0.1326969
   180     0.7437617  0.7164835  0.6363636  0.09458893  0.1172031  0.1345792
   270     0.7401066  0.7113736  0.6482576  0.09711150  0.1200042  0.1334947
   360     0.7391946  0.7098352  0.6437879  0.10134510  0.1198981  0.1312733
   450     0.7393003  0.7080220  0.6482576  0.09522273  0.1266376  0.1262179
   540     0.7397865  0.7144505  0.6543939  0.09473970  0.1236907  0.1309098
   630     0.7390322  0.7166484  0.6498485  0.10125792  0.1152517  0.1354276
   720     0.7409382  0.7130220  0.6509848  0.10089143  0.1193249  0.1377437
   810     0.7386824  0.7142857  0.6500000  0.10090951  0.1189310  0.1376794
   900     0.7381550  0.7137363  0.6502273  0.10146484  0.1170013  0.1334460
   990     0.7385762  0.7151648  0.6455303  0.10112415  0.1147226  0.1288410
  1080     0.7376832  0.7107143  0.6501515  0.10108684  0.1137285  0.1291469
  1170     0.7363027  0.7121429  0.6492424  0.09993787  0.1175432  0.1282692
  1260     0.7343925  0.7136264  0.6474242  0.09884117  0.1188291  0.1284404
  1350     0.7365129  0.7120879  0.6446970  0.09205845  0.1174241  0.1315359
  1440     0.7355378  0.7032967  0.6565152  0.09208577  0.1172265  0.1318296
  1530     0.7366404  0.6946154  0.6699242  0.09141872  0.1240838  0.1263326
  1620     0.7379826  0.6873626  0.6915909  0.09426125  0.1267591  0.1183435
  1710     0.7376948  0.6741209  0.7121212  0.09263945  0.1253419  0.1156314
  1800     0.7363745  0.6631868  0.7301515  0.09516305  0.1282705  0.1182282
  1890     0.7336653  0.6507143  0.7454545  0.09748747  0.1277196  0.1108290
  1980     0.7355399  0.6457143  0.7526515  0.09722359  0.1252854  0.1117685
  2070     0.7337167  0.6306044  0.7589394  0.09589676  0.1273001  0.1121259
  2160     0.7332900  0.6209890  0.7653030  0.09715384  0.1249015  0.1123769
  2250     0.7326174  0.6093407  0.7707576  0.09680433  0.1292864  0.1118631
  2340     0.7333914  0.6012637  0.7753030  0.09679861  0.1270229  0.1111018
  2430     0.7329518  0.5945604  0.7778788  0.09708714  0.1305861  0.1116570
  2520     0.7331627  0.5889560  0.7824242  0.09844880  0.1293647  0.1067584
  2610     0.7340064  0.5810440  0.7869697  0.09964057  0.1279632  0.1093402
  2700     0.7329287  0.5774176  0.7932576  0.09982207  0.1292901  0.1053493

Tuning parameter 'interaction.depth' was held constant at a value of 18

Tuning parameter 'shrinkage' was held constant at a value of 0.25

Tuning parameter 'n.minobsinnode' was held constant at a value of 10
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 90, interaction.depth =
 18, shrinkage = 0.25 and n.minobsinnode = 10. 
> 
> ## The acid test is dissapointing, but I've seen worse.
> 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
  Accuracy      Kappa 
 0.3888889 -0.2222222 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     16   20
    Weak       24   12
                                          
               Accuracy : 0.3889          
                 95% CI : (0.2762, 0.5111)
    No Information Rate : 0.5556          
    P-Value [Acc > NIR] : 0.9984          
                                          
                  Kappa : -0.2222         
 Mcnemar's Test P-Value : 0.6511          
                                          
            Sensitivity : 0.3750          
            Specificity : 0.4000          
         Pos Pred Value : 0.3333          
         Neg Pred Value : 0.4444          
             Prevalence : 0.4444          
         Detection Rate : 0.1667          
   Detection Prevalence : 0.5000          
      Balanced Accuracy : 0.3875          
                                          
       'Positive' Class : Weak            
                                          
> 
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
Accuracy    Kappa 
       1        1 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    137    0
    Weak        0  111
                                     
               Accuracy : 1          
                 95% CI : (0.9852, 1)
    No Information Rate : 0.5524     
    P-Value [Acc > NIR] : < 2.2e-16  
                                     
                  Kappa : 1          
 Mcnemar's Test P-Value : NA         
                                     
            Sensitivity : 1.0000     
            Specificity : 1.0000     
         Pos Pred Value : 1.0000     
         Neg Pred Value : 1.0000     
             Prevalence : 0.4476     
         Detection Rate : 0.4476     
   Detection Prevalence : 0.4476     
      Balanced Accuracy : 1.0000     
                                     
       'Positive' Class : Weak       
                                     
> trellis.par.set(caretTheme())
Warning message:
In trellis.par.set(caretTheme()) :
  Note: The default device has been opened to honour attempt to modify trellis settings
> plot(gbmFit1, metric = "ROC")
> 
Error: unexpected ')' in ")"
> attributes(gbmFit1)
$names
 [1] "method"       "modelInfo"    "modelType"    "results"      "pred"        
 [6] "bestTune"     "call"         "dots"         "metric"       "control"     
[11] "finalModel"   "preProcess"   "trainingData" "resample"     "resampledCM" 
[16] "perfNames"    "maximize"     "yLimits"      "times"       

$class
[1] "train"

> gbmFit1$finalModel
A gradient boosted model with bernoulli loss function.
90 iterations were performed.
There were 18 predictors of which 18 had non-zero influence.
> gbmFit1$pred
NULL
> gbmFit1$call
train.default(x = trainDescr, y = trainClass, method = "gbm", 
    verbose = FALSE, metric = "ROC", trControl = fitControl, 
    tuneGrid = gbmGrid)
> fitControl <- trainControl(## 10-fold CV
+     method = "repeatedcv",
+     number = 10,
+     ## repeated ten times
+     repeats = 10,
+     classProbs = TRUE,
+     summaryFunction = twoClassSummary)
> gbmGrid <- expand.grid(interaction.depth = 
+                            c(length(colnames(trainDescr), 8, 2),
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.2,
+                         n.minobsinnode = 10)
+ 
+ set.seed(seed.mine)
Error: unexpected symbol in:
"
set.seed"
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "ROC",
+                  verbose = FALSE)
> gbmFit1
Stochastic Gradient Boosting 

248 samples
 18 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 223, 224, 224, 223, 222, 223, ... 

Resampling results across tuning parameters:

  n.trees  ROC        Sens       Spec       ROC SD      Sens SD    Spec SD  
    90     0.7422219  0.7212637  0.6499242  0.10608846  0.1215505  0.1434019
   180     0.7397232  0.7164286  0.6506061  0.10169247  0.1227737  0.1498813
   270     0.7358750  0.7132967  0.6468939  0.10144807  0.1223420  0.1455072
   360     0.7411364  0.7155495  0.6397727  0.10088073  0.1172444  0.1513290
   450     0.7344922  0.7170879  0.6372727  0.11135341  0.1232759  0.1462162
   540     0.7405395  0.7182967  0.6468939  0.10248723  0.1201272  0.1415284
   630     0.7414194  0.7154396  0.6477273  0.10188363  0.1210437  0.1444339
   720     0.7407076  0.7153846  0.6440909  0.10046656  0.1245740  0.1404598
   810     0.7368611  0.7184066  0.6476515  0.10611387  0.1223918  0.1380474
   900     0.7374746  0.7163736  0.6496212  0.10547676  0.1234818  0.1447181
   990     0.7350437  0.7141758  0.6424242  0.11080867  0.1311376  0.1456470
  1080     0.7332522  0.7119780  0.6470455  0.11308294  0.1308145  0.1467023
  1170     0.7352079  0.7103297  0.6487879  0.10614035  0.1273916  0.1473506
  1260     0.7312483  0.7118132  0.6478788  0.11034059  0.1269223  0.1438829
  1350     0.7325955  0.7119780  0.6523485  0.10548138  0.1261458  0.1410361
  1440     0.7272015  0.7068681  0.6557576  0.11289137  0.1338817  0.1411939
  1530     0.7309166  0.6929121  0.6703030  0.10462198  0.1342673  0.1376899
  1620     0.7325783  0.6767582  0.6875000  0.09771016  0.1362359  0.1277478
  1710     0.7324401  0.6717582  0.7009091  0.10069125  0.1354988  0.1296626
  1800     0.7325142  0.6592308  0.7181061  0.10163617  0.1414240  0.1266308
  1890     0.7311264  0.6439011  0.7340909  0.10086759  0.1443388  0.1177847
  1980     0.7323822  0.6334066  0.7439394  0.10024073  0.1455137  0.1194731
  2070     0.7302668  0.6224176  0.7502273  0.10740984  0.1420997  0.1202684
  2160     0.7303072  0.6181868  0.7582576  0.10634129  0.1488011  0.1192210
  2250     0.7310250  0.6064835  0.7609848  0.10447647  0.1507926  0.1256522
  2340     0.7310319  0.5954396  0.7708333  0.10413179  0.1483664  0.1213764
  2430     0.7297386  0.5932967  0.7781061  0.10891025  0.1502521  0.1191879
  2520     0.7342256  0.5810440  0.7817424  0.10335020  0.1509071  0.1196656
  2610     0.7332332  0.5758791  0.7844697  0.10217577  0.1520311  0.1201234
  2700     0.7321897  0.5673077  0.7934848  0.10498719  0.1525411  0.1148498

Tuning parameter 'interaction.depth' was held constant at a value of 18

Tuning parameter 'shrinkage' was held constant at a value of 0.25

Tuning parameter 'n.minobsinnode' was held constant at a value of 10
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 90, interaction.depth =
 18, shrinkage = 0.25 and n.minobsinnode = 10. 
> 
> ## The acid test is dissapointing, but I've seen worse.
> 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
  Accuracy      Kappa 
 0.4305556 -0.1640379 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     21   22
    Weak       19   10
                                          
               Accuracy : 0.4306          
                 95% CI : (0.3143, 0.5527)
    No Information Rate : 0.5556          
    P-Value [Acc > NIR] : 0.9876          
                                          
                  Kappa : -0.164          
 Mcnemar's Test P-Value : 0.7548          
                                          
            Sensitivity : 0.3125          
            Specificity : 0.5250          
         Pos Pred Value : 0.3448          
         Neg Pred Value : 0.4884          
             Prevalence : 0.4444          
         Detection Rate : 0.1389          
   Detection Prevalence : 0.4028          
      Balanced Accuracy : 0.4188          
                                          
       'Positive' Class : Weak            
                                          
> 
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
Accuracy    Kappa 
       1        1 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    137    0
    Weak        0  111
                                     
               Accuracy : 1          
                 95% CI : (0.9852, 1)
    No Information Rate : 0.5524     
    P-Value [Acc > NIR] : < 2.2e-16  
                                     
                  Kappa : 1          
 Mcnemar's Test P-Value : NA         
                                     
            Sensitivity : 1.0000     
            Specificity : 1.0000     
         Pos Pred Value : 1.0000     
         Neg Pred Value : 1.0000     
             Prevalence : 0.4476     
         Detection Rate : 0.4476     
   Detection Prevalence : 0.4476     
      Balanced Accuracy : 1.0000     
                                     
       'Positive' Class : Weak       
                                     
> trellis.par.set(caretTheme())
Warning message:
In trellis.par.set(caretTheme()) :
  Note: The default device has been opened to honour attempt to modify trellis settings
> plot(gbmFit1, metric = "ROC")
> fitControl <- trainControl(## 10-fold CV
+     method = "repeatedcv",
+     number = 10,
+     ## repeated ten times
+     repeats = 10,
+     classProbs = TRUE,
+     summaryFunction = twoClassSummary)
> 
> ## Some trial and error with variables to branch and boost.
> ## Try all variables
> 
> gbmGrid <- expand.grid(interaction.depth = 
+                            c(length(colnames(trainDescr)-1, 2),
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.2,
+                         n.minobsinnode = 10)
+ 
+ set.seed(seed.mine)
Error: unexpected symbol in:
"
set.seed"
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "ROC",
+                  verbose = FALSE)
> gbmFit1
Stochastic Gradient Boosting 

248 samples
 18 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 223, 224, 224, 223, 223, 224, ... 

Resampling results across tuning parameters:

  n.trees  ROC        Sens       Spec       ROC SD      Sens SD    Spec SD  
    90     0.7412000  0.7206044  0.6505303  0.10351189  0.1171859  0.1212296
   180     0.7429537  0.7300000  0.6470455  0.09706661  0.1142146  0.1267991
   270     0.7426478  0.7285165  0.6586364  0.09831130  0.1123981  0.1251457
   360     0.7444435  0.7268132  0.6561364  0.09866558  0.1081280  0.1231145
   450     0.7444618  0.7280769  0.6613636  0.09820331  0.1150670  0.1268695
   540     0.7444485  0.7273077  0.6605303  0.09824865  0.1098781  0.1272127
   630     0.7433265  0.7237363  0.6558333  0.09951997  0.1095234  0.1235581
   720     0.7422873  0.7215934  0.6532576  0.09899216  0.1107086  0.1226189
   810     0.7429377  0.7253297  0.6515909  0.09824828  0.1087141  0.1285175
   900     0.7417274  0.7239560  0.6443182  0.09876188  0.1135857  0.1281149
   990     0.7424571  0.7275275  0.6406061  0.09806791  0.1127016  0.1212997
  1080     0.7437766  0.7310440  0.6460606  0.09904189  0.1124992  0.1243849
  1170     0.7426057  0.7275275  0.6470455  0.10052093  0.1180614  0.1190020
  1260     0.7409946  0.7326374  0.6505303  0.09902096  0.1165566  0.1233063
  1350     0.7387259  0.7268681  0.6504545  0.10112544  0.1174378  0.1249195
  1440     0.7401482  0.7145604  0.6622727  0.09994148  0.1180880  0.1205944
  1530     0.7403492  0.7015385  0.6774242  0.09974713  0.1199596  0.1191338
  1620     0.7398568  0.6875275  0.6909091  0.09772206  0.1179699  0.1201602
  1710     0.7390368  0.6732418  0.7053788  0.09621395  0.1272129  0.1177522
  1800     0.7383860  0.6686813  0.7153788  0.09768377  0.1169752  0.1216192
  1890     0.7386888  0.6570879  0.7289394  0.09793884  0.1158925  0.1218446
  1980     0.7399182  0.6431868  0.7397727  0.09906516  0.1169239  0.1182704
  2070     0.7386255  0.6337912  0.7443182  0.10032611  0.1145035  0.1194555
  2160     0.7383825  0.6257143  0.7505303  0.09836638  0.1158825  0.1161130
  2250     0.7381789  0.6177473  0.7578030  0.09940679  0.1108963  0.1143988
  2340     0.7386324  0.6135165  0.7631061  0.09835615  0.1159349  0.1131730
  2430     0.7384205  0.6025275  0.7693182  0.09676246  0.1186363  0.1109617
  2520     0.7373868  0.6011538  0.7730303  0.09587398  0.1188107  0.1129888
  2610     0.7356052  0.5930769  0.7730303  0.09605288  0.1229522  0.1115013
  2700     0.7338287  0.5878022  0.7775758  0.09600757  0.1273459  0.1128841

Tuning parameter 'interaction.depth' was held constant at a value of 18

Tuning parameter 'shrinkage' was held constant at a value of 0.25

Tuning parameter 'n.minobsinnode' was held constant at a value of 10
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 450, interaction.depth =
 18, shrinkage = 0.25 and n.minobsinnode = 10. 
> 
> ## The acid test is dissapointing, but I've seen worse.
> 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
  Accuracy      Kappa 
 0.4444444 -0.1180124 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     19   19
    Weak       21   13
                                          
               Accuracy : 0.4444          
                 95% CI : (0.3272, 0.5664)
    No Information Rate : 0.5556          
    P-Value [Acc > NIR] : 0.9778          
                                          
                  Kappa : -0.118          
 Mcnemar's Test P-Value : 0.8744          
                                          
            Sensitivity : 0.4062          
            Specificity : 0.4750          
         Pos Pred Value : 0.3824          
         Neg Pred Value : 0.5000          
             Prevalence : 0.4444          
         Detection Rate : 0.1806          
   Detection Prevalence : 0.4722          
      Balanced Accuracy : 0.4406          
                                          
       'Positive' Class : Weak            
                                          
> 
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
Accuracy    Kappa 
       1        1 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    137    0
    Weak        0  111
                                     
               Accuracy : 1          
                 95% CI : (0.9852, 1)
    No Information Rate : 0.5524     
    P-Value [Acc > NIR] : < 2.2e-16  
                                     
                  Kappa : 1          
 Mcnemar's Test P-Value : NA         
                                     
            Sensitivity : 1.0000     
            Specificity : 1.0000     
         Pos Pred Value : 1.0000     
         Neg Pred Value : 1.0000     
             Prevalence : 0.4476     
         Detection Rate : 0.4476     
   Detection Prevalence : 0.4476     
      Balanced Accuracy : 1.0000     
                                     
       'Positive' Class : Weak       
                                     
> trellis.par.set(caretTheme())
Warning message:
In trellis.par.set(caretTheme()) :
  Note: The default device has been opened to honour attempt to modify trellis settings
> plot(gbmFit1, metric = "ROC")
> trellis.par.set(caretTheme())
Warning message:
In trellis.par.set(caretTheme()) :
  Note: The default device has been opened to honour attempt to modify trellis settings
> plot(gbmFit1)
> fitControl <- trainControl(## 10-fold CV
+     method = "repeatedcv",
+     number = 10,
+     ## repeated ten times
+     repeats = 10,
+     classProbs = TRUE,
+     summaryFunction = twoClassSummary)
> gbmGrid <- expand.grid(interaction.depth = 
+                            c(length(colnames(trainDescr)-1, 1),
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.2,
+                         n.minobsinnode = 10)
+ 
+ set.seed(seed.mine)
Error: unexpected symbol in:
"
set.seed"
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "ROC",
+                  verbose = FALSE)
> gbmFit1
Stochastic Gradient Boosting 

248 samples
 18 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 223, 223, 223, 223, 224, 223, ... 

Resampling results across tuning parameters:

  n.trees  ROC        Sens       Spec       ROC SD      Sens SD    Spec SD  
    90     0.7563641  0.7286813  0.6553030  0.09783553  0.1222732  0.1365357
   180     0.7582218  0.7175824  0.6571212  0.09883962  0.1157369  0.1371716
   270     0.7581718  0.7250549  0.6442424  0.09667218  0.1137702  0.1337969
   360     0.7535793  0.7244505  0.6461364  0.09525572  0.1150322  0.1294917
   450     0.7542674  0.7207143  0.6409848  0.09552445  0.1121019  0.1434084
   540     0.7521720  0.7293407  0.6390152  0.09318073  0.1068357  0.1361568
   630     0.7541933  0.7245055  0.6415909  0.09602343  0.1116766  0.1383879
   720     0.7529637  0.7206593  0.6369697  0.09410425  0.1155516  0.1367910
   810     0.7540589  0.7215385  0.6334848  0.09231216  0.1147230  0.1419084
   900     0.7540865  0.7250549  0.6406818  0.09328265  0.1174965  0.1411074
   990     0.7533319  0.7265385  0.6453030  0.09276569  0.1113781  0.1365522
  1080     0.7526877  0.7243956  0.6460606  0.09211648  0.1136544  0.1407817
  1170     0.7503020  0.7223626  0.6505303  0.09104680  0.1116232  0.1393271
  1260     0.7504735  0.7216484  0.6487121  0.09233459  0.1099712  0.1435367
  1350     0.7499763  0.7208242  0.6541667  0.09202463  0.1089333  0.1427702
  1440     0.7493719  0.7185165  0.6578030  0.09086201  0.1184759  0.1386991
  1530     0.7464344  0.7089011  0.6758333  0.09452535  0.1192306  0.1322953
  1620     0.7470854  0.7008242  0.6929545  0.09367456  0.1123473  0.1326242
  1710     0.7477897  0.6897802  0.7090909  0.09262047  0.1153976  0.1325566
  1800     0.7479379  0.6745055  0.7227273  0.09270327  0.1176501  0.1321624
  1890     0.7464057  0.6628022  0.7390152  0.09727591  0.1170486  0.1261909
  1980     0.7465145  0.6441209  0.7400000  0.09573484  0.1225847  0.1328706
  2070     0.7440283  0.6358791  0.7606818  0.09828012  0.1253861  0.1185920
  2160     0.7460129  0.6293407  0.7626515  0.09722405  0.1278178  0.1218706
  2250     0.7447629  0.6128022  0.7662879  0.09746639  0.1319547  0.1232627
  2340     0.7450393  0.6089560  0.7734091  0.09849237  0.1329507  0.1209588
  2430     0.7438085  0.6039011  0.7761364  0.09993043  0.1330379  0.1209122
  2520     0.7429772  0.5929121  0.7834091  0.10160421  0.1330677  0.1183866
  2610     0.7430276  0.5900000  0.7868939  0.10040380  0.1308648  0.1245041
  2700     0.7437868  0.5870879  0.7923485  0.09938430  0.1331737  0.1203342

Tuning parameter 'interaction.depth' was held constant at a value of 18

Tuning parameter 'shrinkage' was held constant at a value of 0.25

Tuning parameter 'n.minobsinnode' was held constant at a value of 10
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 180, interaction.depth =
 18, shrinkage = 0.25 and n.minobsinnode = 10. 
> 
> ## The acid test is dissapointing, but I've seen worse.
> 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
   Accuracy       Kappa 
 0.47222222 -0.04268293 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     17   15
    Weak       23   17
                                          
               Accuracy : 0.4722          
                 95% CI : (0.3533, 0.5935)
    No Information Rate : 0.5556          
    P-Value [Acc > NIR] : 0.9380          
                                          
                  Kappa : -0.0427         
 Mcnemar's Test P-Value : 0.2561          
                                          
            Sensitivity : 0.5312          
            Specificity : 0.4250          
         Pos Pred Value : 0.4250          
         Neg Pred Value : 0.5312          
             Prevalence : 0.4444          
         Detection Rate : 0.2361          
   Detection Prevalence : 0.5556          
      Balanced Accuracy : 0.4781          
                                          
       'Positive' Class : Weak            
                                          
> 
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
Accuracy    Kappa 
       1        1 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    137    0
    Weak        0  111
                                     
               Accuracy : 1          
                 95% CI : (0.9852, 1)
    No Information Rate : 0.5524     
    P-Value [Acc > NIR] : < 2.2e-16  
                                     
                  Kappa : 1          
 Mcnemar's Test P-Value : NA         
                                     
            Sensitivity : 1.0000     
            Specificity : 1.0000     
         Pos Pred Value : 1.0000     
         Neg Pred Value : 1.0000     
             Prevalence : 0.4476     
         Detection Rate : 0.4476     
   Detection Prevalence : 0.4476     
      Balanced Accuracy : 1.0000     
                                     
       'Positive' Class : Weak       
                                     
> trellis.par.set(caretTheme())
Warning message:
In trellis.par.set(caretTheme()) :
  Note: The default device has been opened to honour attempt to modify trellis settings
> plot(gbmFit1, metric = "ROC")
> fitControl <- trainControl(## 10-fold CV
+     method = "repeatedcv",
+     number = 10,
+     ## repeated ten times
+     repeats = 10,
+     classProbs = TRUE,
+     summaryFunction = twoClassSummary)
> gbmGrid <- expand.grid(interaction.depth = 
+                            c(length(colnames(trainDescr)-1, 1),
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.2,
+                         n.minobsinnode = 10)
+ 
+ set.seed(seed.mine)
Error: unexpected symbol in:
"
set.seed"
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "Kappa",
+                  verbose = FALSE)
Warning message:
In train.default(trainDescr, trainClass, method = "gbm", trControl = fitControl,  :
  The metric "Kappa" was not in the result set. ROC will be used instead.
> gbmFit1
Stochastic Gradient Boosting 

248 samples
 18 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 223, 223, 223, 223, 222, 223, ... 

Resampling results across tuning parameters:

  n.trees  ROC        Sens       Spec       ROC SD     Sens SD    Spec SD  
    90     0.7327851  0.7008242  0.6351515  0.1057793  0.1341570  0.1325729
   180     0.7341467  0.7045604  0.6457576  0.1108318  0.1338942  0.1411479
   270     0.7379666  0.7125824  0.6343939  0.1106265  0.1300371  0.1358040
   360     0.7383121  0.7117582  0.6406818  0.1088744  0.1310200  0.1298180
   450     0.7327880  0.7073626  0.6481818  0.1120844  0.1269181  0.1319048
   540     0.7378180  0.7073077  0.6569697  0.1066821  0.1301593  0.1266206
   630     0.7355794  0.7110989  0.6496212  0.1096016  0.1254136  0.1234507
   720     0.7335585  0.7087912  0.6415909  0.1127214  0.1237167  0.1224905
   810     0.7325972  0.7094505  0.6424242  0.1109243  0.1248192  0.1203096
   900     0.7316504  0.7167582  0.6459848  0.1097231  0.1185056  0.1208138
   990     0.7361060  0.7059341  0.6488636  0.1008456  0.1241042  0.1204703
  1080     0.7341492  0.7094505  0.6415909  0.1026806  0.1188291  0.1237383
  1170     0.7318396  0.7102198  0.6459848  0.1039092  0.1220281  0.1222970
  1260     0.7329808  0.7144505  0.6468939  0.1051710  0.1200068  0.1231334
  1350     0.7338114  0.7087363  0.6478788  0.1049047  0.1254728  0.1232303
  1440     0.7331758  0.7007143  0.6558333  0.1058636  0.1337087  0.1210746
  1530     0.7332482  0.6862088  0.6775758  0.1088130  0.1352742  0.1225029
  1620     0.7332501  0.6760989  0.6900758  0.1125126  0.1404099  0.1276421
  1710     0.7338407  0.6657143  0.7073485  0.1110682  0.1450491  0.1279486
  1800     0.7365537  0.6547253  0.7281818  0.1087334  0.1423926  0.1288364
  1890     0.7347194  0.6468681  0.7389394  0.1087545  0.1385042  0.1339203
  1980     0.7366213  0.6345604  0.7407576  0.1044864  0.1425762  0.1324935
  2070     0.7392320  0.6258242  0.7471212  0.1040787  0.1414855  0.1326300
  2160     0.7399931  0.6182967  0.7553030  0.1035150  0.1393834  0.1282330
  2250     0.7370790  0.6110989  0.7641667  0.1051031  0.1444673  0.1238926
  2340     0.7381976  0.6022527  0.7667424  0.1043175  0.1446663  0.1248651
  2430     0.7369641  0.5936264  0.7711364  0.1056828  0.1451567  0.1284399
  2520     0.7366898  0.5834066  0.7801515  0.1056917  0.1462501  0.1309328
  2610     0.7362781  0.5760989  0.7829545  0.1040611  0.1393964  0.1281420
  2700     0.7370777  0.5725275  0.7900758  0.1051228  0.1422153  0.1276158

Tuning parameter 'interaction.depth' was held constant at a value of 18

Tuning parameter 'shrinkage' was held constant at a value of 0.25

Tuning parameter 'n.minobsinnode' was held constant at a value of 10
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 2160, interaction.depth
 = 18, shrinkage = 0.25 and n.minobsinnode = 10. 
> 
> ## The acid test is dissapointing, but I've seen worse.
> 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
  Accuracy      Kappa 
 0.4166667 -0.1595092 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     16   18
    Weak       24   14
                                          
               Accuracy : 0.4167          
                 95% CI : (0.3015, 0.5389)
    No Information Rate : 0.5556          
    P-Value [Acc > NIR] : 0.9935          
                                          
                  Kappa : -0.1595         
 Mcnemar's Test P-Value : 0.4404          
                                          
            Sensitivity : 0.4375          
            Specificity : 0.4000          
         Pos Pred Value : 0.3684          
         Neg Pred Value : 0.4706          
             Prevalence : 0.4444          
         Detection Rate : 0.1944          
   Detection Prevalence : 0.5278          
      Balanced Accuracy : 0.4188          
                                          
       'Positive' Class : Weak            
                                          
> 
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
Accuracy    Kappa 
       1        1 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    137    0
    Weak        0  111
                                     
               Accuracy : 1          
                 95% CI : (0.9852, 1)
    No Information Rate : 0.5524     
    P-Value [Acc > NIR] : < 2.2e-16  
                                     
                  Kappa : 1          
 Mcnemar's Test P-Value : NA         
                                     
            Sensitivity : 1.0000     
            Specificity : 1.0000     
         Pos Pred Value : 1.0000     
         Neg Pred Value : 1.0000     
             Prevalence : 0.4476     
         Detection Rate : 0.4476     
   Detection Prevalence : 0.4476     
      Balanced Accuracy : 1.0000     
                                     
       'Positive' Class : Weak       
                                     
> trellis.par.set(caretTheme())
Warning message:
In trellis.par.set(caretTheme()) :
  Note: The default device has been opened to honour attempt to modify trellis settings
> plot(gbmFit1, metric = "Kappa")
Error in `[.data.frame`(dat, , c(metric, params)) : 
  undefined columns selected
> trellis.par.set(caretTheme())
Warning message:
In trellis.par.set(caretTheme()) :
  Note: The default device has been opened to honour attempt to modify trellis settings
> plot(gbmFit1, metric = "ROC")
> ggplot(gbmFit1)
> fitControl <- trainControl(## 10-fold CV
+     method = "repeatedcv",
+     number = 10,
+     ## repeated ten times
+     repeats = 10,
+     classProbs = TRUE,
+     summaryFunction = twoClassSummary)
> 
> ## Some trial and error with variables to branch and boost.
> ## Try all variables
> 
> gbmGrid <- expand.grid(interaction.depth = 
+                            c(length(colnames(trainDescr)-4, 1),
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.2,
+                         n.minobsinnode = 10)
+ 
+ set.seed(seed.mine)
Error: unexpected symbol in:
"
set.seed"
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "Kappa",
+                  verbose = FALSE)
Warning message:
In train.default(trainDescr, trainClass, method = "gbm", trControl = fitControl,  :
  The metric "Kappa" was not in the result set. ROC will be used instead.
> gbmFit1
Stochastic Gradient Boosting 

248 samples
 18 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 224, 223, 223, 223, 222, 224, ... 

Resampling results across tuning parameters:

  n.trees  ROC        Sens       Spec       ROC SD      Sens SD    Spec SD  
    90     0.7465505  0.7141209  0.6558333  0.10401463  0.1175005  0.1427494
   180     0.7431360  0.7081319  0.6578030  0.10551421  0.1212677  0.1432513
   270     0.7473177  0.7147802  0.6588636  0.10382231  0.1193766  0.1436974
   360     0.7449754  0.7140659  0.6543182  0.10290307  0.1279859  0.1426779
   450     0.7463095  0.7147802  0.6553030  0.10231908  0.1214482  0.1427098
   540     0.7470804  0.7194505  0.6534848  0.09963098  0.1210828  0.1493169
   630     0.7469535  0.7206593  0.6507576  0.09944479  0.1238219  0.1464152
   720     0.7467349  0.7236813  0.6535606  0.09935908  0.1216970  0.1451201
   810     0.7472324  0.7207692  0.6553788  0.09770781  0.1215894  0.1460385
   900     0.7478259  0.7228571  0.6481061  0.09870950  0.1193490  0.1445177
   990     0.7471370  0.7206593  0.6553788  0.09815028  0.1192248  0.1419808
  1080     0.7447124  0.7214286  0.6534848  0.10127585  0.1237992  0.1407757
  1170     0.7427244  0.7207143  0.6571970  0.10141137  0.1220367  0.1351868
  1260     0.7440888  0.7228571  0.6570455  0.10038115  0.1233076  0.1380279
  1350     0.7424051  0.7185165  0.6571212  0.10077417  0.1223157  0.1329480
  1440     0.7426457  0.7068681  0.6680303  0.10221015  0.1259528  0.1332866
  1530     0.7440732  0.6951099  0.6812879  0.09858657  0.1247708  0.1364837
  1620     0.7449376  0.6826374  0.6993939  0.09917828  0.1284003  0.1296331
  1710     0.7441046  0.6708791  0.7138636  0.09815295  0.1283917  0.1216077
  1800     0.7451386  0.6630220  0.7301515  0.09542148  0.1310494  0.1262341
  1890     0.7451511  0.6519231  0.7383333  0.09710205  0.1305372  0.1213862
  1980     0.7456806  0.6439560  0.7490909  0.09747287  0.1379243  0.1242133
  2070     0.7447694  0.6339560  0.7544697  0.09679378  0.1339805  0.1223408
  2160     0.7440087  0.6289011  0.7652273  0.09743618  0.1335580  0.1186966
  2250     0.7433718  0.6208242  0.7697727  0.09772902  0.1411618  0.1174860
  2340     0.7442285  0.6112637  0.7798485  0.09863151  0.1381901  0.1136686
  2430     0.7429206  0.6060440  0.7834848  0.09988901  0.1353026  0.1133794
  2520     0.7437415  0.5950549  0.7862121  0.10078001  0.1364315  0.1152778
  2610     0.7437348  0.5878571  0.7934848  0.10062508  0.1334074  0.1163542
  2700     0.7405145  0.5849451  0.7943939  0.10582394  0.1380666  0.1190260

Tuning parameter 'interaction.depth' was held constant at a value of 18

Tuning parameter 'shrinkage' was held constant at a value of 0.25

Tuning parameter 'n.minobsinnode' was held constant at a value of 10
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 900, interaction.depth =
 18, shrinkage = 0.25 and n.minobsinnode = 10. 
> 
> ## The acid test is dissapointing, but I've seen worse.
> 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
  Accuracy      Kappa 
 0.4166667 -0.1666667 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     17   19
    Weak       23   13
                                          
               Accuracy : 0.4167          
                 95% CI : (0.3015, 0.5389)
    No Information Rate : 0.5556          
    P-Value [Acc > NIR] : 0.9935          
                                          
                  Kappa : -0.1667         
 Mcnemar's Test P-Value : 0.6434          
                                          
            Sensitivity : 0.4062          
            Specificity : 0.4250          
         Pos Pred Value : 0.3611          
         Neg Pred Value : 0.4722          
             Prevalence : 0.4444          
         Detection Rate : 0.1806          
   Detection Prevalence : 0.5000          
      Balanced Accuracy : 0.4156          
                                          
       'Positive' Class : Weak            
                                          
> 
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
Accuracy    Kappa 
       1        1 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    137    0
    Weak        0  111
                                     
               Accuracy : 1          
                 95% CI : (0.9852, 1)
    No Information Rate : 0.5524     
    P-Value [Acc > NIR] : < 2.2e-16  
                                     
                  Kappa : 1          
 Mcnemar's Test P-Value : NA         
                                     
            Sensitivity : 1.0000     
            Specificity : 1.0000     
         Pos Pred Value : 1.0000     
         Neg Pred Value : 1.0000     
             Prevalence : 0.4476     
         Detection Rate : 0.4476     
   Detection Prevalence : 0.4476     
      Balanced Accuracy : 1.0000     
                                     
       'Positive' Class : Weak       
                                     
> gbmGrid <- expand.grid(interaction.depth = 
+                            c(length(colnames(trainDescr))-4, 1),
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.2,
+                         n.minobsinnode = 10)
> set.seed(seed.mine)
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "Kappa",
+                  verbose = FALSE)
Warning message:
In train.default(trainDescr, trainClass, method = "gbm", trControl = fitControl,  :
  The metric "Kappa" was not in the result set. ROC will be used instead.
> gbmFit1
Stochastic Gradient Boosting 

248 samples
 18 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 222, 223, 223, 224, 223, 223, ... 

Resampling results across tuning parameters:

  interaction.depth  n.trees  ROC        Sens       Spec       ROC SD    
   1                   90     0.7781473  0.7167582  0.7029545  0.08608499
   1                  180     0.7763778  0.7357692  0.6893182  0.08200670
   1                  270     0.7725549  0.7191758  0.6978030  0.08627553
   1                  360     0.7665010  0.7248901  0.6975758  0.09117716
   1                  450     0.7687446  0.7176923  0.6944697  0.08313779
   1                  540     0.7651424  0.7147253  0.6940152  0.08593064
   1                  630     0.7635277  0.7067033  0.6907576  0.08752021
   1                  720     0.7656731  0.7097253  0.6921970  0.08284352
   1                  810     0.7643065  0.7147802  0.6849242  0.08442314
   1                  900     0.7591817  0.7088462  0.6805303  0.09266772
   1                  990     0.7590364  0.7138462  0.6771212  0.09122055
   1                 1080     0.7603651  0.7136264  0.6725000  0.09057900
   1                 1170     0.7602851  0.7086264  0.6734091  0.08569530
   1                 1260     0.7584782  0.7114286  0.6867424  0.08683460
   1                 1350     0.7595176  0.7135165  0.6769697  0.08686875
   1                 1440     0.7573951  0.7122527  0.6779545  0.09294014
   1                 1530     0.7581843  0.7165934  0.6761364  0.08896083
   1                 1620     0.7545076  0.7124725  0.6752273  0.09109368
   1                 1710     0.7554525  0.7123077  0.6779545  0.08871959
   1                 1800     0.7561272  0.7158242  0.6734091  0.08856918
   1                 1890     0.7538928  0.7142857  0.6753030  0.09324984
   1                 1980     0.7521100  0.7193407  0.6734848  0.09422469
   1                 2070     0.7530091  0.7200549  0.6671970  0.09054282
   1                 2160     0.7526061  0.7230220  0.6708333  0.08731890
   1                 2250     0.7536464  0.7208242  0.6662879  0.08992846
   1                 2340     0.7545084  0.7179121  0.6681061  0.09022174
   1                 2430     0.7550799  0.7164286  0.6655303  0.08916465
   1                 2520     0.7528792  0.7186264  0.6673485  0.09392014
   1                 2610     0.7526707  0.7100000  0.6628030  0.09046932
   1                 2700     0.7528488  0.7134615  0.6646212  0.08956221
  14                   90     0.7457488  0.7067033  0.6701515  0.08863631
  14                  180     0.7455087  0.7004945  0.6504545  0.08756591
  14                  270     0.7457821  0.7122527  0.6521970  0.08752750
  14                  360     0.7446312  0.7097802  0.6534848  0.08871410
  14                  450     0.7443860  0.7093407  0.6499242  0.09040571
  14                  540     0.7439848  0.7106593  0.6450758  0.08993745
  14                  630     0.7432459  0.7107143  0.6459091  0.09264584
  14                  720     0.7435490  0.7135165  0.6478030  0.09342997
  14                  810     0.7422965  0.7164286  0.6478030  0.09526902
  14                  900     0.7434578  0.7149451  0.6405303  0.09679052
  14                  990     0.7432696  0.7143407  0.6422727  0.09781483
  14                 1080     0.7418902  0.7109341  0.6378030  0.09740331
  14                 1170     0.7426440  0.7130769  0.6342424  0.09765771
  14                 1260     0.7419200  0.7137363  0.6396212  0.09715248
  14                 1350     0.7421287  0.7159890  0.6325758  0.09736122
  14                 1440     0.7411355  0.7137363  0.6352273  0.09821020
  14                 1530     0.7417301  0.7138462  0.6359848  0.09747176
  14                 1620     0.7422394  0.7145055  0.6352273  0.09694503
  14                 1710     0.7411986  0.7101648  0.6396970  0.09925906
  14                 1800     0.7406931  0.7006044  0.6541667  0.09774796
  14                 1890     0.7395188  0.6935165  0.6731061  0.09626164
  14                 1980     0.7387055  0.6823626  0.6849242  0.09596679
  14                 2070     0.7405393  0.6678022  0.7029545  0.09667243
  14                 2160     0.7399505  0.6605495  0.7183333  0.09700981
  14                 2250     0.7408392  0.6540659  0.7263636  0.09568891
  14                 2340     0.7403721  0.6475275  0.7361364  0.09446705
  14                 2430     0.7387800  0.6395055  0.7424242  0.09759880
  14                 2520     0.7390799  0.6283516  0.7468939  0.09509419
  14                 2610     0.7370573  0.6226374  0.7523485  0.09940125
  14                 2700     0.7365262  0.6168132  0.7550000  0.09915044
  Sens SD    Spec SD  
  0.1180699  0.1281462
  0.1041780  0.1433259
  0.1195394  0.1349787
  0.1177903  0.1282067
  0.1204894  0.1263868
  0.1203930  0.1299235
  0.1122099  0.1321422
  0.1155788  0.1258563
  0.1172476  0.1322681
  0.1101769  0.1333461
  0.1139249  0.1393443
  0.1148091  0.1330144
  0.1129404  0.1271999
  0.1113990  0.1379964
  0.1103885  0.1338471
  0.1131783  0.1312932
  0.1157426  0.1380468
  0.1154865  0.1361792
  0.1138093  0.1399119
  0.1171148  0.1397104
  0.1154150  0.1365337
  0.1140854  0.1335652
  0.1143489  0.1479072
  0.1138591  0.1430906
  0.1123102  0.1443853
  0.1207232  0.1422426
  0.1180532  0.1498778
  0.1159877  0.1507099
  0.1199436  0.1485222
  0.1177829  0.1481837
  0.1154884  0.1372722
  0.1118989  0.1439938
  0.1130327  0.1409176
  0.1198871  0.1417892
  0.1140555  0.1391716
  0.1140976  0.1309479
  0.1171781  0.1304833
  0.1152670  0.1324231
  0.1193045  0.1343010
  0.1199479  0.1332823
  0.1233377  0.1380813
  0.1212114  0.1372522
  0.1172150  0.1394245
  0.1217877  0.1368316
  0.1204310  0.1327817
  0.1243669  0.1387129
  0.1192988  0.1318743
  0.1192611  0.1311911
  0.1230577  0.1280648
  0.1245433  0.1252270
  0.1222527  0.1239007
  0.1209263  0.1228185
  0.1203746  0.1231776
  0.1235603  0.1230038
  0.1210277  0.1252081
  0.1226631  0.1230258
  0.1215857  0.1243053
  0.1222551  0.1229741
  0.1227662  0.1226513
  0.1306195  0.1179899

Tuning parameter 'shrinkage' was held constant at a value of 0.2

Tuning parameter 'n.minobsinnode' was held constant at a value of 10
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 90, interaction.depth =
 1, shrinkage = 0.2 and n.minobsinnode = 10. 
> 
> ## The acid test is dissapointing, but I've seen worse.
> 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
  Accuracy      Kappa 
 0.4305556 -0.1424149 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     18   19
    Weak       22   13
                                          
               Accuracy : 0.4306          
                 95% CI : (0.3143, 0.5527)
    No Information Rate : 0.5556          
    P-Value [Acc > NIR] : 0.9876          
                                          
                  Kappa : -0.1424         
 Mcnemar's Test P-Value : 0.7548          
                                          
            Sensitivity : 0.4062          
            Specificity : 0.4500          
         Pos Pred Value : 0.3714          
         Neg Pred Value : 0.4865          
             Prevalence : 0.4444          
         Detection Rate : 0.1806          
   Detection Prevalence : 0.4861          
      Balanced Accuracy : 0.4281          
                                          
       'Positive' Class : Weak            
                                          
> 
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
 Accuracy     Kappa 
0.8185484 0.6327498 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    115   23
    Weak       22   88
                                          
               Accuracy : 0.8185          
                 95% CI : (0.7648, 0.8645)
    No Information Rate : 0.5524          
    P-Value [Acc > NIR] : <2e-16          
                                          
                  Kappa : 0.6327          
 Mcnemar's Test P-Value : 1               
                                          
            Sensitivity : 0.7928          
            Specificity : 0.8394          
         Pos Pred Value : 0.8000          
         Neg Pred Value : 0.8333          
             Prevalence : 0.4476          
         Detection Rate : 0.3548          
   Detection Prevalence : 0.4435          
      Balanced Accuracy : 0.8161          
                                          
       'Positive' Class : Weak            
                                          
> gbmGrid <- expand.grid(interaction.depth = 
+                            c(length(colnames(trainDescr))-1, 1),
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.2,
+                         n.minobsinnode = 10)
> set.seed(seed.mine)
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "Kappa",
+                  verbose = FALSE)
Warning message:
In train.default(trainDescr, trainClass, method = "gbm", trControl = fitControl,  :
  The metric "Kappa" was not in the result set. ROC will be used instead.
> gbmFit1
Stochastic Gradient Boosting 

248 samples
 18 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 222, 223, 223, 224, 223, 223, ... 

Resampling results across tuning parameters:

  interaction.depth  n.trees  ROC        Sens       Spec       ROC SD    
   1                   90     0.7894635  0.7314286  0.7121212  0.08105550
   1                  180     0.7749313  0.7277473  0.6976515  0.08640145
   1                  270     0.7703875  0.7197253  0.7042424  0.09515936
   1                  360     0.7688212  0.7205495  0.7060606  0.08806458
   1                  450     0.7714186  0.7109890  0.6850000  0.08327925
   1                  540     0.7653830  0.7087912  0.6841667  0.08772077
   1                  630     0.7672502  0.7152747  0.6796212  0.08564338
   1                  720     0.7650158  0.7065934  0.6797727  0.08756604
   1                  810     0.7636951  0.7095055  0.6868939  0.09013013
   1                  900     0.7624247  0.7036813  0.6832576  0.09174672
   1                  990     0.7625708  0.7095604  0.6759848  0.08911368
   1                 1080     0.7618498  0.7143956  0.6759848  0.09084825
   1                 1170     0.7613815  0.7143956  0.6779545  0.08847332
   1                 1260     0.7622157  0.7112637  0.6770455  0.08985483
   1                 1350     0.7605386  0.7135714  0.6796970  0.09038049
   1                 1440     0.7589785  0.7078022  0.6797727  0.08990726
   1                 1530     0.7600591  0.7070879  0.6781061  0.09344769
   1                 1620     0.7600749  0.7107143  0.6789394  0.09052070
   1                 1710     0.7584058  0.7158242  0.6744697  0.09049725
   1                 1800     0.7588686  0.7150000  0.6716667  0.09500065
   1                 1890     0.7597028  0.7115385  0.6689394  0.09136706
   1                 1980     0.7580990  0.7136264  0.6697727  0.08885073
   1                 2070     0.7572898  0.7121429  0.6653030  0.08787002
   1                 2160     0.7559848  0.7173077  0.6725000  0.09342791
   1                 2250     0.7551811  0.7130220  0.6679545  0.09293237
   1                 2340     0.7583970  0.7186813  0.6688636  0.09117576
   1                 2430     0.7555186  0.7163736  0.6616667  0.09191981
   1                 2520     0.7550495  0.7164286  0.6653788  0.09147775
   1                 2610     0.7564365  0.7192857  0.6734848  0.08796164
   1                 2700     0.7561901  0.7178571  0.6761364  0.08822951
  17                   90     0.7476748  0.7190110  0.6568182  0.09973469
  17                  180     0.7471699  0.7253846  0.6568182  0.09325633
  17                  270     0.7425092  0.7181868  0.6460606  0.09319088
  17                  360     0.7446112  0.7224176  0.6459848  0.10091963
  17                  450     0.7462021  0.7237912  0.6486364  0.09538754
  17                  540     0.7430715  0.7298901  0.6361364  0.09454836
  17                  630     0.7442761  0.7231868  0.6479545  0.09842475
  17                  720     0.7436447  0.7288462  0.6442424  0.09864044
  17                  810     0.7440385  0.7254396  0.6478788  0.09569313
  17                  900     0.7423489  0.7226374  0.6488636  0.09684194
  17                  990     0.7438703  0.7241209  0.6487121  0.09364834
  17                 1080     0.7439007  0.7197253  0.6469697  0.09425154
  17                 1170     0.7452762  0.7211538  0.6487879  0.09464422
  17                 1260     0.7439908  0.7211538  0.6441667  0.09679524
  17                 1350     0.7433716  0.7197253  0.6459091  0.09713239
  17                 1440     0.7434351  0.7196154  0.6504545  0.09644887
  17                 1530     0.7435623  0.7197253  0.6468939  0.09608614
  17                 1620     0.7433525  0.7197253  0.6450758  0.09608758
  17                 1710     0.7423183  0.7191758  0.6522727  0.09674891
  17                 1800     0.7419299  0.7096154  0.6660606  0.09598941
  17                 1890     0.7428626  0.7015385  0.6830303  0.09584332
  17                 1980     0.7416067  0.6878022  0.7037879  0.09588890
  17                 2070     0.7418407  0.6747802  0.7127273  0.09457272
  17                 2160     0.7415805  0.6667033  0.7217424  0.09415442
  17                 2250     0.7417924  0.6598901  0.7317424  0.09209962
  17                 2340     0.7423083  0.6474725  0.7396970  0.09304735
  17                 2430     0.7381870  0.6446154  0.7433333  0.09905309
  17                 2520     0.7373087  0.6293956  0.7462121  0.09985087
  17                 2610     0.7380563  0.6207143  0.7541667  0.09981833
  17                 2700     0.7393363  0.6120879  0.7586364  0.09911485
  Sens SD     Spec SD  
  0.12527765  0.1243379
  0.11256695  0.1326357
  0.12155708  0.1378180
  0.11763687  0.1324341
  0.11668419  0.1285116
  0.11961620  0.1326034
  0.11950240  0.1270239
  0.11190025  0.1367154
  0.11555404  0.1254845
  0.11752855  0.1272446
  0.11335427  0.1353132
  0.11149888  0.1347680
  0.11387754  0.1336867
  0.11181676  0.1371591
  0.11066343  0.1360448
  0.10855943  0.1381244
  0.11331841  0.1463914
  0.11731851  0.1353086
  0.11257428  0.1383450
  0.11432833  0.1334120
  0.11556947  0.1364678
  0.10985481  0.1354812
  0.10580685  0.1397041
  0.10229132  0.1366306
  0.10579521  0.1359210
  0.09878078  0.1298315
  0.11161588  0.1330901
  0.10775734  0.1327098
  0.11142533  0.1368241
  0.11353263  0.1299212
  0.11217793  0.1426244
  0.11291210  0.1355171
  0.11561377  0.1380498
  0.11377708  0.1337966
  0.12002558  0.1343540
  0.11826949  0.1357349
  0.12072205  0.1315930
  0.12212742  0.1222689
  0.12089036  0.1253525
  0.11943373  0.1305532
  0.12065513  0.1279395
  0.11769771  0.1303294
  0.11819897  0.1255975
  0.11776215  0.1279749
  0.11644742  0.1225658
  0.11489453  0.1278006
  0.11651811  0.1273457
  0.11473527  0.1261679
  0.11752243  0.1203939
  0.12166711  0.1211436
  0.11690059  0.1221066
  0.11855190  0.1159793
  0.11840085  0.1136781
  0.11844083  0.1169815
  0.12097621  0.1142702
  0.12118328  0.1184131
  0.12343260  0.1248464
  0.12537521  0.1260397
  0.12516118  0.1256292
  0.12427740  0.1259961

Tuning parameter 'shrinkage' was held constant at a value of 0.2

Tuning parameter 'n.minobsinnode' was held constant at a value of 10
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 90, interaction.depth =
 1, shrinkage = 0.2 and n.minobsinnode = 10. 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
  Accuracy      Kappa 
 0.4305556 -0.1424149 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     18   19
    Weak       22   13
                                          
               Accuracy : 0.4306          
                 95% CI : (0.3143, 0.5527)
    No Information Rate : 0.5556          
    P-Value [Acc > NIR] : 0.9876          
                                          
                  Kappa : -0.1424         
 Mcnemar's Test P-Value : 0.7548          
                                          
            Sensitivity : 0.4062          
            Specificity : 0.4500          
         Pos Pred Value : 0.3714          
         Neg Pred Value : 0.4865          
             Prevalence : 0.4444          
         Detection Rate : 0.1806          
   Detection Prevalence : 0.4861          
      Balanced Accuracy : 0.4281          
                                          
       'Positive' Class : Weak            
                                          
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
 Accuracy     Kappa 
0.8185484 0.6327498 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    115   23
    Weak       22   88
                                          
               Accuracy : 0.8185          
                 95% CI : (0.7648, 0.8645)
    No Information Rate : 0.5524          
    P-Value [Acc > NIR] : <2e-16          
                                          
                  Kappa : 0.6327          
 Mcnemar's Test P-Value : 1               
                                          
            Sensitivity : 0.7928          
            Specificity : 0.8394          
         Pos Pred Value : 0.8000          
         Neg Pred Value : 0.8333          
             Prevalence : 0.4476          
         Detection Rate : 0.3548          
   Detection Prevalence : 0.4435          
      Balanced Accuracy : 0.8161          
                                          
       'Positive' Class : Weak            
                                          
> ?update.train
> quit()
Save workspace image? [y/n/c]: y

Process R finished at Sat May  7 05:37:02 2016


R version 3.2.5 (2016-04-14) -- "Very, Very Secure Dishes"
Copyright (C) 2016 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> options(STERM='iESS', str.dendrogram.last="'", editor='emacsclient', show.error.locations=TRUE)
> 
+ . + + . + + . + 
> ### weaves
> 
> ## Processing for flights data.
> 
> ## Following the caret vignette.
> 
> ###################################################
> ### code chunk number 1: loadLibs
> ###################################################
> library(MASS)

> library(caret)
Loading required package: lattice
Loading required package: ggplot2

> library(mlbench)

> library(pROC)
Type 'citation("pROC")' for a citation.

Attaching package: 'pROC'

The following objects are masked from 'package:stats':

    cov, smooth, var


> library(pls)

Attaching package: 'pls'

The following object is masked from 'package:caret':

    R2

The following object is masked from 'package:stats':

    loadings


> library(doMC)
Loading required package: foreach
foreach: simple, scalable parallel programming from Revolution Analytics
Use Revolution R for scalability, fault tolerance and more.
http://www.revolutionanalytics.com
Loading required package: iterators
Loading required package: parallel

> registerDoMC(cores = 4)

> options(useFancyQuotes = FALSE) 

> # Accounting info.
> getInfo <- function(what = "Suggests")
+ {
+   text <- packageDescription("caret")[what][[1]]
+   text <- gsub("\n", ", ", text, fixed = TRUE)
+   text <- gsub(">=", "$\\\\ge$", text, fixed = TRUE)
+   eachPkg <- strsplit(text, ", ", fixed = TRUE)[[1]]
+   eachPkg <- gsub(",", .... [TRUNCATED] 

> ### project-specific: begin
> ## Set-seed, load original CSV file, order it
> ## and do some simple-cleaning
> ## Various datasets 
> 
> seed.mine = 107

> set.seed(seed.mine)                     # helpful for testing

> flight <- read.csv("../bak/flight.csv")

> flight <- flight[order(flight$D00),]

> # Backup
> flight.raw <- flight

> # To check adjustment, there is test code in flight-nb.R
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"

> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"

> # And some deletions
> 
> t.cols <- colnames(flight)

> t.drops <- t.cols[grep("^RANK*", t.cols)]

> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])

> t.drops <- c(t.drops, "D80THPCTL")

> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]

> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR

> flight$xHNGR <- flight$xDURN < 0

> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+  .... [TRUNCATED] 

> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))

> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE

> t.cols <- colnames(flight)

> t.drops <- c("SARRHR", "xDURN")

> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]

> ## Backup
> 
> flight00 <- flight

> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]

> paste("samples in use: ", dim(flight)[1])
[1] "samples in use:  320"

> ## Data insights
> 
> ## *Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> flight <- flight1

> ### Numeric variables
> 
> ### Try and impute the AVG, it might have more information than the
> ### bucket.
> 
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))
Error in `$<-.data.frame`(`*tmp*`, "xAVAILBUCKET", value = numeric(0)) (from flight0.R!504903A#117) : 
  replacement has 0 rows, data has 320
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))
Error in `$<-.data.frame`(`*tmp*`, "xAVAILBUCKET", value = numeric(0)) : 
  replacement has 0 rows, data has 320
> flight
     SDEPHR SKDDEPSTA SKDARRSTA SKDEQP SKDEPS       D00    AVGSQ AVGLOFATC
2        14       CCC       PPP    734     32 0.2500000 3.258065  3.258065
5        11       DTW       PPP    E90     72 0.2916667 2.986111  3.805556
7        14       CCC       LGA    321     88 0.3295455 2.551724  3.701149
13       13       PPP       ORD    734     32 0.3750000 3.000000  3.903226
14       16       CCC       BOS    321     72 0.3750000 3.295775  3.859155
17       15       DDD       CCC    19W     84 0.3809524 3.939759  3.361446
18       17       BOS       CCC    19W     63 0.3809524 4.213115  4.196721
20       17       TPA       CCC    734     90 0.3888889 4.388889  3.255556
33       16       ORD       PPP    734     32 0.4062500 4.000000  3.903226
34       22       CCC       EWR    321     64 0.4062500 5.111111  3.746032
36       19       BWI       CCC    734     65 0.4153846 5.174603  3.412698
37       13       DFW       PPP    19W     31 0.4193548 2.870968  3.548387
43        9       PPP       DTW    E90     72 0.4305556 1.986111  3.805556
44        9       CCC       MCO    321     44 0.4318182 1.886364  3.181818
45       16       CCC       ORD    321     67 0.4328358 3.348485  3.954545
46       17       FLL       CCC    734     90 0.4333333 4.449438  3.303371
57       20       CCC       BOS    321     83 0.4457831 4.358025  3.382716
63       14       CCC       RSW    734     46 0.4565217 3.326087  3.108696
68       17       DFW       CCC    734     39 0.4615385 4.025641  3.615385
71       19       CCC       ROC    319     84 0.4642857 5.321429  3.595238
74       16       BOS       XHP    A05     62 0.4677419 3.816667  3.716667
76       16       MSY       CCC    734     64 0.4687500 4.656250  3.109375
81       14       CCC       DFW    734     51 0.4705882 3.156863  3.254902
82       18       CCC       LAX    320     34 0.4705882 4.588235  3.294118
83       19       FLL       CCC    321     55 0.4727273 4.600000  4.054545
84       22       CCC       PPP    734     59 0.4745763 5.881356  3.508475
86       20       CCC       EWR    321     69 0.4782609 4.731343  3.910448
87       22       PPP       BOS    E90     69 0.4782609 5.925373  4.208955
88       14       CCC       EWR    321     73 0.4794521 3.194444  4.027778
99       14       CCC       PPP    321     37 0.4864865 3.540541  3.405405
103      18       CCC       SFO    321     49 0.4897959 3.918367  3.265306
108      18       CCC       ORD    321     75 0.4933333 4.351351  3.216216
114      13       DFW       CCC    321     82 0.5000000 3.085366  3.243902
117      19       PBI       CCC    734     40 0.5000000 4.700000  3.175000
123      22       CCC       TPA    321     60 0.5000000 4.600000  3.416667
133      15       TPA       CCC    320     39 0.5128205 4.179487  3.358974
134      17       CCC       JAX    734     35 0.5142857 4.500000  3.411765
140      19       BDL       CCC    734     33 0.5151515 4.875000  3.343750
143      20       CCC       BDL    321     89 0.5168539 4.218391  3.321839
144      18       CCC       LAX    321     56 0.5178571 4.017857  3.250000
147      15       DFW       PPP    320     48 0.5208333 3.000000  3.854167
150      14       MIA       CCC    734     86 0.5232558 2.953488  3.267442
155      11       SRQ       CCC    19W     36 0.5277778 2.971429  3.714286
165      18       PPP       BOS    E90     64 0.5312500 4.200000  3.716667
170      14       CCC       FLL    734     90 0.5333333 3.483146  3.303371
171      19       MIA       CCC    734     75 0.5333333 4.773333  3.946667
172      16       CCC       FLL    321     56 0.5357143 3.607143  4.053571
184      18       TPA       DDD    319     33 0.5454545 4.969697  3.303030
186      22       CCC       MIA    734     33 0.5454545 5.424242  3.333333
188      14       CCC       PIT    319     53 0.5471698 3.849057  3.264151
189      16       CCC       RSW    734     53 0.5471698 3.792453  3.169811
196      22       CCC       BDL    734     78 0.5512821 5.697368  3.302632
197      16       JFK       XHP    A21     56 0.5535714 3.000000  3.518519
199      22       CCC       LGA    319     65 0.5538462 5.937500  3.765625
202      17       LGA       CCC    321     88 0.5568182 3.558140  3.732558
205      14       CCC       BDL    734     77 0.5584416 3.460526  3.157895
208      13       ORD       PPP    320     68 0.5588235 3.015152  3.530303
213      16       RDU       CCC    734     41 0.5609756 4.609756  3.634146
214      19       CCC       MIA    734     41 0.5609756 5.400000  3.275000
215      19       CCC       CLE    19W     41 0.5609756 5.146341  3.219512
217      10       TPA       CCC    734     80 0.5625000 2.725000  3.450000
218      11       RDU       CCC    320     48 0.5625000 2.937500  3.500000
223      11       TPA       CCC    321     39 0.5641026 2.026316  3.473684
227      13       CCC       PPP    19W     60 0.5666667 3.516667  4.083333
228      16       CCC       JAX    19W     60 0.5666667 3.883333  3.216667
229      17       JAX       CCC    19W     60 0.5666667 4.883333  3.216667
232      16       CCC       MIA    734     88 0.5681818 3.738636  3.693182
233      17       CCC       BWI    734     65 0.5692308 4.174603  3.412698
234      17       ATT       PPP    E90     72 0.5694444 4.722222  4.013889
238      17       BNA       CCC    19W     61 0.5737705 5.366667  4.333333
242      18       CCC       DFW    321     66 0.5757576 3.893939  3.151515
249      19       MCO       CCC    321     76 0.5789474 4.526316  3.552632
250      17       MCO       CCC    321     88 0.5795455 4.181818  3.465909
256      22       CCC       FLL    321     43 0.5813953 4.837209  3.581395
260      18       CCC       STL    19W     84 0.5833333 5.144578  4.048193
262       9       ORD       CCC    A05     89 0.5842697 1.976744  3.813953
266      17       RSW       CCC    734     46 0.5869565 4.326087  3.108696
267      14       CCC       BOS    19W     63 0.5873016 3.131148  3.983607
274      19       CCC       DDD    19W     68 0.5882353 5.441176  3.411765
276      22       CCC       ORD    321     78 0.5897436 5.168831  4.038961
279      12       MCO       CCC    321     44 0.5909091 2.790698  3.325581
281      20       CCC       ORD    321     86 0.5930233 4.905882  4.188235
283      16       CCC       MCI    319     64 0.5937500 4.177419  4.258065
285      22       LAX       CCC    A21     79 0.5949367 4.620253  3.113924
286      13       CCC       BOS    A05     89 0.5955056 2.872093  3.755814
290      20       CCC       PIT    19W     52 0.5961538 5.576923  3.288462
295       9       CCC       JFK    319     77 0.5974026 1.986842  3.960526
296      11       CCC       DFW    321     82 0.5975610 2.085366  3.243902
300      12       BWI       CCC    734     45 0.6000000 2.977273  3.590909
303      15       IAH       CCC    320     30 0.6000000 4.433333  4.000000
310      20       CCC       IAH    320     53 0.6037736 4.415094  3.150943
311      17       CCC       DDD    19W     48 0.6041667 4.270833  4.104167
317      22       CCC       MCO    321     33 0.6060606 4.909091  3.515152
318      16       CCC       BNA    19W     61 0.6065574 4.366667  4.333333
326      13       CCC       JFK    A21     90 0.6111111 2.000000  3.454545
327      14       CCC       TPA    734     90 0.6111111 3.355556  3.244444
337      20       CCC       PVD    734     83 0.6144578 5.345679  3.172840
338      18       PPP       PIT    E90     78 0.6153846 4.371795  3.397436
343      11       CCC       DDD    319     68 0.6176471 2.029851  3.910448
351      16       PVD       CCC    319     74 0.6216216 4.694444  3.486111
352      20       CCC       FLL    321     37 0.6216216 4.540541  3.243243
354      10       DFW       CCC    321     61 0.6229508 2.180328  4.229508
356      22       CCC       JAX    734     61 0.6229508 5.950820  3.393443
357       9       PPP       BOS    E90     64 0.6250000 1.952381  4.063492
359      11       PBI       DDD    19W     32 0.6250000 3.000000  3.161290
362      14       CCC       MCO    321     88 0.6250000 3.250000  3.488636
363      16       BOS       PPP    E90     64 0.6250000 3.542373  3.711864
364      18       PBI       DDD    319     32 0.6250000 5.062500  3.625000
365      18       MCI       CCC    319     64 0.6250000 5.177419  4.258065
369      14       BOS       CCC    321     67 0.6268657 2.984615  3.846154
370      17       ORD       CCC    321     51 0.6274510 4.260000  4.220000
377      16       STL       CCC    319     38 0.6315789 4.918919  3.162162
382      20       BOS       PPP    E90     49 0.6326531 5.333333  4.111111
390      17       MCO       CCC    734     71 0.6338028 4.666667  3.130435
395       7       CCC       ORD    A05     85 0.6352941 1.012048  3.843373
400      15       DDD       TPA    319     33 0.6363636 3.969697  3.303030
401      15       MCI       CCC    19W     33 0.6363636 4.322581  3.258065
402      17       BDL       CCC    734     77 0.6363636 4.460526  3.157895
404      17       PPP       DDD    19W     77 0.6363636 4.131579  3.986842
405      17       IAH       PPP    E90     77 0.6363636 4.697368  3.473684
406      17       RDU       PPP    E90     69 0.6376812 4.632353  3.764706
408      14       PPP       ATT    E90     72 0.6388889 3.722222  4.013889
411       0       XHP       CCC    321     50 0.6400000 1.000000  3.640000
413      16       CCC       SYR    19W     64 0.6406250 4.375000  3.750000
418      22       CCC       PBI    734     78 0.6410256 5.589744  3.487179
419      14       CCC       RDU    734     42 0.6428571 3.595238  3.619048
427       6       JFK       CCC    19W     87 0.6436782 1.000000  3.710843
429      22       CCC       PIT    321     59 0.6440678 4.762712  3.610169
434      11       PPP       DFW    320     48 0.6458333 2.000000  3.854167
435      20       CCC       DFW    734     48 0.6458333 5.520833  3.270833
436      21       PPP       BOS    19W     48 0.6458333 4.787234  3.510638
438      10       PPP       CCC    320     51 0.6470588 1.980392  3.294118
440      11       CCC       BOS    321     68 0.6470588 1.984848  3.848485
445      16       CCC       MCO    321     88 0.6477273 3.545455  3.454545
446      12       PIT       CCC    734     37 0.6486486 2.972973  3.756757
447      16       CCC       RSW    321     37 0.6486486 3.891892  4.108108
448      18       PPP       DFW    19W     37 0.6486486 3.864865  3.189189
450      22       CCC       BUF    734     77 0.6493506 5.842105  3.421053
458      19       DDD       TPA    19W     46 0.6521739 5.173913  4.260870
459      15       DDD       PPP    19W     75 0.6533333 3.890411  4.109589
463      13       CCC       MIA    734     81 0.6543210 2.654321  3.370370
466       8       DDD       PBI    19W     32 0.6562500 2.000000  3.161290
467      17       MSP       CCC    319     32 0.6562500 4.687500  3.281250
482      20       PPP       ORD    320     50 0.6600000 4.224490  3.122449
488      11       PPP       ORD    320     68 0.6617647 2.015152  3.530303
489      13       DDD       CCC    319     68 0.6617647 3.298507  4.283582
495       9       CCC       RDU    320     48 0.6666667 1.937500  3.500000
497      10       CCC       LGA    321     90 0.6666667 1.640449  4.191011
498      10       MIA       CCC    734     69 0.6666667 1.637681  3.637681
501      11       CCC       LGA    321     90 0.6666667 2.011236  3.865169
503      12       JFK       CCC    319     72 0.6666667 2.985915  3.957746
504      12       NAS       CCC    734     84 0.6666667 2.940476  3.214286
505      13       CCC       TPA    320     39 0.6666667 3.179487  3.358974
518      16       MIA       PPP    734     82 0.6707317 3.670732  3.390244
519      17       DDD       CCC    319     76 0.6710526 4.333333  3.800000
520      12       BOS       CCC    321     70 0.6714286 2.955224  4.119403
522      20       CCC       PBI    734     67 0.6716418 5.378788  3.181818
531      11       ORF       CCC    319     49 0.6734694 3.042553  4.085106
532      18       PPP       IAH    E90     49 0.6734694 4.326531  3.204082
535      11       DFW       PPP    19W     46 0.6739130 2.021739  4.043478
544      12       PVD       CCC    734     40 0.6750000 2.925000  3.500000
545      20       PPP       TPA    734     77 0.6753247 4.960526  3.460526
553      20       PPP       BDL    19W     68 0.6764706 4.537313  3.298507
561      11       MIA       CCC    734     84 0.6785714 2.011905  3.916667
562      14       MIA       PPP    734     84 0.6785714 3.000000  3.228916
564      19       RSW       CCC    734     53 0.6792453 4.792453  3.169811
568      20       PPP       PVD    E90     72 0.6805556 5.549296  4.042254
584      13       LAX       CCC    321     73 0.6849315 2.972222  3.750000
590       9       PPP       DFW    19W     32 0.6875000 1.875000  3.531250
592      17       DTW       CCC    19W     64 0.6875000 4.921875  3.578125
593      12       DFW       CCC    321     61 0.6885246 2.918033  3.573770
596      12       DDD       CCC    319     45 0.6888889 2.840909  4.159091
597      18       CCC       SEA    321     45 0.6888889 3.711111  3.111111
598      18       PPP       SAT    E90     90 0.6888889 4.333333  3.244444
610       9       CCC       ORF    319     49 0.6938776 2.041667  4.041667
614      12       BWI       CCC    321     36 0.6944444 2.944444  3.861111
615      18       PPP       RDU    E90     72 0.6944444 4.416667  3.194444
628      19       CCC       ORF    319     86 0.6976744 5.302326  3.418605
629      22       CCC       DDD    19W     63 0.6984127 5.709677  3.387097
638       7       PPP       MIA    734     84 0.7023810 1.011905  3.916667
639       9       PPP       MIA    734     84 0.7023810 2.000000  3.202381
644      10       MCO       CCC    321     88 0.7045455 2.494253  3.275862
647       9       CCC       DFW    321     61 0.7049180 1.918033  3.573770
653      18       BWI       PPP    319     51 0.7058824 5.120000  3.320000
655      22       CCC       PVD    734     65 0.7076923 5.859375  3.453125
657      20       CCC       ATT    321     89 0.7078652 4.584270  3.662921
662      11       CCC       MIA    734     86 0.7093023 1.953488  3.267442
664      12       DFW       PPP    319     31 0.7096774 2.935484  3.774194
668      13       JAX       CCC    319     76 0.7105263 3.605263  3.723684
677      10       EWR       CCC    320     35 0.7142857 2.205882  4.235294
687      15       EWR       CCC    321     81 0.7160494 2.974359  3.474359
688      14       CCC       PVD    319     74 0.7162162 3.694444  3.486111
692      15       PIT       CCC    734     60 0.7166667 4.237288  3.288136
697       9       CCC       LAX    321     78 0.7179487 1.974359  3.602564
702       9       PPP       DFW    319     32 0.7187500 1.937500  3.781250
703      14       CCC       MSP    319     32 0.7187500 3.687500  3.281250
706      22       CCC       DTW    321     32 0.7187500 4.937500  3.531250
717      22       CCC       RSW    321     43 0.7209302 4.395349  3.162791
721      15       MCI       CCC    320     36 0.7222222 4.305556  3.111111
724      20       CCC       BUF    734     90 0.7222222 5.222222  3.188889
729      15       PPP       RDU    E90     69 0.7246377 3.623188  3.782609
735       7       CCC       MCO    321     84 0.7261905 1.583333  3.273810
737      16       ORD       PPP    19W     33 0.7272727 3.242424  3.727273
744      22       CCC       MSP    320     33 0.7272727 5.424242  3.787879
745      11       CCC       EWR    321     81 0.7283951 1.974359  3.474359
747      13       PPP       CCC    320     59 0.7288136 2.355932  3.406780
750       7       CCC       PPP    320     48 0.7291667 1.416667  3.229167
751      13       CCC       JAX    319     48 0.7291667 3.020833  3.770833
758      14       ATT       PPP    E90     52 0.7307692 3.115385  3.230769
766      13       CCC       IAH    320     30 0.7333333 3.433333  4.000000
767      13       CCC       PIT    734     60 0.7333333 3.237288  3.288136
768      13       CCC       BWI    320     60 0.7333333 3.533333  3.966667
772      19       DDD       TPA    19W     30 0.7333333 5.100000  3.866667
773      20       PPP       CCC    319     64 0.7343750 5.171875  3.437500
780      20       PPP       RDU    E90     72 0.7361111 5.585714  3.800000
781      14       CCC       STL    319     38 0.7368421 3.918919  3.162162
787      18       CCC       SAT    319     77 0.7402597 5.012987  3.480519
800      16       CCC       BWI    319     51 0.7450980 4.117647  3.294118
809      10       LGA       CCC    319     76 0.7500000 2.108108  4.270270
812      14       PPP       BOS    E90     64 0.7500000 2.610169  3.661017
813      15       BWI       CCC    320     60 0.7500000 4.533333  3.966667
820      20       CCC       MCI    319     76 0.7500000 6.253333  3.853333
822      21       PPP       BWI    19W     72 0.7500000 4.842857  3.885714
831      16       CCC       DDD    320     78 0.7564103 3.435897  3.538462
836       9       PPP       RDU    19W     33 0.7575758 2.000000  3.212121
839      13       CCC       MCI    19W     33 0.7575758 3.322581  3.258065
848       5       BWI       CCC    19W     75 0.7600000 1.000000  3.306667
851       8       BOS       PPP    E90     71 0.7605634 1.750000  4.102941
854      14       PPP       IAH    E90     88 0.7613636 3.602273  3.352273
857       7       PPP       TPA    321     38 0.7631579 1.026316  3.421053
872       6       TPA       CCC    321     81 0.7654321 1.000000  3.493827
873       8       MIA       CCC    734     47 0.7659574 1.000000  3.425532
877      20       PPP       PIT    734     30 0.7666667 4.766667  3.333333
891      11       PPP       BOS    E90     61 0.7704918 2.016949  4.305085
893       8       PPP       MSP    E90     48 0.7708333 1.434783  3.456522
894       9       CCC       BOS    321     70 0.7714286 1.955882  4.073529
895      16       MSP       PPP    E90     70 0.7714286 4.200000  3.828571
900      11       CCC       ORD    321     88 0.7727273 1.952941  3.129412
906      12       LGA       CCC    321     84 0.7738095 2.626506  4.132530
912      13       PPP       MSP    E90     71 0.7746479 3.183099  3.802817
913       6       RSW       CCC    321     80 0.7750000 1.000000  3.550000
918       6       MIA       CCC    734     85 0.7764706 1.000000  3.892857
922       9       CCC       BWI    734     45 0.7777778 1.977273  3.590909
926      17       DDD       TPA    319     77 0.7792208 4.526316  3.368421
942      14       ORD       CCC    321     83 0.7831325 2.924051  3.151899
947       7       BOS       PPP    19W     56 0.7857143 1.017857  3.982143
948      10       MCO       PPP    320     42 0.7857143 2.000000  3.190476
953       8       DFW       PPP    19W     47 0.7872340 1.000000  3.340426
956      11       RDU       PPP    19W     33 0.7878788 3.000000  3.212121
961      21       PPP       MHT    E90     71 0.7887324 5.571429  4.257143
962      22       CCC       ATT    321     71 0.7887324 4.436620  3.323944
975      16       PPP       ATT    E90     77 0.7922078 3.831169  4.363636
977       7       TPA       DDD    19W     87 0.7931034 1.000000  3.129412
980      16       CCC       TPA    320     34 0.7941176 3.441176  3.764706
982       9       CCC       NAS    734     78 0.7948718 1.948718  3.243590
985       7       MHT       PPP    E90     83 0.7951807 1.000000  3.506329
988       6       IND       CCC    319     88 0.7954545 1.125000  3.329545
998       6       PPP       BOS    E90     50 0.8000000 1.021277  4.340426
1001      7       CHS       CCC    19W     30 0.8000000 1.000000  4.166667
1002      7       CCC       MIA    734     40 0.8000000 1.100000  4.050000
1003      7       CCC       EWR    320     35 0.8000000 1.205882  4.235294
1010     20       CCC       RIC    319     65 0.8000000 5.630769  3.215385
1013     11       CCC       JAX    319     76 0.8026316 2.605263  3.723684
1014     11       BOS       PPP    E90     76 0.8026316 2.780822  3.876712
1023      9       CCC       BWI    321     36 0.8055556 1.944444  3.861111
1024      9       CCC       SRQ    19W     36 0.8055556 1.972222  3.666667
1025     13       CCC       MCI    320     36 0.8055556 3.305556  3.111111
1048     14       CCC       DDD    319     58 0.8103448 3.724138  3.810345
1051      7       ORD       CCC    321     90 0.8111111 1.078652  3.112360
1056      5       MCO       CCC    321     32 0.8125000 1.000000  3.375000
1058      7       CCC       TPA    734     48 0.8125000 1.729167  3.333333
1062     19       DDD       MCO    320     48 0.8125000 4.562500  3.520833
1068      8       MIA       CCC    321     43 0.8139535 1.000000  3.790698
1076      7       DFW       CCC    321     88 0.8181818 1.000000  3.795455
1081      6       MIA       PPP    734     83 0.8192771 1.000000  3.337349
1082      6       EWR       CCC    321    156 0.8205128 1.000000  3.847682
1098     22       CCC       RIC    19W     52 0.8269231 5.903846  3.653846
1099     22       CCC       BNA    19W     64 0.8281250 5.843750  3.531250
1104     19       TPA       CCC    320     35 0.8285714 4.457143  3.742857
1105     22       CCC       ILM    734     35 0.8285714 5.823529  3.470588
1106      6       MSY       PPP    E90     82 0.8292683 1.000000  3.237500
1109     11       MSP       PPP    E90     53 0.8301887 2.431373  3.431373
1110      7       ORD       PPP    320     71 0.8309859 1.000000  3.718310
1113      6       PPP       MCO    320     42 0.8333333 1.000000  3.190476
1129     10       CCC       JAX    19W     68 0.8382353 1.955882  3.338235
1136      7       CCC       DFW    321     57 0.8421053 1.263158  4.245614
1143     14       CCC       DTW    19W     64 0.8437500 3.921875  3.578125
1144     19       ATT       PPP    E90     77 0.8441558 4.842105  4.381579
1147     20       CCC       MDT    19W     71 0.8450704 5.802817  3.971831
1149      7       CHS       CCC    319     39 0.8461538 1.000000  3.605263
1152      5       DFW       CCC    734     72 0.8472222 1.000000  3.750000
1153      7       PVD       PPP    E90     72 0.8472222 1.000000  3.647887
1179      6       DFW       PPP    19W     76 0.8552632 1.000000  3.263158
1180      6       LGA       CCC    321     83 0.8554217 1.000000  3.939024
1181      8       DFW       CCC    A21     90 0.8555556 1.000000  3.438202
1182     14       LGA       CCC    321     90 0.8555556 3.011236  3.865169
1196      6       BOS       PPP    19W     51 0.8627451 1.000000  3.520000
1205      9       CCC       PIT    734     37 0.8648649 1.972973  3.756757
1207      6       BOS       CCC    321     89 0.8651685 1.000000  3.425287
1208     11       PPP       ATT    E90     52 0.8653846 2.115385  3.230769
1211      8       ATT       CCC    321     82 0.8658537 1.000000  3.600000
1213      5       PPP       CCC    734     60 0.8666667 1.000000  3.966667
1214      7       PPP       DFW    19W     45 0.8666667 1.044444  4.088889
1226     17       PIT       CCC    319     53 0.8679245 4.849057  3.264151
1242      9       CCC       PVD    734     40 0.8750000 1.925000  3.500000
1245     15       JAX       CCC    319     48 0.8750000 4.020833  3.770833
1257     12       JAX       CCC    19W     68 0.8823529 2.955882  3.338235
1268      6       CCC       PPP    319     72 0.8888889 1.000000  3.746479
1273      7       BOS       PPP    320     74 0.8918919 1.000000  4.397260
1274      9       CLE       CCC    734     37 0.8918919 1.000000  3.111111
1283     22       CCC       ORF    319     58 0.8965517 6.017241  4.206897
1302      7       RIC       CCC    319     42 0.9047619 1.000000  3.857143
1306      7       ORF       CCC    319     85 0.9058824 1.000000  3.130952
1308     13       PPP       ORD    19W     32 0.9062500 2.250000  3.781250
1309      8       CCC       PIT    19W     65 0.9076923 1.969231  4.107692
1311     10       PIT       CCC    19W     66 0.9090909 2.909091  4.090909
1331      6       DDD       CCC    19W     62 0.9193548 1.000000  3.590164
1363      5       ORF       CCC    319     69 0.9420290 1.000000  4.362319
1370      5       RIC       CCC    19W     59 0.9491525 1.000000  3.966102
1387      6       BOS       DDD    320     39 0.9743590 1.000000  4.205128
     UPLINEATCIMP DEPSTAATCIMP DOWNLINEATCIMP DEPBUCKET ARRBUCKET DEPRANKGRP
2             Med         High           High        D5        A6        Low
5            High          Low           High        D4        A5        Med
7          MedLow         High           High        D5        A6        Low
13            Med         High           High        D5        A6     MedLow
14         MedLow         High           High        D6        A7        Low
17            Low         High           High        D6        A6     MedLow
18           High         High           High        D6        A7        Med
20           High          Low           High        D6        A7        Low
33           High         High           High        D6        A7        Med
34            Low         High           High        D8        A8        Low
36           High          Low           High        D7        A8        Low
37           High         High           High        D5        A6        Med
43            Low         High            Low        D4        A4     MedLow
44         MedLow         High            Low        D4        A4        Low
45            Med         High           High        D6        A6        Low
46           High          Low           High        D6        A7     MedLow
57            Med         High           High        D7        A8        Low
63         MedLow         High            Low        D5        A6        Low
68           High         High           High        D6        A7        Med
71         MedLow         High            Low        D7        A8        Low
74           High         High            Low        D6        A7        Med
76           High          Low           High        D6        A7        Low
81         MedLow         High           High        D5        A6        Low
82            Low         High           High        D7        A7        Low
83           High          Low           High        D7        A8     MedLow
84            Low         High           High        D8        A8        Low
86        MedHigh         High           High        D7        A8        Low
87         MedLow         High           High        D8        A8     MedLow
88        MedHigh         High           High        D5        A6        Low
99         MedLow         High           High        D5        A6        Low
103       MedHigh         High            Low        D7        A7        Low
108        MedLow         High           High        D7        A7        Low
114          High         High           High        D5        A6        Med
117          High          Low           High        D7        A8        Low
123           Med         High            Low        D8        A8        Low
133          High          Low           High        D6        A6        Low
134        MedLow         High            Low        D6        A7        Low
140          High          Low           High        D7        A8     MedLow
143           Med         High            Low        D7        A8        Low
144           Med         High           High        D7        A7        Low
147          High         High           High        D6        A7        Med
150          High         High           High        D5        A6     MedLow
155          High          Low           High        D4        A5        Low
165        MedLow         High           High        D7        A7     MedLow
170           Low         High            Low        D5        A6        Low
171          High         High           High        D7        A8     MedLow
172       MedHigh         High            Low        D6        A7        Low
184          High          Low           High        D7        A7        Low
186        MedLow         High           High        D8        A1        Low
188        MedLow         High            Low        D5        A6        Low
189           Low         High            Low        D6        A7        Low
196           Low         High            Low        D8        A8        Low
197          High         High            Low        D6        A7     MedLow
199        MedLow         High           High        D8        A8        Low
202          High         High           High        D6        A7        Med
205           Low         High            Low        D5        A6        Low
208          High         High           High        D5        A6        Med
213          High          Low           High        D6        A6        Med
214           Low         High           High        D7        A8        Low
215           Low         High            Low        D7        A8        Low
217          High          Low           High        D4        A5        Low
218          High          Low           High        D4        A5        Med
223          High          Low           High        D4        A5        Low
227           Med         High           High        D5        A5        Low
228           Low         High            Low        D6        A6        Low
229          High          Low           High        D6        A7    MedHigh
232           Low         High           High        D6        A7        Low
233        MedLow         High            Low        D6        A7        Low
234          High         High           High        D6        A7        Med
238          High          Low           High        D6        A7    MedHigh
242       MedHigh         High           High        D7        A7        Low
249          High          Low           High        D7        A7     MedLow
250          High          Low           High        D6        A7     MedLow
256        MedLow         High            Low        D8        A8        Low
260       MedHigh         High            Low        D7        A7        Low
262          High         High           High        D4        A5        Med
266          High          Low           High        D6        A7     MedLow
267        MedLow         High           High        D5        A6        Low
274           Low         High           High        D7        A8        Low
276       MedHigh         High           High        D8        A8        Low
279          High          Low           High        D5        A5     MedLow
281       MedHigh         High           High        D7        A8        Low
283       MedHigh         High            Low        D6        A6        Low
285           Low         High           High        D8        A3     MedLow
286          High         High           High        D5        A6        Low
290           Low         High            Low        D7        A8        Low
295           Low         High           High        D4        A4        Low
296        MedLow         High           High        D4        A5        Low
300          High          Low           High        D5        A5        Low
303          High          Low           High        D6        A7        Med
310           Low         High            Low        D7        A8        Low
311        MedLow         High           High        D6        A7        Low
317        MedLow         High            Low        D8        A8        Low
318           Med         High            Low        D6        A6        Low
326          High         High           High        D5        A6        Low
327           Med         High            Low        D5        A6        Low
337           Low         High            Low        D7        A8        Low
338       MedHigh         High            Low        D7        A7     MedLow
343           Low         High           High        D4        A5        Low
351          High          Low           High        D6        A7    MedHigh
352           Low         High            Low        D7        A8        Low
354          High         High           High        D4        A5        Med
356           Low         High            Low        D8        A8        Low
357           Low         High           High        D4        A4     MedLow
359          High          Low           High        D4        A5        Low
362           Med         High            Low        D5        A6        Low
363          High         High           High        D6        A7        Med
364          High          Low           High        D7        A7        Low
365          High          Low           High        D7        A8        Med
369          High         High           High        D5        A6        Med
370          High         High           High        D6        A7        Med
377          High          Low           High        D6        A7        Med
382          High         High           High        D7        A8        Med
390          High          Low           High        D6        A7     MedLow
395           Low         High           High        D3        A3        Low
400        MedLow         High            Low        D6        A6     MedLow
401          High          Low           High        D6        A7        Med
402          High          Low           High        D6        A7     MedLow
404           Med         High           High        D6        A7     MedLow
405          High          Low           High        D6        A8        Med
406          High          Low           High        D6        A7        Med
408           Low         High           High        D5        A6     MedLow
411          High          Low           High        D1        A2     MedLow
413        MedLow         High            Low        D6        A7        Low
418        MedLow         High            Low        D8        A8        Low
419           Low         High            Low        D5        A6        Low
427           Low         High           High        D3        A3     MedLow
429           Med         High            Low        D8        A8        Low
434          High         High           High        D4        A5     MedLow
435           Low         High           High        D7        A8        Low
436           Med         High           High        D8        A8     MedLow
438        MedLow         High           High        D4        A5     MedLow
440          High         High           High        D4        A5        Low
445       MedHigh         High            Low        D6        A7        Low
446          High          Low           High        D5        A5    MedHigh
447          High         High            Low        D6        A7        Low
448           Med         High           High        D7        A8     MedLow
450           Low         High            Low        D8        A8        Low
458          High         High            Low        D7        A8     MedLow
459        MedLow         High           High        D6        A6     MedLow
463           Low         High           High        D5        A6        Low
466           Low         High            Low        D3        A4     MedLow
467          High          Low           High        D6        A7        Med
482        MedLow         High           High        D7        A8     MedLow
488           Med         High           High        D4        A5     MedLow
489          High         High           High        D5        A6     MedLow
495           Low         High            Low        D4        A4        Low
497           Med         High           High        D4        A4        Low
498           Med         High           High        D4        A5     MedLow
501          High         High           High        D4        A5        Low
503          High         High           High        D5        A5     MedLow
504          High          Low           High        D5        A6        Low
505           Med         High            Low        D5        A5        Low
518          High         High           High        D6        A7     MedLow
519        MedLow         High           High        D6        A7     MedLow
520          High         High           High        D5        A6        Med
522           Low         High            Low        D7        A8        Low
531          High          Low           High        D4        A5    MedHigh
532        MedLow         High            Low        D7        A8     MedLow
535          High         High           High        D4        A6        Med
544          High          Low           High        D5        A6    MedHigh
545           Med         High            Low        D7        A8     MedLow
553        MedLow         High            Low        D7        A8     MedLow
561          High         High           High        D4        A5     MedLow
562          High         High           High        D5        A6     MedLow
564          High          Low           High        D7        A8     MedLow
568          High         High            Low        D7        A8     MedLow
584          High         High           High        D5        A7     MedLow
590           Med         High           High        D4        A5     MedLow
592          High          Low           High        D6        A7        Med
593          High         High           High        D5        A6        Med
596          High         High           High        D5        A5     MedLow
597       MedHigh         High            Low        D7        A8        Low
598           Med         High            Low        D7        A8     MedLow
610           Low         High            Low        D4        A4        Low
614          High          Low           High        D5        A5        Low
615        MedLow         High            Low        D7        A7     MedLow
628        MedLow         High            Low        D7        A8        Low
629           Low         High           High        D8        A8        Low
638           Low         High           High        D3        A4     MedLow
639        MedLow         High           High        D4        A5     MedLow
644          High          Low           High        D4        A5     MedLow
647           Low         High           High        D4        A4        Low
653          High          Low           High        D7        A7        Low
655           Low         High            Low        D8        A8        Low
657          High         High           High        D7        A8        Low
662           Low         High           High        D4        A5        Low
664          High         High           High        D5        A6        Med
668          High          Low           High        D5        A6    MedHigh
677          High         High           High        D4        A5        Med
687          High         High           High        D6        A6        Med
688        MedLow         High            Low        D5        A6        Low
692          High          Low           High        D6        A6    MedHigh
697          High         High           High        D4        A5        Low
702       MedHigh         High           High        D4        A5     MedLow
703           Med         High            Low        D5        A6        Low
706        MedLow         High            Low        D8        A8        Low
717        MedLow         High            Low        D8        A8        Low
721          High          Low           High        D6        A7        Med
724           Low         High            Low        D7        A8        Low
729           Med         High            Low        D6        A6     MedLow
735        MedLow         High            Low        D3        A4        Low
737          High         High           High        D6        A7        Med
744        MedLow         High            Low        D8        A8        Low
745           Med         High           High        D4        A5        Low
747           Med         High           High        D5        A6     MedLow
750           Low         High           High        D3        A4        Low
751          High         High            Low        D5        A5        Low
758          High         High           High        D5        A6        Med
766          High         High            Low        D5        A5        Low
767           Low         High            Low        D5        A5        Low
768          High         High            Low        D5        A5        Low
772          High         High            Low        D7        A8     MedLow
773        MedLow         High           High        D7        A8     MedLow
780           Low         High            Low        D7        A8     MedLow
781           Low         High            Low        D5        A6        Low
787           Low         High            Low        D7        A7        Low
800           Low         High            Low        D6        A6        Low
809       MedHigh         High           High        D4        A5        Med
812           Low         High           High        D5        A6     MedLow
813          High          Low           High        D6        A6        Low
820           Low         High            Low        D7        A8        Low
822           Med         High            Low        D8        A8     MedLow
831           Med         High           High        D6        A7        Low
836           Low         High            Low        D4        A4     MedLow
839           Med         High            Low        D5        A5        Low
848           Low          Low           High        D2        A3        Low
851       MedHigh         High           High        D3        A4        Med
854       MedHigh         High            Low        D5        A6     MedLow
857           Low         High            Low        D3        A4     MedLow
872           Low          Low           High        D3        A3        Low
873           Low         High           High        D3        A4     MedLow
877       MedHigh         High            Low        D7        A8     MedLow
891           Low         High           High        D4        A5     MedLow
893        MedLow         High            Low        D3        A4     MedLow
894           Low         High           High        D4        A4        Low
895          High          Low           High        D6        A7        Med
900           Low         High           High        D4        A5        Low
906          High         High           High        D5        A5        Med
912       MedHigh         High            Low        D5        A6     MedLow
913           Low          Low           High        D3        A3     MedLow
918           Low         High           High        D3        A3     MedLow
922       MedHigh         High            Low        D4        A4        Low
926       MedHigh         High            Low        D6        A7     MedLow
942          High         High           High        D5        A6        Med
947           Low         High           High        D3        A4        Med
948          High          Low           High        D4        A5     MedLow
953           Low         High           High        D3        A5        Med
956          High          Low           High        D4        A5        Med
961           Low         High            Low        D8        A8     MedLow
962        MedLow         High           High        D8        A8        Low
975       MedHigh         High           High        D6        A7     MedLow
977           Low          Low           High        D3        A4        Low
980          High         High            Low        D6        A7        Low
982        MedLow         High            Low        D4        A5        Low
985           Low          Low           High        D3        A3    MedHigh
988           Low          Low           High        D3        A3    MedHigh
998           Low         High           High        D3        A3     MedLow
1001          Low          Low           High        D3        A3    MedHigh
1002          Low         High           High        D3        A4        Low
1003          Low         High           High        D3        A4        Low
1010          Low         High            Low        D7        A8        Low
1013          Med         High            Low        D4        A5        Low
1014         High         High           High        D4        A5        Med
1023       MedLow         High            Low        D4        A4        Low
1024      MedHigh         High            Low        D4        A4        Low
1025          Med         High            Low        D5        A5        Low
1048          Med         High           High        D5        A6        Low
1051          Low         High           High        D3        A4        Med
1056          Low          Low           High        D2        A3     MedLow
1058       MedLow         High            Low        D3        A4        Low
1062         High         High            Low        D7        A8     MedLow
1068          Low         High           High        D3        A4     MedLow
1076          Low         High           High        D3        A4        Med
1081          Low         High           High        D3        A3     MedLow
1082          Low         High           High        D3        A3        Med
1098       MedLow         High            Low        D8        A8        Low
1099          Low         High            Low        D8        A8        Low
1104         High          Low           High        D7        A7        Low
1105          Low         High            Low        D8        A8        Low
1106          Low          Low           High        D3        A4        Low
1109         High          Low           High        D4        A5        Med
1110          Low         High           High        D3        A4        Med
1113          Low         High            Low        D3        A4     MedLow
1129          Low         High            Low        D4        A4        Low
1136          Low         High           High        D3        A4        Low
1143          Low         High            Low        D5        A6        Low
1144         High         High           High        D7        A8        Med
1147          Low         High            Low        D7        A8        Low
1149          Low          Low           High        D3        A3    MedHigh
1152          Low         High           High        D2        A3        Med
1153          Low          Low           High        D3        A3    MedHigh
1179          Low         High           High        D3        A4        Med
1180          Low         High           High        D3        A3        Med
1181          Low         High           High        D3        A5        Med
1182         High         High           High        D5        A6        Med
1196          Low         High           High        D3        A3        Med
1205      MedHigh         High            Low        D4        A4        Low
1207          Low         High           High        D3        A3        Med
1208          Low         High           High        D4        A5     MedLow
1211          Low         High           High        D3        A4        Med
1213          Low         High           High        D2        A3     MedLow
1214          Low         High           High        D3        A4     MedLow
1226         High          Low           High        D6        A7    MedHigh
1242         High         High            Low        D4        A4        Low
1245         High          Low           High        D6        A6    MedHigh
1257         High          Low           High        D5        A5    MedHigh
1268          Low         High           High        D3        A3        Low
1273          Low         High           High        D3        A3        Med
1274          Low          Low           High        D4        A4       High
1283          Low         High            Low        D8        A8        Low
1302          Low          Low           High        D3        A3    MedHigh
1306          Low          Low           High        D3        A3    MedHigh
1308      MedHigh         High           High        D5        A6     MedLow
1309          Med         High            Low        D3        A4        Low
1311         High          Low           High        D4        A5    MedHigh
1331          Low         High           High        D3        A3     MedLow
1363          Low          Low           High        D2        A3    MedHigh
1370          Low          Low           High        D2        A3    MedHigh
1387          Low         High           High        D3        A3        Med
     TRNRANKGRP ARRRANKGRP LEGTYPE DEPSPOKE ARRSPOKE xDURN2 xAVGSKDAVAIL
2           Low    MedHigh    Weak    FALSE    FALSE      2 -0.635067532
5           Low    MedHigh    Weak     TRUE    FALSE      2 -1.220310866
7           Low        Med    Weak    FALSE     TRUE      2 -0.717640228
13       MedLow     MedLow    Weak    FALSE     TRUE      2 -0.210978159
14          Low    MedHigh    Weak    FALSE     TRUE      2 -0.230546855
17          Med    MedHigh    Weak    FALSE    FALSE      2 -0.653556794
18          Med    MedHigh    Weak     TRUE    FALSE      2 -0.946599414
20          Low    MedHigh    Weak     TRUE    FALSE      1 -1.154577014
33       MedLow    MedHigh    Weak     TRUE    FALSE      3 -0.365770781
34          Low        Med    Weak    FALSE     TRUE      1  0.015909655
36          Low    MedHigh    Weak     TRUE    FALSE      2 -1.190052426
37       MedLow    MedHigh    Weak     TRUE    FALSE      4 -1.042193330
43       MedLow       High    Weak    FALSE     TRUE      1 -1.261275441
44          Low     MedLow    Weak    FALSE     TRUE      2 -0.766434264
45          Low     MedLow    Weak    FALSE     TRUE      1 -0.261607906
46          Low    MedHigh    Weak     TRUE    FALSE      2 -0.755742401
57          Low    MedHigh    Weak    FALSE     TRUE      2  0.037559156
63          Low        Med    Weak    FALSE     TRUE      2 -0.152850258
68       MedLow    MedHigh    Weak     TRUE    FALSE      3 -0.802310982
71          Low        Low    Weak    FALSE     TRUE      2  0.347563251
74          Med       High    Weak     TRUE    FALSE      4 -0.755791640
76          Low    MedHigh    Weak     TRUE    FALSE      3 -1.244961061
81          Low     MedLow    Weak    FALSE     TRUE      2 -0.164373444
82          Low        Med    Weak    FALSE     TRUE      2  0.009298850
83          Low    MedHigh    Weak     TRUE    FALSE      2 -1.001596411
84          Low    MedHigh    Weak    FALSE    FALSE      1  1.051406519
86          Low        Med    Weak    FALSE     TRUE      1 -0.220567643
87       MedLow    MedHigh    Weak    FALSE     TRUE      1 -0.316715666
88          Low        Med    Weak    FALSE     TRUE      2  0.161039096
99          Low    MedHigh    Weak    FALSE    FALSE      2 -0.161462860
103         Low        Med    Weak    FALSE     TRUE      2  0.215101836
108         Low     MedLow    Weak    FALSE     TRUE      1 -0.532770298
114      MedLow    MedHigh    Weak     TRUE    FALSE      4 -1.341357351
117         Low    MedHigh    Weak     TRUE    FALSE      2 -0.927795222
123         Low     MedLow    Weak    FALSE     TRUE      1  0.476718099
133         Low    MedHigh    Weak     TRUE    FALSE      2 -0.974230289
134         Low     MedLow    Weak    FALSE     TRUE      2 -0.487571743
140         Low    MedHigh    Weak     TRUE    FALSE      2 -0.628706192
143         Low     MedLow    Weak    FALSE     TRUE      2 -0.455963741
144         Low        Med    Weak    FALSE     TRUE      2 -0.149788121
147      MedLow    MedHigh    Weak     TRUE    FALSE      4 -0.287711830
150      MedLow    MedHigh    Weak     TRUE    FALSE      2 -0.492652403
155      MedLow    MedHigh    Weak     TRUE    FALSE      2 -1.103868042
165      MedLow    MedHigh    Weak    FALSE     TRUE      1  1.065890250
170         Low        Low    Weak    FALSE     TRUE      2 -0.817783341
171      MedLow    MedHigh    Weak     TRUE    FALSE      2 -0.745274224
172         Low        Low    Weak    FALSE     TRUE      2 -0.296451445
184         Low        Med    Weak     TRUE    FALSE      2 -0.622730387
186         Low     MedLow    Weak    FALSE     TRUE      2  1.893830408
188         Low       High    Weak    FALSE     TRUE      2 -0.359569474
189         Low        Med    Weak    FALSE     TRUE      2  0.036217012
196         Low     MedLow    Weak    FALSE     TRUE      1  0.444658431
197      MedLow       High    Weak     TRUE    FALSE      4  0.055412795
199         Low        Med    Weak    FALSE     TRUE      1  1.327406040
202     MedHigh    MedHigh    Weak     TRUE    FALSE      2 -0.564501033
205         Low     MedLow    Weak    FALSE     TRUE      2 -0.749794868
208      MedLow    MedHigh    Weak     TRUE    FALSE      3 -0.371746585
213      MedLow    MedHigh    Weak     TRUE    FALSE      1 -1.127321514
214         Low     MedLow    Weak    FALSE     TRUE      2 -0.717446893
215         Low       High    Weak    FALSE     TRUE      2  0.777998258
217         Low    MedHigh    Weak     TRUE    FALSE      2 -0.829367426
218      MedLow    MedHigh    Weak     TRUE    FALSE      1 -1.009414756
223         Low    MedHigh    Weak     TRUE    FALSE      2  0.028632336
227         Low    MedHigh    Weak    FALSE    FALSE      1 -0.236569760
228         Low     MedLow    Weak    FALSE     TRUE      1 -0.370227313
229     MedHigh    MedHigh    Weak     TRUE    FALSE      2 -1.189635068
232         Low     MedLow    Weak    FALSE     TRUE      2 -0.313500488
233         Low        Med    Weak    FALSE     TRUE      2  0.620237011
234      MedLow    MedHigh    Weak     TRUE    FALSE      2 -0.824081810
238         Med    MedHigh    Weak     TRUE    FALSE      2 -1.223597559
242         Low     MedLow    Weak    FALSE     TRUE      2  0.834132881
249         Low    MedHigh    Weak     TRUE    FALSE      1 -0.691845287
250         Low    MedHigh    Weak     TRUE    FALSE      1 -0.879689993
256         Low        Low    Weak    FALSE     TRUE      1  0.355772906
260         Low    MedHigh    Weak    FALSE     TRUE      1 -0.104438634
262      MedLow    MedHigh    Weak     TRUE    FALSE      3 -0.799772604
266         Med    MedHigh    Weak     TRUE    FALSE      2 -0.885925615
267         Low    MedHigh    Weak    FALSE     TRUE      2 -0.334575054
274         Low        Med    Weak    FALSE    FALSE      2 -0.077701838
276         Low     MedLow    Weak    FALSE     TRUE      1  0.178881143
279         Low    MedHigh    Weak     TRUE    FALSE      1 -0.211372661
281         Low     MedLow    Weak    FALSE     TRUE      1 -0.174982281
283         Low    MedHigh    Weak    FALSE     TRUE      1 -0.145939535
285      MedLow    MedHigh    Weak     TRUE    FALSE      8  3.266232603
286         Low    MedHigh    Weak    FALSE     TRUE      2 -0.608359999
290         Low       High    Weak    FALSE     TRUE      1  0.975452638
295         Low     MedLow    Weak    FALSE     TRUE      2 -0.461303980
296         Low     MedLow    Weak    FALSE     TRUE      2 -0.499673073
300         Low    MedHigh    Weak     TRUE    FALSE      1 -0.264182099
303         Med    MedHigh    Weak     TRUE    FALSE      4 -0.698822301
310         Low    MedHigh    Weak    FALSE     TRUE      1  0.787672296
311         Low        Med    Weak    FALSE    FALSE      2  0.841341788
317         Low     MedLow    Weak    FALSE     TRUE      1  0.303519357
318         Low    MedHigh    Weak    FALSE     TRUE      0 -0.775511796
326         Low     MedLow    Weak    FALSE     TRUE      2  0.077932726
327         Low     MedLow    Weak    FALSE     TRUE      2 -0.283603465
337         Low    MedHigh    Weak    FALSE     TRUE      1 -0.443008058
338      MedLow       High    Weak    FALSE     TRUE      2  0.699994085
343         Low        Med    Weak    FALSE    FALSE      1 -0.218367596
351         Med    MedHigh    Weak     TRUE    FALSE      3 -1.204790373
352         Low        Low    Weak    FALSE     TRUE      1 -0.582514836
354      MedLow    MedHigh    Weak     TRUE    FALSE      3 -1.095762514
356         Low     MedLow    Weak    FALSE     TRUE      1  0.671962010
357      MedLow    MedHigh    Weak    FALSE     TRUE      1 -0.648426347
359         Low        Med    Weak     TRUE    FALSE      3 -0.694440044
362         Low     MedLow    Weak    FALSE     TRUE      2 -0.207858422
363         Med    MedHigh    Weak     TRUE    FALSE      2  0.935994268
364         Low        Med    Weak     TRUE    FALSE      2 -0.704710959
365         Med    MedHigh    Weak     TRUE    FALSE      3 -1.138673662
369         Med    MedHigh    Weak     TRUE    FALSE      3 -0.183738573
370      MedLow    MedHigh    Weak     TRUE    FALSE      3 -1.226884252
377         Med    MedHigh    Weak     TRUE    FALSE      3 -0.882758650
382         Med    MedHigh    Weak     TRUE    FALSE      1 -0.283968653
390         Low    MedHigh    Weak     TRUE    FALSE      2 -0.622037540
395         Low     MedLow    Weak    FALSE     TRUE      1  1.045102157
400         Med     MedLow    Weak    FALSE     TRUE      2 -0.226335335
401         Med    MedHigh    Weak     TRUE    FALSE      3 -0.770776131
402         Low    MedHigh    Weak     TRUE    FALSE      2 -0.392583273
404      MedLow        Med    Weak    FALSE    FALSE      1  0.824357922
405         Med    MedHigh    Weak     TRUE    FALSE      4 -0.570756611
406      MedLow    MedHigh    Weak     TRUE    FALSE      2 -0.783374080
408      MedLow    MedHigh    Weak    FALSE     TRUE      2  1.290357121
411      MedLow    MedHigh    Weak    FALSE    FALSE      5  7.365844981
413         Low    MedHigh    Weak    FALSE     TRUE      2 -0.076130992
418         Low     MedLow    Weak    FALSE     TRUE      1  1.484167647
419         Low    MedHigh    Weak    FALSE     TRUE      1 -0.814404326
427      MedLow    MedHigh    Weak     TRUE    FALSE      2  1.336952727
429         Low       High    Weak    FALSE     TRUE      1  0.788471108
434      MedLow     MedLow    Weak    FALSE     TRUE      3 -0.541537387
435         Low     MedLow    Weak    FALSE     TRUE      2  0.014937784
436      MedLow    MedHigh    Weak    FALSE     TRUE      1  1.974074659
438      MedLow    MedHigh    Weak    FALSE    FALSE      2  0.047804710
440         Low    MedHigh    Weak    FALSE     TRUE      2  0.324940319
445         Low     MedLow    Weak    FALSE     TRUE      2  0.584725619
446     MedHigh    MedHigh    Weak     TRUE    FALSE      1 -1.085289980
447         Low        Med    Weak    FALSE     TRUE      2  0.192078673
448      MedLow     MedLow    Weak    FALSE     TRUE      3  2.762065047
450         Low       High    Weak    FALSE     TRUE      1  0.115989167
458         Med     MedLow    Weak    FALSE     TRUE      2  0.721695784
459         Med    MedHigh    Weak    FALSE    FALSE      1 -0.016390851
463         Low     MedLow    Weak    FALSE     TRUE      2  0.589398907
466         Med     MedLow    Weak    FALSE     TRUE      3 -1.004025286
467         Med    MedHigh    Weak     TRUE    FALSE      3 -1.023109308
482      MedLow     MedLow  Strong    FALSE     TRUE      2  1.751127580
488      MedLow     MedLow  Strong    FALSE     TRUE      1  0.021328575
489         Med    MedHigh  Strong    FALSE    FALSE      2 -0.555123520
495         Low    MedHigh  Strong    FALSE     TRUE      1 -0.782085181
497         Low        Med  Strong    FALSE     TRUE      1  0.920572718
498      MedLow    MedHigh  Strong     TRUE    FALSE      2 -1.023109308
501         Low        Med  Strong    FALSE     TRUE      2 -0.281692597
503      MedLow    MedHigh  Strong     TRUE    FALSE      2 -0.835166039
504         Med    MedHigh  Strong     TRUE    FALSE      3 -1.074757335
505         Low     MedLow  Strong    FALSE     TRUE      1 -0.766915831
518      MedLow    MedHigh  Strong     TRUE    FALSE      3  0.172926159
519         Med    MedHigh  Strong    FALSE    FALSE      1 -0.759297446
520         Med    MedHigh  Strong     TRUE    FALSE      3 -0.406977076
522         Low     MedLow  Strong    FALSE     TRUE      2 -0.194862763
531         Med    MedHigh  Strong     TRUE    FALSE      1 -1.006326197
532      MedLow    MedHigh  Strong    FALSE     TRUE      3  0.688709774
535      MedLow    MedHigh  Strong     TRUE    FALSE      4 -0.760173897
544         Med    MedHigh  Strong     TRUE    FALSE      3 -0.037101517
545      MedLow     MedLow  Strong    FALSE     TRUE      3  0.697214812
553      MedLow     MedLow  Strong    FALSE     TRUE      1  1.485901287
561      MedLow    MedHigh  Strong     TRUE    FALSE      2 -0.333686400
562      MedLow    MedHigh  Strong     TRUE    FALSE      2  0.685970864
564         Med    MedHigh  Strong     TRUE    FALSE      2 -0.629946453
568      MedLow    MedHigh  Strong    FALSE     TRUE      1  2.196910422
584      MedLow    MedHigh  Strong     TRUE    FALSE      7 -0.996633173
590      MedLow     MedLow  Strong    FALSE     TRUE      3  0.615541736
592         Low    MedHigh  Strong     TRUE    FALSE      1 -0.822826476
593      MedLow    MedHigh  Strong     TRUE    FALSE      3 -0.886253582
596         Med    MedHigh  Strong    FALSE    FALSE      1 -0.802431374
597         Low     MedLow  Strong    FALSE     TRUE      3  0.014546511
598      MedLow        Low  Strong    FALSE     TRUE      3  0.637962994
610         Low    MedHigh  Strong    FALSE     TRUE      1 -0.612272728
614         Low    MedHigh  Strong     TRUE    FALSE      1 -0.281777524
615      MedLow    MedHigh  Strong    FALSE     TRUE      2  0.742575015
628         Low    MedHigh  Strong    FALSE     TRUE      2  0.679856086
629         Low        Med  Strong    FALSE    FALSE      1  2.179825679
638      MedLow     MedLow  Strong    FALSE     TRUE      3 -2.009117100
639      MedLow     MedLow  Strong    FALSE     TRUE      3 -0.299244954
644         Low    MedHigh  Strong     TRUE    FALSE      2 -0.605738942
647         Low     MedLow  Strong    FALSE     TRUE      2 -0.315028859
653         Low    MedHigh  Strong     TRUE    FALSE      1 -0.194862763
655         Low    MedHigh  Strong    FALSE     TRUE      1 -0.065273168
657         Low    MedHigh  Strong    FALSE     TRUE      1 -0.201066857
662         Low     MedLow  Strong    FALSE     TRUE      2  0.325651967
664      MedLow    MedHigh  Strong     TRUE    FALSE      5 -1.116408970
668     MedHigh    MedHigh  Strong     TRUE    FALSE      2 -0.744605353
677     MedHigh    MedHigh  Strong     TRUE    FALSE      2 -1.025042657
687     MedHigh    MedHigh  Strong     TRUE    FALSE      1  0.932051440
688         Low    MedHigh  Strong    FALSE     TRUE      2 -0.280983637
692     MedHigh    MedHigh  Strong     TRUE    FALSE      2 -0.431504633
697         Low        Med  Strong    FALSE     TRUE      3 -0.288792979
702      MedLow     MedLow  Strong    FALSE     TRUE      3  0.655295065
703         Low        Med  Strong    FALSE     TRUE      2 -0.190480506
706         Low       High  Strong    FALSE     TRUE      1 -0.204616819
717         Low        Med  Strong    FALSE     TRUE      1  0.580490961
721         Med    MedHigh  Strong     TRUE    FALSE      3 -0.577579862
724         Low       High  Strong    FALSE     TRUE      2  0.428324383
729      MedLow    MedHigh  Strong    FALSE     TRUE      2 -0.086899890
735         Low     MedLow  Strong    FALSE     TRUE      2  0.022058951
737      MedLow    MedHigh  Strong     TRUE    FALSE      3 -0.068972475
744         Low        Med  Strong    FALSE     TRUE      1  2.472736498
745         Low        Med  Strong    FALSE     TRUE      2  0.397274889
747      MedLow    MedHigh  Strong    FALSE    FALSE      2 -0.219311143
750         Low    MedHigh  Strong    FALSE    FALSE      2 -0.659518935
751         Low     MedLow  Strong    FALSE     TRUE      1 -0.133604407
758      MedLow    MedHigh  Strong     TRUE    FALSE      2 -0.700760607
766         Low    MedHigh  Strong    FALSE     TRUE      1 -0.657190861
767         Low       High  Strong    FALSE     TRUE      1 -0.176641801
768         Low        Med  Strong    FALSE     TRUE      1  0.103130702
772         Med     MedLow  Strong    FALSE     TRUE      3  0.690353121
773      MedLow    MedHigh  Strong    FALSE    FALSE      2  0.855440953
780      MedLow    MedHigh  Strong    FALSE     TRUE      1  0.546990718
781         Low    MedHigh  Strong    FALSE     TRUE      1 -0.579405802
787         Low        Low  Strong    FALSE     TRUE      2  0.644777649
800         Low        Med  Strong    FALSE     TRUE      1  0.227122793
809     MedHigh    MedHigh  Strong     TRUE    FALSE      2 -0.795923887
812      MedLow    MedHigh  Strong    FALSE     TRUE      1  2.324704281
813         Low    MedHigh  Strong     TRUE    FALSE      1 -0.163091401
820         Low    MedHigh  Strong    FALSE     TRUE      1  0.201521374
822      MedLow        Med  Strong    FALSE     TRUE      0  1.490972394
831         Low        Med  Strong    FALSE    FALSE      2  0.500013254
836      MedLow    MedHigh  Strong    FALSE     TRUE      2  0.532591874
839         Low    MedHigh  Strong    FALSE     TRUE      1 -0.018017495
848         Low    MedHigh  Strong     TRUE    FALSE      1  1.336952727
851         Med    MedHigh  Strong     TRUE    FALSE      2  0.449865597
854      MedLow    MedHigh  Strong    FALSE     TRUE      3  1.121457638
857      MedLow     MedLow  Strong    FALSE     TRUE      3  0.076106785
872         Low    MedHigh  Strong     TRUE    FALSE      2  1.336952727
873      MedLow    MedHigh  Strong     TRUE    FALSE      2  1.336952727
877      MedLow       High  Strong    FALSE     TRUE      1  1.544893207
891      MedLow    MedHigh  Strong    FALSE     TRUE      1 -0.805149691
893      MedLow        Med  Strong    FALSE     TRUE      2  0.771424872
894         Low    MedHigh  Strong    FALSE     TRUE      2 -0.049236997
895         Med    MedHigh  Strong     TRUE    FALSE      3 -0.310366533
900         Low     MedLow  Strong    FALSE     TRUE      1  0.971913123
906     MedHigh    MedHigh  Strong     TRUE    FALSE      2  0.293943670
912      MedLow        Med  Strong    FALSE     TRUE      2  0.467502471
913         Med    MedHigh  Strong     TRUE    FALSE      2  1.336952727
918      MedLow    MedHigh  Strong     TRUE    FALSE      2  1.336952727
922         Low        Med  Strong    FALSE     TRUE      2  0.153985264
926         Med     MedLow  Strong    FALSE     TRUE      2  0.535474938
942      MedLow    MedHigh  Strong     TRUE    FALSE      2  0.453822194
947         Med    MedHigh  Strong     TRUE    FALSE      2 -1.877649394
948         Low    MedHigh  Strong     TRUE    FALSE      2 -0.373596239
953      MedLow    MedHigh  Strong     TRUE    FALSE      4  1.336952727
956      MedLow    MedHigh  Strong     TRUE    FALSE      2 -1.100794771
961      MedLow    MedHigh  Strong    FALSE     TRUE      1  1.954634222
962         Low    MedHigh  Strong    FALSE     TRUE      1  1.482183728
975      MedLow    MedHigh  Strong    FALSE     TRUE      2  2.175938193
977         Low        Med  Strong     TRUE    FALSE      2  1.336952727
980         Low     MedLow  Strong    FALSE     TRUE      2  0.586374117
982         Low     MedLow  Strong    FALSE     TRUE      3 -0.251180686
985        High    MedHigh  Strong     TRUE    FALSE      1  1.336952727
988         Med    MedHigh  Strong     TRUE    FALSE      2 -0.521888681
998      MedLow    MedHigh  Strong    FALSE     TRUE      1 -2.009117100
1001       High    MedHigh  Strong     TRUE    FALSE      1  1.336952727
1002        Low     MedLow  Strong    FALSE     TRUE      2 -1.828349005
1003        Low        Med  Strong    FALSE     TRUE      2  0.004729117
1010        Low    MedHigh  Strong    FALSE     TRUE      1  1.272440081
1013        Low     MedLow  Strong    FALSE     TRUE      2  0.027767417
1014        Med    MedHigh  Strong     TRUE    FALSE      2  0.737414749
1023        Low        Med  Strong    FALSE     TRUE      2  0.071166005
1024        Low        Low  Strong    FALSE     TRUE      2  1.003371467
1025        Low    MedHigh  Strong    FALSE     TRUE      1 -0.341867562
1048        Low        Med  Strong    FALSE    FALSE      2  0.484074030
1051     MedLow    MedHigh  Strong     TRUE    FALSE      3  3.794795430
1056        Low    MedHigh  Strong     TRUE    FALSE      1  1.336952727
1058        Low     MedLow  Strong    FALSE     TRUE      2 -0.803370429
1062        Med     MedLow  Strong    FALSE     TRUE      2  2.385464849
1068     MedLow    MedHigh  Strong     TRUE    FALSE      2  1.336952727
1076     MedLow    MedHigh  Strong     TRUE    FALSE      3  1.336952727
1081     MedLow    MedHigh  Strong     TRUE    FALSE      2  1.336952727
1082    MedHigh    MedHigh  Strong     TRUE    FALSE      2  1.336952727
1098        Low    MedHigh  Strong    FALSE     TRUE      1  1.639756178
1099        Low    MedHigh  Strong    FALSE     TRUE      0  2.331371366
1104        Low    MedHigh  Strong     TRUE    FALSE      1 -0.211765754
1105        Low       High  Strong    FALSE     TRUE      1  0.403701966
1106        Low    MedHigh  Strong     TRUE    FALSE      4  1.336952727
1109        Med    MedHigh  Strong     TRUE    FALSE      3  0.266588883
1110     MedLow    MedHigh  Strong     TRUE    FALSE      3  1.336952727
1113     MedLow     MedLow  Strong    FALSE     TRUE      3  1.336952727
1129        Low     MedLow  Strong    FALSE     TRUE      1  1.118542024
1136        Low     MedLow  Strong    FALSE     TRUE      2 -0.593311040
1143        Low       High  Strong    FALSE     TRUE      2 -0.188083960
1144     MedLow    MedHigh  Strong     TRUE    FALSE      2  0.958420385
1147        Low       High  Strong    FALSE     TRUE      1  0.842435950
1149       High    MedHigh  Strong     TRUE    FALSE      1  1.336952727
1152     MedLow    MedHigh  Strong     TRUE    FALSE      3  1.336952727
1153        Med    MedHigh  Strong     TRUE    FALSE      1  1.336952727
1179     MedLow    MedHigh  Strong     TRUE    FALSE      4  1.336952727
1180    MedHigh    MedHigh  Strong     TRUE    FALSE      2  1.336952727
1181     MedLow    MedHigh  Strong     TRUE    FALSE      4  1.336952727
1182    MedHigh    MedHigh  Strong     TRUE    FALSE      2  0.434852774
1196        Med    MedHigh  Strong     TRUE    FALSE      2  1.336952727
1205        Low       High  Strong    FALSE     TRUE      2  0.174707564
1207        Med    MedHigh  Strong     TRUE    FALSE      2  1.336952727
1208     MedLow    MedHigh  Strong    FALSE     TRUE      3  0.693704258
1211     MedLow    MedHigh  Strong     TRUE    FALSE      2  1.336952727
1213     MedLow    MedHigh  Strong    FALSE    FALSE      2  1.336952727
1214     MedLow     MedLow  Strong    FALSE     TRUE      3 -1.779048615
1226    MedHigh    MedHigh  Strong     TRUE    FALSE      1  0.774029421
1242        Low    MedHigh  Strong    FALSE     TRUE      2  0.474556580
1245    MedHigh    MedHigh  Strong     TRUE    FALSE      1 -0.013820777
1257    MedHigh    MedHigh  Strong     TRUE    FALSE      1 -0.235269749
1268        Low    MedHigh  Strong    FALSE    FALSE      2  1.336952727
1273        Med    MedHigh  Strong     TRUE    FALSE      1  1.336952727
1274       High    MedHigh  Strong     TRUE    FALSE      1  1.336952727
1283        Low    MedHigh  Strong    FALSE     TRUE      1  1.351381970
1302    MedHigh    MedHigh  Strong     TRUE    FALSE      1  1.336952727
1306        Med    MedHigh  Strong     TRUE    FALSE      1  1.336952727
1308     MedLow     MedLow  Strong    FALSE     TRUE      2  0.696241778
1309        Low       High  Strong    FALSE     TRUE      1 -0.169612617
1311    MedHigh    MedHigh  Strong     TRUE    FALSE      2  0.424062544
1331        Med    MedHigh  Strong    FALSE    FALSE      2  1.336952727
1363        Med    MedHigh  Strong     TRUE    FALSE      1  1.336952727
1370    MedHigh    MedHigh  Strong     TRUE    FALSE      1  1.336952727
1387        Med        Med  Strong     TRUE    FALSE      1  1.336952727
> colnames(flight)
 [1] "SDEPHR"         "SKDDEPSTA"      "SKDARRSTA"      "SKDEQP"        
 [5] "SKDEPS"         "D00"            "AVGSQ"          "AVGLOFATC"     
 [9] "UPLINEATCIMP"   "DEPSTAATCIMP"   "DOWNLINEATCIMP" "DEPBUCKET"     
[13] "ARRBUCKET"      "DEPRANKGRP"     "TRNRANKGRP"     "ARRRANKGRP"    
[17] "LEGTYPE"        "DEPSPOKE"       "ARRSPOKE"       "xDURN2"        
[21] "xAVGSKDAVAIL"  
> ### weaves
> ###################################################
> ### code chunk number 1: loadLibs
> ###################################################
> library(MASS)
> library(caret)
> library(mlbench)
> library(pROC)
> library(pls)
> library(doMC)
> registerDoMC(cores = 4)
> options(useFancyQuotes = FALSE)
> 
+ . + 
> getInfo <- function(what = "Suggests")
+ {
+   text <- packageDescription("caret")[what][[1]]
+   text <- gsub("\n", ", ", text, fixed = TRUE)
+   text <- gsub(">=", "$\\\\ge$", text, fixed = TRUE)
+   eachPkg <- strsplit(text, ", ", fixed = TRUE)[[1]]
+   eachPkg <- gsub(",", "", eachPkg, fixed = .... [TRUNCATED] 
> seed.mine = 107
> set.seed(seed.mine)                     # helpful for testing
> flight <- read.csv("../bak/flight.csv")
> flight <- flight[order(flight$D00),]
> # Backup
> flight.raw <- flight
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"
> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"
> t.cols <- colnames(flight)
> t.drops <- t.cols[grep("^RANK*", t.cols)]
> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])
> t.drops <- c(t.drops, "D80THPCTL")
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> flight$xDURN <- flight$SARRHR - flight$SDEPHR
> flight$xHNGR <- flight$xDURN < 0
> 
+ . + 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+ }
> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))
> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE
> t.cols <- colnames(flight)
> t.drops <- c("SARRHR", "xDURN")
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> flight00 <- flight
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]
> paste("samples in use: ", dim(flight)[1])
[1] "samples in use:  320"
> flight <- flight1
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))
Error in `$<-.data.frame`(`*tmp*`, "xAVAILBUCKET", value = numeric(0)) : 
  replacement has 0 rows, data has 320
> flight$AVAILBUCKET
NULL
> flight <- read.csv("../bak/flight.csv")
> flight <- flight[order(flight$D00),]
> colnames(flight)
 [1] "SDEPHR"         "SARRHR"         "SKDDEPSTA"      "SKDARRSTA"     
 [5] "SKDEQP"         "SKDEPS"         "D00"            "AVGSQ"         
 [9] "AVGLOFATC"      "UPLINEATCIMP"   "DEPSTAATCIMP"   "DOWNLINEATCIMP"
[13] "AVGSKDAVAIL"    "AVAILBUCKET"    "DEPGRP"         "ARRGRP"        
[17] "DEPBUCKET"      "ARRBUCKET"      "D80THPCTL"      "RANKD00"       
[21] "RANKT00"        "RANKA00"        "DEPRANKGRP"     "TRNRANKGRP"    
[25] "ARRRANKGRP"     "LEGTYPE"       
> # Backup
> flight.raw <- flight
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"
> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"
> t.cols <- colnames(flight)
> t.drops <- t.cols[grep("^RANK*", t.cols)]
> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])
> t.drops <- c(t.drops, "D80THPCTL")
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> colnames(flight)
 [1] "SDEPHR"         "SARRHR"         "SKDDEPSTA"      "SKDARRSTA"     
 [5] "SKDEQP"         "SKDEPS"         "D00"            "AVGSQ"         
 [9] "AVGLOFATC"      "UPLINEATCIMP"   "DEPSTAATCIMP"   "DOWNLINEATCIMP"
[13] "AVGSKDAVAIL"    "AVAILBUCKET"    "DEPBUCKET"      "ARRBUCKET"     
[17] "DEPRANKGRP"     "TRNRANKGRP"     "ARRRANKGRP"     "LEGTYPE"       
[21] "DEPSPOKE"       "ARRSPOKE"      
> flight$xDURN <- flight$SARRHR - flight$SDEPHR
> flight$xHNGR <- flight$xDURN < 0
> 
+ . + 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+ }
> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))
> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE
> t.cols <- colnames(flight)
> t.cols
 [1] "SDEPHR"         "SARRHR"         "SKDDEPSTA"      "SKDARRSTA"     
 [5] "SKDEQP"         "SKDEPS"         "D00"            "AVGSQ"         
 [9] "AVGLOFATC"      "UPLINEATCIMP"   "DEPSTAATCIMP"   "DOWNLINEATCIMP"
[13] "AVGSKDAVAIL"    "AVAILBUCKET"    "DEPBUCKET"      "ARRBUCKET"     
[17] "DEPRANKGRP"     "TRNRANKGRP"     "ARRRANKGRP"     "LEGTYPE"       
[21] "DEPSPOKE"       "ARRSPOKE"       "xDURN"          "xHNGR"         
[25] "xDURN2"        
> t.drops <- c("SARRHR", "xDURN")
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> flight00 <- flight
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]
> colnames(flight)
 [1] "SDEPHR"         "SKDDEPSTA"      "SKDARRSTA"      "SKDEQP"        
 [5] "SKDEPS"         "D00"            "AVGSQ"          "AVGLOFATC"     
 [9] "UPLINEATCIMP"   "DEPSTAATCIMP"   "DOWNLINEATCIMP" "AVGSKDAVAIL"   
[13] "AVAILBUCKET"    "DEPBUCKET"      "ARRBUCKET"      "DEPRANKGRP"    
[17] "TRNRANKGRP"     "ARRRANKGRP"     "LEGTYPE"        "DEPSPOKE"      
[21] "ARRSPOKE"       "xHNGR"          "xDURN2"        
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]
> paste("samples in use: ", dim(flight)[1])
[1] "samples in use:  320"
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))
> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1
> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]
> preProcValues <- preProcess(flight.na, method = c("knnImpute"))
> flight.na1 <- predict(preProcValues, flight.na)
> ## I'll add the new imputed value and drop the others
> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL
> flight$AVGSKDAVAIL <- NULL
> flight$xAVAILBUCKET <- NULL
> flight$AVAILBUCKET <- NULL
> flight$xHNGR <- NULL
> x1 <- as.data.frame(as.matrix(sapply(flight, class)))
> flight.num <- flight[,names(x1[which(x1$V1 %in% c("numeric", "integer")),])]
> flight.nzv <- nearZeroVar(flight.num, saveMetrics = TRUE)
> flight.nzv
             freqRatio percentUnique zeroVar   nzv
SDEPHR        1.038462        5.9375   FALSE FALSE
SKDEPS        1.000000       19.0625   FALSE FALSE
D00           1.166667       75.3125   FALSE FALSE
AVGSQ         6.333333       82.8125   FALSE FALSE
AVGLOFATC     1.000000       78.4375   FALSE FALSE
xDURN2        1.428571        2.5000   FALSE FALSE
xAVGSKDAVAIL 18.500000       87.8125   FALSE FALSE
> # annoying NA should be gone.
> flight.cor <- cor(flight.num, use = "pairwise.complete.obs")
> descrCorr <- findCorrelation(flight.cor, cutoff = .65, verbose=TRUE)
Considering row	 4 column	 1 value	 0.956 
  Flagging column	 4 
Considering row	 1 column	 3 value	 0.43 
Considering row	 1 column	 7 value	 0.053 
Considering row	 1 column	 6 value	 0.204 
Considering row	 1 column	 5 value	 0.131 
Considering row	 1 column	 2 value	 0.054 
Considering row	 3 column	 7 value	 0.401 
Considering row	 3 column	 6 value	 0.071 
Considering row	 3 column	 5 value	 0.114 
Considering row	 3 column	 2 value	 0.006 
Considering row	 7 column	 6 value	 0.019 
Considering row	 7 column	 5 value	 0.07 
Considering row	 7 column	 2 value	 0.113 
Considering row	 6 column	 5 value	 0.137 
Considering row	 6 column	 2 value	 0.005 
Considering row	 5 column	 2 value	 0.041 
> colnames(flight.num)[descrCorr]
[1] "AVGSQ"
> ## Re-classing
> ## Check warnings to see it adjustment has taken place.
> ## We want the proportion in the training class to be about 0.55 0.45
> ## Strong to Weak
> ## I've achieved this heuristically
> src.adjust <- TRUE
> source(file = "flight1.R")
Warning message:
In eval(expr, envir, enclos) : adjusting
> flight1 <- flight
> ## This should be deleted, leave it in and the results
> ## are ideal because it defines LEGTYPE.
> flight$D00 <- NULL
> ## Keep the results but don't change the order.
> outcomes.flight <- flight$LEGTYPE
> flight$LEGTYPE <- NULL
> 

> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))
> flight.num0 <- factors.numeric(flight)
> flight.scl0 <- scale(flight.num0)
> set.seed(seed.mine)
> inTrain <- createDataPartition(outcomes.flight, p = 0.77, list = FALSE)
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> prop.table(table(trainClass))
trainClass
   Strong      Weak 
0.5524194 0.4475806 
> dim(trainDescr)
[1] 248  19
> prop.table(table(testClass))
testClass
   Strong      Weak 
0.5555556 0.4444444 
> dim(testDescr)
[1] 72 19
> nzv <- nearZeroVar(trainDescr, saveMetrics= TRUE)
> stopifnot( all(nzv$nzv == FALSE) )
> descrCorr <- cor(scale(trainDescr))
> ## This cut-off should be under src.adjust control.
> ## I'm under Git, so I can tinker with it.
> highCorr <- findCorrelation(descrCorr, cutoff = .95, verbose = TRUE)
Considering row	 17 column	 16 value	 0.85 
Considering row	 17 column	 10 value	 0.671 
Considering row	 17 column	 1 value	 0.279 
Considering row	 17 column	 11 value	 0.277 
Considering row	 17 column	 6 value	 0.22 
Considering row	 17 column	 12 value	 0.226 
Considering row	 17 column	 2 value	 0.298 
Considering row	 17 column	 9 value	 0.586 
Considering row	 17 column	 14 value	 0.226 
Considering row	 17 column	 13 value	 0.23 
Considering row	 17 column	 8 value	 0.541 
Considering row	 17 column	 3 value	 0.346 
Considering row	 17 column	 18 value	 0.261 
Considering row	 17 column	 19 value	 0.138 
Considering row	 17 column	 15 value	 0.057 
Considering row	 17 column	 4 value	 0.067 
Considering row	 17 column	 7 value	 0.034 
Considering row	 17 column	 5 value	 0.018 
Considering row	 16 column	 10 value	 0.568 
Considering row	 16 column	 1 value	 0.236 
Considering row	 16 column	 11 value	 0.231 
Considering row	 16 column	 6 value	 0.189 
Considering row	 16 column	 12 value	 0.19 
Considering row	 16 column	 2 value	 0.333 
Considering row	 16 column	 9 value	 0.671 
Considering row	 16 column	 14 value	 0.242 
Considering row	 16 column	 13 value	 0.208 
Considering row	 16 column	 8 value	 0.6 
Considering row	 16 column	 3 value	 0.318 
Considering row	 16 column	 18 value	 0.279 
Considering row	 16 column	 19 value	 0.213 
Considering row	 16 column	 15 value	 0.083 
Considering row	 16 column	 4 value	 0.02 
Considering row	 16 column	 7 value	 0.009 
Considering row	 16 column	 5 value	 0.005 
Considering row	 10 column	 1 value	 0.281 
Considering row	 10 column	 11 value	 0.275 
Considering row	 10 column	 6 value	 0.298 
Considering row	 10 column	 12 value	 0.255 
Considering row	 10 column	 2 value	 0.286 
Considering row	 10 column	 9 value	 0.404 
Considering row	 10 column	 14 value	 0.224 
Considering row	 10 column	 13 value	 0.199 
Considering row	 10 column	 8 value	 0.366 
Considering row	 10 column	 3 value	 0.462 
Considering row	 10 column	 18 value	 0.226 
Considering row	 10 column	 19 value	 0.103 
Considering row	 10 column	 15 value	 0.274 
Considering row	 10 column	 4 value	 0.018 
Considering row	 10 column	 7 value	 0.127 
Considering row	 10 column	 5 value	 0.096 
Considering row	 1 column	 11 value	 0.988 
  Flagging column	 1 
Considering row	 11 column	 6 value	 0.945 
Considering row	 11 column	 12 value	 0.889 
Considering row	 11 column	 2 value	 0.165 
Considering row	 11 column	 9 value	 0.139 
Considering row	 11 column	 14 value	 0.171 
Considering row	 11 column	 13 value	 0.156 
Considering row	 11 column	 8 value	 0.145 
Considering row	 11 column	 3 value	 0.073 
Considering row	 11 column	 18 value	 0.183 
Considering row	 11 column	 19 value	 0.053 
Considering row	 11 column	 15 value	 0.142 
Considering row	 11 column	 4 value	 0.037 
Considering row	 11 column	 7 value	 0.053 
Considering row	 11 column	 5 value	 0.03 
Considering row	 6 column	 12 value	 0.883 
Considering row	 6 column	 2 value	 0.151 
Considering row	 6 column	 9 value	 0.04 
Considering row	 6 column	 14 value	 0.188 
Considering row	 6 column	 13 value	 0.161 
Considering row	 6 column	 8 value	 0.063 
Considering row	 6 column	 3 value	 0.083 
Considering row	 6 column	 18 value	 0.197 
Considering row	 6 column	 19 value	 0.114 
Considering row	 6 column	 15 value	 0.159 
Considering row	 6 column	 4 value	 0.01 
Considering row	 6 column	 7 value	 0.027 
Considering row	 6 column	 5 value	 0.039 
Considering row	 12 column	 2 value	 0.121 
Considering row	 12 column	 9 value	 0.128 
Considering row	 12 column	 14 value	 0.092 
Considering row	 12 column	 13 value	 0.105 
Considering row	 12 column	 8 value	 0.071 
Considering row	 12 column	 3 value	 0.093 
Considering row	 12 column	 18 value	 0.126 
Considering row	 12 column	 19 value	 0.171 
Considering row	 12 column	 15 value	 0.13 
Considering row	 12 column	 4 value	 0.01 
Considering row	 12 column	 7 value	 0.043 
Considering row	 12 column	 5 value	 0.017 
Considering row	 2 column	 9 value	 0.423 
Considering row	 2 column	 14 value	 0.574 
Considering row	 2 column	 13 value	 0.557 
Considering row	 2 column	 8 value	 0.165 
Considering row	 2 column	 3 value	 0.263 
Considering row	 2 column	 18 value	 0.128 
Considering row	 2 column	 19 value	 0.089 
Considering row	 2 column	 15 value	 0.069 
Considering row	 2 column	 4 value	 0.27 
Considering row	 2 column	 7 value	 0.045 
Considering row	 2 column	 5 value	 0.024 
Considering row	 9 column	 14 value	 0.147 
Considering row	 9 column	 13 value	 0.125 
Considering row	 9 column	 8 value	 0.449 
Considering row	 9 column	 3 value	 0.322 
Considering row	 9 column	 18 value	 0.018 
Considering row	 9 column	 19 value	 0.141 
Considering row	 9 column	 15 value	 0.073 
Considering row	 9 column	 4 value	 0.006 
Considering row	 9 column	 7 value	 0.136 
Considering row	 9 column	 5 value	 0.123 
Considering row	 14 column	 13 value	 0.659 
Considering row	 14 column	 8 value	 0.097 
Considering row	 14 column	 3 value	 0.106 
Considering row	 14 column	 18 value	 0.361 
Considering row	 14 column	 19 value	 0.092 
Considering row	 14 column	 15 value	 0.084 
Considering row	 14 column	 4 value	 0.263 
Considering row	 14 column	 7 value	 0.139 
Considering row	 14 column	 5 value	 0.031 
Considering row	 13 column	 8 value	 0.097 
Considering row	 13 column	 3 value	 0.167 
Considering row	 13 column	 18 value	 0.18 
Considering row	 13 column	 19 value	 0.131 
Considering row	 13 column	 15 value	 0.137 
Considering row	 13 column	 4 value	 0.24 
Considering row	 13 column	 7 value	 0.085 
Considering row	 13 column	 5 value	 0.027 
Considering row	 8 column	 3 value	 0.224 
Considering row	 8 column	 18 value	 0.173 
Considering row	 8 column	 19 value	 0.235 
Considering row	 8 column	 15 value	 0.07 
Considering row	 8 column	 4 value	 0.02 
Considering row	 8 column	 7 value	 0.085 
Considering row	 8 column	 5 value	 0.004 
Considering row	 3 column	 18 value	 0.028 
Considering row	 3 column	 19 value	 0.027 
Considering row	 3 column	 15 value	 0.017 
Considering row	 3 column	 4 value	 0.094 
Considering row	 3 column	 7 value	 0.095 
Considering row	 3 column	 5 value	 0.097 
Considering row	 18 column	 19 value	 0.019 
Considering row	 18 column	 15 value	 0.12 
Considering row	 18 column	 4 value	 0.086 
Considering row	 18 column	 7 value	 0.132 
Considering row	 18 column	 5 value	 0.002 
Considering row	 19 column	 15 value	 0.019 
Considering row	 19 column	 4 value	 0.032 
Considering row	 19 column	 7 value	 0.056 
Considering row	 19 column	 5 value	 0.075 
Considering row	 15 column	 4 value	 0.043 
Considering row	 15 column	 7 value	 0.061 
Considering row	 15 column	 5 value	 0.08 
Considering row	 4 column	 7 value	 0.005 
Considering row	 4 column	 5 value	 0.213 
Considering row	 7 column	 5 value	 0.008 
> colnames(trainDescr)[highCorr]
[1] "SDEPHR"
> descr.ncol0 <- ncol(trainDescr)
> # I've switched off the correlation remover and the results are better.
> if (sum(highCorr) > 0) {
+     warning("overfitting: correlations: err.trainDescr: ", paste(colnames(trainDescr)[highCorr], collapse = ", ") )
+     err.trainDescr <- trainDescr
+     trainDescr <- trainDescr[,-highCorr]
+ }
Warning message:
overfitting: correlations: err.trainDescr: SDEPHR 
> descr.ncol1 <- ncol(trainDescr)
> paste("Dropped: ", as.character(descr.ncol0 - descr.ncol1))
[1] "Dropped:  1"
> descrCorr <- cor(trainDescr)
> summary(descrCorr[upper.tri(descrCorr)])
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
-0.85020 -0.13860 -0.01766  0.01577  0.11970  0.94490 
> table.descrCorr <- as.data.frame(as.table(descrCorr))
> table.descrCorr <- table.descrCorr[which(table.descrCorr$Var1 != table.descrCorr$Var2),]
> table.descrCorr[order(abs(table.descrCorr$Freq), decreasing = TRUE),]
              Var1           Var2         Freq
82       DEPBUCKET          AVGSQ  0.944870657
167          AVGSQ      DEPBUCKET  0.944870657
173      ARRBUCKET      DEPBUCKET  0.889095737
190      DEPBUCKET      ARRBUCKET  0.889095737
83       ARRBUCKET          AVGSQ  0.882590635
185          AVGSQ      ARRBUCKET  0.882590635
268       ARRSPOKE       DEPSPOKE -0.850165355
285       DEPSPOKE       ARRSPOKE -0.850165355
141       DEPSPOKE   DEPSTAATCIMP  0.671264566
260   DEPSTAATCIMP       DEPSPOKE  0.671264566
160       ARRSPOKE DOWNLINEATCIMP  0.671009330
279 DOWNLINEATCIMP       ARRSPOKE  0.671009330
211     TRNRANKGRP     DEPRANKGRP  0.658724662
228     DEPRANKGRP     TRNRANKGRP  0.658724662
123       DEPSPOKE   UPLINEATCIMP -0.600008252
259   UPLINEATCIMP       DEPSPOKE -0.600008252
142       ARRSPOKE   DEPSTAATCIMP -0.586442959
278   DEPSTAATCIMP       ARRSPOKE -0.586442959
13      TRNRANKGRP      SKDDEPSTA  0.574035134
217      SKDDEPSTA     TRNRANKGRP  0.574035134
159       DEPSPOKE DOWNLINEATCIMP -0.567682494
261 DOWNLINEATCIMP       DEPSPOKE -0.567682494
12      DEPRANKGRP      SKDDEPSTA  0.557399203
199      SKDDEPSTA     DEPRANKGRP  0.557399203
124       ARRSPOKE   UPLINEATCIMP  0.540734833
277   UPLINEATCIMP       ARRSPOKE  0.540734833
27  DOWNLINEATCIMP      SKDARRSTA  0.462378131
146      SKDARRSTA DOWNLINEATCIMP  0.462378131
116   DEPSTAATCIMP   UPLINEATCIMP -0.449249986
133   UPLINEATCIMP   DEPSTAATCIMP -0.449249986
8     DEPSTAATCIMP      SKDDEPSTA  0.423425796
127      SKDDEPSTA   DEPSTAATCIMP  0.423425796
135 DOWNLINEATCIMP   DEPSTAATCIMP -0.403695561
152   DEPSTAATCIMP DOWNLINEATCIMP -0.403695561
117 DOWNLINEATCIMP   UPLINEATCIMP  0.365833687
151   UPLINEATCIMP DOWNLINEATCIMP  0.365833687
233         xDURN2     TRNRANKGRP  0.361347207
301     TRNRANKGRP         xDURN2  0.361347207
34        ARRSPOKE      SKDARRSTA  0.345987375
272      SKDARRSTA       ARRSPOKE  0.345987375
15        DEPSPOKE      SKDDEPSTA  0.332823310
253      SKDDEPSTA       DEPSPOKE  0.332823310
26    DEPSTAATCIMP      SKDARRSTA -0.322204878
128      SKDARRSTA   DEPSTAATCIMP -0.322204878
33        DEPSPOKE      SKDARRSTA -0.318093195
254      SKDARRSTA       DEPSPOKE -0.318093195
81  DOWNLINEATCIMP          AVGSQ  0.298096458
149          AVGSQ DOWNLINEATCIMP  0.298096458
16        ARRSPOKE      SKDDEPSTA -0.298036487
271      SKDDEPSTA       ARRSPOKE -0.298036487
9   DOWNLINEATCIMP      SKDDEPSTA -0.285911992
145      SKDDEPSTA DOWNLINEATCIMP -0.285911992
269         xDURN2       DEPSPOKE  0.279030910
303       DEPSPOKE         xDURN2  0.279030910
178       ARRSPOKE      DEPBUCKET  0.276615722
280      DEPBUCKET       ARRSPOKE  0.276615722
154      DEPBUCKET DOWNLINEATCIMP  0.275167866
171 DOWNLINEATCIMP      DEPBUCKET  0.275167866
158     ARRRANKGRP DOWNLINEATCIMP -0.274110143
243 DOWNLINEATCIMP     ARRRANKGRP -0.274110143
3           SKDEQP      SKDDEPSTA  0.270065872
37       SKDDEPSTA         SKDEQP  0.270065872
2        SKDARRSTA      SKDDEPSTA -0.263453106
19       SKDDEPSTA      SKDARRSTA -0.263453106
49      TRNRANKGRP         SKDEQP  0.262837233
219         SKDEQP     TRNRANKGRP  0.262837233
287         xDURN2       ARRSPOKE -0.261107447
304       ARRSPOKE         xDURN2 -0.261107447
155      ARRBUCKET DOWNLINEATCIMP  0.255480148
189 DOWNLINEATCIMP      ARRBUCKET  0.255480148
231       DEPSPOKE     TRNRANKGRP  0.242138220
265     TRNRANKGRP       DEPSPOKE  0.242138220
48      DEPRANKGRP         SKDEQP  0.239915140
201         SKDEQP     DEPRANKGRP  0.239915140
126   xAVGSKDAVAIL   UPLINEATCIMP  0.234867014
313   UPLINEATCIMP   xAVGSKDAVAIL  0.234867014
177       DEPSPOKE      DEPBUCKET -0.231298301
262      DEPBUCKET       DEPSPOKE -0.231298301
214       ARRSPOKE     DEPRANKGRP -0.229640758
282     DEPRANKGRP       ARRSPOKE -0.229640758
161         xDURN2 DOWNLINEATCIMP -0.226093423
297 DOWNLINEATCIMP         xDURN2 -0.226093423
196       ARRSPOKE      ARRBUCKET  0.225890655
281      ARRBUCKET       ARRSPOKE  0.225890655
232       ARRSPOKE     TRNRANKGRP -0.225591539
283     TRNRANKGRP       ARRSPOKE -0.225591539
157     TRNRANKGRP DOWNLINEATCIMP -0.224193213
225 DOWNLINEATCIMP     TRNRANKGRP -0.224193213
25    UPLINEATCIMP      SKDARRSTA  0.223824406
110      SKDARRSTA   UPLINEATCIMP  0.223824406
88        ARRSPOKE          AVGSQ  0.219975654
275          AVGSQ       ARRSPOKE  0.219975654
270   xAVGSKDAVAIL       DEPSPOKE -0.212821518
321       DEPSPOKE   xAVGSKDAVAIL -0.212821518
40          SKDEPS         SKDEQP  0.212586898
57          SKDEQP         SKDEPS  0.212586898
213       DEPSPOKE     DEPRANKGRP  0.208188512
264     DEPRANKGRP       DEPSPOKE  0.208188512
156     DEPRANKGRP DOWNLINEATCIMP -0.199411990
207 DOWNLINEATCIMP     DEPRANKGRP -0.199411990
89          xDURN2          AVGSQ -0.197447957
293          AVGSQ         xDURN2 -0.197447957
195       DEPSPOKE      ARRBUCKET -0.189934966
263      ARRBUCKET       DEPSPOKE -0.189934966
87        DEPSPOKE          AVGSQ -0.188666787
257          AVGSQ       DEPSPOKE -0.188666787
85      TRNRANKGRP          AVGSQ -0.188226304
221          AVGSQ     TRNRANKGRP -0.188226304
179         xDURN2      DEPBUCKET -0.183349624
298      DEPBUCKET         xDURN2 -0.183349624
215         xDURN2     DEPRANKGRP  0.180043357
300     DEPRANKGRP         xDURN2  0.180043357
125         xDURN2   UPLINEATCIMP -0.173240320
295   UPLINEATCIMP         xDURN2 -0.173240320
198   xAVGSKDAVAIL      ARRBUCKET -0.170644257
317      ARRBUCKET   xAVGSKDAVAIL -0.170644257
175     TRNRANKGRP      DEPBUCKET -0.170618431
226      DEPBUCKET     TRNRANKGRP -0.170618431
30      DEPRANKGRP      SKDARRSTA -0.167375913
200      SKDARRSTA     DEPRANKGRP -0.167375913
10       DEPBUCKET      SKDDEPSTA -0.165029385
163      SKDDEPSTA      DEPBUCKET -0.165029385
7     UPLINEATCIMP      SKDDEPSTA -0.164964952
109      SKDDEPSTA   UPLINEATCIMP -0.164964952
84      DEPRANKGRP          AVGSQ -0.161451853
203          AVGSQ     DEPRANKGRP -0.161451853
86      ARRRANKGRP          AVGSQ -0.159135469
239          AVGSQ     ARRRANKGRP -0.159135469
174     DEPRANKGRP      DEPBUCKET -0.155547085
208      DEPBUCKET     DEPRANKGRP -0.155547085
5            AVGSQ      SKDDEPSTA -0.150522366
73       SKDDEPSTA          AVGSQ -0.150522366
139     TRNRANKGRP   DEPSTAATCIMP -0.147409309
224   DEPSTAATCIMP     TRNRANKGRP -0.147409309
118      DEPBUCKET   UPLINEATCIMP  0.144940797
169   UPLINEATCIMP      DEPBUCKET  0.144940797
176     ARRRANKGRP      DEPBUCKET -0.142348062
244      DEPBUCKET     ARRRANKGRP -0.142348062
144   xAVGSKDAVAIL   DEPSTAATCIMP -0.141077194
314   DEPSTAATCIMP   xAVGSKDAVAIL -0.141077194
103     TRNRANKGRP      AVGLOFATC  0.139184315
222      AVGLOFATC     TRNRANKGRP  0.139184315
136      DEPBUCKET   DEPSTAATCIMP -0.138581846
170   DEPSTAATCIMP      DEPBUCKET -0.138581846
288   xAVGSKDAVAIL       ARRSPOKE  0.137677242
322       ARRSPOKE   xAVGSKDAVAIL  0.137677242
212     ARRRANKGRP     DEPRANKGRP  0.136562948
246     DEPRANKGRP     ARRRANKGRP  0.136562948
98    DEPSTAATCIMP      AVGLOFATC -0.135778614
132      AVGLOFATC   DEPSTAATCIMP -0.135778614
107         xDURN2      AVGLOFATC -0.132084629
294      AVGLOFATC         xDURN2 -0.132084629
216   xAVGSKDAVAIL     DEPRANKGRP  0.130574789
318     DEPRANKGRP   xAVGSKDAVAIL  0.130574789
194     ARRRANKGRP      ARRBUCKET -0.129698517
245      ARRBUCKET     ARRRANKGRP -0.129698517
137      ARRBUCKET   DEPSTAATCIMP -0.127726148
188   DEPSTAATCIMP      ARRBUCKET -0.127726148
17          xDURN2      SKDDEPSTA  0.127598189
289      SKDDEPSTA         xDURN2  0.127598189
99  DOWNLINEATCIMP      AVGLOFATC -0.126763572
150      AVGLOFATC DOWNLINEATCIMP -0.126763572
197         xDURN2      ARRBUCKET -0.125836459
299      ARRBUCKET         xDURN2 -0.125836459
138     DEPRANKGRP   DEPSTAATCIMP  0.124672682
206   DEPSTAATCIMP     DEPRANKGRP  0.124672682
62    DEPSTAATCIMP         SKDEPS -0.123445793
130         SKDEPS   DEPSTAATCIMP -0.123445793
11       ARRBUCKET      SKDDEPSTA -0.120728212
181      SKDDEPSTA      ARRBUCKET -0.120728212
251         xDURN2     ARRRANKGRP  0.119675180
302     ARRRANKGRP         xDURN2  0.119675180
90    xAVGSKDAVAIL          AVGSQ -0.113720147
311          AVGSQ   xAVGSKDAVAIL -0.113720147
31      TRNRANKGRP      SKDARRSTA -0.105802023
218      SKDARRSTA     TRNRANKGRP -0.105802023
192     DEPRANKGRP      ARRBUCKET -0.105057984
209      ARRBUCKET     DEPRANKGRP -0.105057984
162   xAVGSKDAVAIL DOWNLINEATCIMP  0.102577364
315 DOWNLINEATCIMP   xAVGSKDAVAIL  0.102577364
120     DEPRANKGRP   UPLINEATCIMP -0.097218129
205   UPLINEATCIMP     DEPRANKGRP -0.097218129
121     TRNRANKGRP   UPLINEATCIMP -0.097037814
223   UPLINEATCIMP     TRNRANKGRP -0.097037814
22          SKDEPS      SKDARRSTA -0.096699169
56       SKDARRSTA         SKDEPS -0.096699169
63  DOWNLINEATCIMP         SKDEPS -0.095568613
148         SKDEPS DOWNLINEATCIMP -0.095568613
24       AVGLOFATC      SKDARRSTA -0.095234466
92       SKDARRSTA      AVGLOFATC -0.095234466
21          SKDEQP      SKDARRSTA  0.094073459
38       SKDARRSTA         SKDEQP  0.094073459
29       ARRBUCKET      SKDARRSTA  0.092625400
182      SKDARRSTA      ARRBUCKET  0.092625400
193     TRNRANKGRP      ARRBUCKET -0.092415252
227      ARRBUCKET     TRNRANKGRP -0.092415252
234   xAVGSKDAVAIL     TRNRANKGRP  0.092011501
319     TRNRANKGRP   xAVGSKDAVAIL  0.092011501
18    xAVGSKDAVAIL      SKDDEPSTA  0.088580325
307      SKDDEPSTA   xAVGSKDAVAIL  0.088580325
53          xDURN2         SKDEQP  0.086170070
291         SKDEQP         xDURN2  0.086170070
102     DEPRANKGRP      AVGLOFATC  0.085474019
204      AVGLOFATC     DEPRANKGRP  0.085474019
97    UPLINEATCIMP      AVGLOFATC -0.085180887
114      AVGLOFATC   UPLINEATCIMP -0.085180887
230     ARRRANKGRP     TRNRANKGRP  0.083906762
247     TRNRANKGRP     ARRRANKGRP  0.083906762
249       DEPSPOKE     ARRRANKGRP  0.083162083
266     ARRRANKGRP       DEPSPOKE  0.083162083
23           AVGSQ      SKDARRSTA  0.082898864
74       SKDARRSTA          AVGSQ  0.082898864
68      ARRRANKGRP         SKDEPS  0.080398834
238         SKDEPS     ARRRANKGRP  0.080398834
72    xAVGSKDAVAIL         SKDEPS  0.075169577
310         SKDEPS   xAVGSKDAVAIL  0.075169577
140     ARRRANKGRP   DEPSTAATCIMP  0.073371196
242   DEPSTAATCIMP     ARRRANKGRP  0.073371196
28       DEPBUCKET      SKDARRSTA  0.072910977
164      SKDARRSTA      DEPBUCKET  0.072910977
119      ARRBUCKET   UPLINEATCIMP  0.071409699
187   UPLINEATCIMP      ARRBUCKET  0.071409699
122     ARRRANKGRP   UPLINEATCIMP -0.069790367
241   UPLINEATCIMP     ARRRANKGRP -0.069790367
14      ARRRANKGRP      SKDDEPSTA  0.068927801
235      SKDDEPSTA     ARRRANKGRP  0.068927801
52        ARRSPOKE         SKDEQP  0.066579707
273         SKDEQP       ARRSPOKE  0.066579707
79    UPLINEATCIMP          AVGSQ  0.062631172
113          AVGSQ   UPLINEATCIMP  0.062631172
104     ARRRANKGRP      AVGLOFATC -0.061491190
240      AVGLOFATC     ARRRANKGRP -0.061491190
250       ARRSPOKE     ARRRANKGRP -0.057002549
284     ARRRANKGRP       ARRSPOKE -0.057002549
108   xAVGSKDAVAIL      AVGLOFATC -0.056264979
312      AVGLOFATC   xAVGSKDAVAIL -0.056264979
100      DEPBUCKET      AVGLOFATC -0.053357134
168      AVGLOFATC      DEPBUCKET -0.053357134
180   xAVGSKDAVAIL      DEPBUCKET -0.053125467
316      DEPBUCKET   xAVGSKDAVAIL -0.053125467
6        AVGLOFATC      SKDDEPSTA -0.044946507
91       SKDDEPSTA      AVGLOFATC -0.044946507
101      ARRBUCKET      AVGLOFATC -0.043093769
186      AVGLOFATC      ARRBUCKET -0.043093769
50      ARRRANKGRP         SKDEQP -0.042512956
237         SKDEQP     ARRRANKGRP -0.042512956
80    DEPSTAATCIMP          AVGSQ -0.040428658
131          AVGSQ   DEPSTAATCIMP -0.040428658
59           AVGSQ         SKDEPS -0.038820886
76          SKDEPS          AVGSQ -0.038820886
46       DEPBUCKET         SKDEQP  0.037125178
165         SKDEQP      DEPBUCKET  0.037125178
106       ARRSPOKE      AVGLOFATC -0.034402462
276      AVGLOFATC       ARRSPOKE -0.034402462
54    xAVGSKDAVAIL         SKDEQP  0.031863410
309         SKDEQP   xAVGSKDAVAIL  0.031863410
67      TRNRANKGRP         SKDEPS  0.030883560
220         SKDEPS     TRNRANKGRP  0.030883560
64       DEPBUCKET         SKDEPS -0.030101407
166         SKDEPS      DEPBUCKET -0.030101407
35          xDURN2      SKDARRSTA  0.027576751
290      SKDARRSTA         xDURN2  0.027576751
78       AVGLOFATC          AVGSQ -0.027382453
95           AVGSQ      AVGLOFATC -0.027382453
36    xAVGSKDAVAIL      SKDARRSTA  0.027225219
308      SKDARRSTA   xAVGSKDAVAIL  0.027225219
66      DEPRANKGRP         SKDEPS  0.027025501
202         SKDEPS     DEPRANKGRP  0.027025501
4           SKDEPS      SKDDEPSTA -0.024267794
55       SKDDEPSTA         SKDEPS -0.024267794
43    UPLINEATCIMP         SKDEQP -0.019807499
111         SKDEQP   UPLINEATCIMP -0.019807499
51        DEPSPOKE         SKDEQP  0.019755644
255         SKDEQP       DEPSPOKE  0.019755644
306   xAVGSKDAVAIL         xDURN2 -0.019255572
323         xDURN2   xAVGSKDAVAIL -0.019255572
252   xAVGSKDAVAIL     ARRRANKGRP -0.018743432
320     ARRRANKGRP   xAVGSKDAVAIL -0.018743432
143         xDURN2   DEPSTAATCIMP -0.017999758
296   DEPSTAATCIMP         xDURN2 -0.017999758
45  DOWNLINEATCIMP         SKDEQP -0.017658860
147         SKDEQP DOWNLINEATCIMP -0.017658860
70        ARRSPOKE         SKDEPS  0.017573485
274         SKDEPS       ARRSPOKE  0.017573485
65       ARRBUCKET         SKDEPS  0.017414895
184         SKDEPS      ARRBUCKET  0.017414895
32      ARRRANKGRP      SKDARRSTA  0.016733374
236      SKDARRSTA     ARRRANKGRP  0.016733374
41           AVGSQ         SKDEQP  0.010218807
75          SKDEQP          AVGSQ  0.010218807
47       ARRBUCKET         SKDEQP  0.009926479
183         SKDEQP      ARRBUCKET  0.009926479
105       DEPSPOKE      AVGLOFATC -0.008540402
258      AVGLOFATC       DEPSPOKE -0.008540402
60       AVGLOFATC         SKDEPS  0.008240563
94          SKDEPS      AVGLOFATC  0.008240563
44    DEPSTAATCIMP         SKDEQP -0.005922601
129         SKDEQP   DEPSTAATCIMP -0.005922601
42       AVGLOFATC         SKDEQP -0.004889040
93          SKDEQP      AVGLOFATC -0.004889040
69        DEPSPOKE         SKDEPS -0.004617067
256         SKDEPS       DEPSPOKE -0.004617067
61    UPLINEATCIMP         SKDEPS  0.004016263
112         SKDEPS   UPLINEATCIMP  0.004016263
71          xDURN2         SKDEPS  0.001748012
292         SKDEPS         xDURN2  0.001748012
> tr.cols <- colnames(trainDescr)
> tr.cols
 [1] "SKDDEPSTA"      "SKDARRSTA"      "SKDEQP"         "SKDEPS"        
 [5] "AVGSQ"          "AVGLOFATC"      "UPLINEATCIMP"   "DEPSTAATCIMP"  
 [9] "DOWNLINEATCIMP" "DEPBUCKET"      "ARRBUCKET"      "DEPRANKGRP"    
[13] "TRNRANKGRP"     "ARRRANKGRP"     "DEPSPOKE"       "ARRSPOKE"      
[17] "xDURN2"         "xAVGSKDAVAIL"  
> tr.icols <- grep("((STA|EQP)$)|(^xD)", tr.cols)
> tr.icols <- rev(tr.icols)
> fitControl <- trainControl(## 10-fold CV
+     method = "repeatedcv",
+     number = 10,
+     ## repeated ten times
+     repeats = 10,
+     classProbs = TRUE,
+     summaryFunction = twoClassSummary)
> gbmGrid <- expand.grid(interaction.depth = 
+                            c(length(colnames(trainDescr)), 1),
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.2,
+                         n.minobsinnode = 10)
> set.seed(seed.mine)
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "Kappa",
+                  verbose = FALSE)
Loading required package: gbm
Loading required package: survival

Attaching package: 'survival'

The following object is masked from 'package:caret':

    cluster

Loading required package: splines
Loaded gbm 2.1.1
Loading required package: plyr
Warning message:
In train.default(trainDescr, trainClass, method = "gbm", trControl = fitControl,  :
  The metric "Kappa" was not in the result set. ROC will be used instead.
> gbmFit1
Stochastic Gradient Boosting 

248 samples
 18 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 222, 223, 223, 224, 223, 223, ... 

Resampling results across tuning parameters:

  interaction.depth  n.trees  ROC        Sens       Spec       ROC SD    
   1                   90     0.7811339  0.7382967  0.7029545  0.08319165
   1                  180     0.7763437  0.7234066  0.7040909  0.08696037
   1                  270     0.7783845  0.7218132  0.7050000  0.08421748
   1                  360     0.7758800  0.7161538  0.7092424  0.08512409
   1                  450     0.7700296  0.7135714  0.6868182  0.08379250
   1                  540     0.7687637  0.7103846  0.6978788  0.08311648
   1                  630     0.7678634  0.7139560  0.6950758  0.08539494
   1                  720     0.7670609  0.7229121  0.6968939  0.08542038
   1                  810     0.7647794  0.7149451  0.6932576  0.08800892
   1                  900     0.7628563  0.7127473  0.6960606  0.08931207
   1                  990     0.7637184  0.7182967  0.6815909  0.09033694
   1                 1080     0.7611072  0.7181319  0.6831818  0.08977929
   1                 1170     0.7605453  0.7196154  0.6814394  0.08975140
   1                 1260     0.7626399  0.7180769  0.6823485  0.09094180
   1                 1350     0.7649038  0.7209341  0.6822727  0.08815589
   1                 1440     0.7636555  0.7186813  0.6815152  0.08932488
   1                 1530     0.7613024  0.7187363  0.6787121  0.09076178
   1                 1620     0.7558183  0.7157143  0.6680303  0.09815624
   1                 1710     0.7603742  0.7163187  0.6743939  0.08826350
   1                 1800     0.7570967  0.7207692  0.6690152  0.09470472
   1                 1890     0.7601270  0.7207692  0.6680303  0.08842924
   1                 1980     0.7577269  0.7217033  0.6618182  0.09124220
   1                 2070     0.7576249  0.7194505  0.6627273  0.09163044
   1                 2160     0.7579254  0.7201099  0.6618182  0.09180109
   1                 2250     0.7600208  0.7222527  0.6618939  0.09107760
   1                 2340     0.7573389  0.7209890  0.6582576  0.09062144
   1                 2430     0.7578018  0.7267033  0.6618182  0.09330800
   1                 2520     0.7571083  0.7215385  0.6645455  0.09024002
   1                 2610     0.7565052  0.7237363  0.6608333  0.09154974
   1                 2700     0.7549209  0.7215934  0.6690152  0.09082254
  18                   90     0.7416346  0.7115934  0.6433333  0.09827257
  18                  180     0.7407468  0.7116484  0.6445455  0.10217676
  18                  270     0.7432201  0.7153846  0.6606818  0.09325125
  18                  360     0.7457413  0.7115385  0.6497727  0.09415398
  18                  450     0.7474854  0.7118132  0.6478788  0.09529465
  18                  540     0.7467037  0.7109890  0.6516667  0.09401062
  18                  630     0.7471737  0.7131319  0.6495455  0.09469197
  18                  720     0.7480698  0.7191209  0.6532576  0.09152939
  18                  810     0.7488453  0.7168132  0.6460606  0.09072571
  18                  900     0.7483412  0.7188462  0.6435606  0.09052522
  18                  990     0.7481202  0.7174725  0.6390152  0.08953055
  18                 1080     0.7476511  0.7151099  0.6408333  0.08944807
  18                 1170     0.7476977  0.7196154  0.6390152  0.09081915
  18                 1260     0.7460410  0.7129670  0.6325758  0.09622036
  18                 1350     0.7449519  0.7165934  0.6315909  0.09607643
  18                 1440     0.7468361  0.7181868  0.6342424  0.09218728
  18                 1530     0.7457582  0.7167582  0.6352273  0.09296214
  18                 1620     0.7454606  0.7160440  0.6397727  0.09322094
  18                 1710     0.7449892  0.7137912  0.6416667  0.09401712
  18                 1800     0.7442227  0.7057692  0.6568939  0.09496933
  18                 1890     0.7461103  0.6925275  0.6712121  0.09390657
  18                 1980     0.7447940  0.6846703  0.6912121  0.09422774
  18                 2070     0.7455386  0.6817582  0.7028788  0.09346136
  18                 2160     0.7451694  0.6680220  0.7191667  0.09248349
  18                 2250     0.7409649  0.6592857  0.7334848  0.09860280
  18                 2340     0.7391230  0.6506044  0.7380303  0.09969164
  18                 2430     0.7394603  0.6470879  0.7451515  0.09929998
  18                 2520     0.7379389  0.6384615  0.7532576  0.10026153
  18                 2610     0.7366910  0.6304945  0.7596212  0.10035411
  18                 2700     0.7370265  0.6217582  0.7631818  0.09946363
  Sens SD    Spec SD  
  0.1142082  0.1281462
  0.1097352  0.1306884
  0.1087230  0.1348065
  0.1087751  0.1330925
  0.1132779  0.1470225
  0.1152783  0.1402669
  0.1109446  0.1440758
  0.1191648  0.1335174
  0.1185954  0.1391891
  0.1102422  0.1433129
  0.1172990  0.1354057
  0.1170378  0.1288548
  0.1187063  0.1370564
  0.1170279  0.1370559
  0.1195838  0.1365116
  0.1213826  0.1306533
  0.1180526  0.1333158
  0.1141494  0.1340326
  0.1215750  0.1339184
  0.1211648  0.1396764
  0.1147695  0.1401226
  0.1184670  0.1398581
  0.1155967  0.1414571
  0.1153828  0.1407383
  0.1143463  0.1374926
  0.1111225  0.1356856
  0.1149560  0.1418256
  0.1098815  0.1428664
  0.1113021  0.1386481
  0.1098542  0.1414334
  0.1200628  0.1307809
  0.1092541  0.1318536
  0.1139285  0.1260434
  0.1181632  0.1314449
  0.1137527  0.1243635
  0.1164199  0.1294008
  0.1157245  0.1256211
  0.1187341  0.1349872
  0.1168002  0.1252951
  0.1167392  0.1282189
  0.1183583  0.1342314
  0.1183227  0.1352242
  0.1153422  0.1336081
  0.1208946  0.1288509
  0.1194942  0.1270985
  0.1228914  0.1292578
  0.1220875  0.1291379
  0.1227314  0.1281239
  0.1213427  0.1231503
  0.1212176  0.1188421
  0.1225326  0.1155361
  0.1162939  0.1119745
  0.1161332  0.1208557
  0.1144017  0.1218953
  0.1160671  0.1212713
  0.1174996  0.1233417
  0.1180324  0.1238171
  0.1186769  0.1175766
  0.1180415  0.1217173
  0.1201091  0.1210284

Tuning parameter 'shrinkage' was held constant at a value of 0.2

Tuning parameter 'n.minobsinnode' was held constant at a value of 10
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 90, interaction.depth =
 1, shrinkage = 0.2 and n.minobsinnode = 10. 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
  Accuracy      Kappa 
 0.4305556 -0.1424149 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     18   19
    Weak       22   13
                                          
               Accuracy : 0.4306          
                 95% CI : (0.3143, 0.5527)
    No Information Rate : 0.5556          
    P-Value [Acc > NIR] : 0.9876          
                                          
                  Kappa : -0.1424         
 Mcnemar's Test P-Value : 0.7548          
                                          
            Sensitivity : 0.4062          
            Specificity : 0.4500          
         Pos Pred Value : 0.3714          
         Neg Pred Value : 0.4865          
             Prevalence : 0.4444          
         Detection Rate : 0.1806          
   Detection Prevalence : 0.4861          
      Balanced Accuracy : 0.4281          
                                          
       'Positive' Class : Weak            
                                          
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
 Accuracy     Kappa 
0.8185484 0.6327498 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    115   23
    Weak       22   88
                                          
               Accuracy : 0.8185          
                 95% CI : (0.7648, 0.8645)
    No Information Rate : 0.5524          
    P-Value [Acc > NIR] : <2e-16          
                                          
                  Kappa : 0.6327          
 Mcnemar's Test P-Value : 1               
                                          
            Sensitivity : 0.7928          
            Specificity : 0.8394          
         Pos Pred Value : 0.8000          
         Neg Pred Value : 0.8333          
             Prevalence : 0.4476          
         Detection Rate : 0.3548          
   Detection Prevalence : 0.4435          
      Balanced Accuracy : 0.8161          
                                          
       'Positive' Class : Weak            
                                          
> trellis.par.set(caretTheme())
Warning message:
In trellis.par.set(caretTheme()) :
  Note: The default device has been opened to honour attempt to modify trellis settings
> plot(gbmFit1, metric = "ROC")
> gbmGrid <- expand.grid(interaction.depth = 
+                            c(length(colnames(trainDescr))-1, 1),
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.2,
+                         n.minobsinnode = 10)
> update.train(gbmFit1, tuneGrid = gbmGrid)
Error: could not find function "update.train"
> update(gbmFit1, tuneGrid = gbmGrid)
Stochastic Gradient Boosting 

248 samples
 18 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 222, 223, 223, 224, 223, 223, ... 

Resampling results across tuning parameters:

  interaction.depth  n.trees  ROC        Sens       Spec       ROC SD    
   1                   90     0.7811339  0.7382967  0.7029545  0.08319165
   1                  180     0.7763437  0.7234066  0.7040909  0.08696037
   1                  270     0.7783845  0.7218132  0.7050000  0.08421748
   1                  360     0.7758800  0.7161538  0.7092424  0.08512409
   1                  450     0.7700296  0.7135714  0.6868182  0.08379250
   1                  540     0.7687637  0.7103846  0.6978788  0.08311648
   1                  630     0.7678634  0.7139560  0.6950758  0.08539494
   1                  720     0.7670609  0.7229121  0.6968939  0.08542038
   1                  810     0.7647794  0.7149451  0.6932576  0.08800892
   1                  900     0.7628563  0.7127473  0.6960606  0.08931207
   1                  990     0.7637184  0.7182967  0.6815909  0.09033694
   1                 1080     0.7611072  0.7181319  0.6831818  0.08977929
   1                 1170     0.7605453  0.7196154  0.6814394  0.08975140
   1                 1260     0.7626399  0.7180769  0.6823485  0.09094180
   1                 1350     0.7649038  0.7209341  0.6822727  0.08815589
   1                 1440     0.7636555  0.7186813  0.6815152  0.08932488
   1                 1530     0.7613024  0.7187363  0.6787121  0.09076178
   1                 1620     0.7558183  0.7157143  0.6680303  0.09815624
   1                 1710     0.7603742  0.7163187  0.6743939  0.08826350
   1                 1800     0.7570967  0.7207692  0.6690152  0.09470472
   1                 1890     0.7601270  0.7207692  0.6680303  0.08842924
   1                 1980     0.7577269  0.7217033  0.6618182  0.09124220
   1                 2070     0.7576249  0.7194505  0.6627273  0.09163044
   1                 2160     0.7579254  0.7201099  0.6618182  0.09180109
   1                 2250     0.7600208  0.7222527  0.6618939  0.09107760
   1                 2340     0.7573389  0.7209890  0.6582576  0.09062144
   1                 2430     0.7578018  0.7267033  0.6618182  0.09330800
   1                 2520     0.7571083  0.7215385  0.6645455  0.09024002
   1                 2610     0.7565052  0.7237363  0.6608333  0.09154974
   1                 2700     0.7549209  0.7215934  0.6690152  0.09082254
  18                   90     0.7416346  0.7115934  0.6433333  0.09827257
  18                  180     0.7407468  0.7116484  0.6445455  0.10217676
  18                  270     0.7432201  0.7153846  0.6606818  0.09325125
  18                  360     0.7457413  0.7115385  0.6497727  0.09415398
  18                  450     0.7474854  0.7118132  0.6478788  0.09529465
  18                  540     0.7467037  0.7109890  0.6516667  0.09401062
  18                  630     0.7471737  0.7131319  0.6495455  0.09469197
  18                  720     0.7480698  0.7191209  0.6532576  0.09152939
  18                  810     0.7488453  0.7168132  0.6460606  0.09072571
  18                  900     0.7483412  0.7188462  0.6435606  0.09052522
  18                  990     0.7481202  0.7174725  0.6390152  0.08953055
  18                 1080     0.7476511  0.7151099  0.6408333  0.08944807
  18                 1170     0.7476977  0.7196154  0.6390152  0.09081915
  18                 1260     0.7460410  0.7129670  0.6325758  0.09622036
  18                 1350     0.7449519  0.7165934  0.6315909  0.09607643
  18                 1440     0.7468361  0.7181868  0.6342424  0.09218728
  18                 1530     0.7457582  0.7167582  0.6352273  0.09296214
  18                 1620     0.7454606  0.7160440  0.6397727  0.09322094
  18                 1710     0.7449892  0.7137912  0.6416667  0.09401712
  18                 1800     0.7442227  0.7057692  0.6568939  0.09496933
  18                 1890     0.7461103  0.6925275  0.6712121  0.09390657
  18                 1980     0.7447940  0.6846703  0.6912121  0.09422774
  18                 2070     0.7455386  0.6817582  0.7028788  0.09346136
  18                 2160     0.7451694  0.6680220  0.7191667  0.09248349
  18                 2250     0.7409649  0.6592857  0.7334848  0.09860280
  18                 2340     0.7391230  0.6506044  0.7380303  0.09969164
  18                 2430     0.7394603  0.6470879  0.7451515  0.09929998
  18                 2520     0.7379389  0.6384615  0.7532576  0.10026153
  18                 2610     0.7366910  0.6304945  0.7596212  0.10035411
  18                 2700     0.7370265  0.6217582  0.7631818  0.09946363
  Sens SD    Spec SD  
  0.1142082  0.1281462
  0.1097352  0.1306884
  0.1087230  0.1348065
  0.1087751  0.1330925
  0.1132779  0.1470225
  0.1152783  0.1402669
  0.1109446  0.1440758
  0.1191648  0.1335174
  0.1185954  0.1391891
  0.1102422  0.1433129
  0.1172990  0.1354057
  0.1170378  0.1288548
  0.1187063  0.1370564
  0.1170279  0.1370559
  0.1195838  0.1365116
  0.1213826  0.1306533
  0.1180526  0.1333158
  0.1141494  0.1340326
  0.1215750  0.1339184
  0.1211648  0.1396764
  0.1147695  0.1401226
  0.1184670  0.1398581
  0.1155967  0.1414571
  0.1153828  0.1407383
  0.1143463  0.1374926
  0.1111225  0.1356856
  0.1149560  0.1418256
  0.1098815  0.1428664
  0.1113021  0.1386481
  0.1098542  0.1414334
  0.1200628  0.1307809
  0.1092541  0.1318536
  0.1139285  0.1260434
  0.1181632  0.1314449
  0.1137527  0.1243635
  0.1164199  0.1294008
  0.1157245  0.1256211
  0.1187341  0.1349872
  0.1168002  0.1252951
  0.1167392  0.1282189
  0.1183583  0.1342314
  0.1183227  0.1352242
  0.1153422  0.1336081
  0.1208946  0.1288509
  0.1194942  0.1270985
  0.1228914  0.1292578
  0.1220875  0.1291379
  0.1227314  0.1281239
  0.1213427  0.1231503
  0.1212176  0.1188421
  0.1225326  0.1155361
  0.1162939  0.1119745
  0.1161332  0.1208557
  0.1144017  0.1218953
  0.1160671  0.1212713
  0.1174996  0.1233417
  0.1180324  0.1238171
  0.1186769  0.1175766
  0.1180415  0.1217173
  0.1201091  0.1210284

Tuning parameter 'shrinkage' was held constant at a value of 0.2

Tuning parameter 'n.minobsinnode' was held constant at a value of 10
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 90, interaction.depth =
 1, shrinkage = 0.2 and n.minobsinnode = 10. 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
  Accuracy      Kappa 
 0.4305556 -0.1424149 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     18   19
    Weak       22   13
                                          
               Accuracy : 0.4306          
                 95% CI : (0.3143, 0.5527)
    No Information Rate : 0.5556          
    P-Value [Acc > NIR] : 0.9876          
                                          
                  Kappa : -0.1424         
 Mcnemar's Test P-Value : 0.7548          
                                          
            Sensitivity : 0.4062          
            Specificity : 0.4500          
         Pos Pred Value : 0.3714          
         Neg Pred Value : 0.4865          
             Prevalence : 0.4444          
         Detection Rate : 0.1806          
   Detection Prevalence : 0.4861          
      Balanced Accuracy : 0.4281          
                                          
       'Positive' Class : Weak            
                                          
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
 Accuracy     Kappa 
0.8185484 0.6327498 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    115   23
    Weak       22   88
                                          
               Accuracy : 0.8185          
                 95% CI : (0.7648, 0.8645)
    No Information Rate : 0.5524          
    P-Value [Acc > NIR] : <2e-16          
                                          
                  Kappa : 0.6327          
 Mcnemar's Test P-Value : 1               
                                          
            Sensitivity : 0.7928          
            Specificity : 0.8394          
         Pos Pred Value : 0.8000          
         Neg Pred Value : 0.8333          
             Prevalence : 0.4476          
         Detection Rate : 0.3548          
   Detection Prevalence : 0.4435          
      Balanced Accuracy : 0.8161          
                                          
       'Positive' Class : Weak            
                                          
> trellis.par.set(caretTheme())
Warning message:
In trellis.par.set(caretTheme()) :
  Note: The default device has been opened to honour attempt to modify trellis settings
> plot(gbmFit1, metric = "ROC")
> gbmGrid <- expand.grid(interaction.depth = 
+                            c(length(colnames(trainDescr))-1, 1),
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.2,
+                         n.minobsinnode = 10)
> fitControl <- trainControl(## 10-fold CV
+     method = "repeatedcv",
+     number = 10,
+     ## repeated ten times
+     repeats = 10,
+     classProbs = TRUE,
+     summaryFunction = twoClassSummary)
> 
> ## Some trial and error with variables to branch and boost.
> ## Try all variables
> 
> gbmGrid <- expand.grid(interaction.depth = 
+                            c(length(colnames(trainDescr))-1, 1),
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.2,
+                         n.minobsinnode = 10)
> 
> set.seed(seed.mine)
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "Kappa",
+                  verbose = FALSE)
Warning message:
In train.default(trainDescr, trainClass, method = "gbm", trControl = fitControl,  :
  The metric "Kappa" was not in the result set. ROC will be used instead.
> gbmFit1
Stochastic Gradient Boosting 

248 samples
 18 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 222, 223, 223, 224, 223, 223, ... 

Resampling results across tuning parameters:

  interaction.depth  n.trees  ROC        Sens       Spec       ROC SD    
   1                   90     0.7876240  0.7295055  0.7091667  0.07903857
   1                  180     0.7812646  0.7212088  0.7017424  0.07547646
   1                  270     0.7712841  0.7139011  0.6933333  0.08213448
   1                  360     0.7721953  0.7183516  0.6906818  0.08168059
   1                  450     0.7706140  0.7189560  0.6933333  0.08398431
   1                  540     0.7685810  0.7130769  0.6880303  0.07889419
   1                  630     0.7715730  0.7165385  0.6809848  0.08177553
   1                  720     0.7695484  0.7124176  0.6899242  0.08082919
   1                  810     0.7660427  0.7205495  0.6924242  0.08180993
   1                  900     0.7642008  0.7225824  0.6818182  0.08863711
   1                  990     0.7667724  0.7205495  0.6771212  0.08310619
   1                 1080     0.7634307  0.7145055  0.6817424  0.08396681
   1                 1170     0.7639277  0.7153846  0.6817424  0.09026899
   1                 1260     0.7614356  0.7080220  0.6762121  0.08885290
   1                 1350     0.7610802  0.7049451  0.6743939  0.08903790
   1                 1440     0.7614019  0.7130220  0.6781061  0.08874181
   1                 1530     0.7591101  0.7107692  0.6690909  0.09074053
   1                 1620     0.7576773  0.7099451  0.6637879  0.09158104
   1                 1710     0.7577452  0.7158791  0.6654545  0.09132578
   1                 1800     0.7583129  0.7152198  0.6662121  0.08984568
   1                 1890     0.7600945  0.7173626  0.6645455  0.08542040
   1                 1980     0.7567562  0.7187912  0.6628030  0.09166384
   1                 2070     0.7557959  0.7179121  0.6680303  0.09713843
   1                 2160     0.7579958  0.7151648  0.6707576  0.09338578
   1                 2250     0.7617324  0.7120330  0.6709848  0.08618446
   1                 2340     0.7607201  0.7179121  0.6628030  0.08504277
   1                 2430     0.7613853  0.7193956  0.6617424  0.08511424
   1                 2520     0.7581976  0.7207692  0.6653788  0.09081914
   1                 2610     0.7596220  0.7208791  0.6636364  0.08368552
   1                 2700     0.7583179  0.7185714  0.6698485  0.08564839
  17                   90     0.7513690  0.7232418  0.6702273  0.09513848
  17                  180     0.7474297  0.7240659  0.6764394  0.10252599
  17                  270     0.7497465  0.7297253  0.6575000  0.09718910
  17                  360     0.7445117  0.7210440  0.6557576  0.09627929
  17                  450     0.7423514  0.7174176  0.6514394  0.09885907
  17                  540     0.7403222  0.7159890  0.6540909  0.10200340
  17                  630     0.7425962  0.7228022  0.6532576  0.10060280
  17                  720     0.7402106  0.7241758  0.6514394  0.10443618
  17                  810     0.7403147  0.7190659  0.6488636  0.10492133
  17                  900     0.7395442  0.7191209  0.6488636  0.10587551
  17                  990     0.7408467  0.7197802  0.6406818  0.10481175
  17                 1080     0.7413058  0.7197253  0.6441667  0.10177475
  17                 1170     0.7412975  0.7204945  0.6425000  0.10301364
  17                 1260     0.7405168  0.7206044  0.6459848  0.10143656
  17                 1350     0.7429427  0.7213187  0.6441667  0.09544679
  17                 1440     0.7425268  0.7184066  0.6432576  0.09670230
  17                 1530     0.7409451  0.7175275  0.6414394  0.09805333
  17                 1620     0.7407561  0.7176374  0.6440152  0.09803069
  17                 1710     0.7411649  0.7124176  0.6522727  0.09889977
  17                 1800     0.7397199  0.7072527  0.6577273  0.09920945
  17                 1890     0.7417951  0.7037912  0.6747727  0.09368882
  17                 1980     0.7416046  0.6986813  0.6901515  0.09345109
  17                 2070     0.7416404  0.6914835  0.7036364  0.09411113
  17                 2160     0.7422611  0.6834066  0.7144697  0.09466995
  17                 2250     0.7414494  0.6717582  0.7288636  0.09352966
  17                 2340     0.7398504  0.6592308  0.7315909  0.09601866
  17                 2430     0.7383849  0.6463187  0.7432576  0.09545818
  17                 2520     0.7370303  0.6397802  0.7478030  0.09912687
  17                 2610     0.7373158  0.6273626  0.7568939  0.09885604
  17                 2700     0.7371814  0.6244505  0.7587879  0.09486141
  Sens SD    Spec SD  
  0.1064274  0.1170560
  0.1136917  0.1327823
  0.1105024  0.1307046
  0.1109331  0.1410614
  0.1137366  0.1381313
  0.1123479  0.1412598
  0.1070339  0.1406368
  0.1123984  0.1370898
  0.1141692  0.1288261
  0.1095775  0.1321361
  0.1165456  0.1398219
  0.1141021  0.1299619
  0.1123978  0.1397668
  0.1126878  0.1382996
  0.1097666  0.1309682
  0.1131761  0.1345296
  0.1113663  0.1392115
  0.1089993  0.1387063
  0.1089014  0.1385136
  0.1122867  0.1328791
  0.1100878  0.1401048
  0.1108031  0.1396216
  0.1096268  0.1332823
  0.1071638  0.1306822
  0.1097738  0.1320231
  0.1084550  0.1311872
  0.1160139  0.1335603
  0.1097384  0.1340615
  0.1094954  0.1310436
  0.1082365  0.1342824
  0.1170538  0.1331869
  0.1164738  0.1355804
  0.1203449  0.1191295
  0.1186328  0.1289310
  0.1171569  0.1314212
  0.1227707  0.1323825
  0.1185236  0.1301239
  0.1217338  0.1224232
  0.1226016  0.1289583
  0.1203894  0.1320544
  0.1213123  0.1265619
  0.1218452  0.1262418
  0.1202789  0.1251591
  0.1176818  0.1277727
  0.1178597  0.1298412
  0.1185442  0.1289255
  0.1170028  0.1323336
  0.1171482  0.1262328
  0.1198536  0.1258464
  0.1214782  0.1224653
  0.1202343  0.1231257
  0.1188790  0.1213961
  0.1162584  0.1227060
  0.1186352  0.1231795
  0.1191836  0.1229044
  0.1201478  0.1253005
  0.1235333  0.1220362
  0.1213759  0.1264016
  0.1191267  0.1212795
  0.1204201  0.1186000

Tuning parameter 'shrinkage' was held constant at a value of 0.2

Tuning parameter 'n.minobsinnode' was held constant at a value of 10
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 90, interaction.depth =
 1, shrinkage = 0.2 and n.minobsinnode = 10. 
> 
> ## The acid test is dissapointing, but I've seen worse.
> 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
  Accuracy      Kappa 
 0.4305556 -0.1424149 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     18   19
    Weak       22   13
                                          
               Accuracy : 0.4306          
                 95% CI : (0.3143, 0.5527)
    No Information Rate : 0.5556          
    P-Value [Acc > NIR] : 0.9876          
                                          
                  Kappa : -0.1424         
 Mcnemar's Test P-Value : 0.7548          
                                          
            Sensitivity : 0.4062          
            Specificity : 0.4500          
         Pos Pred Value : 0.3714          
         Neg Pred Value : 0.4865          
             Prevalence : 0.4444          
         Detection Rate : 0.1806          
   Detection Prevalence : 0.4861          
      Balanced Accuracy : 0.4281          
                                          
       'Positive' Class : Weak            
                                          
> 
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
 Accuracy     Kappa 
0.8185484 0.6327498 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    115   23
    Weak       22   88
                                          
               Accuracy : 0.8185          
                 95% CI : (0.7648, 0.8645)
    No Information Rate : 0.5524          
    P-Value [Acc > NIR] : <2e-16          
                                          
                  Kappa : 0.6327          
 Mcnemar's Test P-Value : 1               
                                          
            Sensitivity : 0.7928          
            Specificity : 0.8394          
         Pos Pred Value : 0.8000          
         Neg Pred Value : 0.8333          
             Prevalence : 0.4476          
         Detection Rate : 0.3548          
   Detection Prevalence : 0.4435          
      Balanced Accuracy : 0.8161          
                                          
       'Positive' Class : Weak            
                                          
> gbmGrid <- expand.grid(interaction.depth = 
+                            c(length(colnames(trainDescr)), 1),
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.2,
+                         n.minobsinnode = 10)
> 
> set.seed(seed.mine)
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "Kappa",
+                  verbose = FALSE)
Warning message:
In train.default(trainDescr, trainClass, method = "gbm", trControl = fitControl,  :
  The metric "Kappa" was not in the result set. ROC will be used instead.
> gbmFit1
Stochastic Gradient Boosting 

248 samples
 18 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 222, 223, 223, 224, 223, 223, ... 

Resampling results across tuning parameters:

  interaction.depth  n.trees  ROC        Sens       Spec       ROC SD    
   1                   90     0.7853139  0.7354396  0.6959848  0.09217945
   1                  180     0.7765485  0.7215385  0.7067424  0.09439271
   1                  270     0.7771279  0.7258242  0.7006818  0.08857260
   1                  360     0.7778680  0.7149451  0.7081818  0.08125456
   1                  450     0.7754050  0.7178571  0.6987121  0.07999925
   1                  540     0.7721379  0.7234615  0.6945455  0.08277913
   1                  630     0.7660710  0.7198352  0.6807576  0.09058009
   1                  720     0.7705316  0.7184615  0.6790152  0.08433560
   1                  810     0.7696878  0.7167033  0.6843182  0.08469345
   1                  900     0.7700300  0.7219231  0.6770455  0.08565336
   1                  990     0.7670067  0.7189560  0.6859848  0.08454208
   1                 1080     0.7643244  0.7233516  0.6834848  0.08608836
   1                 1170     0.7651074  0.7210989  0.6835606  0.08288581
   1                 1260     0.7662521  0.7210989  0.6781818  0.08417511
   1                 1350     0.7665976  0.7189560  0.6789394  0.08419683
   1                 1440     0.7653388  0.7180769  0.6844697  0.08356570
   1                 1530     0.7631031  0.7201099  0.6709091  0.08374631
   1                 1620     0.7632326  0.7180769  0.6725758  0.08280364
   1                 1710     0.7644127  0.7201099  0.6778788  0.08320554
   1                 1800     0.7625895  0.7173077  0.6769697  0.08522433
   1                 1890     0.7629433  0.7253297  0.6743939  0.08513413
   1                 1980     0.7609266  0.7245055  0.6699242  0.08425124
   1                 2070     0.7606373  0.7238462  0.6734091  0.08524888
   1                 2160     0.7612213  0.7243956  0.6699242  0.08221780
   1                 2250     0.7586293  0.7289011  0.6690152  0.08485256
   1                 2340     0.7576648  0.7243956  0.6671970  0.08486754
   1                 2430     0.7602040  0.7229670  0.6655303  0.08634125
   1                 2520     0.7604246  0.7260440  0.6700000  0.08551958
   1                 2610     0.7593223  0.7247253  0.6654545  0.08944935
   1                 2700     0.7578463  0.7254396  0.6609848  0.08932746
  18                   90     0.7545713  0.7129121  0.6496970  0.09110274
  18                  180     0.7461397  0.7090659  0.6433333  0.09624531
  18                  270     0.7444347  0.7089560  0.6443939  0.09749573
  18                  360     0.7434703  0.7045604  0.6488636  0.09980186
  18                  450     0.7444002  0.7118681  0.6433333  0.09747159
  18                  540     0.7465572  0.7109890  0.6432576  0.09223886
  18                  630     0.7454791  0.7101648  0.6523485  0.09416140
  18                  720     0.7474942  0.7103846  0.6443939  0.09424393
  18                  810     0.7455686  0.7204945  0.6525000  0.09353175
  18                  900     0.7473839  0.7161538  0.6471970  0.09181528
  18                  990     0.7468007  0.7169231  0.6480303  0.09392733
  18                 1080     0.7451565  0.7133516  0.6487121  0.09309564
  18                 1170     0.7435818  0.7117582  0.6496970  0.09374334
  18                 1260     0.7432264  0.7161538  0.6495455  0.09461661
  18                 1350     0.7414227  0.7140110  0.6460606  0.09683009
  18                 1440     0.7421210  0.7162637  0.6442424  0.09354487
  18                 1530     0.7417241  0.7175824  0.6452273  0.09585742
  18                 1620     0.7427891  0.7183516  0.6470455  0.09405381
  18                 1710     0.7414381  0.7161538  0.6532576  0.09543642
  18                 1800     0.7387565  0.7081868  0.6586364  0.09572762
  18                 1890     0.7395234  0.7009341  0.6721970  0.09538270
  18                 1980     0.7389165  0.6945055  0.6821212  0.09712367
  18                 2070     0.7391918  0.6813187  0.7037121  0.09464940
  18                 2160     0.7393502  0.6667582  0.7145455  0.09441157
  18                 2250     0.7388343  0.6552198  0.7271212  0.09363034
  18                 2340     0.7391523  0.6501099  0.7287121  0.09387588
  18                 2430     0.7395192  0.6419231  0.7379545  0.09293802
  18                 2520     0.7399967  0.6337912  0.7476515  0.09113474
  18                 2610     0.7402683  0.6308791  0.7558333  0.09161940
  18                 2700     0.7387452  0.6243956  0.7576515  0.09072518
  Sens SD    Spec SD  
  0.1228444  0.1295068
  0.1195445  0.1243440
  0.1146555  0.1205094
  0.1143300  0.1386674
  0.1147562  0.1311004
  0.1070052  0.1388988
  0.1109190  0.1336976
  0.1120286  0.1433710
  0.1087333  0.1382385
  0.1124328  0.1410721
  0.1119285  0.1397207
  0.1134225  0.1387180
  0.1180847  0.1361247
  0.1155262  0.1341671
  0.1142796  0.1338959
  0.1135228  0.1416164
  0.1167151  0.1407498
  0.1120791  0.1440202
  0.1158997  0.1469565
  0.1174510  0.1444541
  0.1165704  0.1450966
  0.1172292  0.1440632
  0.1169547  0.1442267
  0.1125841  0.1387501
  0.1094570  0.1462852
  0.1101222  0.1500590
  0.1091556  0.1488493
  0.1059052  0.1459425
  0.1073281  0.1501072
  0.1043429  0.1425345
  0.1210993  0.1459377
  0.1223145  0.1312411
  0.1215244  0.1262572
  0.1218186  0.1211613
  0.1141646  0.1284371
  0.1162600  0.1232849
  0.1197802  0.1255808
  0.1195277  0.1293911
  0.1202789  0.1283422
  0.1150027  0.1245488
  0.1181915  0.1314694
  0.1245104  0.1256766
  0.1241041  0.1251981
  0.1232233  0.1250614
  0.1246923  0.1268585
  0.1221028  0.1240855
  0.1232598  0.1225253
  0.1211654  0.1203149
  0.1237074  0.1225385
  0.1197586  0.1250948
  0.1258847  0.1215744
  0.1252989  0.1217843
  0.1233637  0.1205594
  0.1222098  0.1221881
  0.1257225  0.1161615
  0.1249623  0.1180118
  0.1208414  0.1179155
  0.1187832  0.1171441
  0.1204606  0.1168277
  0.1173137  0.1191986

Tuning parameter 'shrinkage' was held constant at a value of 0.2

Tuning parameter 'n.minobsinnode' was held constant at a value of 10
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 90, interaction.depth =
 1, shrinkage = 0.2 and n.minobsinnode = 10. 
> 
> ## The acid test is dissapointing, but I've seen worse.
> 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
  Accuracy      Kappa 
 0.4305556 -0.1424149 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     18   19
    Weak       22   13
                                          
               Accuracy : 0.4306          
                 95% CI : (0.3143, 0.5527)
    No Information Rate : 0.5556          
    P-Value [Acc > NIR] : 0.9876          
                                          
                  Kappa : -0.1424         
 Mcnemar's Test P-Value : 0.7548          
                                          
            Sensitivity : 0.4062          
            Specificity : 0.4500          
         Pos Pred Value : 0.3714          
         Neg Pred Value : 0.4865          
             Prevalence : 0.4444          
         Detection Rate : 0.1806          
   Detection Prevalence : 0.4861          
      Balanced Accuracy : 0.4281          
                                          
       'Positive' Class : Weak            
                                          
> 
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
 Accuracy     Kappa 
0.8185484 0.6327498 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    115   23
    Weak       22   88
                                          
               Accuracy : 0.8185          
                 95% CI : (0.7648, 0.8645)
    No Information Rate : 0.5524          
    P-Value [Acc > NIR] : <2e-16          
                                          
                  Kappa : 0.6327          
 Mcnemar's Test P-Value : 1               
                                          
            Sensitivity : 0.7928          
            Specificity : 0.8394          
         Pos Pred Value : 0.8000          
         Neg Pred Value : 0.8333          
             Prevalence : 0.4476          
         Detection Rate : 0.3548          
   Detection Prevalence : 0.4435          
      Balanced Accuracy : 0.8161          
                                          
       'Positive' Class : Weak            
                                          
> trellis.par.set(caretTheme())
Warning message:
In trellis.par.set(caretTheme()) :
  Note: The default device has been opened to honour attempt to modify trellis settings
> plot(gbmFit1, metric = "ROC")
> gbmGrid <- expand.grid(interaction.depth = 
+                            length(colnames(trainDescr)),
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.2,
+                         n.minobsinnode = 10)
> set.seed(seed.mine)
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "Kappa",
+                  verbose = FALSE)
Warning message:
In train.default(trainDescr, trainClass, method = "gbm", trControl = fitControl,  :
  The metric "Kappa" was not in the result set. ROC will be used instead.
> gbmFit1
Stochastic Gradient Boosting 

248 samples
 18 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 222, 223, 223, 224, 223, 223, ... 

Resampling results across tuning parameters:

  n.trees  ROC        Sens       Spec       ROC SD      Sens SD    Spec SD  
    90     0.7524679  0.7208791  0.6534091  0.09166895  0.1179604  0.1404655
   180     0.7497028  0.7243407  0.6562879  0.08884326  0.1126636  0.1329438
   270     0.7463953  0.7255495  0.6482576  0.09399026  0.1217197  0.1340667
   360     0.7467170  0.7269780  0.6436364  0.09170860  0.1260721  0.1337059
   450     0.7457122  0.7259890  0.6425758  0.09104195  0.1124132  0.1229849
   540     0.7442545  0.7253846  0.6515909  0.09282488  0.1153330  0.1296582
   630     0.7460498  0.7231319  0.6397727  0.09346636  0.1190461  0.1301931
   720     0.7451207  0.7258791  0.6453030  0.09450436  0.1166290  0.1239662
   810     0.7448277  0.7253846  0.6524242  0.09378507  0.1171250  0.1260847
   900     0.7456090  0.7275824  0.6470455  0.09379856  0.1162605  0.1244083
   990     0.7444239  0.7238462  0.6533333  0.09420711  0.1190684  0.1261897
  1080     0.7433662  0.7218681  0.6470455  0.09436526  0.1201016  0.1244083
  1170     0.7440876  0.7247253  0.6515152  0.09280874  0.1191782  0.1288306
  1260     0.7416710  0.7180769  0.6514394  0.09845810  0.1207218  0.1278935
  1350     0.7408494  0.7233516  0.6524242  0.09710952  0.1198209  0.1291465
  1440     0.7412744  0.7219780  0.6462879  0.09548256  0.1211613  0.1345089
  1530     0.7404562  0.7225824  0.6515909  0.09709603  0.1210543  0.1289858
  1620     0.7379795  0.7189560  0.6496970  0.09965381  0.1211447  0.1278374
  1710     0.7387123  0.7197802  0.6542424  0.09617243  0.1234181  0.1259708
  1800     0.7389546  0.7065385  0.6632576  0.09527567  0.1252041  0.1242511
  1890     0.7393303  0.7013736  0.6758333  0.09615643  0.1229982  0.1227108
  1980     0.7391371  0.6941758  0.6876515  0.09559103  0.1222593  0.1209097
  2070     0.7391648  0.6877473  0.7000758  0.09242473  0.1223437  0.1161321
  2160     0.7387885  0.6689560  0.7108333  0.08952067  0.1232880  0.1126709
  2250     0.7372571  0.6658791  0.7262121  0.09474934  0.1255656  0.1138480
  2340     0.7379633  0.6543407  0.7353030  0.09609810  0.1247796  0.1098297
  2430     0.7407684  0.6434615  0.7389394  0.09295292  0.1204897  0.1139823
  2520     0.7413505  0.6376374  0.7489394  0.09331139  0.1217172  0.1143358
  2610     0.7388285  0.6326374  0.7561364  0.09369120  0.1273867  0.1175245
  2700     0.7396039  0.6240659  0.7588636  0.09429201  0.1288201  0.1135524

Tuning parameter 'interaction.depth' was held constant at a value of 18

Tuning parameter 'shrinkage' was held constant at a value of 0.2

Tuning parameter 'n.minobsinnode' was held constant at a value of 10
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 90, interaction.depth =
 18, shrinkage = 0.2 and n.minobsinnode = 10. 
> 
> ## The acid test is dissapointing, but I've seen worse.
> 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
  Accuracy      Kappa 
0.52777778 0.03164557 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     25   19
    Weak       15   13
                                          
               Accuracy : 0.5278          
                 95% CI : (0.4065, 0.6467)
    No Information Rate : 0.5556          
    P-Value [Acc > NIR] : 0.7242          
                                          
                  Kappa : 0.0316          
 Mcnemar's Test P-Value : 0.6069          
                                          
            Sensitivity : 0.4062          
            Specificity : 0.6250          
         Pos Pred Value : 0.4643          
         Neg Pred Value : 0.5682          
             Prevalence : 0.4444          
         Detection Rate : 0.1806          
   Detection Prevalence : 0.3889          
      Balanced Accuracy : 0.5156          
                                          
       'Positive' Class : Weak            
                                          
> 
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
Accuracy    Kappa 
       1        1 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    137    0
    Weak        0  111
                                     
               Accuracy : 1          
                 95% CI : (0.9852, 1)
    No Information Rate : 0.5524     
    P-Value [Acc > NIR] : < 2.2e-16  
                                     
                  Kappa : 1          
 Mcnemar's Test P-Value : NA         
                                     
            Sensitivity : 1.0000     
            Specificity : 1.0000     
         Pos Pred Value : 1.0000     
         Neg Pred Value : 1.0000     
             Prevalence : 0.4476     
         Detection Rate : 0.4476     
   Detection Prevalence : 0.4476     
      Balanced Accuracy : 1.0000     
                                     
       'Positive' Class : Weak       
                                     
> quit()
Save workspace image? [y/n/c]: n

Process R finished at Sat May  7 06:16:28 2016


R version 3.2.5 (2016-04-14) -- "Very, Very Secure Dishes"
Copyright (C) 2016 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> > options(STERM='iESS', str.dendrogram.last="'", editor='emacsclient', show.error.locations=TRUE)
> 
+ . + + . + + . + 
> ### weaves
> 
> ## Processing for flights data.
> 
> ## Following the caret vignette.
> 
> ###################################################
> ### code chunk number 1: loadLibs
> ###################################################
> library(MASS)

> library(caret)
Loading required package: lattice
Loading required package: ggplot2

> library(mlbench)

> library(pROC)
Type 'citation("pROC")' for a citation.

Attaching package: 'pROC'

The following objects are masked from 'package:stats':

    cov, smooth, var


> library(pls)

Attaching package: 'pls'

The following object is masked from 'package:caret':

    R2

The following object is masked from 'package:stats':

    loadings


> library(doMC)
Loading required package: foreach
foreach: simple, scalable parallel programming from Revolution Analytics
Use Revolution R for scalability, fault tolerance and more.
http://www.revolutionanalytics.com
Loading required package: iterators
Loading required package: parallel

> registerDoMC(cores = 4)

> options(useFancyQuotes = FALSE) 

> # Accounting info.
> getInfo <- function(what = "Suggests")
+ {
+   text <- packageDescription("caret")[what][[1]]
+   text <- gsub("\n", ", ", text, fixed = TRUE)
+   text <- gsub(">=", "$\\\\ge$", text, fixed = TRUE)
+   eachPkg <- strsplit(text, ", ", fixed = TRUE)[[1]]
+   eachPkg <- gsub(",", .... [TRUNCATED] 

> ### project-specific: begin
> ## Set-seed, load original CSV file, order it
> ## and do some simple-cleaning
> ## Various datasets 
> 
> seed.mine = 107

> set.seed(seed.mine)                     # helpful for testing

> flight <- read.csv("../bak/flight.csv")

> flight <- flight[order(flight$D00),]

> # Backup
> flight.raw <- flight

> # To check adjustment, there is test code in flight-nb.R
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"

> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"

> # And some deletions
> 
> t.cols <- colnames(flight)

> t.drops <- t.cols[grep("^RANK*", t.cols)]

> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])

> t.drops <- c(t.drops, "D80THPCTL")

> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]

> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR

> flight$xHNGR <- flight$xDURN < 0

> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+  .... [TRUNCATED] 

> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))

> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE

> t.cols <- colnames(flight)

> t.drops <- c("SARRHR", "xDURN")

> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]

> ## Backup
> 
> flight00 <- flight

> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]

> paste("samples in use: ", dim(flight)[1])
[1] "samples in use:  320"

> ## Data insights
> 
> ## *Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> ### Numeric variables
> 
> ### Try and impute the AVG, it might have more information than the
> ### bucket.
> 
> flight$xAVAILBUC .... [TRUNCATED] 

> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1

> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]

> preProcValues <- preProcess(flight.na, method = c("knnImpute"))

> flight.na1 <- predict(preProcValues, flight.na)

> ## I'll add the new imputed value and drop the others
> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL

> flight$AVGSKDAVAIL <- NULL

> flight$xAVAILBUCKET <- NULL

> flight$AVAILBUCKET <- NULL

> flight$xHNGR <- NULL

> ## Check some more numeric correlations, I haven't scaled everything yet.
> ## I'd cut correlations above 0.65 to 0.75 because of overfitting.
> 
> x1 <- as.data.frame(as.matrix(sapply(flight, class)))

> flight.num <- flight[,names(x1[which(x1$V1 %in% c("numeric", "integer")),])]

> flight.nzv <- nearZeroVar(flight.num, saveMetrics = TRUE)

> flight.nzv
             freqRatio percentUnique zeroVar   nzv
SDEPHR        1.038462        5.9375   FALSE FALSE
SKDEPS        1.000000       19.0625   FALSE FALSE
D00           1.166667       75.3125   FALSE FALSE
AVGSQ         6.333333       82.8125   FALSE FALSE
AVGLOFATC     1.000000       78.4375   FALSE FALSE
xDURN2        1.428571        2.5000   FALSE FALSE
xAVGSKDAVAIL 18.500000       87.8125   FALSE FALSE

> # annoying NA should be gone.
> flight.cor <- cor(flight.num, use = "pairwise.complete.obs")

> descrCorr <- findCorrelation(flight.cor, cutoff = .65, verbose=TRUE)
Considering row	 4 column	 1 value	 0.956 
  Flagging column	 4 
Considering row	 1 column	 3 value	 0.43 
Considering row	 1 column	 7 value	 0.053 
Considering row	 1 column	 6 value	 0.204 
Considering row	 1 column	 5 value	 0.131 
Considering row	 1 column	 2 value	 0.054 
Considering row	 3 column	 7 value	 0.401 
Considering row	 3 column	 6 value	 0.071 
Considering row	 3 column	 5 value	 0.114 
Considering row	 3 column	 2 value	 0.006 
Considering row	 7 column	 6 value	 0.019 
Considering row	 7 column	 5 value	 0.07 
Considering row	 7 column	 2 value	 0.113 
Considering row	 6 column	 5 value	 0.137 
Considering row	 6 column	 2 value	 0.005 
Considering row	 5 column	 2 value	 0.041 

> colnames(flight.num)[descrCorr]
[1] "AVGSQ"

> ## And I'll leave the centered and scale values in for now.
> ## and delete the troublesome ones
> 
> ## Re-classing
> ## Check warnings to see it adjustment has taken place.
> ## We want the proportion in the training class to be about 0.55 0.45
> ## Strong to Weak
> ## I've achieved this heurist .... [TRUNCATED] 

> source(file = "flight1.R")

> flight1 <- flight

> ## This should be deleted, leave it in and the results
> ## are ideal because it defines LEGTYPE.
> flight$D00 <- NULL

> ## Keep the results but don't change the order.
> outcomes.flight <- flight$LEGTYPE

> flight$LEGTYPE <- NULL

> ## If you know your factors are definitely factors, you don't need this
> ##  asNumeric <- function(x) as.numeric(as.character(x))
> 
> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))

> flight.num0 <- factors.numeric(flight)

> flight.scl0 <- scale(flight.num0)

> ## Now split the samples
> ## we need at least 60 to test with, p at 0.77 gives about 75.
> ## Difficulty here is the bias in the table
> ## Because we only have [3.1, 4.4] the proportion of Weak is higher.
> ## see prop.table(results)
> 
> set.seed(seed.mine)

> inTrain <- createDataPartition(outcomes.flight, p = 0.77, list = FALSE)

> trainDescr <- flight.scl0[inTrain,]

> testDescr <- flight.scl0[-inTrain,]

> trainClass <- outcomes.flight[inTrain]

> testClass <- outcomes.flight[-inTrain]

> prop.table(table(trainClass))
trainClass
   Strong      Weak 
0.5524194 0.4475806 

> dim(trainDescr)
[1] 248  19

> prop.table(table(testClass))
testClass
   Strong      Weak 
0.5555556 0.4444444 

> dim(testDescr)
[1] 72 19

> ## Check Near-zero variance
> 
> nzv <- nearZeroVar(trainDescr, saveMetrics= TRUE)

> stopifnot( all(nzv$nzv == FALSE) )

> # It's imputed and behaves well, no need for this.
> # descrCorr <- cor(scale(trainDescr), use = "pairwise.complete.obs")
> 
> descrCorr <- cor(scale(trainDescr))

> ## This cut-off should be under src.adjust control.
> ## I'm under Git, so I can tinker with it.
> highCorr <- findCorrelation(descrCorr, cutoff = .95, verbose = TRUE)
Considering row	 17 column	 16 value	 0.85 
Considering row	 17 column	 10 value	 0.671 
Considering row	 17 column	 1 value	 0.279 
Considering row	 17 column	 11 value	 0.277 
Considering row	 17 column	 6 value	 0.22 
Considering row	 17 column	 12 value	 0.226 
Considering row	 17 column	 2 value	 0.298 
Considering row	 17 column	 9 value	 0.586 
Considering row	 17 column	 14 value	 0.226 
Considering row	 17 column	 13 value	 0.23 
Considering row	 17 column	 8 value	 0.541 
Considering row	 17 column	 3 value	 0.346 
Considering row	 17 column	 18 value	 0.261 
Considering row	 17 column	 19 value	 0.138 
Considering row	 17 column	 15 value	 0.057 
Considering row	 17 column	 4 value	 0.067 
Considering row	 17 column	 7 value	 0.034 
Considering row	 17 column	 5 value	 0.018 
Considering row	 16 column	 10 value	 0.568 
Considering row	 16 column	 1 value	 0.236 
Considering row	 16 column	 11 value	 0.231 
Considering row	 16 column	 6 value	 0.189 
Considering row	 16 column	 12 value	 0.19 
Considering row	 16 column	 2 value	 0.333 
Considering row	 16 column	 9 value	 0.671 
Considering row	 16 column	 14 value	 0.242 
Considering row	 16 column	 13 value	 0.208 
Considering row	 16 column	 8 value	 0.6 
Considering row	 16 column	 3 value	 0.318 
Considering row	 16 column	 18 value	 0.279 
Considering row	 16 column	 19 value	 0.213 
Considering row	 16 column	 15 value	 0.083 
Considering row	 16 column	 4 value	 0.02 
Considering row	 16 column	 7 value	 0.009 
Considering row	 16 column	 5 value	 0.005 
Considering row	 10 column	 1 value	 0.281 
Considering row	 10 column	 11 value	 0.275 
Considering row	 10 column	 6 value	 0.298 
Considering row	 10 column	 12 value	 0.255 
Considering row	 10 column	 2 value	 0.286 
Considering row	 10 column	 9 value	 0.404 
Considering row	 10 column	 14 value	 0.224 
Considering row	 10 column	 13 value	 0.199 
Considering row	 10 column	 8 value	 0.366 
Considering row	 10 column	 3 value	 0.462 
Considering row	 10 column	 18 value	 0.226 
Considering row	 10 column	 19 value	 0.103 
Considering row	 10 column	 15 value	 0.274 
Considering row	 10 column	 4 value	 0.018 
Considering row	 10 column	 7 value	 0.127 
Considering row	 10 column	 5 value	 0.096 
Considering row	 1 column	 11 value	 0.988 
  Flagging column	 1 
Considering row	 11 column	 6 value	 0.945 
Considering row	 11 column	 12 value	 0.889 
Considering row	 11 column	 2 value	 0.165 
Considering row	 11 column	 9 value	 0.139 
Considering row	 11 column	 14 value	 0.171 
Considering row	 11 column	 13 value	 0.156 
Considering row	 11 column	 8 value	 0.145 
Considering row	 11 column	 3 value	 0.073 
Considering row	 11 column	 18 value	 0.183 
Considering row	 11 column	 19 value	 0.053 
Considering row	 11 column	 15 value	 0.142 
Considering row	 11 column	 4 value	 0.037 
Considering row	 11 column	 7 value	 0.053 
Considering row	 11 column	 5 value	 0.03 
Considering row	 6 column	 12 value	 0.883 
Considering row	 6 column	 2 value	 0.151 
Considering row	 6 column	 9 value	 0.04 
Considering row	 6 column	 14 value	 0.188 
Considering row	 6 column	 13 value	 0.161 
Considering row	 6 column	 8 value	 0.063 
Considering row	 6 column	 3 value	 0.083 
Considering row	 6 column	 18 value	 0.197 
Considering row	 6 column	 19 value	 0.114 
Considering row	 6 column	 15 value	 0.159 
Considering row	 6 column	 4 value	 0.01 
Considering row	 6 column	 7 value	 0.027 
Considering row	 6 column	 5 value	 0.039 
Considering row	 12 column	 2 value	 0.121 
Considering row	 12 column	 9 value	 0.128 
Considering row	 12 column	 14 value	 0.092 
Considering row	 12 column	 13 value	 0.105 
Considering row	 12 column	 8 value	 0.071 
Considering row	 12 column	 3 value	 0.093 
Considering row	 12 column	 18 value	 0.126 
Considering row	 12 column	 19 value	 0.171 
Considering row	 12 column	 15 value	 0.13 
Considering row	 12 column	 4 value	 0.01 
Considering row	 12 column	 7 value	 0.043 
Considering row	 12 column	 5 value	 0.017 
Considering row	 2 column	 9 value	 0.423 
Considering row	 2 column	 14 value	 0.574 
Considering row	 2 column	 13 value	 0.557 
Considering row	 2 column	 8 value	 0.165 
Considering row	 2 column	 3 value	 0.263 
Considering row	 2 column	 18 value	 0.128 
Considering row	 2 column	 19 value	 0.089 
Considering row	 2 column	 15 value	 0.069 
Considering row	 2 column	 4 value	 0.27 
Considering row	 2 column	 7 value	 0.045 
Considering row	 2 column	 5 value	 0.024 
Considering row	 9 column	 14 value	 0.147 
Considering row	 9 column	 13 value	 0.125 
Considering row	 9 column	 8 value	 0.449 
Considering row	 9 column	 3 value	 0.322 
Considering row	 9 column	 18 value	 0.018 
Considering row	 9 column	 19 value	 0.141 
Considering row	 9 column	 15 value	 0.073 
Considering row	 9 column	 4 value	 0.006 
Considering row	 9 column	 7 value	 0.136 
Considering row	 9 column	 5 value	 0.123 
Considering row	 14 column	 13 value	 0.659 
Considering row	 14 column	 8 value	 0.097 
Considering row	 14 column	 3 value	 0.106 
Considering row	 14 column	 18 value	 0.361 
Considering row	 14 column	 19 value	 0.092 
Considering row	 14 column	 15 value	 0.084 
Considering row	 14 column	 4 value	 0.263 
Considering row	 14 column	 7 value	 0.139 
Considering row	 14 column	 5 value	 0.031 
Considering row	 13 column	 8 value	 0.097 
Considering row	 13 column	 3 value	 0.167 
Considering row	 13 column	 18 value	 0.18 
Considering row	 13 column	 19 value	 0.131 
Considering row	 13 column	 15 value	 0.137 
Considering row	 13 column	 4 value	 0.24 
Considering row	 13 column	 7 value	 0.085 
Considering row	 13 column	 5 value	 0.027 
Considering row	 8 column	 3 value	 0.224 
Considering row	 8 column	 18 value	 0.173 
Considering row	 8 column	 19 value	 0.235 
Considering row	 8 column	 15 value	 0.07 
Considering row	 8 column	 4 value	 0.02 
Considering row	 8 column	 7 value	 0.085 
Considering row	 8 column	 5 value	 0.004 
Considering row	 3 column	 18 value	 0.028 
Considering row	 3 column	 19 value	 0.027 
Considering row	 3 column	 15 value	 0.017 
Considering row	 3 column	 4 value	 0.094 
Considering row	 3 column	 7 value	 0.095 
Considering row	 3 column	 5 value	 0.097 
Considering row	 18 column	 19 value	 0.019 
Considering row	 18 column	 15 value	 0.12 
Considering row	 18 column	 4 value	 0.086 
Considering row	 18 column	 7 value	 0.132 
Considering row	 18 column	 5 value	 0.002 
Considering row	 19 column	 15 value	 0.019 
Considering row	 19 column	 4 value	 0.032 
Considering row	 19 column	 7 value	 0.056 
Considering row	 19 column	 5 value	 0.075 
Considering row	 15 column	 4 value	 0.043 
Considering row	 15 column	 7 value	 0.061 
Considering row	 15 column	 5 value	 0.08 
Considering row	 4 column	 7 value	 0.005 
Considering row	 4 column	 5 value	 0.213 
Considering row	 7 column	 5 value	 0.008 

> colnames(trainDescr)[highCorr]
[1] "SDEPHR"

> descr.ncol0 <- ncol(trainDescr)

> # I've switched off the correlation remover and the results are better.
> if (sum(highCorr) > 0) {
+     warning("overfitting: correlations: err.trainDescr: ", paste(colnames(trainDescr)[highCorr], collapse = ", ") )
+     err.trainDescr <- trainDescr
+     trainDescr <- trainDescr[,-highCorr]
+ }

> descr.ncol1 <- ncol(trainDescr)

> paste("Dropped: ", as.character(descr.ncol0 - descr.ncol1))
[1] "Dropped:  1"

> descrCorr <- cor(trainDescr)

> summary(descrCorr[upper.tri(descrCorr)])
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
-0.85020 -0.13860 -0.01766  0.01577  0.11970  0.94490 

> ## Dominant correlations
> ## At 0.9, there are some big ones that might need re-thinking.
> 
> table.descrCorr <- as.data.frame(as.table(descrCorr))

> table.descrCorr <- table.descrCorr[which(table.descrCorr$Var1 != table.descrCorr$Var2),]

> table.descrCorr[order(abs(table.descrCorr$Freq), decreasing = TRUE),]
              Var1           Var2         Freq
82       DEPBUCKET          AVGSQ  0.944870657
167          AVGSQ      DEPBUCKET  0.944870657
173      ARRBUCKET      DEPBUCKET  0.889095737
190      DEPBUCKET      ARRBUCKET  0.889095737
83       ARRBUCKET          AVGSQ  0.882590635
185          AVGSQ      ARRBUCKET  0.882590635
268       ARRSPOKE       DEPSPOKE -0.850165355
285       DEPSPOKE       ARRSPOKE -0.850165355
141       DEPSPOKE   DEPSTAATCIMP  0.671264566
260   DEPSTAATCIMP       DEPSPOKE  0.671264566
160       ARRSPOKE DOWNLINEATCIMP  0.671009330
279 DOWNLINEATCIMP       ARRSPOKE  0.671009330
211     TRNRANKGRP     DEPRANKGRP  0.658724662
228     DEPRANKGRP     TRNRANKGRP  0.658724662
123       DEPSPOKE   UPLINEATCIMP -0.600008252
259   UPLINEATCIMP       DEPSPOKE -0.600008252
142       ARRSPOKE   DEPSTAATCIMP -0.586442959
278   DEPSTAATCIMP       ARRSPOKE -0.586442959
13      TRNRANKGRP      SKDDEPSTA  0.574035134
217      SKDDEPSTA     TRNRANKGRP  0.574035134
159       DEPSPOKE DOWNLINEATCIMP -0.567682494
261 DOWNLINEATCIMP       DEPSPOKE -0.567682494
12      DEPRANKGRP      SKDDEPSTA  0.557399203
199      SKDDEPSTA     DEPRANKGRP  0.557399203
124       ARRSPOKE   UPLINEATCIMP  0.540734833
277   UPLINEATCIMP       ARRSPOKE  0.540734833
27  DOWNLINEATCIMP      SKDARRSTA  0.462378131
146      SKDARRSTA DOWNLINEATCIMP  0.462378131
116   DEPSTAATCIMP   UPLINEATCIMP -0.449249986
133   UPLINEATCIMP   DEPSTAATCIMP -0.449249986
8     DEPSTAATCIMP      SKDDEPSTA  0.423425796
127      SKDDEPSTA   DEPSTAATCIMP  0.423425796
135 DOWNLINEATCIMP   DEPSTAATCIMP -0.403695561
152   DEPSTAATCIMP DOWNLINEATCIMP -0.403695561
117 DOWNLINEATCIMP   UPLINEATCIMP  0.365833687
151   UPLINEATCIMP DOWNLINEATCIMP  0.365833687
233         xDURN2     TRNRANKGRP  0.361347207
301     TRNRANKGRP         xDURN2  0.361347207
34        ARRSPOKE      SKDARRSTA  0.345987375
272      SKDARRSTA       ARRSPOKE  0.345987375
15        DEPSPOKE      SKDDEPSTA  0.332823310
253      SKDDEPSTA       DEPSPOKE  0.332823310
26    DEPSTAATCIMP      SKDARRSTA -0.322204878
128      SKDARRSTA   DEPSTAATCIMP -0.322204878
33        DEPSPOKE      SKDARRSTA -0.318093195
254      SKDARRSTA       DEPSPOKE -0.318093195
81  DOWNLINEATCIMP          AVGSQ  0.298096458
149          AVGSQ DOWNLINEATCIMP  0.298096458
16        ARRSPOKE      SKDDEPSTA -0.298036487
271      SKDDEPSTA       ARRSPOKE -0.298036487
9   DOWNLINEATCIMP      SKDDEPSTA -0.285911992
145      SKDDEPSTA DOWNLINEATCIMP -0.285911992
269         xDURN2       DEPSPOKE  0.279030910
303       DEPSPOKE         xDURN2  0.279030910
178       ARRSPOKE      DEPBUCKET  0.276615722
280      DEPBUCKET       ARRSPOKE  0.276615722
154      DEPBUCKET DOWNLINEATCIMP  0.275167866
171 DOWNLINEATCIMP      DEPBUCKET  0.275167866
158     ARRRANKGRP DOWNLINEATCIMP -0.274110143
243 DOWNLINEATCIMP     ARRRANKGRP -0.274110143
3           SKDEQP      SKDDEPSTA  0.270065872
37       SKDDEPSTA         SKDEQP  0.270065872
2        SKDARRSTA      SKDDEPSTA -0.263453106
19       SKDDEPSTA      SKDARRSTA -0.263453106
49      TRNRANKGRP         SKDEQP  0.262837233
219         SKDEQP     TRNRANKGRP  0.262837233
287         xDURN2       ARRSPOKE -0.261107447
304       ARRSPOKE         xDURN2 -0.261107447
155      ARRBUCKET DOWNLINEATCIMP  0.255480148
189 DOWNLINEATCIMP      ARRBUCKET  0.255480148
231       DEPSPOKE     TRNRANKGRP  0.242138220
265     TRNRANKGRP       DEPSPOKE  0.242138220
48      DEPRANKGRP         SKDEQP  0.239915140
201         SKDEQP     DEPRANKGRP  0.239915140
126   xAVGSKDAVAIL   UPLINEATCIMP  0.234867014
313   UPLINEATCIMP   xAVGSKDAVAIL  0.234867014
177       DEPSPOKE      DEPBUCKET -0.231298301
262      DEPBUCKET       DEPSPOKE -0.231298301
214       ARRSPOKE     DEPRANKGRP -0.229640758
282     DEPRANKGRP       ARRSPOKE -0.229640758
161         xDURN2 DOWNLINEATCIMP -0.226093423
297 DOWNLINEATCIMP         xDURN2 -0.226093423
196       ARRSPOKE      ARRBUCKET  0.225890655
281      ARRBUCKET       ARRSPOKE  0.225890655
232       ARRSPOKE     TRNRANKGRP -0.225591539
283     TRNRANKGRP       ARRSPOKE -0.225591539
157     TRNRANKGRP DOWNLINEATCIMP -0.224193213
225 DOWNLINEATCIMP     TRNRANKGRP -0.224193213
25    UPLINEATCIMP      SKDARRSTA  0.223824406
110      SKDARRSTA   UPLINEATCIMP  0.223824406
88        ARRSPOKE          AVGSQ  0.219975654
275          AVGSQ       ARRSPOKE  0.219975654
270   xAVGSKDAVAIL       DEPSPOKE -0.212821518
321       DEPSPOKE   xAVGSKDAVAIL -0.212821518
40          SKDEPS         SKDEQP  0.212586898
57          SKDEQP         SKDEPS  0.212586898
213       DEPSPOKE     DEPRANKGRP  0.208188512
264     DEPRANKGRP       DEPSPOKE  0.208188512
156     DEPRANKGRP DOWNLINEATCIMP -0.199411990
207 DOWNLINEATCIMP     DEPRANKGRP -0.199411990
89          xDURN2          AVGSQ -0.197447957
293          AVGSQ         xDURN2 -0.197447957
195       DEPSPOKE      ARRBUCKET -0.189934966
263      ARRBUCKET       DEPSPOKE -0.189934966
87        DEPSPOKE          AVGSQ -0.188666787
257          AVGSQ       DEPSPOKE -0.188666787
85      TRNRANKGRP          AVGSQ -0.188226304
221          AVGSQ     TRNRANKGRP -0.188226304
179         xDURN2      DEPBUCKET -0.183349624
298      DEPBUCKET         xDURN2 -0.183349624
215         xDURN2     DEPRANKGRP  0.180043357
300     DEPRANKGRP         xDURN2  0.180043357
125         xDURN2   UPLINEATCIMP -0.173240320
295   UPLINEATCIMP         xDURN2 -0.173240320
198   xAVGSKDAVAIL      ARRBUCKET -0.170644257
317      ARRBUCKET   xAVGSKDAVAIL -0.170644257
175     TRNRANKGRP      DEPBUCKET -0.170618431
226      DEPBUCKET     TRNRANKGRP -0.170618431
30      DEPRANKGRP      SKDARRSTA -0.167375913
200      SKDARRSTA     DEPRANKGRP -0.167375913
10       DEPBUCKET      SKDDEPSTA -0.165029385
163      SKDDEPSTA      DEPBUCKET -0.165029385
7     UPLINEATCIMP      SKDDEPSTA -0.164964952
109      SKDDEPSTA   UPLINEATCIMP -0.164964952
84      DEPRANKGRP          AVGSQ -0.161451853
203          AVGSQ     DEPRANKGRP -0.161451853
86      ARRRANKGRP          AVGSQ -0.159135469
239          AVGSQ     ARRRANKGRP -0.159135469
174     DEPRANKGRP      DEPBUCKET -0.155547085
208      DEPBUCKET     DEPRANKGRP -0.155547085
5            AVGSQ      SKDDEPSTA -0.150522366
73       SKDDEPSTA          AVGSQ -0.150522366
139     TRNRANKGRP   DEPSTAATCIMP -0.147409309
224   DEPSTAATCIMP     TRNRANKGRP -0.147409309
118      DEPBUCKET   UPLINEATCIMP  0.144940797
169   UPLINEATCIMP      DEPBUCKET  0.144940797
176     ARRRANKGRP      DEPBUCKET -0.142348062
244      DEPBUCKET     ARRRANKGRP -0.142348062
144   xAVGSKDAVAIL   DEPSTAATCIMP -0.141077194
314   DEPSTAATCIMP   xAVGSKDAVAIL -0.141077194
103     TRNRANKGRP      AVGLOFATC  0.139184315
222      AVGLOFATC     TRNRANKGRP  0.139184315
136      DEPBUCKET   DEPSTAATCIMP -0.138581846
170   DEPSTAATCIMP      DEPBUCKET -0.138581846
288   xAVGSKDAVAIL       ARRSPOKE  0.137677242
322       ARRSPOKE   xAVGSKDAVAIL  0.137677242
212     ARRRANKGRP     DEPRANKGRP  0.136562948
246     DEPRANKGRP     ARRRANKGRP  0.136562948
98    DEPSTAATCIMP      AVGLOFATC -0.135778614
132      AVGLOFATC   DEPSTAATCIMP -0.135778614
107         xDURN2      AVGLOFATC -0.132084629
294      AVGLOFATC         xDURN2 -0.132084629
216   xAVGSKDAVAIL     DEPRANKGRP  0.130574789
318     DEPRANKGRP   xAVGSKDAVAIL  0.130574789
194     ARRRANKGRP      ARRBUCKET -0.129698517
245      ARRBUCKET     ARRRANKGRP -0.129698517
137      ARRBUCKET   DEPSTAATCIMP -0.127726148
188   DEPSTAATCIMP      ARRBUCKET -0.127726148
17          xDURN2      SKDDEPSTA  0.127598189
289      SKDDEPSTA         xDURN2  0.127598189
99  DOWNLINEATCIMP      AVGLOFATC -0.126763572
150      AVGLOFATC DOWNLINEATCIMP -0.126763572
197         xDURN2      ARRBUCKET -0.125836459
299      ARRBUCKET         xDURN2 -0.125836459
138     DEPRANKGRP   DEPSTAATCIMP  0.124672682
206   DEPSTAATCIMP     DEPRANKGRP  0.124672682
62    DEPSTAATCIMP         SKDEPS -0.123445793
130         SKDEPS   DEPSTAATCIMP -0.123445793
11       ARRBUCKET      SKDDEPSTA -0.120728212
181      SKDDEPSTA      ARRBUCKET -0.120728212
251         xDURN2     ARRRANKGRP  0.119675180
302     ARRRANKGRP         xDURN2  0.119675180
90    xAVGSKDAVAIL          AVGSQ -0.113720147
311          AVGSQ   xAVGSKDAVAIL -0.113720147
31      TRNRANKGRP      SKDARRSTA -0.105802023
218      SKDARRSTA     TRNRANKGRP -0.105802023
192     DEPRANKGRP      ARRBUCKET -0.105057984
209      ARRBUCKET     DEPRANKGRP -0.105057984
162   xAVGSKDAVAIL DOWNLINEATCIMP  0.102577364
315 DOWNLINEATCIMP   xAVGSKDAVAIL  0.102577364
120     DEPRANKGRP   UPLINEATCIMP -0.097218129
205   UPLINEATCIMP     DEPRANKGRP -0.097218129
121     TRNRANKGRP   UPLINEATCIMP -0.097037814
223   UPLINEATCIMP     TRNRANKGRP -0.097037814
22          SKDEPS      SKDARRSTA -0.096699169
56       SKDARRSTA         SKDEPS -0.096699169
63  DOWNLINEATCIMP         SKDEPS -0.095568613
148         SKDEPS DOWNLINEATCIMP -0.095568613
24       AVGLOFATC      SKDARRSTA -0.095234466
92       SKDARRSTA      AVGLOFATC -0.095234466
21          SKDEQP      SKDARRSTA  0.094073459
38       SKDARRSTA         SKDEQP  0.094073459
29       ARRBUCKET      SKDARRSTA  0.092625400
182      SKDARRSTA      ARRBUCKET  0.092625400
193     TRNRANKGRP      ARRBUCKET -0.092415252
227      ARRBUCKET     TRNRANKGRP -0.092415252
234   xAVGSKDAVAIL     TRNRANKGRP  0.092011501
319     TRNRANKGRP   xAVGSKDAVAIL  0.092011501
18    xAVGSKDAVAIL      SKDDEPSTA  0.088580325
307      SKDDEPSTA   xAVGSKDAVAIL  0.088580325
53          xDURN2         SKDEQP  0.086170070
291         SKDEQP         xDURN2  0.086170070
102     DEPRANKGRP      AVGLOFATC  0.085474019
204      AVGLOFATC     DEPRANKGRP  0.085474019
97    UPLINEATCIMP      AVGLOFATC -0.085180887
114      AVGLOFATC   UPLINEATCIMP -0.085180887
230     ARRRANKGRP     TRNRANKGRP  0.083906762
247     TRNRANKGRP     ARRRANKGRP  0.083906762
249       DEPSPOKE     ARRRANKGRP  0.083162083
266     ARRRANKGRP       DEPSPOKE  0.083162083
23           AVGSQ      SKDARRSTA  0.082898864
74       SKDARRSTA          AVGSQ  0.082898864
68      ARRRANKGRP         SKDEPS  0.080398834
238         SKDEPS     ARRRANKGRP  0.080398834
72    xAVGSKDAVAIL         SKDEPS  0.075169577
310         SKDEPS   xAVGSKDAVAIL  0.075169577
140     ARRRANKGRP   DEPSTAATCIMP  0.073371196
242   DEPSTAATCIMP     ARRRANKGRP  0.073371196
28       DEPBUCKET      SKDARRSTA  0.072910977
164      SKDARRSTA      DEPBUCKET  0.072910977
119      ARRBUCKET   UPLINEATCIMP  0.071409699
187   UPLINEATCIMP      ARRBUCKET  0.071409699
122     ARRRANKGRP   UPLINEATCIMP -0.069790367
241   UPLINEATCIMP     ARRRANKGRP -0.069790367
14      ARRRANKGRP      SKDDEPSTA  0.068927801
235      SKDDEPSTA     ARRRANKGRP  0.068927801
52        ARRSPOKE         SKDEQP  0.066579707
273         SKDEQP       ARRSPOKE  0.066579707
79    UPLINEATCIMP          AVGSQ  0.062631172
113          AVGSQ   UPLINEATCIMP  0.062631172
104     ARRRANKGRP      AVGLOFATC -0.061491190
240      AVGLOFATC     ARRRANKGRP -0.061491190
250       ARRSPOKE     ARRRANKGRP -0.057002549
284     ARRRANKGRP       ARRSPOKE -0.057002549
108   xAVGSKDAVAIL      AVGLOFATC -0.056264979
312      AVGLOFATC   xAVGSKDAVAIL -0.056264979
100      DEPBUCKET      AVGLOFATC -0.053357134
168      AVGLOFATC      DEPBUCKET -0.053357134
180   xAVGSKDAVAIL      DEPBUCKET -0.053125467
316      DEPBUCKET   xAVGSKDAVAIL -0.053125467
6        AVGLOFATC      SKDDEPSTA -0.044946507
91       SKDDEPSTA      AVGLOFATC -0.044946507
101      ARRBUCKET      AVGLOFATC -0.043093769
186      AVGLOFATC      ARRBUCKET -0.043093769
50      ARRRANKGRP         SKDEQP -0.042512956
237         SKDEQP     ARRRANKGRP -0.042512956
80    DEPSTAATCIMP          AVGSQ -0.040428658
131          AVGSQ   DEPSTAATCIMP -0.040428658
59           AVGSQ         SKDEPS -0.038820886
76          SKDEPS          AVGSQ -0.038820886
46       DEPBUCKET         SKDEQP  0.037125178
165         SKDEQP      DEPBUCKET  0.037125178
106       ARRSPOKE      AVGLOFATC -0.034402462
276      AVGLOFATC       ARRSPOKE -0.034402462
54    xAVGSKDAVAIL         SKDEQP  0.031863410
309         SKDEQP   xAVGSKDAVAIL  0.031863410
67      TRNRANKGRP         SKDEPS  0.030883560
220         SKDEPS     TRNRANKGRP  0.030883560
64       DEPBUCKET         SKDEPS -0.030101407
166         SKDEPS      DEPBUCKET -0.030101407
35          xDURN2      SKDARRSTA  0.027576751
290      SKDARRSTA         xDURN2  0.027576751
78       AVGLOFATC          AVGSQ -0.027382453
95           AVGSQ      AVGLOFATC -0.027382453
36    xAVGSKDAVAIL      SKDARRSTA  0.027225219
308      SKDARRSTA   xAVGSKDAVAIL  0.027225219
66      DEPRANKGRP         SKDEPS  0.027025501
202         SKDEPS     DEPRANKGRP  0.027025501
4           SKDEPS      SKDDEPSTA -0.024267794
55       SKDDEPSTA         SKDEPS -0.024267794
43    UPLINEATCIMP         SKDEQP -0.019807499
111         SKDEQP   UPLINEATCIMP -0.019807499
51        DEPSPOKE         SKDEQP  0.019755644
255         SKDEQP       DEPSPOKE  0.019755644
306   xAVGSKDAVAIL         xDURN2 -0.019255572
323         xDURN2   xAVGSKDAVAIL -0.019255572
252   xAVGSKDAVAIL     ARRRANKGRP -0.018743432
320     ARRRANKGRP   xAVGSKDAVAIL -0.018743432
143         xDURN2   DEPSTAATCIMP -0.017999758
296   DEPSTAATCIMP         xDURN2 -0.017999758
45  DOWNLINEATCIMP         SKDEQP -0.017658860
147         SKDEQP DOWNLINEATCIMP -0.017658860
70        ARRSPOKE         SKDEPS  0.017573485
274         SKDEPS       ARRSPOKE  0.017573485
65       ARRBUCKET         SKDEPS  0.017414895
184         SKDEPS      ARRBUCKET  0.017414895
32      ARRRANKGRP      SKDARRSTA  0.016733374
236      SKDARRSTA     ARRRANKGRP  0.016733374
41           AVGSQ         SKDEQP  0.010218807
75          SKDEQP          AVGSQ  0.010218807
47       ARRBUCKET         SKDEQP  0.009926479
183         SKDEQP      ARRBUCKET  0.009926479
105       DEPSPOKE      AVGLOFATC -0.008540402
258      AVGLOFATC       DEPSPOKE -0.008540402
60       AVGLOFATC         SKDEPS  0.008240563
94          SKDEPS      AVGLOFATC  0.008240563
44    DEPSTAATCIMP         SKDEQP -0.005922601
129         SKDEQP   DEPSTAATCIMP -0.005922601
42       AVGLOFATC         SKDEQP -0.004889040
93          SKDEQP      AVGLOFATC -0.004889040
69        DEPSPOKE         SKDEPS -0.004617067
256         SKDEPS       DEPSPOKE -0.004617067
61    UPLINEATCIMP         SKDEPS  0.004016263
112         SKDEPS   UPLINEATCIMP  0.004016263
71          xDURN2         SKDEPS  0.001748012
292         SKDEPS         xDURN2  0.001748012

> ### Models
> 
> ## Try GBM (gradient boosting). Works well for mixed data.
> ## And there is a tutorial for it with caret.
> 
> ## Training controller and big grid
> ## Check the ROC (my preferred.)
> 
> # I'm not using this at the moment.
> 
> tr.cols <- colnames(trainDescr)

> tr.cols
 [1] "SKDDEPSTA"      "SKDARRSTA"      "SKDEQP"         "SKDEPS"        
 [5] "AVGSQ"          "AVGLOFATC"      "UPLINEATCIMP"   "DEPSTAATCIMP"  
 [9] "DOWNLINEATCIMP" "DEPBUCKET"      "ARRBUCKET"      "DEPRANKGRP"    
[13] "TRNRANKGRP"     "ARRRANKGRP"     "DEPSPOKE"       "ARRSPOKE"      
[17] "xDURN2"         "xAVGSKDAVAIL"  

> tr.icols <- grep("((STA|EQP)$)|(^xD)", tr.cols)

> tr.icols <- rev(tr.icols)

> fitControl <- trainControl(## 10-fold CV
+     method = "repeatedcv",
+     number = 10,
+     ## repeated ten times
+     repeats = 10,
+     classProbs = TRUE,
+     summaryFunction = twoClassSummary)

> ## Some trial and error with variables to branch and boost.
> ## Try all variables
> 
> gbmGrid <- expand.grid(interaction.depth = 
+                            length(colnames(trainDescr)),
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.2,
+                 .... [TRUNCATED] 

> set.seed(seed.mine)

> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "Kapp ..." ... [TRUNCATED] 
Loading required package: gbm
Loading required package: survival

Attaching package: 'survival'

The following object is masked from 'package:caret':

    cluster

Loading required package: splines
Loaded gbm 2.1.1
Loading required package: plyr

> gbmFit1
Stochastic Gradient Boosting 

248 samples
 18 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 222, 223, 223, 224, 223, 223, ... 

Resampling results across tuning parameters:

  n.trees  ROC        Sens       Spec       ROC SD      Sens SD    Spec SD  
    90     0.7492187  0.7168681  0.6496970  0.09146887  0.1183539  0.1272602
   180     0.7495871  0.7043956  0.6559848  0.09630313  0.1223435  0.1295446
   270     0.7464019  0.7111538  0.6568939  0.09285957  0.1206702  0.1319706
   360     0.7502493  0.7131868  0.6478788  0.09138317  0.1216937  0.1261500
   450     0.7463765  0.7124725  0.6513636  0.09583922  0.1152195  0.1333892
   540     0.7474151  0.7151648  0.6540909  0.09344322  0.1140053  0.1328372
   630     0.7466367  0.7219780  0.6559091  0.09357245  0.1204444  0.1319481
   720     0.7451311  0.7224725  0.6559848  0.09362990  0.1172304  0.1295714
   810     0.7450112  0.7239011  0.6497727  0.09304817  0.1163790  0.1336622
   900     0.7441704  0.7240110  0.6478788  0.09512993  0.1182054  0.1302915
   990     0.7436801  0.7262637  0.6461364  0.09588569  0.1162348  0.1285617
  1080     0.7441554  0.7247802  0.6479545  0.09491961  0.1197540  0.1238823
  1170     0.7429878  0.7232967  0.6415909  0.09501370  0.1181142  0.1239817
  1260     0.7428161  0.7247802  0.6487879  0.09564067  0.1215310  0.1253064
  1350     0.7422990  0.7219231  0.6506818  0.09645096  0.1180325  0.1231475
  1440     0.7431972  0.7233516  0.6534091  0.09739013  0.1203010  0.1244841
  1530     0.7434291  0.7204945  0.6524242  0.09682833  0.1149508  0.1254209
  1620     0.7418977  0.7219231  0.6460606  0.09529932  0.1179627  0.1252164
  1710     0.7406327  0.7169780  0.6470455  0.09553259  0.1200196  0.1227618
  1800     0.7412344  0.7096703  0.6624242  0.09324471  0.1235803  0.1155778
  1890     0.7384765  0.6979121  0.6741667  0.09685727  0.1215156  0.1121678
  1980     0.7391196  0.6891758  0.6850000  0.09653725  0.1285881  0.1174332
  2070     0.7384669  0.6745604  0.6950000  0.09392612  0.1285967  0.1145617
  2160     0.7375803  0.6696154  0.7040152  0.09606853  0.1252177  0.1189784
  2250     0.7376444  0.6607692  0.7210606  0.09715351  0.1280114  0.1211374
  2340     0.7376923  0.6520330  0.7281818  0.09639182  0.1308468  0.1205901
  2430     0.7387075  0.6419231  0.7363636  0.09425798  0.1286564  0.1219702
  2520     0.7383500  0.6332418  0.7391667  0.09475335  0.1257929  0.1286562
  2610     0.7387492  0.6244505  0.7462121  0.09627933  0.1239786  0.1281697
  2700     0.7391357  0.6223626  0.7531818  0.09476717  0.1213446  0.1242968

Tuning parameter 'interaction.depth' was held constant at a value of 18

Tuning parameter 'shrinkage' was held constant at a value of 0.2

Tuning parameter 'n.minobsinnode' was held constant at a value of 10
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 360, interaction.depth =
 18, shrinkage = 0.2 and n.minobsinnode = 10. 

> ## The acid test is dissapointing, but I've seen worse.
> 
> testPred <- predict(gbmFit1, testDescr)

> postResample(testPred, testClass)
  Accuracy      Kappa 
 0.4444444 -0.1392405 

> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     22   22
    Weak       18   10
                                          
               Accuracy : 0.4444          
                 95% CI : (0.3272, 0.5664)
    No Information Rate : 0.5556          
    P-Value [Acc > NIR] : 0.9778          
                                          
                  Kappa : -0.1392         
 Mcnemar's Test P-Value : 0.6353          
                                          
            Sensitivity : 0.3125          
            Specificity : 0.5500          
         Pos Pred Value : 0.3571          
         Neg Pred Value : 0.5000          
             Prevalence : 0.4444          
         Detection Rate : 0.1389          
   Detection Prevalence : 0.3889          
      Balanced Accuracy : 0.4313          
                                          
       'Positive' Class : Weak            
                                          

> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)

> postResample(trainPred, trainClass)
Accuracy    Kappa 
       1        1 

> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    137    0
    Weak        0  111
                                     
               Accuracy : 1          
                 95% CI : (0.9852, 1)
    No Information Rate : 0.5524     
    P-Value [Acc > NIR] : < 2.2e-16  
                                     
                  Kappa : 1          
 Mcnemar's Test P-Value : NA         
                                     
            Sensitivity : 1.0000     
            Specificity : 1.0000     
         Pos Pred Value : 1.0000     
         Neg Pred Value : 1.0000     
             Prevalence : 0.4476     
         Detection Rate : 0.4476     
   Detection Prevalence : 0.4476     
      Balanced Accuracy : 1.0000     
                                     
       'Positive' Class : Weak       
                                     
Warning messages:
1: In eval(expr, envir, enclos) : adjusting
2: In eval(expr, envir, enclos) :
  overfitting: correlations: err.trainDescr: SDEPHR
3: In train.default(trainDescr, trainClass, method = "gbm", trControl = fitControl,  :
  The metric "Kappa" was not in the result set. ROC will be used instead.
> gbmGrid <- expand.grid(interaction.depth = 
+                            length(colnames(trainDescr)),
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.2,
+                         n.minobsinnode = 10)
> 
> set.seed(seed.mine)
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "ROC",
+                  verbose = FALSE)
> gbmFit1
Stochastic Gradient Boosting 

248 samples
 18 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 222, 223, 223, 224, 223, 223, ... 

Resampling results across tuning parameters:

  n.trees  ROC        Sens       Spec       ROC SD      Sens SD    Spec SD  
    90     0.7450416  0.7050000  0.6533333  0.09231115  0.1246442  0.1264788
   180     0.7426232  0.7137912  0.6453030  0.09512261  0.1234134  0.1372593
   270     0.7432988  0.7175824  0.6543939  0.10057952  0.1164304  0.1289016
   360     0.7414286  0.7175275  0.6514394  0.09709401  0.1182111  0.1277620
   450     0.7426894  0.7168132  0.6487879  0.09554245  0.1236906  0.1194659
   540     0.7407455  0.7133516  0.6440909  0.09482079  0.1221191  0.1224776
   630     0.7410410  0.7184066  0.6505303  0.09485776  0.1213785  0.1275402
   720     0.7422565  0.7132418  0.6460606  0.09268701  0.1225321  0.1166550
   810     0.7398614  0.7147253  0.6450758  0.09383592  0.1159624  0.1200654
   900     0.7415851  0.7198352  0.6388636  0.09293129  0.1138173  0.1268218
   990     0.7426590  0.7189011  0.6433333  0.09314399  0.1154354  0.1239114
  1080     0.7416321  0.7168132  0.6433333  0.09740026  0.1170115  0.1206065
  1170     0.7429797  0.7167582  0.6415909  0.09373122  0.1174925  0.1198447
  1260     0.7426711  0.7154396  0.6434848  0.09453193  0.1151460  0.1200628
  1350     0.7416958  0.7160989  0.6417424  0.09706725  0.1163624  0.1257856
  1440     0.7431789  0.7168132  0.6373485  0.09596110  0.1156827  0.1262748
  1530     0.7423772  0.7132967  0.6371212  0.09637691  0.1161902  0.1260351
  1620     0.7403653  0.7132418  0.6381061  0.09651598  0.1149641  0.1238842
  1710     0.7405284  0.7102747  0.6408333  0.09538963  0.1182853  0.1234775
  1800     0.7399523  0.7058242  0.6543939  0.09299705  0.1177131  0.1173769
  1890     0.7388501  0.6956593  0.6671212  0.09560012  0.1168589  0.1215170
  1980     0.7389473  0.6839560  0.6823485  0.09448854  0.1173526  0.1196247
  2070     0.7394620  0.6760989  0.7056061  0.09656296  0.1174510  0.1244639
  2160     0.7381926  0.6643956  0.7136364  0.09699515  0.1136489  0.1252346
  2250     0.7384803  0.6570879  0.7243939  0.09409316  0.1129232  0.1203760
  2340     0.7357669  0.6476374  0.7343182  0.09988326  0.1160307  0.1252959
  2430     0.7379606  0.6375824  0.7388636  0.09733904  0.1177791  0.1252876
  2520     0.7376567  0.6280769  0.7461364  0.09718664  0.1221981  0.1226881
  2610     0.7359474  0.6157692  0.7543182  0.09719917  0.1201967  0.1193967
  2700     0.7352165  0.6106593  0.7624242  0.09773968  0.1194913  0.1203988

Tuning parameter 'interaction.depth' was held constant at a value of 18

Tuning parameter 'shrinkage' was held constant at a value of 0.2

Tuning parameter 'n.minobsinnode' was held constant at a value of 10
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 90, interaction.depth =
 18, shrinkage = 0.2 and n.minobsinnode = 10. 
> 
> ## The acid test is dissapointing, but I've seen worse.
> 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
  Accuracy      Kappa 
0.52777778 0.03164557 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     25   19
    Weak       15   13
                                          
               Accuracy : 0.5278          
                 95% CI : (0.4065, 0.6467)
    No Information Rate : 0.5556          
    P-Value [Acc > NIR] : 0.7242          
                                          
                  Kappa : 0.0316          
 Mcnemar's Test P-Value : 0.6069          
                                          
            Sensitivity : 0.4062          
            Specificity : 0.6250          
         Pos Pred Value : 0.4643          
         Neg Pred Value : 0.5682          
             Prevalence : 0.4444          
         Detection Rate : 0.1806          
   Detection Prevalence : 0.3889          
      Balanced Accuracy : 0.5156          
                                          
       'Positive' Class : Weak            
                                          
> 
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
Accuracy    Kappa 
       1        1 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    137    0
    Weak        0  111
                                     
               Accuracy : 1          
                 95% CI : (0.9852, 1)
    No Information Rate : 0.5524     
    P-Value [Acc > NIR] : < 2.2e-16  
                                     
                  Kappa : 1          
 Mcnemar's Test P-Value : NA         
                                     
            Sensitivity : 1.0000     
            Specificity : 1.0000     
         Pos Pred Value : 1.0000     
         Neg Pred Value : 1.0000     
             Prevalence : 0.4476     
         Detection Rate : 0.4476     
   Detection Prevalence : 0.4476     
      Balanced Accuracy : 1.0000     
                                     
       'Positive' Class : Weak       
                                     
> set.seed(seed.mine)
> inTrain <- createDataPartition(outcomes.flight, p = 0.77, list = FALSE)
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> ### weaves
> 
> ## Processing for flights data.
> 
> ## Following the caret vignette.
> 
> ###################################################
> ### code chunk number 1: loadLibs
> ###################################################
> library(MASS)
> library(caret)
> library(mlbench)
> library(pROC)
> library(pls)
> 
> library(doMC)
> registerDoMC(cores = 4)
> 
> options(useFancyQuotes = FALSE) 
> 
> # Accounting info.
> getInfo <- function(what = "Suggests")
+ {
+   text <- packageDescription("caret")[what][[1]]
+   text <- gsub("\n", ", ", text, fixed = TRUE)
+   text <- gsub(">=", "$\\\\ge$", text, fixed = TRUE)
+   eachPkg <- strsplit(text, ", ", fixed = TRUE)[[1]]
+   eachPkg <- gsub(",", "", eachPkg, fixed = TRUE)
+   # out <- paste("\\\\pkg{", eachPkg[order(tolower(eachPkg))], "}", sep = "")
+   # paste(out, collapse = ", ")
+   length(eachPkg)
+ }
> 
> ### project-specific: begin
> ## Set-seed, load original CSV file, order it
> ## and do some simple-cleaning
> ## Various datasets 
> 
> seed.mine = 107
> set.seed(seed.mine)                     # helpful for testing
> 
> flight <- read.csv("../bak/flight.csv")
> flight <- flight[order(flight$D00),]
> 
> # Backup
> flight.raw <- flight
> 
> # To check adjustment, there is test code in flight-nb.R
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"
> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"
> 
> # And some deletions
> 
> t.cols <- colnames(flight)
> 
> t.drops <- t.cols[grep("^RANK*", t.cols)]
> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])
> t.drops <- c(t.drops, "D80THPCTL")
> 
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR
> flight$xHNGR <- flight$xDURN < 0
> 
> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+ }
> 
> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))
> 
> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE
> t.cols <- colnames(flight)
> 
> t.drops <- c("SARRHR", "xDURN")
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Backup
> 
> flight00 <- flight
> 
> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]
> 
> paste("samples in use: ", dim(flight)[1])
[1] "samples in use:  320"
> 
> ## Data insights
> 
> ## *Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> ### Numeric variables
> 
> ### Try and impute the AVG, it might have more information than the
> ### bucket.
> 
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))
> 
> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1
> 
> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]
> 
> preProcValues <- preProcess(flight.na, method = c("knnImpute"))
> flight.na1 <- predict(preProcValues, flight.na)
> 
> ## I'll add the new imputed value and drop the others
> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL
> flight$AVGSKDAVAIL <- NULL
> flight$xAVAILBUCKET <- NULL
> flight$AVAILBUCKET <- NULL
> 
> flight$xHNGR <- NULL
> 
> ## Check some more numeric correlations, I haven't scaled everything yet.
> ## I'd cut correlations above 0.65 to 0.75 because of overfitting.
> 
> x1 <- as.data.frame(as.matrix(sapply(flight, class)))
> 
> flight.num <- flight[,names(x1[which(x1$V1 %in% c("numeric", "integer")),])]
> 
> flight.nzv <- nearZeroVar(flight.num, saveMetrics = TRUE)
> flight.nzv
             freqRatio percentUnique zeroVar   nzv
SDEPHR        1.038462        5.9375   FALSE FALSE
SKDEPS        1.000000       19.0625   FALSE FALSE
D00           1.166667       75.3125   FALSE FALSE
AVGSQ         6.333333       82.8125   FALSE FALSE
AVGLOFATC     1.000000       78.4375   FALSE FALSE
xDURN2        1.428571        2.5000   FALSE FALSE
xAVGSKDAVAIL 18.500000       87.8125   FALSE FALSE
> 
> # annoying NA should be gone.
> flight.cor <- cor(flight.num, use = "pairwise.complete.obs")
> 
> descrCorr <- findCorrelation(flight.cor, cutoff = .65, verbose=TRUE)
Considering row	 4 column	 1 value	 0.956 
  Flagging column	 4 
Considering row	 1 column	 3 value	 0.43 
Considering row	 1 column	 7 value	 0.053 
Considering row	 1 column	 6 value	 0.204 
Considering row	 1 column	 5 value	 0.131 
Considering row	 1 column	 2 value	 0.054 
Considering row	 3 column	 7 value	 0.401 
Considering row	 3 column	 6 value	 0.071 
Considering row	 3 column	 5 value	 0.114 
Considering row	 3 column	 2 value	 0.006 
Considering row	 7 column	 6 value	 0.019 
Considering row	 7 column	 5 value	 0.07 
Considering row	 7 column	 2 value	 0.113 
Considering row	 6 column	 5 value	 0.137 
Considering row	 6 column	 2 value	 0.005 
Considering row	 5 column	 2 value	 0.041 
> 
> colnames(flight.num)[descrCorr]
[1] "AVGSQ"
> 
> ## And I'll leave the centered and scale values in for now.
> ## and delete the troublesome ones
> 
> ## Re-classing
> ## Check warnings to see it adjustment has taken place.
> ## We want the proportion in the training class to be about 0.55 0.45
> ## Strong to Weak
> ## I've achieved this heuristically
> src.adjust <- TRUE
> source(file = "flight1.R")
Warning message:
In eval(expr, envir, enclos) : adjusting
> flight1 <- flight
> 
> ## This should be deleted, leave it in and the results
> ## are ideal because it defines LEGTYPE.
> flight$D00 <- NULL
> 
> ## Keep the results but don't change the order.
> outcomes.flight <- flight$LEGTYPE
> 
> flight$LEGTYPE <- NULL
> 
> ## If you know your factors are definitely factors, you don't need this
> ##  asNumeric <- function(x) as.numeric(as.character(x))
> 
> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))
> 
> flight.num0 <- factors.numeric(flight)
> 
> flight.scl0 <- scale(flight.num0)
> 
> ## Now split the samples
> ## we need at least 60 to test with, p at 0.77 gives about 75.
> ## Difficulty here is the bias in the table
> ## Because we only have [3.1, 4.4] the proportion of Weak is higher.
> ## see prop.table(results)
> 
> set.seed(seed.mine)
> inTrain <- createDataPartition(outcomes.flight, p = 0.77, list = FALSE)
> 
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> 
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> 
> prop.table(table(trainClass))
trainClass
   Strong      Weak 
0.5524194 0.4475806 
> dim(trainDescr)
[1] 248  19
> 
> prop.table(table(testClass))
testClass
   Strong      Weak 
0.5555556 0.4444444 
> dim(testDescr)
[1] 72 19
> 
> ## Check Near-zero variance
> 
> nzv <- nearZeroVar(trainDescr, saveMetrics= TRUE)
> stopifnot( all(nzv$nzv == FALSE) )
> 
> # It's imputed and behaves well, no need for this.
> # descrCorr <- cor(scale(trainDescr), use = "pairwise.complete.obs")
> 
> descrCorr <- cor(scale(trainDescr))
> 
> ## This cut-off should be under src.adjust control.
> ## I'm under Git, so I can tinker with it.
> highCorr <- findCorrelation(descrCorr, cutoff = .80, verbose = TRUE)
Considering row	 17 column	 16 value	 0.85 
  Flagging column	 17 
Considering row	 16 column	 10 value	 0.568 
Considering row	 16 column	 1 value	 0.236 
Considering row	 16 column	 11 value	 0.231 
Considering row	 16 column	 6 value	 0.189 
Considering row	 16 column	 12 value	 0.19 
Considering row	 16 column	 2 value	 0.333 
Considering row	 16 column	 9 value	 0.671 
Considering row	 16 column	 14 value	 0.242 
Considering row	 16 column	 13 value	 0.208 
Considering row	 16 column	 8 value	 0.6 
Considering row	 16 column	 3 value	 0.318 
Considering row	 16 column	 18 value	 0.279 
Considering row	 16 column	 19 value	 0.213 
Considering row	 16 column	 15 value	 0.083 
Considering row	 16 column	 4 value	 0.02 
Considering row	 16 column	 7 value	 0.009 
Considering row	 16 column	 5 value	 0.005 
Considering row	 10 column	 1 value	 0.281 
Considering row	 10 column	 11 value	 0.275 
Considering row	 10 column	 6 value	 0.298 
Considering row	 10 column	 12 value	 0.255 
Considering row	 10 column	 2 value	 0.286 
Considering row	 10 column	 9 value	 0.404 
Considering row	 10 column	 14 value	 0.224 
Considering row	 10 column	 13 value	 0.199 
Considering row	 10 column	 8 value	 0.366 
Considering row	 10 column	 3 value	 0.462 
Considering row	 10 column	 18 value	 0.226 
Considering row	 10 column	 19 value	 0.103 
Considering row	 10 column	 15 value	 0.274 
Considering row	 10 column	 4 value	 0.018 
Considering row	 10 column	 7 value	 0.127 
Considering row	 10 column	 5 value	 0.096 
Considering row	 1 column	 11 value	 0.988 
  Flagging column	 1 
Considering row	 11 column	 6 value	 0.945 
  Flagging column	 11 
Considering row	 6 column	 12 value	 0.883 
  Flagging column	 6 
Considering row	 12 column	 2 value	 0.121 
Considering row	 12 column	 9 value	 0.128 
Considering row	 12 column	 14 value	 0.092 
Considering row	 12 column	 13 value	 0.105 
Considering row	 12 column	 8 value	 0.071 
Considering row	 12 column	 3 value	 0.093 
Considering row	 12 column	 18 value	 0.126 
Considering row	 12 column	 19 value	 0.171 
Considering row	 12 column	 15 value	 0.13 
Considering row	 12 column	 4 value	 0.01 
Considering row	 12 column	 7 value	 0.043 
Considering row	 12 column	 5 value	 0.017 
Considering row	 2 column	 9 value	 0.423 
Considering row	 2 column	 14 value	 0.574 
Considering row	 2 column	 13 value	 0.557 
Considering row	 2 column	 8 value	 0.165 
Considering row	 2 column	 3 value	 0.263 
Considering row	 2 column	 18 value	 0.128 
Considering row	 2 column	 19 value	 0.089 
Considering row	 2 column	 15 value	 0.069 
Considering row	 2 column	 4 value	 0.27 
Considering row	 2 column	 7 value	 0.045 
Considering row	 2 column	 5 value	 0.024 
Considering row	 9 column	 14 value	 0.147 
Considering row	 9 column	 13 value	 0.125 
Considering row	 9 column	 8 value	 0.449 
Considering row	 9 column	 3 value	 0.322 
Considering row	 9 column	 18 value	 0.018 
Considering row	 9 column	 19 value	 0.141 
Considering row	 9 column	 15 value	 0.073 
Considering row	 9 column	 4 value	 0.006 
Considering row	 9 column	 7 value	 0.136 
Considering row	 9 column	 5 value	 0.123 
Considering row	 14 column	 13 value	 0.659 
Considering row	 14 column	 8 value	 0.097 
Considering row	 14 column	 3 value	 0.106 
Considering row	 14 column	 18 value	 0.361 
Considering row	 14 column	 19 value	 0.092 
Considering row	 14 column	 15 value	 0.084 
Considering row	 14 column	 4 value	 0.263 
Considering row	 14 column	 7 value	 0.139 
Considering row	 14 column	 5 value	 0.031 
Considering row	 13 column	 8 value	 0.097 
Considering row	 13 column	 3 value	 0.167 
Considering row	 13 column	 18 value	 0.18 
Considering row	 13 column	 19 value	 0.131 
Considering row	 13 column	 15 value	 0.137 
Considering row	 13 column	 4 value	 0.24 
Considering row	 13 column	 7 value	 0.085 
Considering row	 13 column	 5 value	 0.027 
Considering row	 8 column	 3 value	 0.224 
Considering row	 8 column	 18 value	 0.173 
Considering row	 8 column	 19 value	 0.235 
Considering row	 8 column	 15 value	 0.07 
Considering row	 8 column	 4 value	 0.02 
Considering row	 8 column	 7 value	 0.085 
Considering row	 8 column	 5 value	 0.004 
Considering row	 3 column	 18 value	 0.028 
Considering row	 3 column	 19 value	 0.027 
Considering row	 3 column	 15 value	 0.017 
Considering row	 3 column	 4 value	 0.094 
Considering row	 3 column	 7 value	 0.095 
Considering row	 3 column	 5 value	 0.097 
Considering row	 18 column	 19 value	 0.019 
Considering row	 18 column	 15 value	 0.12 
Considering row	 18 column	 4 value	 0.086 
Considering row	 18 column	 7 value	 0.132 
Considering row	 18 column	 5 value	 0.002 
Considering row	 19 column	 15 value	 0.019 
Considering row	 19 column	 4 value	 0.032 
Considering row	 19 column	 7 value	 0.056 
Considering row	 19 column	 5 value	 0.075 
Considering row	 15 column	 4 value	 0.043 
Considering row	 15 column	 7 value	 0.061 
Considering row	 15 column	 5 value	 0.08 
Considering row	 4 column	 7 value	 0.005 
Considering row	 4 column	 5 value	 0.213 
Considering row	 7 column	 5 value	 0.008 
> 
> colnames(trainDescr)[highCorr]
[1] "ARRSPOKE"  "SDEPHR"    "DEPBUCKET" "AVGSQ"    
> 
> descr.ncol0 <- ncol(trainDescr)
> 
> # I've switched off the correlation remover and the results are better.
> if (sum(highCorr) > 0) {
+     warning("overfitting: correlations: err.trainDescr: ", paste(colnames(trainDescr)[highCorr], collapse = ", ") )
+     err.trainDescr <- trainDescr
+     trainDescr <- trainDescr[,-highCorr]
+ }
Warning message:
overfitting: correlations: err.trainDescr: ARRSPOKE, SDEPHR, DEPBUCKET, AVGSQ 
> 
> descr.ncol1 <- ncol(trainDescr)
> 
> paste("Dropped: ", as.character(descr.ncol0 - descr.ncol1))
[1] "Dropped:  4"
> 
> descrCorr <- cor(trainDescr)
> summary(descrCorr[upper.tri(descrCorr)])
     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
-0.600000 -0.123400 -0.004617  0.012770  0.102600  0.671300 
> 
> ## Dominant correlations
> ## At 0.9, there are some big ones that might need re-thinking.
> 
> table.descrCorr <- as.data.frame(as.table(descrCorr))
> table.descrCorr <- table.descrCorr[which(table.descrCorr$Var1 != table.descrCorr$Var2),]
> table.descrCorr[order(abs(table.descrCorr$Freq), decreasing = TRUE),]
              Var1           Var2         Freq
103       DEPSPOKE   DEPSTAATCIMP  0.671264566
187   DEPSTAATCIMP       DEPSPOKE  0.671264566
146     TRNRANKGRP     DEPRANKGRP  0.658724662
160     DEPRANKGRP     TRNRANKGRP  0.658724662
88        DEPSPOKE   UPLINEATCIMP -0.600008252
186   UPLINEATCIMP       DEPSPOKE -0.600008252
11      TRNRANKGRP      SKDDEPSTA  0.574035134
151      SKDDEPSTA     TRNRANKGRP  0.574035134
118       DEPSPOKE DOWNLINEATCIMP -0.567682494
188 DOWNLINEATCIMP       DEPSPOKE -0.567682494
10      DEPRANKGRP      SKDDEPSTA  0.557399203
136      SKDDEPSTA     DEPRANKGRP  0.557399203
23  DOWNLINEATCIMP      SKDARRSTA  0.462378131
107      SKDARRSTA DOWNLINEATCIMP  0.462378131
82    DEPSTAATCIMP   UPLINEATCIMP -0.449249986
96    UPLINEATCIMP   DEPSTAATCIMP -0.449249986
7     DEPSTAATCIMP      SKDDEPSTA  0.423425796
91       SKDDEPSTA   DEPSTAATCIMP  0.423425796
98  DOWNLINEATCIMP   DEPSTAATCIMP -0.403695561
112   DEPSTAATCIMP DOWNLINEATCIMP -0.403695561
83  DOWNLINEATCIMP   UPLINEATCIMP  0.365833687
111   UPLINEATCIMP DOWNLINEATCIMP  0.365833687
164         xDURN2     TRNRANKGRP  0.361347207
206     TRNRANKGRP         xDURN2  0.361347207
13        DEPSPOKE      SKDDEPSTA  0.332823310
181      SKDDEPSTA       DEPSPOKE  0.332823310
22    DEPSTAATCIMP      SKDARRSTA -0.322204878
92       SKDARRSTA   DEPSTAATCIMP -0.322204878
28        DEPSPOKE      SKDARRSTA -0.318093195
182      SKDARRSTA       DEPSPOKE -0.318093195
8   DOWNLINEATCIMP      SKDDEPSTA -0.285911992
106      SKDDEPSTA DOWNLINEATCIMP -0.285911992
194         xDURN2       DEPSPOKE  0.279030910
208       DEPSPOKE         xDURN2  0.279030910
117     ARRRANKGRP DOWNLINEATCIMP -0.274110143
173 DOWNLINEATCIMP     ARRRANKGRP -0.274110143
3           SKDEQP      SKDDEPSTA  0.270065872
31       SKDDEPSTA         SKDEQP  0.270065872
2        SKDARRSTA      SKDDEPSTA -0.263453106
16       SKDDEPSTA      SKDARRSTA -0.263453106
41      TRNRANKGRP         SKDEQP  0.262837233
153         SKDEQP     TRNRANKGRP  0.262837233
114      ARRBUCKET DOWNLINEATCIMP  0.255480148
128 DOWNLINEATCIMP      ARRBUCKET  0.255480148
163       DEPSPOKE     TRNRANKGRP  0.242138220
191     TRNRANKGRP       DEPSPOKE  0.242138220
40      DEPRANKGRP         SKDEQP  0.239915140
138         SKDEQP     DEPRANKGRP  0.239915140
90    xAVGSKDAVAIL   UPLINEATCIMP  0.234867014
216   UPLINEATCIMP   xAVGSKDAVAIL  0.234867014
119         xDURN2 DOWNLINEATCIMP -0.226093423
203 DOWNLINEATCIMP         xDURN2 -0.226093423
116     TRNRANKGRP DOWNLINEATCIMP -0.224193213
158 DOWNLINEATCIMP     TRNRANKGRP -0.224193213
21    UPLINEATCIMP      SKDARRSTA  0.223824406
77       SKDARRSTA   UPLINEATCIMP  0.223824406
195   xAVGSKDAVAIL       DEPSPOKE -0.212821518
223       DEPSPOKE   xAVGSKDAVAIL -0.212821518
34          SKDEPS         SKDEQP  0.212586898
48          SKDEQP         SKDEPS  0.212586898
148       DEPSPOKE     DEPRANKGRP  0.208188512
190     DEPRANKGRP       DEPSPOKE  0.208188512
115     DEPRANKGRP DOWNLINEATCIMP -0.199411990
143 DOWNLINEATCIMP     DEPRANKGRP -0.199411990
133       DEPSPOKE      ARRBUCKET -0.189934966
189      ARRBUCKET       DEPSPOKE -0.189934966
149         xDURN2     DEPRANKGRP  0.180043357
205     DEPRANKGRP         xDURN2  0.180043357
89          xDURN2   UPLINEATCIMP -0.173240320
201   UPLINEATCIMP         xDURN2 -0.173240320
135   xAVGSKDAVAIL      ARRBUCKET -0.170644257
219      ARRBUCKET   xAVGSKDAVAIL -0.170644257
25      DEPRANKGRP      SKDARRSTA -0.167375913
137      SKDARRSTA     DEPRANKGRP -0.167375913
6     UPLINEATCIMP      SKDDEPSTA -0.164964952
76       SKDDEPSTA   UPLINEATCIMP -0.164964952
101     TRNRANKGRP   DEPSTAATCIMP -0.147409309
157   DEPSTAATCIMP     TRNRANKGRP -0.147409309
105   xAVGSKDAVAIL   DEPSTAATCIMP -0.141077194
217   DEPSTAATCIMP   xAVGSKDAVAIL -0.141077194
71      TRNRANKGRP      AVGLOFATC  0.139184315
155      AVGLOFATC     TRNRANKGRP  0.139184315
147     ARRRANKGRP     DEPRANKGRP  0.136562948
175     DEPRANKGRP     ARRRANKGRP  0.136562948
67    DEPSTAATCIMP      AVGLOFATC -0.135778614
95       AVGLOFATC   DEPSTAATCIMP -0.135778614
74          xDURN2      AVGLOFATC -0.132084629
200      AVGLOFATC         xDURN2 -0.132084629
150   xAVGSKDAVAIL     DEPRANKGRP  0.130574789
220     DEPRANKGRP   xAVGSKDAVAIL  0.130574789
132     ARRRANKGRP      ARRBUCKET -0.129698517
174      ARRBUCKET     ARRRANKGRP -0.129698517
99       ARRBUCKET   DEPSTAATCIMP -0.127726148
127   DEPSTAATCIMP      ARRBUCKET -0.127726148
14          xDURN2      SKDDEPSTA  0.127598189
196      SKDDEPSTA         xDURN2  0.127598189
68  DOWNLINEATCIMP      AVGLOFATC -0.126763572
110      AVGLOFATC DOWNLINEATCIMP -0.126763572
134         xDURN2      ARRBUCKET -0.125836459
204      ARRBUCKET         xDURN2 -0.125836459
100     DEPRANKGRP   DEPSTAATCIMP  0.124672682
142   DEPSTAATCIMP     DEPRANKGRP  0.124672682
52    DEPSTAATCIMP         SKDEPS -0.123445793
94          SKDEPS   DEPSTAATCIMP -0.123445793
9        ARRBUCKET      SKDDEPSTA -0.120728212
121      SKDDEPSTA      ARRBUCKET -0.120728212
179         xDURN2     ARRRANKGRP  0.119675180
207     ARRRANKGRP         xDURN2  0.119675180
26      TRNRANKGRP      SKDARRSTA -0.105802023
152      SKDARRSTA     TRNRANKGRP -0.105802023
130     DEPRANKGRP      ARRBUCKET -0.105057984
144      ARRBUCKET     DEPRANKGRP -0.105057984
120   xAVGSKDAVAIL DOWNLINEATCIMP  0.102577364
218 DOWNLINEATCIMP   xAVGSKDAVAIL  0.102577364
85      DEPRANKGRP   UPLINEATCIMP -0.097218129
141   UPLINEATCIMP     DEPRANKGRP -0.097218129
86      TRNRANKGRP   UPLINEATCIMP -0.097037814
156   UPLINEATCIMP     TRNRANKGRP -0.097037814
19          SKDEPS      SKDARRSTA -0.096699169
47       SKDARRSTA         SKDEPS -0.096699169
53  DOWNLINEATCIMP         SKDEPS -0.095568613
109         SKDEPS DOWNLINEATCIMP -0.095568613
20       AVGLOFATC      SKDARRSTA -0.095234466
62       SKDARRSTA      AVGLOFATC -0.095234466
18          SKDEQP      SKDARRSTA  0.094073459
32       SKDARRSTA         SKDEQP  0.094073459
24       ARRBUCKET      SKDARRSTA  0.092625400
122      SKDARRSTA      ARRBUCKET  0.092625400
131     TRNRANKGRP      ARRBUCKET -0.092415252
159      ARRBUCKET     TRNRANKGRP -0.092415252
165   xAVGSKDAVAIL     TRNRANKGRP  0.092011501
221     TRNRANKGRP   xAVGSKDAVAIL  0.092011501
15    xAVGSKDAVAIL      SKDDEPSTA  0.088580325
211      SKDDEPSTA   xAVGSKDAVAIL  0.088580325
44          xDURN2         SKDEQP  0.086170070
198         SKDEQP         xDURN2  0.086170070
70      DEPRANKGRP      AVGLOFATC  0.085474019
140      AVGLOFATC     DEPRANKGRP  0.085474019
66    UPLINEATCIMP      AVGLOFATC -0.085180887
80       AVGLOFATC   UPLINEATCIMP -0.085180887
162     ARRRANKGRP     TRNRANKGRP  0.083906762
176     TRNRANKGRP     ARRRANKGRP  0.083906762
178       DEPSPOKE     ARRRANKGRP  0.083162083
192     ARRRANKGRP       DEPSPOKE  0.083162083
57      ARRRANKGRP         SKDEPS  0.080398834
169         SKDEPS     ARRRANKGRP  0.080398834
60    xAVGSKDAVAIL         SKDEPS  0.075169577
214         SKDEPS   xAVGSKDAVAIL  0.075169577
102     ARRRANKGRP   DEPSTAATCIMP  0.073371196
172   DEPSTAATCIMP     ARRRANKGRP  0.073371196
84       ARRBUCKET   UPLINEATCIMP  0.071409699
126   UPLINEATCIMP      ARRBUCKET  0.071409699
87      ARRRANKGRP   UPLINEATCIMP -0.069790367
171   UPLINEATCIMP     ARRRANKGRP -0.069790367
12      ARRRANKGRP      SKDDEPSTA  0.068927801
166      SKDDEPSTA     ARRRANKGRP  0.068927801
72      ARRRANKGRP      AVGLOFATC -0.061491190
170      AVGLOFATC     ARRRANKGRP -0.061491190
75    xAVGSKDAVAIL      AVGLOFATC -0.056264979
215      AVGLOFATC   xAVGSKDAVAIL -0.056264979
5        AVGLOFATC      SKDDEPSTA -0.044946507
61       SKDDEPSTA      AVGLOFATC -0.044946507
69       ARRBUCKET      AVGLOFATC -0.043093769
125      AVGLOFATC      ARRBUCKET -0.043093769
42      ARRRANKGRP         SKDEQP -0.042512956
168         SKDEQP     ARRRANKGRP -0.042512956
45    xAVGSKDAVAIL         SKDEQP  0.031863410
213         SKDEQP   xAVGSKDAVAIL  0.031863410
56      TRNRANKGRP         SKDEPS  0.030883560
154         SKDEPS     TRNRANKGRP  0.030883560
29          xDURN2      SKDARRSTA  0.027576751
197      SKDARRSTA         xDURN2  0.027576751
30    xAVGSKDAVAIL      SKDARRSTA  0.027225219
212      SKDARRSTA   xAVGSKDAVAIL  0.027225219
55      DEPRANKGRP         SKDEPS  0.027025501
139         SKDEPS     DEPRANKGRP  0.027025501
4           SKDEPS      SKDDEPSTA -0.024267794
46       SKDDEPSTA         SKDEPS -0.024267794
36    UPLINEATCIMP         SKDEQP -0.019807499
78          SKDEQP   UPLINEATCIMP -0.019807499
43        DEPSPOKE         SKDEQP  0.019755644
183         SKDEQP       DEPSPOKE  0.019755644
210   xAVGSKDAVAIL         xDURN2 -0.019255572
224         xDURN2   xAVGSKDAVAIL -0.019255572
180   xAVGSKDAVAIL     ARRRANKGRP -0.018743432
222     ARRRANKGRP   xAVGSKDAVAIL -0.018743432
104         xDURN2   DEPSTAATCIMP -0.017999758
202   DEPSTAATCIMP         xDURN2 -0.017999758
38  DOWNLINEATCIMP         SKDEQP -0.017658860
108         SKDEQP DOWNLINEATCIMP -0.017658860
54       ARRBUCKET         SKDEPS  0.017414895
124         SKDEPS      ARRBUCKET  0.017414895
27      ARRRANKGRP      SKDARRSTA  0.016733374
167      SKDARRSTA     ARRRANKGRP  0.016733374
39       ARRBUCKET         SKDEQP  0.009926479
123         SKDEQP      ARRBUCKET  0.009926479
73        DEPSPOKE      AVGLOFATC -0.008540402
185      AVGLOFATC       DEPSPOKE -0.008540402
50       AVGLOFATC         SKDEPS  0.008240563
64          SKDEPS      AVGLOFATC  0.008240563
37    DEPSTAATCIMP         SKDEQP -0.005922601
93          SKDEQP   DEPSTAATCIMP -0.005922601
35       AVGLOFATC         SKDEQP -0.004889040
63          SKDEQP      AVGLOFATC -0.004889040
58        DEPSPOKE         SKDEPS -0.004617067
184         SKDEPS       DEPSPOKE -0.004617067
51    UPLINEATCIMP         SKDEPS  0.004016263
79          SKDEPS   UPLINEATCIMP  0.004016263
59          xDURN2         SKDEPS  0.001748012
199         SKDEPS         xDURN2  0.001748012
> 
> ### Models
> 
> ## Try GBM (gradient boosting). Works well for mixed data.
> ## And there is a tutorial for it with caret.
> 
> ## Training controller and big grid
> ## Check the ROC (my preferred.)
> 
> # I'm not using this at the moment.
> 
> tr.cols <- colnames(trainDescr)
> tr.cols
 [1] "SKDDEPSTA"      "SKDARRSTA"      "SKDEQP"         "SKDEPS"        
 [5] "AVGLOFATC"      "UPLINEATCIMP"   "DEPSTAATCIMP"   "DOWNLINEATCIMP"
 [9] "ARRBUCKET"      "DEPRANKGRP"     "TRNRANKGRP"     "ARRRANKGRP"    
[13] "DEPSPOKE"       "xDURN2"         "xAVGSKDAVAIL"  
> tr.icols <- grep("((STA|EQP)$)|(^xD)", tr.cols)
> tr.icols <- rev(tr.icols)
> 
> fitControl <- trainControl(## 10-fold CV
+     method = "repeatedcv",
+     number = 10,
+     ## repeated ten times
+     repeats = 10,
+     classProbs = TRUE,
+     summaryFunction = twoClassSummary)
> 
> ## Some trial and error with variables to branch and boost.
> ## Try all variables
> 
> gbmGrid <- expand.grid(interaction.depth = 
+                            length(colnames(trainDescr)),
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.2,
+                         n.minobsinnode = 10)
> 
> set.seed(seed.mine)
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "ROC",
+                  verbose = FALSE)
> gbmFit1
Stochastic Gradient Boosting 

248 samples
 15 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 222, 223, 223, 224, 223, 223, ... 

Resampling results across tuning parameters:

  n.trees  ROC        Sens       Spec       ROC SD      Sens SD    Spec SD  
    90     0.7205524  0.6977473  0.6253030  0.09284581  0.1136350  0.1207877
   180     0.7134366  0.6949451  0.6209091  0.09469234  0.1219828  0.1231335
   270     0.7116292  0.6934615  0.6100758  0.09099778  0.1192084  0.1204996
   360     0.7097773  0.6884615  0.6245455  0.09317606  0.1111991  0.1280512
   450     0.7113441  0.6899451  0.6216667  0.09535103  0.1107147  0.1266148
   540     0.7079833  0.6834615  0.6216667  0.09870284  0.1135851  0.1233823
   630     0.7055432  0.6834066  0.6234848  0.09927061  0.1160521  0.1208553
   720     0.7059382  0.6885714  0.6206818  0.10445390  0.1122835  0.1173792
   810     0.7042478  0.6877473  0.6279545  0.10519627  0.1112417  0.1243281
   900     0.7092903  0.6914286  0.6242424  0.09439095  0.1110652  0.1233878
   990     0.7085918  0.6915385  0.6180303  0.09910894  0.1084291  0.1233229
  1080     0.7057919  0.6914286  0.6253030  0.10065141  0.1141229  0.1228436
  1170     0.7110554  0.6906044  0.6253030  0.09799237  0.1122042  0.1235213
  1260     0.7111695  0.6920330  0.6305303  0.09819768  0.1087727  0.1218411
  1350     0.7104181  0.6936264  0.6306818  0.09694832  0.1089037  0.1227962
  1440     0.7102504  0.6892857  0.6306061  0.09614270  0.1114617  0.1196143
  1530     0.7090299  0.6900000  0.6278788  0.09566320  0.1099932  0.1208542
  1620     0.7093188  0.6900000  0.6296970  0.09077781  0.1119253  0.1210795
  1710     0.7089993  0.6893956  0.6296212  0.09671808  0.1154188  0.1211207
  1800     0.7096886  0.6937363  0.6314394  0.09142336  0.1111061  0.1205184
  1890     0.7087009  0.6878022  0.6342424  0.09611141  0.1115273  0.1157370
  1980     0.7075254  0.6834066  0.6377273  0.09633981  0.1149458  0.1153522
  2070     0.7090718  0.6710989  0.6513636  0.09213573  0.1179553  0.1154607
  2160     0.7072919  0.6657692  0.6657576  0.09652109  0.1233614  0.1120736
  2250     0.7080586  0.6578571  0.6739394  0.08995694  0.1194628  0.1156410
  2340     0.7097453  0.6475275  0.6775000  0.09345671  0.1257492  0.1146913
  2430     0.7110219  0.6373077  0.6893182  0.09251897  0.1259167  0.1166919
  2520     0.7108639  0.6323077  0.6911364  0.09221171  0.1274912  0.1136586
  2610     0.7106712  0.6272527  0.7003030  0.08980895  0.1299809  0.1165817
  2700     0.7099292  0.6156044  0.7074242  0.08953826  0.1331475  0.1130291

Tuning parameter 'interaction.depth' was held constant at a value of 15

Tuning parameter 'shrinkage' was held constant at a value of 0.2

Tuning parameter 'n.minobsinnode' was held constant at a value of 10
ROC was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 90, interaction.depth =
 15, shrinkage = 0.2 and n.minobsinnode = 10. 
> 
> ## The acid test is dissapointing, but I've seen worse.
> 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
  Accuracy      Kappa 
 0.4583333 -0.1661130 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     30   29
    Weak       10    3
                                        
               Accuracy : 0.4583        
                 95% CI : (0.3402, 0.58)
    No Information Rate : 0.5556        
    P-Value [Acc > NIR] : 0.961950      
                                        
                  Kappa : -0.1661       
 Mcnemar's Test P-Value : 0.003948      
                                        
            Sensitivity : 0.09375       
            Specificity : 0.75000       
         Pos Pred Value : 0.23077       
         Neg Pred Value : 0.50847       
             Prevalence : 0.44444       
         Detection Rate : 0.04167       
   Detection Prevalence : 0.18056       
      Balanced Accuracy : 0.42188       
                                        
       'Positive' Class : Weak          
                                        
> 
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
Accuracy    Kappa 
       1        1 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    137    0
    Weak        0  111
                                     
               Accuracy : 1          
                 95% CI : (0.9852, 1)
    No Information Rate : 0.5524     
    P-Value [Acc > NIR] : < 2.2e-16  
                                     
                  Kappa : 1          
 Mcnemar's Test P-Value : NA         
                                     
            Sensitivity : 1.0000     
            Specificity : 1.0000     
         Pos Pred Value : 1.0000     
         Neg Pred Value : 1.0000     
             Prevalence : 0.4476     
         Detection Rate : 0.4476     
   Detection Prevalence : 0.4476     
      Balanced Accuracy : 1.0000     
                                     
       'Positive' Class : Weak       
                                     
> fitControl <- trainControl(## 10-fold CV
+     method = "repeatedcv",
+     number = 10,
+     ## repeated ten times
+     repeats = 10,
+     classProbs = TRUE)
> gbmGrid <- expand.grid(interaction.depth = 
+                            length(colnames(trainDescr)),
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.2,
+                         n.minobsinnode = 10)
> 
> set.seed(seed.mine)
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "Kappa",
+                  verbose = FALSE)
> gbmFit1
Stochastic Gradient Boosting 

248 samples
 15 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 222, 223, 223, 224, 223, 223, ... 

Resampling results across tuning parameters:

  n.trees  Accuracy   Kappa      Accuracy SD  Kappa SD 
    90     0.6695872  0.3322597  0.09174327   0.1852057
   180     0.6615000  0.3158974  0.08708940   0.1754597
   270     0.6647692  0.3234612  0.09532155   0.1915806
   360     0.6636128  0.3206214  0.08703660   0.1751569
   450     0.6587808  0.3113901  0.08754801   0.1754021
   540     0.6596128  0.3124967  0.08762808   0.1763402
   630     0.6627949  0.3190267  0.08629633   0.1727114
   720     0.6648321  0.3229431  0.08796064   0.1769742
   810     0.6604141  0.3136439  0.09166589   0.1851194
   900     0.6617615  0.3170798  0.09018843   0.1822284
   990     0.6628974  0.3192030  0.08988253   0.1806255
  1080     0.6612013  0.3161210  0.08952607   0.1801357
  1170     0.6608654  0.3158945  0.09101330   0.1832697
  1260     0.6632321  0.3206902  0.09154642   0.1843782
  1350     0.6636513  0.3210078  0.09112378   0.1835298
  1440     0.6628308  0.3194742  0.08881751   0.1780229
  1530     0.6648013  0.3231889  0.09125443   0.1838799
  1620     0.6620000  0.3176732  0.08904003   0.1799414
  1710     0.6628641  0.3197283  0.08880397   0.1787247
  1800     0.6640154  0.3226359  0.08891266   0.1783206
  1890     0.6640487  0.3226577  0.08680569   0.1747388
  1980     0.6616141  0.3186280  0.08749600   0.1751395
  2070     0.6648026  0.3264868  0.08952405   0.1784946
  2160     0.6624013  0.3233999  0.08891747   0.1765646
  2250     0.6643692  0.3282060  0.08893652   0.1766627
  2340     0.6643667  0.3300769  0.08957316   0.1771656
  2430     0.6672013  0.3364317  0.08807872   0.1740777
  2520     0.6628013  0.3293043  0.08991650   0.1763352
  2610     0.6620487  0.3281368  0.08790223   0.1725176
  2700     0.6564641  0.3182887  0.08914926   0.1735205

Tuning parameter 'interaction.depth' was held constant at a value of 15

Tuning parameter 'shrinkage' was held constant at a value of 0.2

Tuning parameter 'n.minobsinnode' was held constant at a value of 10
Kappa was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 2430, interaction.depth
 = 15, shrinkage = 0.2 and n.minobsinnode = 10. 
> 
> ## The acid test is dissapointing, but I've seen worse.
> 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
  Accuracy      Kappa 
 0.4166667 -0.2272727 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     25   27
    Weak       15    5
                                          
               Accuracy : 0.4167          
                 95% CI : (0.3015, 0.5389)
    No Information Rate : 0.5556          
    P-Value [Acc > NIR] : 0.99348         
                                          
                  Kappa : -0.2273         
 Mcnemar's Test P-Value : 0.08963         
                                          
            Sensitivity : 0.15625         
            Specificity : 0.62500         
         Pos Pred Value : 0.25000         
         Neg Pred Value : 0.48077         
             Prevalence : 0.44444         
         Detection Rate : 0.06944         
   Detection Prevalence : 0.27778         
      Balanced Accuracy : 0.39062         
                                          
       'Positive' Class : Weak            
                                          
> 
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
Accuracy    Kappa 
       1        1 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    137    0
    Weak        0  111
                                     
               Accuracy : 1          
                 95% CI : (0.9852, 1)
    No Information Rate : 0.5524     
    P-Value [Acc > NIR] : < 2.2e-16  
                                     
                  Kappa : 1          
 Mcnemar's Test P-Value : NA         
                                     
            Sensitivity : 1.0000     
            Specificity : 1.0000     
         Pos Pred Value : 1.0000     
         Neg Pred Value : 1.0000     
             Prevalence : 0.4476     
         Detection Rate : 0.4476     
   Detection Prevalence : 0.4476     
      Balanced Accuracy : 1.0000     
                                     
       'Positive' Class : Weak       
                                     
> ### weaves
> 
> ## Processing for flights data.
> 
> ## Following the caret vignette.
> 
> ###################################################
> ### code chunk number 1: loadLibs
> ###################################################
> library(MASS)
> library(caret)
> library(mlbench)
> library(pROC)
> library(pls)
> 
> library(doMC)
> registerDoMC(cores = 4)
> 
> options(useFancyQuotes = FALSE) 
> 
> # Accounting info.
> getInfo <- function(what = "Suggests")
+ {
+   text <- packageDescription("caret")[what][[1]]
+   text <- gsub("\n", ", ", text, fixed = TRUE)
+   text <- gsub(">=", "$\\\\ge$", text, fixed = TRUE)
+   eachPkg <- strsplit(text, ", ", fixed = TRUE)[[1]]
+   eachPkg <- gsub(",", "", eachPkg, fixed = TRUE)
+   # out <- paste("\\\\pkg{", eachPkg[order(tolower(eachPkg))], "}", sep = "")
+   # paste(out, collapse = ", ")
+   length(eachPkg)
+ }
> 
> ### project-specific: begin
> ## Set-seed, load original CSV file, order it
> ## and do some simple-cleaning
> ## Various datasets 
> 
> seed.mine = 107
> set.seed(seed.mine)                     # helpful for testing
> 
> flight <- read.csv("../bak/flight.csv")
> flight <- flight[order(flight$D00),]
> 
> # Backup
> flight.raw <- flight
> 
> # To check adjustment, there is test code in flight-nb.R
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"
> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"
> 
> # And some deletions
> 
> t.cols <- colnames(flight)
> 
> t.drops <- t.cols[grep("^RANK*", t.cols)]
> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])
> t.drops <- c(t.drops, "D80THPCTL")
> 
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR
> flight$xHNGR <- flight$xDURN < 0
> 
> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+ }
> 
> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))
> 
> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE
> t.cols <- colnames(flight)
> 
> t.drops <- c("SARRHR", "xDURN")
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Backup
> 
> flight00 <- flight
> 
> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]
> 
> paste("samples in use: ", dim(flight)[1])
[1] "samples in use:  320"
> 
> ## Data insights
> 
> ## *Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> ### Numeric variables
> 
> ### Try and impute the AVG, it might have more information than the
> ### bucket.
> 
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))
> 
> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1
> 
> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]
> 
> preProcValues <- preProcess(flight.na, method = c("knnImpute"))
> flight.na1 <- predict(preProcValues, flight.na)
> 
> ## I'll add the new imputed value and drop the others
> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL
> flight$AVGSKDAVAIL <- NULL
> flight$xAVAILBUCKET <- NULL
> flight$AVAILBUCKET <- NULL
> 
> flight$xHNGR <- NULL
> 
> ## Check some more numeric correlations, I haven't scaled everything yet.
> ## I'd cut correlations above 0.65 to 0.75 because of overfitting.
> 
> x1 <- as.data.frame(as.matrix(sapply(flight, class)))
> 
> flight.num <- flight[,names(x1[which(x1$V1 %in% c("numeric", "integer")),])]
> 
> flight.nzv <- nearZeroVar(flight.num, saveMetrics = TRUE)
> flight.nzv
             freqRatio percentUnique zeroVar   nzv
SDEPHR        1.038462        5.9375   FALSE FALSE
SKDEPS        1.000000       19.0625   FALSE FALSE
D00           1.166667       75.3125   FALSE FALSE
AVGSQ         6.333333       82.8125   FALSE FALSE
AVGLOFATC     1.000000       78.4375   FALSE FALSE
xDURN2        1.428571        2.5000   FALSE FALSE
xAVGSKDAVAIL 18.500000       87.8125   FALSE FALSE
> 
> # annoying NA should be gone.
> flight.cor <- cor(flight.num, use = "pairwise.complete.obs")
> 
> descrCorr <- findCorrelation(flight.cor, cutoff = .65, verbose=TRUE)
Considering row	 4 column	 1 value	 0.956 
  Flagging column	 4 
Considering row	 1 column	 3 value	 0.43 
Considering row	 1 column	 7 value	 0.053 
Considering row	 1 column	 6 value	 0.204 
Considering row	 1 column	 5 value	 0.131 
Considering row	 1 column	 2 value	 0.054 
Considering row	 3 column	 7 value	 0.401 
Considering row	 3 column	 6 value	 0.071 
Considering row	 3 column	 5 value	 0.114 
Considering row	 3 column	 2 value	 0.006 
Considering row	 7 column	 6 value	 0.019 
Considering row	 7 column	 5 value	 0.07 
Considering row	 7 column	 2 value	 0.113 
Considering row	 6 column	 5 value	 0.137 
Considering row	 6 column	 2 value	 0.005 
Considering row	 5 column	 2 value	 0.041 
> 
> colnames(flight.num)[descrCorr]
[1] "AVGSQ"
> 
> ## And I'll leave the centered and scale values in for now.
> ## and delete the troublesome ones
> 
> ## Re-classing
> ## Check warnings to see it adjustment has taken place.
> ## We want the proportion in the training class to be about 0.55 0.45
> ## Strong to Weak
> ## I've achieved this heuristically
> src.adjust <- TRUE
> source(file = "flight1.R")
Warning message:
In eval(expr, envir, enclos) : adjusting
> flight1 <- flight
> 
> ## This should be deleted, leave it in and the results
> ## are ideal because it defines LEGTYPE.
> flight$D00 <- NULL
> 
> ## Keep the results but don't change the order.
> outcomes.flight <- flight$LEGTYPE
> 
> flight$LEGTYPE <- NULL
> 
> ## If you know your factors are definitely factors, you don't need this
> ##  asNumeric <- function(x) as.numeric(as.character(x))
> 
> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))
> 
> flight.num0 <- factors.numeric(flight)
> 
> flight.scl0 <- scale(flight.num0)
> 
> ## Now split the samples
> ## we need at least 60 to test with, p at 0.77 gives about 75.
> ## Difficulty here is the bias in the table
> ## Because we only have [3.1, 4.4] the proportion of Weak is higher.
> ## see prop.table(results)
> 
> set.seed(seed.mine)
> inTrain <- createDataPartition(outcomes.flight, p = 0.77, list = FALSE)
> 
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> 
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> 
> prop.table(table(trainClass))
trainClass
   Strong      Weak 
0.5524194 0.4475806 
> dim(trainDescr)
[1] 248  19
> 
> prop.table(table(testClass))
testClass
   Strong      Weak 
0.5555556 0.4444444 
> dim(testDescr)
[1] 72 19
> 
> ## Check Near-zero variance
> 
> nzv <- nearZeroVar(trainDescr, saveMetrics= TRUE)
> stopifnot( all(nzv$nzv == FALSE) )
> 
> # It's imputed and behaves well, no need for this.
> # descrCorr <- cor(scale(trainDescr), use = "pairwise.complete.obs")
> 
> descrCorr <- cor(scale(trainDescr))
> 
> ## This cut-off should be under src.adjust control.
> ## I'm under Git, so I can tinker with it.
> highCorr <- findCorrelation(descrCorr, cutoff = .95, verbose = TRUE)
Considering row	 17 column	 16 value	 0.85 
Considering row	 17 column	 10 value	 0.671 
Considering row	 17 column	 1 value	 0.279 
Considering row	 17 column	 11 value	 0.277 
Considering row	 17 column	 6 value	 0.22 
Considering row	 17 column	 12 value	 0.226 
Considering row	 17 column	 2 value	 0.298 
Considering row	 17 column	 9 value	 0.586 
Considering row	 17 column	 14 value	 0.226 
Considering row	 17 column	 13 value	 0.23 
Considering row	 17 column	 8 value	 0.541 
Considering row	 17 column	 3 value	 0.346 
Considering row	 17 column	 18 value	 0.261 
Considering row	 17 column	 19 value	 0.138 
Considering row	 17 column	 15 value	 0.057 
Considering row	 17 column	 4 value	 0.067 
Considering row	 17 column	 7 value	 0.034 
Considering row	 17 column	 5 value	 0.018 
Considering row	 16 column	 10 value	 0.568 
Considering row	 16 column	 1 value	 0.236 
Considering row	 16 column	 11 value	 0.231 
Considering row	 16 column	 6 value	 0.189 
Considering row	 16 column	 12 value	 0.19 
Considering row	 16 column	 2 value	 0.333 
Considering row	 16 column	 9 value	 0.671 
Considering row	 16 column	 14 value	 0.242 
Considering row	 16 column	 13 value	 0.208 
Considering row	 16 column	 8 value	 0.6 
Considering row	 16 column	 3 value	 0.318 
Considering row	 16 column	 18 value	 0.279 
Considering row	 16 column	 19 value	 0.213 
Considering row	 16 column	 15 value	 0.083 
Considering row	 16 column	 4 value	 0.02 
Considering row	 16 column	 7 value	 0.009 
Considering row	 16 column	 5 value	 0.005 
Considering row	 10 column	 1 value	 0.281 
Considering row	 10 column	 11 value	 0.275 
Considering row	 10 column	 6 value	 0.298 
Considering row	 10 column	 12 value	 0.255 
Considering row	 10 column	 2 value	 0.286 
Considering row	 10 column	 9 value	 0.404 
Considering row	 10 column	 14 value	 0.224 
Considering row	 10 column	 13 value	 0.199 
Considering row	 10 column	 8 value	 0.366 
Considering row	 10 column	 3 value	 0.462 
Considering row	 10 column	 18 value	 0.226 
Considering row	 10 column	 19 value	 0.103 
Considering row	 10 column	 15 value	 0.274 
Considering row	 10 column	 4 value	 0.018 
Considering row	 10 column	 7 value	 0.127 
Considering row	 10 column	 5 value	 0.096 
Considering row	 1 column	 11 value	 0.988 
  Flagging column	 1 
Considering row	 11 column	 6 value	 0.945 
Considering row	 11 column	 12 value	 0.889 
Considering row	 11 column	 2 value	 0.165 
Considering row	 11 column	 9 value	 0.139 
Considering row	 11 column	 14 value	 0.171 
Considering row	 11 column	 13 value	 0.156 
Considering row	 11 column	 8 value	 0.145 
Considering row	 11 column	 3 value	 0.073 
Considering row	 11 column	 18 value	 0.183 
Considering row	 11 column	 19 value	 0.053 
Considering row	 11 column	 15 value	 0.142 
Considering row	 11 column	 4 value	 0.037 
Considering row	 11 column	 7 value	 0.053 
Considering row	 11 column	 5 value	 0.03 
Considering row	 6 column	 12 value	 0.883 
Considering row	 6 column	 2 value	 0.151 
Considering row	 6 column	 9 value	 0.04 
Considering row	 6 column	 14 value	 0.188 
Considering row	 6 column	 13 value	 0.161 
Considering row	 6 column	 8 value	 0.063 
Considering row	 6 column	 3 value	 0.083 
Considering row	 6 column	 18 value	 0.197 
Considering row	 6 column	 19 value	 0.114 
Considering row	 6 column	 15 value	 0.159 
Considering row	 6 column	 4 value	 0.01 
Considering row	 6 column	 7 value	 0.027 
Considering row	 6 column	 5 value	 0.039 
Considering row	 12 column	 2 value	 0.121 
Considering row	 12 column	 9 value	 0.128 
Considering row	 12 column	 14 value	 0.092 
Considering row	 12 column	 13 value	 0.105 
Considering row	 12 column	 8 value	 0.071 
Considering row	 12 column	 3 value	 0.093 
Considering row	 12 column	 18 value	 0.126 
Considering row	 12 column	 19 value	 0.171 
Considering row	 12 column	 15 value	 0.13 
Considering row	 12 column	 4 value	 0.01 
Considering row	 12 column	 7 value	 0.043 
Considering row	 12 column	 5 value	 0.017 
Considering row	 2 column	 9 value	 0.423 
Considering row	 2 column	 14 value	 0.574 
Considering row	 2 column	 13 value	 0.557 
Considering row	 2 column	 8 value	 0.165 
Considering row	 2 column	 3 value	 0.263 
Considering row	 2 column	 18 value	 0.128 
Considering row	 2 column	 19 value	 0.089 
Considering row	 2 column	 15 value	 0.069 
Considering row	 2 column	 4 value	 0.27 
Considering row	 2 column	 7 value	 0.045 
Considering row	 2 column	 5 value	 0.024 
Considering row	 9 column	 14 value	 0.147 
Considering row	 9 column	 13 value	 0.125 
Considering row	 9 column	 8 value	 0.449 
Considering row	 9 column	 3 value	 0.322 
Considering row	 9 column	 18 value	 0.018 
Considering row	 9 column	 19 value	 0.141 
Considering row	 9 column	 15 value	 0.073 
Considering row	 9 column	 4 value	 0.006 
Considering row	 9 column	 7 value	 0.136 
Considering row	 9 column	 5 value	 0.123 
Considering row	 14 column	 13 value	 0.659 
Considering row	 14 column	 8 value	 0.097 
Considering row	 14 column	 3 value	 0.106 
Considering row	 14 column	 18 value	 0.361 
Considering row	 14 column	 19 value	 0.092 
Considering row	 14 column	 15 value	 0.084 
Considering row	 14 column	 4 value	 0.263 
Considering row	 14 column	 7 value	 0.139 
Considering row	 14 column	 5 value	 0.031 
Considering row	 13 column	 8 value	 0.097 
Considering row	 13 column	 3 value	 0.167 
Considering row	 13 column	 18 value	 0.18 
Considering row	 13 column	 19 value	 0.131 
Considering row	 13 column	 15 value	 0.137 
Considering row	 13 column	 4 value	 0.24 
Considering row	 13 column	 7 value	 0.085 
Considering row	 13 column	 5 value	 0.027 
Considering row	 8 column	 3 value	 0.224 
Considering row	 8 column	 18 value	 0.173 
Considering row	 8 column	 19 value	 0.235 
Considering row	 8 column	 15 value	 0.07 
Considering row	 8 column	 4 value	 0.02 
Considering row	 8 column	 7 value	 0.085 
Considering row	 8 column	 5 value	 0.004 
Considering row	 3 column	 18 value	 0.028 
Considering row	 3 column	 19 value	 0.027 
Considering row	 3 column	 15 value	 0.017 
Considering row	 3 column	 4 value	 0.094 
Considering row	 3 column	 7 value	 0.095 
Considering row	 3 column	 5 value	 0.097 
Considering row	 18 column	 19 value	 0.019 
Considering row	 18 column	 15 value	 0.12 
Considering row	 18 column	 4 value	 0.086 
Considering row	 18 column	 7 value	 0.132 
Considering row	 18 column	 5 value	 0.002 
Considering row	 19 column	 15 value	 0.019 
Considering row	 19 column	 4 value	 0.032 
Considering row	 19 column	 7 value	 0.056 
Considering row	 19 column	 5 value	 0.075 
Considering row	 15 column	 4 value	 0.043 
Considering row	 15 column	 7 value	 0.061 
Considering row	 15 column	 5 value	 0.08 
Considering row	 4 column	 7 value	 0.005 
Considering row	 4 column	 5 value	 0.213 
Considering row	 7 column	 5 value	 0.008 
> 
> colnames(trainDescr)[highCorr]
[1] "SDEPHR"
> 
> descr.ncol0 <- ncol(trainDescr)
> 
> # I've switched off the correlation remover and the results are better.
> if (sum(highCorr) > 0) {
+     warning("overfitting: correlations: err.trainDescr: ", paste(colnames(trainDescr)[highCorr], collapse = ", ") )
+     err.trainDescr <- trainDescr
+     trainDescr <- trainDescr[,-highCorr]
+ }
Warning message:
overfitting: correlations: err.trainDescr: SDEPHR 
> 
> descr.ncol1 <- ncol(trainDescr)
> 
> paste("Dropped: ", as.character(descr.ncol0 - descr.ncol1))
[1] "Dropped:  1"
> 
> descrCorr <- cor(trainDescr)
> summary(descrCorr[upper.tri(descrCorr)])
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
-0.85020 -0.13860 -0.01766  0.01577  0.11970  0.94490 
> 
> ## Dominant correlations
> ## At 0.9, there are some big ones that might need re-thinking.
> 
> table.descrCorr <- as.data.frame(as.table(descrCorr))
> table.descrCorr <- table.descrCorr[which(table.descrCorr$Var1 != table.descrCorr$Var2),]
> table.descrCorr[order(abs(table.descrCorr$Freq), decreasing = TRUE),]
              Var1           Var2         Freq
82       DEPBUCKET          AVGSQ  0.944870657
167          AVGSQ      DEPBUCKET  0.944870657
173      ARRBUCKET      DEPBUCKET  0.889095737
190      DEPBUCKET      ARRBUCKET  0.889095737
83       ARRBUCKET          AVGSQ  0.882590635
185          AVGSQ      ARRBUCKET  0.882590635
268       ARRSPOKE       DEPSPOKE -0.850165355
285       DEPSPOKE       ARRSPOKE -0.850165355
141       DEPSPOKE   DEPSTAATCIMP  0.671264566
260   DEPSTAATCIMP       DEPSPOKE  0.671264566
160       ARRSPOKE DOWNLINEATCIMP  0.671009330
279 DOWNLINEATCIMP       ARRSPOKE  0.671009330
211     TRNRANKGRP     DEPRANKGRP  0.658724662
228     DEPRANKGRP     TRNRANKGRP  0.658724662
123       DEPSPOKE   UPLINEATCIMP -0.600008252
259   UPLINEATCIMP       DEPSPOKE -0.600008252
142       ARRSPOKE   DEPSTAATCIMP -0.586442959
278   DEPSTAATCIMP       ARRSPOKE -0.586442959
13      TRNRANKGRP      SKDDEPSTA  0.574035134
217      SKDDEPSTA     TRNRANKGRP  0.574035134
159       DEPSPOKE DOWNLINEATCIMP -0.567682494
261 DOWNLINEATCIMP       DEPSPOKE -0.567682494
12      DEPRANKGRP      SKDDEPSTA  0.557399203
199      SKDDEPSTA     DEPRANKGRP  0.557399203
124       ARRSPOKE   UPLINEATCIMP  0.540734833
277   UPLINEATCIMP       ARRSPOKE  0.540734833
27  DOWNLINEATCIMP      SKDARRSTA  0.462378131
146      SKDARRSTA DOWNLINEATCIMP  0.462378131
116   DEPSTAATCIMP   UPLINEATCIMP -0.449249986
133   UPLINEATCIMP   DEPSTAATCIMP -0.449249986
8     DEPSTAATCIMP      SKDDEPSTA  0.423425796
127      SKDDEPSTA   DEPSTAATCIMP  0.423425796
135 DOWNLINEATCIMP   DEPSTAATCIMP -0.403695561
152   DEPSTAATCIMP DOWNLINEATCIMP -0.403695561
117 DOWNLINEATCIMP   UPLINEATCIMP  0.365833687
151   UPLINEATCIMP DOWNLINEATCIMP  0.365833687
233         xDURN2     TRNRANKGRP  0.361347207
301     TRNRANKGRP         xDURN2  0.361347207
34        ARRSPOKE      SKDARRSTA  0.345987375
272      SKDARRSTA       ARRSPOKE  0.345987375
15        DEPSPOKE      SKDDEPSTA  0.332823310
253      SKDDEPSTA       DEPSPOKE  0.332823310
26    DEPSTAATCIMP      SKDARRSTA -0.322204878
128      SKDARRSTA   DEPSTAATCIMP -0.322204878
33        DEPSPOKE      SKDARRSTA -0.318093195
254      SKDARRSTA       DEPSPOKE -0.318093195
81  DOWNLINEATCIMP          AVGSQ  0.298096458
149          AVGSQ DOWNLINEATCIMP  0.298096458
16        ARRSPOKE      SKDDEPSTA -0.298036487
271      SKDDEPSTA       ARRSPOKE -0.298036487
9   DOWNLINEATCIMP      SKDDEPSTA -0.285911992
145      SKDDEPSTA DOWNLINEATCIMP -0.285911992
269         xDURN2       DEPSPOKE  0.279030910
303       DEPSPOKE         xDURN2  0.279030910
178       ARRSPOKE      DEPBUCKET  0.276615722
280      DEPBUCKET       ARRSPOKE  0.276615722
154      DEPBUCKET DOWNLINEATCIMP  0.275167866
171 DOWNLINEATCIMP      DEPBUCKET  0.275167866
158     ARRRANKGRP DOWNLINEATCIMP -0.274110143
243 DOWNLINEATCIMP     ARRRANKGRP -0.274110143
3           SKDEQP      SKDDEPSTA  0.270065872
37       SKDDEPSTA         SKDEQP  0.270065872
2        SKDARRSTA      SKDDEPSTA -0.263453106
19       SKDDEPSTA      SKDARRSTA -0.263453106
49      TRNRANKGRP         SKDEQP  0.262837233
219         SKDEQP     TRNRANKGRP  0.262837233
287         xDURN2       ARRSPOKE -0.261107447
304       ARRSPOKE         xDURN2 -0.261107447
155      ARRBUCKET DOWNLINEATCIMP  0.255480148
189 DOWNLINEATCIMP      ARRBUCKET  0.255480148
231       DEPSPOKE     TRNRANKGRP  0.242138220
265     TRNRANKGRP       DEPSPOKE  0.242138220
48      DEPRANKGRP         SKDEQP  0.239915140
201         SKDEQP     DEPRANKGRP  0.239915140
126   xAVGSKDAVAIL   UPLINEATCIMP  0.234867014
313   UPLINEATCIMP   xAVGSKDAVAIL  0.234867014
177       DEPSPOKE      DEPBUCKET -0.231298301
262      DEPBUCKET       DEPSPOKE -0.231298301
214       ARRSPOKE     DEPRANKGRP -0.229640758
282     DEPRANKGRP       ARRSPOKE -0.229640758
161         xDURN2 DOWNLINEATCIMP -0.226093423
297 DOWNLINEATCIMP         xDURN2 -0.226093423
196       ARRSPOKE      ARRBUCKET  0.225890655
281      ARRBUCKET       ARRSPOKE  0.225890655
232       ARRSPOKE     TRNRANKGRP -0.225591539
283     TRNRANKGRP       ARRSPOKE -0.225591539
157     TRNRANKGRP DOWNLINEATCIMP -0.224193213
225 DOWNLINEATCIMP     TRNRANKGRP -0.224193213
25    UPLINEATCIMP      SKDARRSTA  0.223824406
110      SKDARRSTA   UPLINEATCIMP  0.223824406
88        ARRSPOKE          AVGSQ  0.219975654
275          AVGSQ       ARRSPOKE  0.219975654
270   xAVGSKDAVAIL       DEPSPOKE -0.212821518
321       DEPSPOKE   xAVGSKDAVAIL -0.212821518
40          SKDEPS         SKDEQP  0.212586898
57          SKDEQP         SKDEPS  0.212586898
213       DEPSPOKE     DEPRANKGRP  0.208188512
264     DEPRANKGRP       DEPSPOKE  0.208188512
156     DEPRANKGRP DOWNLINEATCIMP -0.199411990
207 DOWNLINEATCIMP     DEPRANKGRP -0.199411990
89          xDURN2          AVGSQ -0.197447957
293          AVGSQ         xDURN2 -0.197447957
195       DEPSPOKE      ARRBUCKET -0.189934966
263      ARRBUCKET       DEPSPOKE -0.189934966
87        DEPSPOKE          AVGSQ -0.188666787
257          AVGSQ       DEPSPOKE -0.188666787
85      TRNRANKGRP          AVGSQ -0.188226304
221          AVGSQ     TRNRANKGRP -0.188226304
179         xDURN2      DEPBUCKET -0.183349624
298      DEPBUCKET         xDURN2 -0.183349624
215         xDURN2     DEPRANKGRP  0.180043357
300     DEPRANKGRP         xDURN2  0.180043357
125         xDURN2   UPLINEATCIMP -0.173240320
295   UPLINEATCIMP         xDURN2 -0.173240320
198   xAVGSKDAVAIL      ARRBUCKET -0.170644257
317      ARRBUCKET   xAVGSKDAVAIL -0.170644257
175     TRNRANKGRP      DEPBUCKET -0.170618431
226      DEPBUCKET     TRNRANKGRP -0.170618431
30      DEPRANKGRP      SKDARRSTA -0.167375913
200      SKDARRSTA     DEPRANKGRP -0.167375913
10       DEPBUCKET      SKDDEPSTA -0.165029385
163      SKDDEPSTA      DEPBUCKET -0.165029385
7     UPLINEATCIMP      SKDDEPSTA -0.164964952
109      SKDDEPSTA   UPLINEATCIMP -0.164964952
84      DEPRANKGRP          AVGSQ -0.161451853
203          AVGSQ     DEPRANKGRP -0.161451853
86      ARRRANKGRP          AVGSQ -0.159135469
239          AVGSQ     ARRRANKGRP -0.159135469
174     DEPRANKGRP      DEPBUCKET -0.155547085
208      DEPBUCKET     DEPRANKGRP -0.155547085
5            AVGSQ      SKDDEPSTA -0.150522366
73       SKDDEPSTA          AVGSQ -0.150522366
139     TRNRANKGRP   DEPSTAATCIMP -0.147409309
224   DEPSTAATCIMP     TRNRANKGRP -0.147409309
118      DEPBUCKET   UPLINEATCIMP  0.144940797
169   UPLINEATCIMP      DEPBUCKET  0.144940797
176     ARRRANKGRP      DEPBUCKET -0.142348062
244      DEPBUCKET     ARRRANKGRP -0.142348062
144   xAVGSKDAVAIL   DEPSTAATCIMP -0.141077194
314   DEPSTAATCIMP   xAVGSKDAVAIL -0.141077194
103     TRNRANKGRP      AVGLOFATC  0.139184315
222      AVGLOFATC     TRNRANKGRP  0.139184315
136      DEPBUCKET   DEPSTAATCIMP -0.138581846
170   DEPSTAATCIMP      DEPBUCKET -0.138581846
288   xAVGSKDAVAIL       ARRSPOKE  0.137677242
322       ARRSPOKE   xAVGSKDAVAIL  0.137677242
212     ARRRANKGRP     DEPRANKGRP  0.136562948
246     DEPRANKGRP     ARRRANKGRP  0.136562948
98    DEPSTAATCIMP      AVGLOFATC -0.135778614
132      AVGLOFATC   DEPSTAATCIMP -0.135778614
107         xDURN2      AVGLOFATC -0.132084629
294      AVGLOFATC         xDURN2 -0.132084629
216   xAVGSKDAVAIL     DEPRANKGRP  0.130574789
318     DEPRANKGRP   xAVGSKDAVAIL  0.130574789
194     ARRRANKGRP      ARRBUCKET -0.129698517
245      ARRBUCKET     ARRRANKGRP -0.129698517
137      ARRBUCKET   DEPSTAATCIMP -0.127726148
188   DEPSTAATCIMP      ARRBUCKET -0.127726148
17          xDURN2      SKDDEPSTA  0.127598189
289      SKDDEPSTA         xDURN2  0.127598189
99  DOWNLINEATCIMP      AVGLOFATC -0.126763572
150      AVGLOFATC DOWNLINEATCIMP -0.126763572
197         xDURN2      ARRBUCKET -0.125836459
299      ARRBUCKET         xDURN2 -0.125836459
138     DEPRANKGRP   DEPSTAATCIMP  0.124672682
206   DEPSTAATCIMP     DEPRANKGRP  0.124672682
62    DEPSTAATCIMP         SKDEPS -0.123445793
130         SKDEPS   DEPSTAATCIMP -0.123445793
11       ARRBUCKET      SKDDEPSTA -0.120728212
181      SKDDEPSTA      ARRBUCKET -0.120728212
251         xDURN2     ARRRANKGRP  0.119675180
302     ARRRANKGRP         xDURN2  0.119675180
90    xAVGSKDAVAIL          AVGSQ -0.113720147
311          AVGSQ   xAVGSKDAVAIL -0.113720147
31      TRNRANKGRP      SKDARRSTA -0.105802023
218      SKDARRSTA     TRNRANKGRP -0.105802023
192     DEPRANKGRP      ARRBUCKET -0.105057984
209      ARRBUCKET     DEPRANKGRP -0.105057984
162   xAVGSKDAVAIL DOWNLINEATCIMP  0.102577364
315 DOWNLINEATCIMP   xAVGSKDAVAIL  0.102577364
120     DEPRANKGRP   UPLINEATCIMP -0.097218129
205   UPLINEATCIMP     DEPRANKGRP -0.097218129
121     TRNRANKGRP   UPLINEATCIMP -0.097037814
223   UPLINEATCIMP     TRNRANKGRP -0.097037814
22          SKDEPS      SKDARRSTA -0.096699169
56       SKDARRSTA         SKDEPS -0.096699169
63  DOWNLINEATCIMP         SKDEPS -0.095568613
148         SKDEPS DOWNLINEATCIMP -0.095568613
24       AVGLOFATC      SKDARRSTA -0.095234466
92       SKDARRSTA      AVGLOFATC -0.095234466
21          SKDEQP      SKDARRSTA  0.094073459
38       SKDARRSTA         SKDEQP  0.094073459
29       ARRBUCKET      SKDARRSTA  0.092625400
182      SKDARRSTA      ARRBUCKET  0.092625400
193     TRNRANKGRP      ARRBUCKET -0.092415252
227      ARRBUCKET     TRNRANKGRP -0.092415252
234   xAVGSKDAVAIL     TRNRANKGRP  0.092011501
319     TRNRANKGRP   xAVGSKDAVAIL  0.092011501
18    xAVGSKDAVAIL      SKDDEPSTA  0.088580325
307      SKDDEPSTA   xAVGSKDAVAIL  0.088580325
53          xDURN2         SKDEQP  0.086170070
291         SKDEQP         xDURN2  0.086170070
102     DEPRANKGRP      AVGLOFATC  0.085474019
204      AVGLOFATC     DEPRANKGRP  0.085474019
97    UPLINEATCIMP      AVGLOFATC -0.085180887
114      AVGLOFATC   UPLINEATCIMP -0.085180887
230     ARRRANKGRP     TRNRANKGRP  0.083906762
247     TRNRANKGRP     ARRRANKGRP  0.083906762
249       DEPSPOKE     ARRRANKGRP  0.083162083
266     ARRRANKGRP       DEPSPOKE  0.083162083
23           AVGSQ      SKDARRSTA  0.082898864
74       SKDARRSTA          AVGSQ  0.082898864
68      ARRRANKGRP         SKDEPS  0.080398834
238         SKDEPS     ARRRANKGRP  0.080398834
72    xAVGSKDAVAIL         SKDEPS  0.075169577
310         SKDEPS   xAVGSKDAVAIL  0.075169577
140     ARRRANKGRP   DEPSTAATCIMP  0.073371196
242   DEPSTAATCIMP     ARRRANKGRP  0.073371196
28       DEPBUCKET      SKDARRSTA  0.072910977
164      SKDARRSTA      DEPBUCKET  0.072910977
119      ARRBUCKET   UPLINEATCIMP  0.071409699
187   UPLINEATCIMP      ARRBUCKET  0.071409699
122     ARRRANKGRP   UPLINEATCIMP -0.069790367
241   UPLINEATCIMP     ARRRANKGRP -0.069790367
14      ARRRANKGRP      SKDDEPSTA  0.068927801
235      SKDDEPSTA     ARRRANKGRP  0.068927801
52        ARRSPOKE         SKDEQP  0.066579707
273         SKDEQP       ARRSPOKE  0.066579707
79    UPLINEATCIMP          AVGSQ  0.062631172
113          AVGSQ   UPLINEATCIMP  0.062631172
104     ARRRANKGRP      AVGLOFATC -0.061491190
240      AVGLOFATC     ARRRANKGRP -0.061491190
250       ARRSPOKE     ARRRANKGRP -0.057002549
284     ARRRANKGRP       ARRSPOKE -0.057002549
108   xAVGSKDAVAIL      AVGLOFATC -0.056264979
312      AVGLOFATC   xAVGSKDAVAIL -0.056264979
100      DEPBUCKET      AVGLOFATC -0.053357134
168      AVGLOFATC      DEPBUCKET -0.053357134
180   xAVGSKDAVAIL      DEPBUCKET -0.053125467
316      DEPBUCKET   xAVGSKDAVAIL -0.053125467
6        AVGLOFATC      SKDDEPSTA -0.044946507
91       SKDDEPSTA      AVGLOFATC -0.044946507
101      ARRBUCKET      AVGLOFATC -0.043093769
186      AVGLOFATC      ARRBUCKET -0.043093769
50      ARRRANKGRP         SKDEQP -0.042512956
237         SKDEQP     ARRRANKGRP -0.042512956
80    DEPSTAATCIMP          AVGSQ -0.040428658
131          AVGSQ   DEPSTAATCIMP -0.040428658
59           AVGSQ         SKDEPS -0.038820886
76          SKDEPS          AVGSQ -0.038820886
46       DEPBUCKET         SKDEQP  0.037125178
165         SKDEQP      DEPBUCKET  0.037125178
106       ARRSPOKE      AVGLOFATC -0.034402462
276      AVGLOFATC       ARRSPOKE -0.034402462
54    xAVGSKDAVAIL         SKDEQP  0.031863410
309         SKDEQP   xAVGSKDAVAIL  0.031863410
67      TRNRANKGRP         SKDEPS  0.030883560
220         SKDEPS     TRNRANKGRP  0.030883560
64       DEPBUCKET         SKDEPS -0.030101407
166         SKDEPS      DEPBUCKET -0.030101407
35          xDURN2      SKDARRSTA  0.027576751
290      SKDARRSTA         xDURN2  0.027576751
78       AVGLOFATC          AVGSQ -0.027382453
95           AVGSQ      AVGLOFATC -0.027382453
36    xAVGSKDAVAIL      SKDARRSTA  0.027225219
308      SKDARRSTA   xAVGSKDAVAIL  0.027225219
66      DEPRANKGRP         SKDEPS  0.027025501
202         SKDEPS     DEPRANKGRP  0.027025501
4           SKDEPS      SKDDEPSTA -0.024267794
55       SKDDEPSTA         SKDEPS -0.024267794
43    UPLINEATCIMP         SKDEQP -0.019807499
111         SKDEQP   UPLINEATCIMP -0.019807499
51        DEPSPOKE         SKDEQP  0.019755644
255         SKDEQP       DEPSPOKE  0.019755644
306   xAVGSKDAVAIL         xDURN2 -0.019255572
323         xDURN2   xAVGSKDAVAIL -0.019255572
252   xAVGSKDAVAIL     ARRRANKGRP -0.018743432
320     ARRRANKGRP   xAVGSKDAVAIL -0.018743432
143         xDURN2   DEPSTAATCIMP -0.017999758
296   DEPSTAATCIMP         xDURN2 -0.017999758
45  DOWNLINEATCIMP         SKDEQP -0.017658860
147         SKDEQP DOWNLINEATCIMP -0.017658860
70        ARRSPOKE         SKDEPS  0.017573485
274         SKDEPS       ARRSPOKE  0.017573485
65       ARRBUCKET         SKDEPS  0.017414895
184         SKDEPS      ARRBUCKET  0.017414895
32      ARRRANKGRP      SKDARRSTA  0.016733374
236      SKDARRSTA     ARRRANKGRP  0.016733374
41           AVGSQ         SKDEQP  0.010218807
75          SKDEQP          AVGSQ  0.010218807
47       ARRBUCKET         SKDEQP  0.009926479
183         SKDEQP      ARRBUCKET  0.009926479
105       DEPSPOKE      AVGLOFATC -0.008540402
258      AVGLOFATC       DEPSPOKE -0.008540402
60       AVGLOFATC         SKDEPS  0.008240563
94          SKDEPS      AVGLOFATC  0.008240563
44    DEPSTAATCIMP         SKDEQP -0.005922601
129         SKDEQP   DEPSTAATCIMP -0.005922601
42       AVGLOFATC         SKDEQP -0.004889040
93          SKDEQP      AVGLOFATC -0.004889040
69        DEPSPOKE         SKDEPS -0.004617067
256         SKDEPS       DEPSPOKE -0.004617067
61    UPLINEATCIMP         SKDEPS  0.004016263
112         SKDEPS   UPLINEATCIMP  0.004016263
71          xDURN2         SKDEPS  0.001748012
292         SKDEPS         xDURN2  0.001748012
> 
> ### Models
> 
> ## Try GBM (gradient boosting). Works well for mixed data.
> ## And there is a tutorial for it with caret.
> 
> ## Training controller and big grid
> ## Check the ROC (my preferred.)
> 
> # I'm not using this at the moment.
> 
> tr.cols <- colnames(trainDescr)
> tr.cols
 [1] "SKDDEPSTA"      "SKDARRSTA"      "SKDEQP"         "SKDEPS"        
 [5] "AVGSQ"          "AVGLOFATC"      "UPLINEATCIMP"   "DEPSTAATCIMP"  
 [9] "DOWNLINEATCIMP" "DEPBUCKET"      "ARRBUCKET"      "DEPRANKGRP"    
[13] "TRNRANKGRP"     "ARRRANKGRP"     "DEPSPOKE"       "ARRSPOKE"      
[17] "xDURN2"         "xAVGSKDAVAIL"  
> tr.icols <- grep("((STA|EQP)$)|(^xD)", tr.cols)
> tr.icols <- rev(tr.icols)
> 
> fitControl <- trainControl(## 10-fold CV
+     method = "repeatedcv",
+     number = 10,
+     ## repeated ten times
+     repeats = 10,
+     classProbs = TRUE)
> 
> ## Some trial and error with variables to branch and boost.
> ## Try all variables
> 
> gbmGrid <- expand.grid(interaction.depth = 
+                            length(colnames(trainDescr)),
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.2,
+                         n.minobsinnode = 10)
> 
> set.seed(seed.mine)
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "Kappa",
+                  verbose = FALSE)
> gbmFit1
Stochastic Gradient Boosting 

248 samples
 18 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 222, 223, 223, 224, 223, 223, ... 

Resampling results across tuning parameters:

  n.trees  Accuracy   Kappa      Accuracy SD  Kappa SD 
    90     0.6838936  0.3619282  0.08346321   0.1688218
   180     0.6914846  0.3773825  0.08453383   0.1701056
   270     0.6942423  0.3821540  0.08898270   0.1795182
   360     0.6842179  0.3621388  0.08966723   0.1800645
   450     0.6861564  0.3646395  0.09226809   0.1876199
   540     0.6805872  0.3539740  0.08551977   0.1721415
   630     0.6818359  0.3561866  0.08608669   0.1740504
   720     0.6850385  0.3625408  0.09128417   0.1845182
   810     0.6846705  0.3620813  0.09317248   0.1876143
   900     0.6846551  0.3622599  0.09244592   0.1855296
   990     0.6855218  0.3639248  0.09288292   0.1863718
  1080     0.6847538  0.3623145  0.09417654   0.1886744
  1170     0.6862744  0.3650754  0.09265716   0.1866584
  1260     0.6854590  0.3639280  0.09404083   0.1893018
  1350     0.6858077  0.3641759  0.09174430   0.1846623
  1440     0.6862090  0.3648156  0.09084085   0.1828310
  1530     0.6849769  0.3624454  0.09162180   0.1837483
  1620     0.6861936  0.3654402  0.09282323   0.1860141
  1710     0.6886103  0.3706193  0.09061932   0.1814166
  1800     0.6854103  0.3653135  0.09266019   0.1853057
  1890     0.6858577  0.3674179  0.08950847   0.1782502
  1980     0.6870590  0.3713084  0.08868665   0.1756880
  2070     0.6834205  0.3661879  0.08707623   0.1724559
  2160     0.6817692  0.3642416  0.08713797   0.1725716
  2250     0.6806513  0.3633843  0.08665616   0.1714398
  2340     0.6782667  0.3600928  0.08904972   0.1750431
  2430     0.6766179  0.3580191  0.09227706   0.1812271
  2520     0.6786346  0.3635091  0.09255330   0.1811225
  2610     0.6766346  0.3598861  0.09491795   0.1860877
  2700     0.6795487  0.3669190  0.09230957   0.1795545

Tuning parameter 'interaction.depth' was held constant at a value of 18

Tuning parameter 'shrinkage' was held constant at a value of 0.2

Tuning parameter 'n.minobsinnode' was held constant at a value of 10
Kappa was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 270, interaction.depth =
 18, shrinkage = 0.2 and n.minobsinnode = 10. 
> 
> ## The acid test is dissapointing, but I've seen worse.
> 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
  Accuracy      Kappa 
 0.4444444 -0.1320755 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     21   21
    Weak       19   11
                                          
               Accuracy : 0.4444          
                 95% CI : (0.3272, 0.5664)
    No Information Rate : 0.5556          
    P-Value [Acc > NIR] : 0.9778          
                                          
                  Kappa : -0.1321         
 Mcnemar's Test P-Value : 0.8744          
                                          
            Sensitivity : 0.3438          
            Specificity : 0.5250          
         Pos Pred Value : 0.3667          
         Neg Pred Value : 0.5000          
             Prevalence : 0.4444          
         Detection Rate : 0.1528          
   Detection Prevalence : 0.4167          
      Balanced Accuracy : 0.4344          
                                          
       'Positive' Class : Weak            
                                          
> 
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
Accuracy    Kappa 
       1        1 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    137    0
    Weak        0  111
                                     
               Accuracy : 1          
                 95% CI : (0.9852, 1)
    No Information Rate : 0.5524     
    P-Value [Acc > NIR] : < 2.2e-16  
                                     
                  Kappa : 1          
 Mcnemar's Test P-Value : NA         
                                     
            Sensitivity : 1.0000     
            Specificity : 1.0000     
         Pos Pred Value : 1.0000     
         Neg Pred Value : 1.0000     
             Prevalence : 0.4476     
         Detection Rate : 0.4476     
   Detection Prevalence : 0.4476     
      Balanced Accuracy : 1.0000     
                                     
       'Positive' Class : Weak       
                                     
> ### weaves
> 
> ## Processing for flights data.
> 
> ## Following the caret vignette.
> 
> ###################################################
> ### code chunk number 1: loadLibs
> ###################################################
> library(MASS)
> library(caret)
> library(mlbench)
> library(pROC)
> library(pls)
> 
> library(doMC)
> registerDoMC(cores = 4)
> 
> options(useFancyQuotes = FALSE) 
> 
> # Accounting info.
> getInfo <- function(what = "Suggests")
+ {
+   text <- packageDescription("caret")[what][[1]]
+   text <- gsub("\n", ", ", text, fixed = TRUE)
+   text <- gsub(">=", "$\\\\ge$", text, fixed = TRUE)
+   eachPkg <- strsplit(text, ", ", fixed = TRUE)[[1]]
+   eachPkg <- gsub(",", "", eachPkg, fixed = TRUE)
+   # out <- paste("\\\\pkg{", eachPkg[order(tolower(eachPkg))], "}", sep = "")
+   # paste(out, collapse = ", ")
+   length(eachPkg)
+ }
> 
> ### project-specific: begin
> ## Set-seed, load original CSV file, order it
> ## and do some simple-cleaning
> ## Various datasets 
> 
> seed.mine = 107
> set.seed(seed.mine)                     # helpful for testing
> 
> flight <- read.csv("../bak/flight.csv")
> flight <- flight[order(flight$D00),]
> 
> # Backup
> flight.raw <- flight
> 
> # To check adjustment, there is test code in flight-nb.R
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"
> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"
> 
> # And some deletions
> 
> t.cols <- colnames(flight)
> 
> t.drops <- t.cols[grep("^RANK*", t.cols)]
> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])
> t.drops <- c(t.drops, "D80THPCTL")
> 
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR
> flight$xHNGR <- flight$xDURN < 0
> 
> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+ }
> 
> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))
> 
> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE
> t.cols <- colnames(flight)
> 
> t.drops <- c("SARRHR", "xDURN")
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Backup
> 
> flight00 <- flight
> 
> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]
> 
> paste("samples in use: ", dim(flight)[1])
[1] "samples in use:  320"
> 
> ## Data insights
> 
> ## *Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> ### Numeric variables
> 
> ### Try and impute the AVG, it might have more information than the
> ### bucket.
> 
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))
> 
> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1
> 
> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]
> 
> preProcValues <- preProcess(flight.na, method = c("knnImpute"))
> flight.na1 <- predict(preProcValues, flight.na)
> 
> ## I'll add the new imputed value and drop the others
> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL
> flight$AVGSKDAVAIL <- NULL
> flight$xAVAILBUCKET <- NULL
> flight$AVAILBUCKET <- NULL
> 
> flight$xHNGR <- NULL
> 
> ## Check some more numeric correlations, I haven't scaled everything yet.
> ## I'd cut correlations above 0.65 to 0.75 because of overfitting.
> 
> x1 <- as.data.frame(as.matrix(sapply(flight, class)))
> 
> flight.num <- flight[,names(x1[which(x1$V1 %in% c("numeric", "integer")),])]
> 
> flight.nzv <- nearZeroVar(flight.num, saveMetrics = TRUE)
> flight.nzv
             freqRatio percentUnique zeroVar   nzv
SDEPHR        1.038462        5.9375   FALSE FALSE
SKDEPS        1.000000       19.0625   FALSE FALSE
D00           1.166667       75.3125   FALSE FALSE
AVGSQ         6.333333       82.8125   FALSE FALSE
AVGLOFATC     1.000000       78.4375   FALSE FALSE
xDURN2        1.428571        2.5000   FALSE FALSE
xAVGSKDAVAIL 18.500000       87.8125   FALSE FALSE
> 
> # annoying NA should be gone.
> flight.cor <- cor(flight.num, use = "pairwise.complete.obs")
> 
> descrCorr <- findCorrelation(flight.cor, cutoff = .65, verbose=TRUE)
Considering row	 4 column	 1 value	 0.956 
  Flagging column	 4 
Considering row	 1 column	 3 value	 0.43 
Considering row	 1 column	 7 value	 0.053 
Considering row	 1 column	 6 value	 0.204 
Considering row	 1 column	 5 value	 0.131 
Considering row	 1 column	 2 value	 0.054 
Considering row	 3 column	 7 value	 0.401 
Considering row	 3 column	 6 value	 0.071 
Considering row	 3 column	 5 value	 0.114 
Considering row	 3 column	 2 value	 0.006 
Considering row	 7 column	 6 value	 0.019 
Considering row	 7 column	 5 value	 0.07 
Considering row	 7 column	 2 value	 0.113 
Considering row	 6 column	 5 value	 0.137 
Considering row	 6 column	 2 value	 0.005 
Considering row	 5 column	 2 value	 0.041 
> 
> colnames(flight.num)[descrCorr]
[1] "AVGSQ"
> 
> ## And I'll leave the centered and scale values in for now.
> ## and delete the troublesome ones
> 
> ## Re-classing
> ## Check warnings to see it adjustment has taken place.
> ## We want the proportion in the training class to be about 0.55 0.45
> ## Strong to Weak
> ## I've achieved this heuristically
> src.adjust <- TRUE
> source(file = "flight1.R")
Warning message:
In eval(expr, envir, enclos) : adjusting
> flight1 <- flight
> 
> ## This should be deleted, leave it in and the results
> ## are ideal because it defines LEGTYPE.
> flight$D00 <- NULL
> 
> ## Keep the results but don't change the order.
> outcomes.flight <- flight$LEGTYPE
> 
> flight$LEGTYPE <- NULL
> 
> ## If you know your factors are definitely factors, you don't need this
> ##  asNumeric <- function(x) as.numeric(as.character(x))
> 
> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))
> 
> flight.num0 <- factors.numeric(flight)
> 
> flight.scl0 <- scale(flight.num0)
> 
> ## Now split the samples
> ## we need at least 60 to test with, p at 0.77 gives about 75.
> ## Difficulty here is the bias in the table
> ## Because we only have [3.1, 4.4] the proportion of Weak is higher.
> ## see prop.table(results)
> 
> set.seed(seed.mine)
> inTrain <- createDataPartition(outcomes.flight, p = 0.77, list = FALSE)
> 
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> 
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> 
> prop.table(table(trainClass))
trainClass
   Strong      Weak 
0.5524194 0.4475806 
> dim(trainDescr)
[1] 248  19
> 
> prop.table(table(testClass))
testClass
   Strong      Weak 
0.5555556 0.4444444 
> dim(testDescr)
[1] 72 19
> 
> ## Check Near-zero variance
> 
> nzv <- nearZeroVar(trainDescr, saveMetrics= TRUE)
> stopifnot( all(nzv$nzv == FALSE) )
> 
> # It's imputed and behaves well, no need for this.
> # descrCorr <- cor(scale(trainDescr), use = "pairwise.complete.obs")
> 
> descrCorr <- cor(scale(trainDescr))
> 
> ## This cut-off should be under src.adjust control.
> ## I'm under Git, so I can tinker with it.
> highCorr <- findCorrelation(descrCorr, cutoff = .90, verbose = TRUE)
Considering row	 17 column	 16 value	 0.85 
Considering row	 17 column	 10 value	 0.671 
Considering row	 17 column	 1 value	 0.279 
Considering row	 17 column	 11 value	 0.277 
Considering row	 17 column	 6 value	 0.22 
Considering row	 17 column	 12 value	 0.226 
Considering row	 17 column	 2 value	 0.298 
Considering row	 17 column	 9 value	 0.586 
Considering row	 17 column	 14 value	 0.226 
Considering row	 17 column	 13 value	 0.23 
Considering row	 17 column	 8 value	 0.541 
Considering row	 17 column	 3 value	 0.346 
Considering row	 17 column	 18 value	 0.261 
Considering row	 17 column	 19 value	 0.138 
Considering row	 17 column	 15 value	 0.057 
Considering row	 17 column	 4 value	 0.067 
Considering row	 17 column	 7 value	 0.034 
Considering row	 17 column	 5 value	 0.018 
Considering row	 16 column	 10 value	 0.568 
Considering row	 16 column	 1 value	 0.236 
Considering row	 16 column	 11 value	 0.231 
Considering row	 16 column	 6 value	 0.189 
Considering row	 16 column	 12 value	 0.19 
Considering row	 16 column	 2 value	 0.333 
Considering row	 16 column	 9 value	 0.671 
Considering row	 16 column	 14 value	 0.242 
Considering row	 16 column	 13 value	 0.208 
Considering row	 16 column	 8 value	 0.6 
Considering row	 16 column	 3 value	 0.318 
Considering row	 16 column	 18 value	 0.279 
Considering row	 16 column	 19 value	 0.213 
Considering row	 16 column	 15 value	 0.083 
Considering row	 16 column	 4 value	 0.02 
Considering row	 16 column	 7 value	 0.009 
Considering row	 16 column	 5 value	 0.005 
Considering row	 10 column	 1 value	 0.281 
Considering row	 10 column	 11 value	 0.275 
Considering row	 10 column	 6 value	 0.298 
Considering row	 10 column	 12 value	 0.255 
Considering row	 10 column	 2 value	 0.286 
Considering row	 10 column	 9 value	 0.404 
Considering row	 10 column	 14 value	 0.224 
Considering row	 10 column	 13 value	 0.199 
Considering row	 10 column	 8 value	 0.366 
Considering row	 10 column	 3 value	 0.462 
Considering row	 10 column	 18 value	 0.226 
Considering row	 10 column	 19 value	 0.103 
Considering row	 10 column	 15 value	 0.274 
Considering row	 10 column	 4 value	 0.018 
Considering row	 10 column	 7 value	 0.127 
Considering row	 10 column	 5 value	 0.096 
Considering row	 1 column	 11 value	 0.988 
  Flagging column	 1 
Considering row	 11 column	 6 value	 0.945 
  Flagging column	 11 
Considering row	 6 column	 12 value	 0.883 
Considering row	 6 column	 2 value	 0.151 
Considering row	 6 column	 9 value	 0.04 
Considering row	 6 column	 14 value	 0.188 
Considering row	 6 column	 13 value	 0.161 
Considering row	 6 column	 8 value	 0.063 
Considering row	 6 column	 3 value	 0.083 
Considering row	 6 column	 18 value	 0.197 
Considering row	 6 column	 19 value	 0.114 
Considering row	 6 column	 15 value	 0.159 
Considering row	 6 column	 4 value	 0.01 
Considering row	 6 column	 7 value	 0.027 
Considering row	 6 column	 5 value	 0.039 
Considering row	 12 column	 2 value	 0.121 
Considering row	 12 column	 9 value	 0.128 
Considering row	 12 column	 14 value	 0.092 
Considering row	 12 column	 13 value	 0.105 
Considering row	 12 column	 8 value	 0.071 
Considering row	 12 column	 3 value	 0.093 
Considering row	 12 column	 18 value	 0.126 
Considering row	 12 column	 19 value	 0.171 
Considering row	 12 column	 15 value	 0.13 
Considering row	 12 column	 4 value	 0.01 
Considering row	 12 column	 7 value	 0.043 
Considering row	 12 column	 5 value	 0.017 
Considering row	 2 column	 9 value	 0.423 
Considering row	 2 column	 14 value	 0.574 
Considering row	 2 column	 13 value	 0.557 
Considering row	 2 column	 8 value	 0.165 
Considering row	 2 column	 3 value	 0.263 
Considering row	 2 column	 18 value	 0.128 
Considering row	 2 column	 19 value	 0.089 
Considering row	 2 column	 15 value	 0.069 
Considering row	 2 column	 4 value	 0.27 
Considering row	 2 column	 7 value	 0.045 
Considering row	 2 column	 5 value	 0.024 
Considering row	 9 column	 14 value	 0.147 
Considering row	 9 column	 13 value	 0.125 
Considering row	 9 column	 8 value	 0.449 
Considering row	 9 column	 3 value	 0.322 
Considering row	 9 column	 18 value	 0.018 
Considering row	 9 column	 19 value	 0.141 
Considering row	 9 column	 15 value	 0.073 
Considering row	 9 column	 4 value	 0.006 
Considering row	 9 column	 7 value	 0.136 
Considering row	 9 column	 5 value	 0.123 
Considering row	 14 column	 13 value	 0.659 
Considering row	 14 column	 8 value	 0.097 
Considering row	 14 column	 3 value	 0.106 
Considering row	 14 column	 18 value	 0.361 
Considering row	 14 column	 19 value	 0.092 
Considering row	 14 column	 15 value	 0.084 
Considering row	 14 column	 4 value	 0.263 
Considering row	 14 column	 7 value	 0.139 
Considering row	 14 column	 5 value	 0.031 
Considering row	 13 column	 8 value	 0.097 
Considering row	 13 column	 3 value	 0.167 
Considering row	 13 column	 18 value	 0.18 
Considering row	 13 column	 19 value	 0.131 
Considering row	 13 column	 15 value	 0.137 
Considering row	 13 column	 4 value	 0.24 
Considering row	 13 column	 7 value	 0.085 
Considering row	 13 column	 5 value	 0.027 
Considering row	 8 column	 3 value	 0.224 
Considering row	 8 column	 18 value	 0.173 
Considering row	 8 column	 19 value	 0.235 
Considering row	 8 column	 15 value	 0.07 
Considering row	 8 column	 4 value	 0.02 
Considering row	 8 column	 7 value	 0.085 
Considering row	 8 column	 5 value	 0.004 
Considering row	 3 column	 18 value	 0.028 
Considering row	 3 column	 19 value	 0.027 
Considering row	 3 column	 15 value	 0.017 
Considering row	 3 column	 4 value	 0.094 
Considering row	 3 column	 7 value	 0.095 
Considering row	 3 column	 5 value	 0.097 
Considering row	 18 column	 19 value	 0.019 
Considering row	 18 column	 15 value	 0.12 
Considering row	 18 column	 4 value	 0.086 
Considering row	 18 column	 7 value	 0.132 
Considering row	 18 column	 5 value	 0.002 
Considering row	 19 column	 15 value	 0.019 
Considering row	 19 column	 4 value	 0.032 
Considering row	 19 column	 7 value	 0.056 
Considering row	 19 column	 5 value	 0.075 
Considering row	 15 column	 4 value	 0.043 
Considering row	 15 column	 7 value	 0.061 
Considering row	 15 column	 5 value	 0.08 
Considering row	 4 column	 7 value	 0.005 
Considering row	 4 column	 5 value	 0.213 
Considering row	 7 column	 5 value	 0.008 
> 
> colnames(trainDescr)[highCorr]
[1] "SDEPHR"    "DEPBUCKET"
> 
> descr.ncol0 <- ncol(trainDescr)
> 
> # I've switched off the correlation remover and the results are better.
> if (sum(highCorr) > 0) {
+     warning("overfitting: correlations: err.trainDescr: ", paste(colnames(trainDescr)[highCorr], collapse = ", ") )
+     err.trainDescr <- trainDescr
+     trainDescr <- trainDescr[,-highCorr]
+ }
Warning message:
overfitting: correlations: err.trainDescr: SDEPHR, DEPBUCKET 
> 
> descr.ncol1 <- ncol(trainDescr)
> 
> paste("Dropped: ", as.character(descr.ncol0 - descr.ncol1))
[1] "Dropped:  2"
> 
> descrCorr <- cor(trainDescr)
> summary(descrCorr[upper.tri(descrCorr)])
     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
-0.850200 -0.130300 -0.007232  0.008050  0.106900  0.882600 
> 
> ## Dominant correlations
> ## At 0.9, there are some big ones that might need re-thinking.
> 
> table.descrCorr <- as.data.frame(as.table(descrCorr))
> table.descrCorr <- table.descrCorr[which(table.descrCorr$Var1 != table.descrCorr$Var2),]
> table.descrCorr[order(abs(table.descrCorr$Freq), decreasing = TRUE),]
              Var1           Var2         Freq
78       ARRBUCKET          AVGSQ  0.882590635
158          AVGSQ      ARRBUCKET  0.882590635
236       ARRSPOKE       DEPSPOKE -0.850165355
252       DEPSPOKE       ARRSPOKE -0.850165355
133       DEPSPOKE   DEPSTAATCIMP  0.671264566
229   DEPSTAATCIMP       DEPSPOKE  0.671264566
151       ARRSPOKE DOWNLINEATCIMP  0.671009330
247 DOWNLINEATCIMP       ARRSPOKE  0.671009330
182     TRNRANKGRP     DEPRANKGRP  0.658724662
198     DEPRANKGRP     TRNRANKGRP  0.658724662
116       DEPSPOKE   UPLINEATCIMP -0.600008252
228   UPLINEATCIMP       DEPSPOKE -0.600008252
134       ARRSPOKE   DEPSTAATCIMP -0.586442959
246   DEPSTAATCIMP       ARRSPOKE -0.586442959
12      TRNRANKGRP      SKDDEPSTA  0.574035134
188      SKDDEPSTA     TRNRANKGRP  0.574035134
150       DEPSPOKE DOWNLINEATCIMP -0.567682494
230 DOWNLINEATCIMP       DEPSPOKE -0.567682494
11      DEPRANKGRP      SKDDEPSTA  0.557399203
171      SKDDEPSTA     DEPRANKGRP  0.557399203
117       ARRSPOKE   UPLINEATCIMP  0.540734833
245   UPLINEATCIMP       ARRSPOKE  0.540734833
26  DOWNLINEATCIMP      SKDARRSTA  0.462378131
138      SKDARRSTA DOWNLINEATCIMP  0.462378131
110   DEPSTAATCIMP   UPLINEATCIMP -0.449249986
126   UPLINEATCIMP   DEPSTAATCIMP -0.449249986
8     DEPSTAATCIMP      SKDDEPSTA  0.423425796
120      SKDDEPSTA   DEPSTAATCIMP  0.423425796
128 DOWNLINEATCIMP   DEPSTAATCIMP -0.403695561
144   DEPSTAATCIMP DOWNLINEATCIMP -0.403695561
111 DOWNLINEATCIMP   UPLINEATCIMP  0.365833687
143   UPLINEATCIMP DOWNLINEATCIMP  0.365833687
203         xDURN2     TRNRANKGRP  0.361347207
267     TRNRANKGRP         xDURN2  0.361347207
32        ARRSPOKE      SKDARRSTA  0.345987375
240      SKDARRSTA       ARRSPOKE  0.345987375
14        DEPSPOKE      SKDDEPSTA  0.332823310
222      SKDDEPSTA       DEPSPOKE  0.332823310
25    DEPSTAATCIMP      SKDARRSTA -0.322204878
121      SKDARRSTA   DEPSTAATCIMP -0.322204878
31        DEPSPOKE      SKDARRSTA -0.318093195
223      SKDARRSTA       DEPSPOKE -0.318093195
77  DOWNLINEATCIMP          AVGSQ  0.298096458
141          AVGSQ DOWNLINEATCIMP  0.298096458
15        ARRSPOKE      SKDDEPSTA -0.298036487
239      SKDDEPSTA       ARRSPOKE -0.298036487
9   DOWNLINEATCIMP      SKDDEPSTA -0.285911992
137      SKDDEPSTA DOWNLINEATCIMP -0.285911992
237         xDURN2       DEPSPOKE  0.279030910
269       DEPSPOKE         xDURN2  0.279030910
149     ARRRANKGRP DOWNLINEATCIMP -0.274110143
213 DOWNLINEATCIMP     ARRRANKGRP -0.274110143
3           SKDEQP      SKDDEPSTA  0.270065872
35       SKDDEPSTA         SKDEQP  0.270065872
2        SKDARRSTA      SKDDEPSTA -0.263453106
18       SKDDEPSTA      SKDARRSTA -0.263453106
46      TRNRANKGRP         SKDEQP  0.262837233
190         SKDEQP     TRNRANKGRP  0.262837233
254         xDURN2       ARRSPOKE -0.261107447
270       ARRSPOKE         xDURN2 -0.261107447
146      ARRBUCKET DOWNLINEATCIMP  0.255480148
162 DOWNLINEATCIMP      ARRBUCKET  0.255480148
201       DEPSPOKE     TRNRANKGRP  0.242138220
233     TRNRANKGRP       DEPSPOKE  0.242138220
45      DEPRANKGRP         SKDEQP  0.239915140
173         SKDEQP     DEPRANKGRP  0.239915140
119   xAVGSKDAVAIL   UPLINEATCIMP  0.234867014
279   UPLINEATCIMP   xAVGSKDAVAIL  0.234867014
185       ARRSPOKE     DEPRANKGRP -0.229640758
249     DEPRANKGRP       ARRSPOKE -0.229640758
152         xDURN2 DOWNLINEATCIMP -0.226093423
264 DOWNLINEATCIMP         xDURN2 -0.226093423
168       ARRSPOKE      ARRBUCKET  0.225890655
248      ARRBUCKET       ARRSPOKE  0.225890655
202       ARRSPOKE     TRNRANKGRP -0.225591539
250     TRNRANKGRP       ARRSPOKE -0.225591539
148     TRNRANKGRP DOWNLINEATCIMP -0.224193213
196 DOWNLINEATCIMP     TRNRANKGRP -0.224193213
24    UPLINEATCIMP      SKDARRSTA  0.223824406
104      SKDARRSTA   UPLINEATCIMP  0.223824406
83        ARRSPOKE          AVGSQ  0.219975654
243          AVGSQ       ARRSPOKE  0.219975654
238   xAVGSKDAVAIL       DEPSPOKE -0.212821518
286       DEPSPOKE   xAVGSKDAVAIL -0.212821518
38          SKDEPS         SKDEQP  0.212586898
54          SKDEQP         SKDEPS  0.212586898
184       DEPSPOKE     DEPRANKGRP  0.208188512
232     DEPRANKGRP       DEPSPOKE  0.208188512
147     DEPRANKGRP DOWNLINEATCIMP -0.199411990
179 DOWNLINEATCIMP     DEPRANKGRP -0.199411990
84          xDURN2          AVGSQ -0.197447957
260          AVGSQ         xDURN2 -0.197447957
167       DEPSPOKE      ARRBUCKET -0.189934966
231      ARRBUCKET       DEPSPOKE -0.189934966
82        DEPSPOKE          AVGSQ -0.188666787
226          AVGSQ       DEPSPOKE -0.188666787
80      TRNRANKGRP          AVGSQ -0.188226304
192          AVGSQ     TRNRANKGRP -0.188226304
186         xDURN2     DEPRANKGRP  0.180043357
266     DEPRANKGRP         xDURN2  0.180043357
118         xDURN2   UPLINEATCIMP -0.173240320
262   UPLINEATCIMP         xDURN2 -0.173240320
170   xAVGSKDAVAIL      ARRBUCKET -0.170644257
282      ARRBUCKET   xAVGSKDAVAIL -0.170644257
28      DEPRANKGRP      SKDARRSTA -0.167375913
172      SKDARRSTA     DEPRANKGRP -0.167375913
7     UPLINEATCIMP      SKDDEPSTA -0.164964952
103      SKDDEPSTA   UPLINEATCIMP -0.164964952
79      DEPRANKGRP          AVGSQ -0.161451853
175          AVGSQ     DEPRANKGRP -0.161451853
81      ARRRANKGRP          AVGSQ -0.159135469
209          AVGSQ     ARRRANKGRP -0.159135469
5            AVGSQ      SKDDEPSTA -0.150522366
69       SKDDEPSTA          AVGSQ -0.150522366
131     TRNRANKGRP   DEPSTAATCIMP -0.147409309
195   DEPSTAATCIMP     TRNRANKGRP -0.147409309
136   xAVGSKDAVAIL   DEPSTAATCIMP -0.141077194
280   DEPSTAATCIMP   xAVGSKDAVAIL -0.141077194
97      TRNRANKGRP      AVGLOFATC  0.139184315
193      AVGLOFATC     TRNRANKGRP  0.139184315
255   xAVGSKDAVAIL       ARRSPOKE  0.137677242
287       ARRSPOKE   xAVGSKDAVAIL  0.137677242
183     ARRRANKGRP     DEPRANKGRP  0.136562948
215     DEPRANKGRP     ARRRANKGRP  0.136562948
93    DEPSTAATCIMP      AVGLOFATC -0.135778614
125      AVGLOFATC   DEPSTAATCIMP -0.135778614
101         xDURN2      AVGLOFATC -0.132084629
261      AVGLOFATC         xDURN2 -0.132084629
187   xAVGSKDAVAIL     DEPRANKGRP  0.130574789
283     DEPRANKGRP   xAVGSKDAVAIL  0.130574789
166     ARRRANKGRP      ARRBUCKET -0.129698517
214      ARRBUCKET     ARRRANKGRP -0.129698517
129      ARRBUCKET   DEPSTAATCIMP -0.127726148
161   DEPSTAATCIMP      ARRBUCKET -0.127726148
16          xDURN2      SKDDEPSTA  0.127598189
256      SKDDEPSTA         xDURN2  0.127598189
94  DOWNLINEATCIMP      AVGLOFATC -0.126763572
142      AVGLOFATC DOWNLINEATCIMP -0.126763572
169         xDURN2      ARRBUCKET -0.125836459
265      ARRBUCKET         xDURN2 -0.125836459
130     DEPRANKGRP   DEPSTAATCIMP  0.124672682
178   DEPSTAATCIMP     DEPRANKGRP  0.124672682
59    DEPSTAATCIMP         SKDEPS -0.123445793
123         SKDEPS   DEPSTAATCIMP -0.123445793
10       ARRBUCKET      SKDDEPSTA -0.120728212
154      SKDDEPSTA      ARRBUCKET -0.120728212
220         xDURN2     ARRRANKGRP  0.119675180
268     ARRRANKGRP         xDURN2  0.119675180
85    xAVGSKDAVAIL          AVGSQ -0.113720147
277          AVGSQ   xAVGSKDAVAIL -0.113720147
29      TRNRANKGRP      SKDARRSTA -0.105802023
189      SKDARRSTA     TRNRANKGRP -0.105802023
164     DEPRANKGRP      ARRBUCKET -0.105057984
180      ARRBUCKET     DEPRANKGRP -0.105057984
153   xAVGSKDAVAIL DOWNLINEATCIMP  0.102577364
281 DOWNLINEATCIMP   xAVGSKDAVAIL  0.102577364
113     DEPRANKGRP   UPLINEATCIMP -0.097218129
177   UPLINEATCIMP     DEPRANKGRP -0.097218129
114     TRNRANKGRP   UPLINEATCIMP -0.097037814
194   UPLINEATCIMP     TRNRANKGRP -0.097037814
21          SKDEPS      SKDARRSTA -0.096699169
53       SKDARRSTA         SKDEPS -0.096699169
60  DOWNLINEATCIMP         SKDEPS -0.095568613
140         SKDEPS DOWNLINEATCIMP -0.095568613
23       AVGLOFATC      SKDARRSTA -0.095234466
87       SKDARRSTA      AVGLOFATC -0.095234466
20          SKDEQP      SKDARRSTA  0.094073459
36       SKDARRSTA         SKDEQP  0.094073459
27       ARRBUCKET      SKDARRSTA  0.092625400
155      SKDARRSTA      ARRBUCKET  0.092625400
165     TRNRANKGRP      ARRBUCKET -0.092415252
197      ARRBUCKET     TRNRANKGRP -0.092415252
204   xAVGSKDAVAIL     TRNRANKGRP  0.092011501
284     TRNRANKGRP   xAVGSKDAVAIL  0.092011501
17    xAVGSKDAVAIL      SKDDEPSTA  0.088580325
273      SKDDEPSTA   xAVGSKDAVAIL  0.088580325
50          xDURN2         SKDEQP  0.086170070
258         SKDEQP         xDURN2  0.086170070
96      DEPRANKGRP      AVGLOFATC  0.085474019
176      AVGLOFATC     DEPRANKGRP  0.085474019
92    UPLINEATCIMP      AVGLOFATC -0.085180887
108      AVGLOFATC   UPLINEATCIMP -0.085180887
200     ARRRANKGRP     TRNRANKGRP  0.083906762
216     TRNRANKGRP     ARRRANKGRP  0.083906762
218       DEPSPOKE     ARRRANKGRP  0.083162083
234     ARRRANKGRP       DEPSPOKE  0.083162083
22           AVGSQ      SKDARRSTA  0.082898864
70       SKDARRSTA          AVGSQ  0.082898864
64      ARRRANKGRP         SKDEPS  0.080398834
208         SKDEPS     ARRRANKGRP  0.080398834
68    xAVGSKDAVAIL         SKDEPS  0.075169577
276         SKDEPS   xAVGSKDAVAIL  0.075169577
132     ARRRANKGRP   DEPSTAATCIMP  0.073371196
212   DEPSTAATCIMP     ARRRANKGRP  0.073371196
112      ARRBUCKET   UPLINEATCIMP  0.071409699
160   UPLINEATCIMP      ARRBUCKET  0.071409699
115     ARRRANKGRP   UPLINEATCIMP -0.069790367
211   UPLINEATCIMP     ARRRANKGRP -0.069790367
13      ARRRANKGRP      SKDDEPSTA  0.068927801
205      SKDDEPSTA     ARRRANKGRP  0.068927801
49        ARRSPOKE         SKDEQP  0.066579707
241         SKDEQP       ARRSPOKE  0.066579707
75    UPLINEATCIMP          AVGSQ  0.062631172
107          AVGSQ   UPLINEATCIMP  0.062631172
98      ARRRANKGRP      AVGLOFATC -0.061491190
210      AVGLOFATC     ARRRANKGRP -0.061491190
219       ARRSPOKE     ARRRANKGRP -0.057002549
251     ARRRANKGRP       ARRSPOKE -0.057002549
102   xAVGSKDAVAIL      AVGLOFATC -0.056264979
278      AVGLOFATC   xAVGSKDAVAIL -0.056264979
6        AVGLOFATC      SKDDEPSTA -0.044946507
86       SKDDEPSTA      AVGLOFATC -0.044946507
95       ARRBUCKET      AVGLOFATC -0.043093769
159      AVGLOFATC      ARRBUCKET -0.043093769
47      ARRRANKGRP         SKDEQP -0.042512956
207         SKDEQP     ARRRANKGRP -0.042512956
76    DEPSTAATCIMP          AVGSQ -0.040428658
124          AVGSQ   DEPSTAATCIMP -0.040428658
56           AVGSQ         SKDEPS -0.038820886
72          SKDEPS          AVGSQ -0.038820886
100       ARRSPOKE      AVGLOFATC -0.034402462
244      AVGLOFATC       ARRSPOKE -0.034402462
51    xAVGSKDAVAIL         SKDEQP  0.031863410
275         SKDEQP   xAVGSKDAVAIL  0.031863410
63      TRNRANKGRP         SKDEPS  0.030883560
191         SKDEPS     TRNRANKGRP  0.030883560
33          xDURN2      SKDARRSTA  0.027576751
257      SKDARRSTA         xDURN2  0.027576751
74       AVGLOFATC          AVGSQ -0.027382453
90           AVGSQ      AVGLOFATC -0.027382453
34    xAVGSKDAVAIL      SKDARRSTA  0.027225219
274      SKDARRSTA   xAVGSKDAVAIL  0.027225219
62      DEPRANKGRP         SKDEPS  0.027025501
174         SKDEPS     DEPRANKGRP  0.027025501
4           SKDEPS      SKDDEPSTA -0.024267794
52       SKDDEPSTA         SKDEPS -0.024267794
41    UPLINEATCIMP         SKDEQP -0.019807499
105         SKDEQP   UPLINEATCIMP -0.019807499
48        DEPSPOKE         SKDEQP  0.019755644
224         SKDEQP       DEPSPOKE  0.019755644
272   xAVGSKDAVAIL         xDURN2 -0.019255572
288         xDURN2   xAVGSKDAVAIL -0.019255572
221   xAVGSKDAVAIL     ARRRANKGRP -0.018743432
285     ARRRANKGRP   xAVGSKDAVAIL -0.018743432
135         xDURN2   DEPSTAATCIMP -0.017999758
263   DEPSTAATCIMP         xDURN2 -0.017999758
43  DOWNLINEATCIMP         SKDEQP -0.017658860
139         SKDEQP DOWNLINEATCIMP -0.017658860
66        ARRSPOKE         SKDEPS  0.017573485
242         SKDEPS       ARRSPOKE  0.017573485
61       ARRBUCKET         SKDEPS  0.017414895
157         SKDEPS      ARRBUCKET  0.017414895
30      ARRRANKGRP      SKDARRSTA  0.016733374
206      SKDARRSTA     ARRRANKGRP  0.016733374
39           AVGSQ         SKDEQP  0.010218807
71          SKDEQP          AVGSQ  0.010218807
44       ARRBUCKET         SKDEQP  0.009926479
156         SKDEQP      ARRBUCKET  0.009926479
99        DEPSPOKE      AVGLOFATC -0.008540402
227      AVGLOFATC       DEPSPOKE -0.008540402
57       AVGLOFATC         SKDEPS  0.008240563
89          SKDEPS      AVGLOFATC  0.008240563
42    DEPSTAATCIMP         SKDEQP -0.005922601
122         SKDEQP   DEPSTAATCIMP -0.005922601
40       AVGLOFATC         SKDEQP -0.004889040
88          SKDEQP      AVGLOFATC -0.004889040
65        DEPSPOKE         SKDEPS -0.004617067
225         SKDEPS       DEPSPOKE -0.004617067
58    UPLINEATCIMP         SKDEPS  0.004016263
106         SKDEPS   UPLINEATCIMP  0.004016263
67          xDURN2         SKDEPS  0.001748012
259         SKDEPS         xDURN2  0.001748012
> 
> ### Models
> 
> ## Try GBM (gradient boosting). Works well for mixed data.
> ## And there is a tutorial for it with caret.
> 
> ## Training controller and big grid
> ## Check the ROC (my preferred.)
> 
> # I'm not using this at the moment.
> 
> tr.cols <- colnames(trainDescr)
> tr.cols
 [1] "SKDDEPSTA"      "SKDARRSTA"      "SKDEQP"         "SKDEPS"        
 [5] "AVGSQ"          "AVGLOFATC"      "UPLINEATCIMP"   "DEPSTAATCIMP"  
 [9] "DOWNLINEATCIMP" "ARRBUCKET"      "DEPRANKGRP"     "TRNRANKGRP"    
[13] "ARRRANKGRP"     "DEPSPOKE"       "ARRSPOKE"       "xDURN2"        
[17] "xAVGSKDAVAIL"  
> tr.icols <- grep("((STA|EQP)$)|(^xD)", tr.cols)
> tr.icols <- rev(tr.icols)
> 
> fitControl <- trainControl(## 10-fold CV
+     method = "repeatedcv",
+     number = 10,
+     ## repeated ten times
+     repeats = 10,
+     classProbs = TRUE)
> 
> ## Some trial and error with variables to branch and boost.
> ## Try all variables
> 
> gbmGrid <- expand.grid(interaction.depth = 
+                            length(colnames(trainDescr)),
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.2,
+                         n.minobsinnode = 10)
> 
> set.seed(seed.mine)
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "Kappa",
+                  verbose = FALSE)
> gbmFit1
Stochastic Gradient Boosting 

248 samples
 17 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 222, 223, 223, 224, 223, 223, ... 

Resampling results across tuning parameters:

  n.trees  Accuracy   Kappa      Accuracy SD  Kappa SD 
    90     0.6910128  0.3751845  0.08862706   0.1784089
   180     0.6829769  0.3582764  0.09121266   0.1849099
   270     0.6777551  0.3487959  0.08538247   0.1729076
   360     0.6789385  0.3503213  0.08285441   0.1662863
   450     0.6818538  0.3555023  0.08847599   0.1782049
   540     0.6826218  0.3572341  0.08592521   0.1721091
   630     0.6831179  0.3585965  0.08624678   0.1732152
   720     0.6814808  0.3550835  0.08425677   0.1695981
   810     0.6831141  0.3584252  0.08587103   0.1729648
   900     0.6834500  0.3587032  0.08402217   0.1694555
   990     0.6810667  0.3546139  0.08158469   0.1636858
  1080     0.6814500  0.3552193  0.08190380   0.1643291
  1170     0.6774500  0.3471382  0.08075369   0.1624480
  1260     0.6838372  0.3603364  0.08503810   0.1703982
  1350     0.6846538  0.3617089  0.08166249   0.1642739
  1440     0.6822038  0.3566083  0.08195060   0.1643704
  1530     0.6838679  0.3599490  0.08305240   0.1665065
  1620     0.6838679  0.3601140  0.08308550   0.1665742
  1710     0.6831167  0.3591712  0.08655728   0.1729412
  1800     0.6874705  0.3697277  0.08821894   0.1760090
  1890     0.6838192  0.3640696  0.08409281   0.1666693
  1980     0.6870526  0.3718725  0.08071585   0.1591699
  2070     0.6822038  0.3638160  0.08080395   0.1585846
  2160     0.6805872  0.3624146  0.08571429   0.1683967
  2250     0.6813897  0.3649141  0.09006153   0.1770470
  2340     0.6798038  0.3628996  0.08954012   0.1761925
  2430     0.6802372  0.3644691  0.09133789   0.1798843
  2520     0.6790538  0.3632949  0.09272763   0.1824249
  2610     0.6774372  0.3611386  0.09124347   0.1794966
  2700     0.6799513  0.3673920  0.09408584   0.1845098

Tuning parameter 'interaction.depth' was held constant at a value of 17

Tuning parameter 'shrinkage' was held constant at a value of 0.2

Tuning parameter 'n.minobsinnode' was held constant at a value of 10
Kappa was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 90, interaction.depth =
 17, shrinkage = 0.2 and n.minobsinnode = 10. 
> 
> ## The acid test is dissapointing, but I've seen worse.
> 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
 Accuracy     Kappa 
 0.375000 -0.223565 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     12   17
    Weak       28   15
                                         
               Accuracy : 0.375          
                 95% CI : (0.2636, 0.497)
    No Information Rate : 0.5556         
    P-Value [Acc > NIR] : 0.9993         
                                         
                  Kappa : -0.2236        
 Mcnemar's Test P-Value : 0.1360         
                                         
            Sensitivity : 0.4688         
            Specificity : 0.3000         
         Pos Pred Value : 0.3488         
         Neg Pred Value : 0.4138         
             Prevalence : 0.4444         
         Detection Rate : 0.2083         
   Detection Prevalence : 0.5972         
      Balanced Accuracy : 0.3844         
                                         
       'Positive' Class : Weak           
                                         
> 
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
Accuracy    Kappa 
       1        1 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    137    0
    Weak        0  111
                                     
               Accuracy : 1          
                 95% CI : (0.9852, 1)
    No Information Rate : 0.5524     
    P-Value [Acc > NIR] : < 2.2e-16  
                                     
                  Kappa : 1          
 Mcnemar's Test P-Value : NA         
                                     
            Sensitivity : 1.0000     
            Specificity : 1.0000     
         Pos Pred Value : 1.0000     
         Neg Pred Value : 1.0000     
             Prevalence : 0.4476     
         Detection Rate : 0.4476     
   Detection Prevalence : 0.4476     
      Balanced Accuracy : 1.0000     
                                     
       'Positive' Class : Weak       
                                     
> quit()
Save workspace image? [y/n/c]: n

Process R finished at Sat May  7 07:06:03 2016


R version 3.2.5 (2016-04-14) -- "Very, Very Secure Dishes"
Copyright (C) 2016 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> > options(STERM='iESS', str.dendrogram.last="'", editor='emacsclient', show.error.locations=TRUE)
> 
+ . + + . + + . + 
> ### weaves
> 
> ## Processing for flights data.
> 
> ## Following the caret vignette.
> 
> ###################################################
> ### code chunk number 1: loadLibs
> ###################################################
> library(MASS)

> library(caret)
Loading required package: lattice
Loading required package: ggplot2

> library(mlbench)

> library(pROC)
Type 'citation("pROC")' for a citation.

Attaching package: 'pROC'

The following objects are masked from 'package:stats':

    cov, smooth, var


> library(pls)

Attaching package: 'pls'

The following object is masked from 'package:caret':

    R2

The following object is masked from 'package:stats':

    loadings


> library(doMC)
Loading required package: foreach
foreach: simple, scalable parallel programming from Revolution Analytics
Use Revolution R for scalability, fault tolerance and more.
http://www.revolutionanalytics.com
Loading required package: iterators
Loading required package: parallel

> registerDoMC(cores = 4)

> options(useFancyQuotes = FALSE) 

> # Accounting info.
> getInfo <- function(what = "Suggests")
+ {
+   text <- packageDescription("caret")[what][[1]]
+   text <- gsub("\n", ", ", text, fixed = TRUE)
+   text <- gsub(">=", "$\\\\ge$", text, fixed = TRUE)
+   eachPkg <- strsplit(text, ", ", fixed = TRUE)[[1]]
+   eachPkg <- gsub(",", .... [TRUNCATED] 

> ### project-specific: begin
> ## Set-seed, load original CSV file, order it
> ## and do some simple-cleaning
> ## Various datasets 
> 
> seed.mine = 107

> set.seed(seed.mine)                     # helpful for testing

> flight <- read.csv("../bak/flight.csv")

> flight <- flight[order(flight$D00),]

> # Backup
> flight.raw <- flight

> # To check adjustment, there is test code in flight-nb.R
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"

> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"

> # And some deletions
> 
> t.cols <- colnames(flight)

> t.drops <- t.cols[grep("^RANK*", t.cols)]

> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])

> t.drops <- c(t.drops, "D80THPCTL")

> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]

> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR

> flight$xHNGR <- flight$xDURN < 0

> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+  .... [TRUNCATED] 

> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))

> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE

> t.cols <- colnames(flight)

> t.drops <- c("SARRHR", "xDURN")

> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]

> ## Backup
> 
> flight00 <- flight

> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]

> paste("samples in use: ", dim(flight)[1])
[1] "samples in use:  320"

> ## Data insights
> 
> ## *Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> ### Numeric variables
> 
> ### Try and impute the AVG, it might have more information than the
> ### bucket.
> 
> flight$xAVAILBUC .... [TRUNCATED] 

> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1

> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]

> preProcValues <- preProcess(flight.na, method = c("knnImpute"))

> flight.na1 <- predict(preProcValues, flight.na)

> ## I'll add the new imputed value and drop the others
> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL

> flight$AVGSKDAVAIL <- NULL

> flight$xAVAILBUCKET <- NULL

> flight$AVAILBUCKET <- NULL

> flight$xHNGR <- NULL

> ## Check some more numeric correlations, I haven't scaled everything yet.
> ## I'd cut correlations above 0.65 to 0.75 because of overfitting.
> 
> x1 <- as.data.frame(as.matrix(sapply(flight, class)))

> flight.num <- flight[,names(x1[which(x1$V1 %in% c("numeric", "integer")),])]

> flight.nzv <- nearZeroVar(flight.num, saveMetrics = TRUE)

> flight.nzv
             freqRatio percentUnique zeroVar   nzv
SDEPHR        1.038462        5.9375   FALSE FALSE
SKDEPS        1.000000       19.0625   FALSE FALSE
D00           1.166667       75.3125   FALSE FALSE
AVGSQ         6.333333       82.8125   FALSE FALSE
AVGLOFATC     1.000000       78.4375   FALSE FALSE
xDURN2        1.428571        2.5000   FALSE FALSE
xAVGSKDAVAIL 18.500000       87.8125   FALSE FALSE

> # annoying NA should be gone.
> flight.cor <- cor(flight.num, use = "pairwise.complete.obs")

> descrCorr <- findCorrelation(flight.cor, cutoff = .65, verbose=TRUE)
Considering row	 4 column	 1 value	 0.956 
  Flagging column	 4 
Considering row	 1 column	 3 value	 0.43 
Considering row	 1 column	 7 value	 0.053 
Considering row	 1 column	 6 value	 0.204 
Considering row	 1 column	 5 value	 0.131 
Considering row	 1 column	 2 value	 0.054 
Considering row	 3 column	 7 value	 0.401 
Considering row	 3 column	 6 value	 0.071 
Considering row	 3 column	 5 value	 0.114 
Considering row	 3 column	 2 value	 0.006 
Considering row	 7 column	 6 value	 0.019 
Considering row	 7 column	 5 value	 0.07 
Considering row	 7 column	 2 value	 0.113 
Considering row	 6 column	 5 value	 0.137 
Considering row	 6 column	 2 value	 0.005 
Considering row	 5 column	 2 value	 0.041 

> colnames(flight.num)[descrCorr]
[1] "AVGSQ"

> ## And I'll leave the centered and scale values in for now.
> ## and delete the troublesome ones
> 
> ## Re-classing
> ## Check warnings to see it adjustment has taken place.
> ## We want the proportion in the training class to be about 0.55 0.45
> ## Strong to Weak
> ## I've achieved this heurist .... [TRUNCATED] 

> source(file = "flight1.R")

> flight1 <- flight

> ## This should be deleted, leave it in and the results
> ## are ideal because it defines LEGTYPE.
> flight$D00 <- NULL

> ## Keep the results but don't change the order.
> outcomes.flight <- flight$LEGTYPE

> flight$LEGTYPE <- NULL

> ## If you know your factors are definitely factors, you don't need this
> ##  asNumeric <- function(x) as.numeric(as.character(x))
> 
> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))

> flight.num0 <- factors.numeric(flight)

> flight.scl0 <- scale(flight.num0)

> ## Now split the samples
> ## we need at least 60 to test with, p at 0.77 gives about 75.
> ## Difficulty here is the bias in the table
> ## Because we only have [3.1, 4.4] the proportion of Weak is higher.
> ## see prop.table(results)
> 
> set.seed(seed.mine)

> inTrain <- createDataPartition(outcomes.flight, p = 0.77, list = FALSE)

> trainDescr <- flight.scl0[inTrain,]

> testDescr <- flight.scl0[-inTrain,]

> trainClass <- outcomes.flight[inTrain]

> testClass <- outcomes.flight[-inTrain]

> prop.table(table(trainClass))
trainClass
   Strong      Weak 
0.5524194 0.4475806 

> dim(trainDescr)
[1] 248  19

> prop.table(table(testClass))
testClass
   Strong      Weak 
0.5555556 0.4444444 

> dim(testDescr)
[1] 72 19

> ## Check Near-zero variance
> 
> nzv <- nearZeroVar(trainDescr, saveMetrics= TRUE)

> stopifnot( all(nzv$nzv == FALSE) )

> # It's imputed and behaves well, no need for this.
> # descrCorr <- cor(scale(trainDescr), use = "pairwise.complete.obs")
> 
> descrCorr <- cor(scale(trainDescr))

> ## This cut-off should be under src.adjust control.
> ## I'm under Git, so I can tinker with it.
> highCorr <- findCorrelation(descrCorr, cutoff = .90, verbose = TRUE)
Considering row	 17 column	 16 value	 0.85 
Considering row	 17 column	 10 value	 0.671 
Considering row	 17 column	 1 value	 0.279 
Considering row	 17 column	 11 value	 0.277 
Considering row	 17 column	 6 value	 0.22 
Considering row	 17 column	 12 value	 0.226 
Considering row	 17 column	 2 value	 0.298 
Considering row	 17 column	 9 value	 0.586 
Considering row	 17 column	 14 value	 0.226 
Considering row	 17 column	 13 value	 0.23 
Considering row	 17 column	 8 value	 0.541 
Considering row	 17 column	 3 value	 0.346 
Considering row	 17 column	 18 value	 0.261 
Considering row	 17 column	 19 value	 0.138 
Considering row	 17 column	 15 value	 0.057 
Considering row	 17 column	 4 value	 0.067 
Considering row	 17 column	 7 value	 0.034 
Considering row	 17 column	 5 value	 0.018 
Considering row	 16 column	 10 value	 0.568 
Considering row	 16 column	 1 value	 0.236 
Considering row	 16 column	 11 value	 0.231 
Considering row	 16 column	 6 value	 0.189 
Considering row	 16 column	 12 value	 0.19 
Considering row	 16 column	 2 value	 0.333 
Considering row	 16 column	 9 value	 0.671 
Considering row	 16 column	 14 value	 0.242 
Considering row	 16 column	 13 value	 0.208 
Considering row	 16 column	 8 value	 0.6 
Considering row	 16 column	 3 value	 0.318 
Considering row	 16 column	 18 value	 0.279 
Considering row	 16 column	 19 value	 0.213 
Considering row	 16 column	 15 value	 0.083 
Considering row	 16 column	 4 value	 0.02 
Considering row	 16 column	 7 value	 0.009 
Considering row	 16 column	 5 value	 0.005 
Considering row	 10 column	 1 value	 0.281 
Considering row	 10 column	 11 value	 0.275 
Considering row	 10 column	 6 value	 0.298 
Considering row	 10 column	 12 value	 0.255 
Considering row	 10 column	 2 value	 0.286 
Considering row	 10 column	 9 value	 0.404 
Considering row	 10 column	 14 value	 0.224 
Considering row	 10 column	 13 value	 0.199 
Considering row	 10 column	 8 value	 0.366 
Considering row	 10 column	 3 value	 0.462 
Considering row	 10 column	 18 value	 0.226 
Considering row	 10 column	 19 value	 0.103 
Considering row	 10 column	 15 value	 0.274 
Considering row	 10 column	 4 value	 0.018 
Considering row	 10 column	 7 value	 0.127 
Considering row	 10 column	 5 value	 0.096 
Considering row	 1 column	 11 value	 0.988 
  Flagging column	 1 
Considering row	 11 column	 6 value	 0.945 
  Flagging column	 11 
Considering row	 6 column	 12 value	 0.883 
Considering row	 6 column	 2 value	 0.151 
Considering row	 6 column	 9 value	 0.04 
Considering row	 6 column	 14 value	 0.188 
Considering row	 6 column	 13 value	 0.161 
Considering row	 6 column	 8 value	 0.063 
Considering row	 6 column	 3 value	 0.083 
Considering row	 6 column	 18 value	 0.197 
Considering row	 6 column	 19 value	 0.114 
Considering row	 6 column	 15 value	 0.159 
Considering row	 6 column	 4 value	 0.01 
Considering row	 6 column	 7 value	 0.027 
Considering row	 6 column	 5 value	 0.039 
Considering row	 12 column	 2 value	 0.121 
Considering row	 12 column	 9 value	 0.128 
Considering row	 12 column	 14 value	 0.092 
Considering row	 12 column	 13 value	 0.105 
Considering row	 12 column	 8 value	 0.071 
Considering row	 12 column	 3 value	 0.093 
Considering row	 12 column	 18 value	 0.126 
Considering row	 12 column	 19 value	 0.171 
Considering row	 12 column	 15 value	 0.13 
Considering row	 12 column	 4 value	 0.01 
Considering row	 12 column	 7 value	 0.043 
Considering row	 12 column	 5 value	 0.017 
Considering row	 2 column	 9 value	 0.423 
Considering row	 2 column	 14 value	 0.574 
Considering row	 2 column	 13 value	 0.557 
Considering row	 2 column	 8 value	 0.165 
Considering row	 2 column	 3 value	 0.263 
Considering row	 2 column	 18 value	 0.128 
Considering row	 2 column	 19 value	 0.089 
Considering row	 2 column	 15 value	 0.069 
Considering row	 2 column	 4 value	 0.27 
Considering row	 2 column	 7 value	 0.045 
Considering row	 2 column	 5 value	 0.024 
Considering row	 9 column	 14 value	 0.147 
Considering row	 9 column	 13 value	 0.125 
Considering row	 9 column	 8 value	 0.449 
Considering row	 9 column	 3 value	 0.322 
Considering row	 9 column	 18 value	 0.018 
Considering row	 9 column	 19 value	 0.141 
Considering row	 9 column	 15 value	 0.073 
Considering row	 9 column	 4 value	 0.006 
Considering row	 9 column	 7 value	 0.136 
Considering row	 9 column	 5 value	 0.123 
Considering row	 14 column	 13 value	 0.659 
Considering row	 14 column	 8 value	 0.097 
Considering row	 14 column	 3 value	 0.106 
Considering row	 14 column	 18 value	 0.361 
Considering row	 14 column	 19 value	 0.092 
Considering row	 14 column	 15 value	 0.084 
Considering row	 14 column	 4 value	 0.263 
Considering row	 14 column	 7 value	 0.139 
Considering row	 14 column	 5 value	 0.031 
Considering row	 13 column	 8 value	 0.097 
Considering row	 13 column	 3 value	 0.167 
Considering row	 13 column	 18 value	 0.18 
Considering row	 13 column	 19 value	 0.131 
Considering row	 13 column	 15 value	 0.137 
Considering row	 13 column	 4 value	 0.24 
Considering row	 13 column	 7 value	 0.085 
Considering row	 13 column	 5 value	 0.027 
Considering row	 8 column	 3 value	 0.224 
Considering row	 8 column	 18 value	 0.173 
Considering row	 8 column	 19 value	 0.235 
Considering row	 8 column	 15 value	 0.07 
Considering row	 8 column	 4 value	 0.02 
Considering row	 8 column	 7 value	 0.085 
Considering row	 8 column	 5 value	 0.004 
Considering row	 3 column	 18 value	 0.028 
Considering row	 3 column	 19 value	 0.027 
Considering row	 3 column	 15 value	 0.017 
Considering row	 3 column	 4 value	 0.094 
Considering row	 3 column	 7 value	 0.095 
Considering row	 3 column	 5 value	 0.097 
Considering row	 18 column	 19 value	 0.019 
Considering row	 18 column	 15 value	 0.12 
Considering row	 18 column	 4 value	 0.086 
Considering row	 18 column	 7 value	 0.132 
Considering row	 18 column	 5 value	 0.002 
Considering row	 19 column	 15 value	 0.019 
Considering row	 19 column	 4 value	 0.032 
Considering row	 19 column	 7 value	 0.056 
Considering row	 19 column	 5 value	 0.075 
Considering row	 15 column	 4 value	 0.043 
Considering row	 15 column	 7 value	 0.061 
Considering row	 15 column	 5 value	 0.08 
Considering row	 4 column	 7 value	 0.005 
Considering row	 4 column	 5 value	 0.213 
Considering row	 7 column	 5 value	 0.008 

> colnames(trainDescr)[highCorr]
[1] "SDEPHR"    "DEPBUCKET"

> descr.ncol0 <- ncol(trainDescr)

> # I've switched off the correlation remover and the results are better.
> if (sum(highCorr) > 0) {
+     warning("overfitting: correlations: err.trainDescr: ", paste(colnames(trainDescr)[highCorr], collapse = ", ") )
+     err.trainDescr <- trainDescr
+     trainDescr <- trainDescr[,-highCorr]
+ }

> descr.ncol1 <- ncol(trainDescr)

> paste("Dropped: ", as.character(descr.ncol0 - descr.ncol1))
[1] "Dropped:  2"

> descrCorr <- cor(trainDescr)

> summary(descrCorr[upper.tri(descrCorr)])
     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
-0.850200 -0.130300 -0.007232  0.008050  0.106900  0.882600 

> ## Dominant correlations
> ## At 0.9, there are some big ones that might need re-thinking.
> 
> table.descrCorr <- as.data.frame(as.table(descrCorr))

> table.descrCorr <- table.descrCorr[which(table.descrCorr$Var1 != table.descrCorr$Var2),]

> table.descrCorr[order(abs(table.descrCorr$Freq), decreasing = TRUE),]
              Var1           Var2         Freq
78       ARRBUCKET          AVGSQ  0.882590635
158          AVGSQ      ARRBUCKET  0.882590635
236       ARRSPOKE       DEPSPOKE -0.850165355
252       DEPSPOKE       ARRSPOKE -0.850165355
133       DEPSPOKE   DEPSTAATCIMP  0.671264566
229   DEPSTAATCIMP       DEPSPOKE  0.671264566
151       ARRSPOKE DOWNLINEATCIMP  0.671009330
247 DOWNLINEATCIMP       ARRSPOKE  0.671009330
182     TRNRANKGRP     DEPRANKGRP  0.658724662
198     DEPRANKGRP     TRNRANKGRP  0.658724662
116       DEPSPOKE   UPLINEATCIMP -0.600008252
228   UPLINEATCIMP       DEPSPOKE -0.600008252
134       ARRSPOKE   DEPSTAATCIMP -0.586442959
246   DEPSTAATCIMP       ARRSPOKE -0.586442959
12      TRNRANKGRP      SKDDEPSTA  0.574035134
188      SKDDEPSTA     TRNRANKGRP  0.574035134
150       DEPSPOKE DOWNLINEATCIMP -0.567682494
230 DOWNLINEATCIMP       DEPSPOKE -0.567682494
11      DEPRANKGRP      SKDDEPSTA  0.557399203
171      SKDDEPSTA     DEPRANKGRP  0.557399203
117       ARRSPOKE   UPLINEATCIMP  0.540734833
245   UPLINEATCIMP       ARRSPOKE  0.540734833
26  DOWNLINEATCIMP      SKDARRSTA  0.462378131
138      SKDARRSTA DOWNLINEATCIMP  0.462378131
110   DEPSTAATCIMP   UPLINEATCIMP -0.449249986
126   UPLINEATCIMP   DEPSTAATCIMP -0.449249986
8     DEPSTAATCIMP      SKDDEPSTA  0.423425796
120      SKDDEPSTA   DEPSTAATCIMP  0.423425796
128 DOWNLINEATCIMP   DEPSTAATCIMP -0.403695561
144   DEPSTAATCIMP DOWNLINEATCIMP -0.403695561
111 DOWNLINEATCIMP   UPLINEATCIMP  0.365833687
143   UPLINEATCIMP DOWNLINEATCIMP  0.365833687
203         xDURN2     TRNRANKGRP  0.361347207
267     TRNRANKGRP         xDURN2  0.361347207
32        ARRSPOKE      SKDARRSTA  0.345987375
240      SKDARRSTA       ARRSPOKE  0.345987375
14        DEPSPOKE      SKDDEPSTA  0.332823310
222      SKDDEPSTA       DEPSPOKE  0.332823310
25    DEPSTAATCIMP      SKDARRSTA -0.322204878
121      SKDARRSTA   DEPSTAATCIMP -0.322204878
31        DEPSPOKE      SKDARRSTA -0.318093195
223      SKDARRSTA       DEPSPOKE -0.318093195
77  DOWNLINEATCIMP          AVGSQ  0.298096458
141          AVGSQ DOWNLINEATCIMP  0.298096458
15        ARRSPOKE      SKDDEPSTA -0.298036487
239      SKDDEPSTA       ARRSPOKE -0.298036487
9   DOWNLINEATCIMP      SKDDEPSTA -0.285911992
137      SKDDEPSTA DOWNLINEATCIMP -0.285911992
237         xDURN2       DEPSPOKE  0.279030910
269       DEPSPOKE         xDURN2  0.279030910
149     ARRRANKGRP DOWNLINEATCIMP -0.274110143
213 DOWNLINEATCIMP     ARRRANKGRP -0.274110143
3           SKDEQP      SKDDEPSTA  0.270065872
35       SKDDEPSTA         SKDEQP  0.270065872
2        SKDARRSTA      SKDDEPSTA -0.263453106
18       SKDDEPSTA      SKDARRSTA -0.263453106
46      TRNRANKGRP         SKDEQP  0.262837233
190         SKDEQP     TRNRANKGRP  0.262837233
254         xDURN2       ARRSPOKE -0.261107447
270       ARRSPOKE         xDURN2 -0.261107447
146      ARRBUCKET DOWNLINEATCIMP  0.255480148
162 DOWNLINEATCIMP      ARRBUCKET  0.255480148
201       DEPSPOKE     TRNRANKGRP  0.242138220
233     TRNRANKGRP       DEPSPOKE  0.242138220
45      DEPRANKGRP         SKDEQP  0.239915140
173         SKDEQP     DEPRANKGRP  0.239915140
119   xAVGSKDAVAIL   UPLINEATCIMP  0.234867014
279   UPLINEATCIMP   xAVGSKDAVAIL  0.234867014
185       ARRSPOKE     DEPRANKGRP -0.229640758
249     DEPRANKGRP       ARRSPOKE -0.229640758
152         xDURN2 DOWNLINEATCIMP -0.226093423
264 DOWNLINEATCIMP         xDURN2 -0.226093423
168       ARRSPOKE      ARRBUCKET  0.225890655
248      ARRBUCKET       ARRSPOKE  0.225890655
202       ARRSPOKE     TRNRANKGRP -0.225591539
250     TRNRANKGRP       ARRSPOKE -0.225591539
148     TRNRANKGRP DOWNLINEATCIMP -0.224193213
196 DOWNLINEATCIMP     TRNRANKGRP -0.224193213
24    UPLINEATCIMP      SKDARRSTA  0.223824406
104      SKDARRSTA   UPLINEATCIMP  0.223824406
83        ARRSPOKE          AVGSQ  0.219975654
243          AVGSQ       ARRSPOKE  0.219975654
238   xAVGSKDAVAIL       DEPSPOKE -0.212821518
286       DEPSPOKE   xAVGSKDAVAIL -0.212821518
38          SKDEPS         SKDEQP  0.212586898
54          SKDEQP         SKDEPS  0.212586898
184       DEPSPOKE     DEPRANKGRP  0.208188512
232     DEPRANKGRP       DEPSPOKE  0.208188512
147     DEPRANKGRP DOWNLINEATCIMP -0.199411990
179 DOWNLINEATCIMP     DEPRANKGRP -0.199411990
84          xDURN2          AVGSQ -0.197447957
260          AVGSQ         xDURN2 -0.197447957
167       DEPSPOKE      ARRBUCKET -0.189934966
231      ARRBUCKET       DEPSPOKE -0.189934966
82        DEPSPOKE          AVGSQ -0.188666787
226          AVGSQ       DEPSPOKE -0.188666787
80      TRNRANKGRP          AVGSQ -0.188226304
192          AVGSQ     TRNRANKGRP -0.188226304
186         xDURN2     DEPRANKGRP  0.180043357
266     DEPRANKGRP         xDURN2  0.180043357
118         xDURN2   UPLINEATCIMP -0.173240320
262   UPLINEATCIMP         xDURN2 -0.173240320
170   xAVGSKDAVAIL      ARRBUCKET -0.170644257
282      ARRBUCKET   xAVGSKDAVAIL -0.170644257
28      DEPRANKGRP      SKDARRSTA -0.167375913
172      SKDARRSTA     DEPRANKGRP -0.167375913
7     UPLINEATCIMP      SKDDEPSTA -0.164964952
103      SKDDEPSTA   UPLINEATCIMP -0.164964952
79      DEPRANKGRP          AVGSQ -0.161451853
175          AVGSQ     DEPRANKGRP -0.161451853
81      ARRRANKGRP          AVGSQ -0.159135469
209          AVGSQ     ARRRANKGRP -0.159135469
5            AVGSQ      SKDDEPSTA -0.150522366
69       SKDDEPSTA          AVGSQ -0.150522366
131     TRNRANKGRP   DEPSTAATCIMP -0.147409309
195   DEPSTAATCIMP     TRNRANKGRP -0.147409309
136   xAVGSKDAVAIL   DEPSTAATCIMP -0.141077194
280   DEPSTAATCIMP   xAVGSKDAVAIL -0.141077194
97      TRNRANKGRP      AVGLOFATC  0.139184315
193      AVGLOFATC     TRNRANKGRP  0.139184315
255   xAVGSKDAVAIL       ARRSPOKE  0.137677242
287       ARRSPOKE   xAVGSKDAVAIL  0.137677242
183     ARRRANKGRP     DEPRANKGRP  0.136562948
215     DEPRANKGRP     ARRRANKGRP  0.136562948
93    DEPSTAATCIMP      AVGLOFATC -0.135778614
125      AVGLOFATC   DEPSTAATCIMP -0.135778614
101         xDURN2      AVGLOFATC -0.132084629
261      AVGLOFATC         xDURN2 -0.132084629
187   xAVGSKDAVAIL     DEPRANKGRP  0.130574789
283     DEPRANKGRP   xAVGSKDAVAIL  0.130574789
166     ARRRANKGRP      ARRBUCKET -0.129698517
214      ARRBUCKET     ARRRANKGRP -0.129698517
129      ARRBUCKET   DEPSTAATCIMP -0.127726148
161   DEPSTAATCIMP      ARRBUCKET -0.127726148
16          xDURN2      SKDDEPSTA  0.127598189
256      SKDDEPSTA         xDURN2  0.127598189
94  DOWNLINEATCIMP      AVGLOFATC -0.126763572
142      AVGLOFATC DOWNLINEATCIMP -0.126763572
169         xDURN2      ARRBUCKET -0.125836459
265      ARRBUCKET         xDURN2 -0.125836459
130     DEPRANKGRP   DEPSTAATCIMP  0.124672682
178   DEPSTAATCIMP     DEPRANKGRP  0.124672682
59    DEPSTAATCIMP         SKDEPS -0.123445793
123         SKDEPS   DEPSTAATCIMP -0.123445793
10       ARRBUCKET      SKDDEPSTA -0.120728212
154      SKDDEPSTA      ARRBUCKET -0.120728212
220         xDURN2     ARRRANKGRP  0.119675180
268     ARRRANKGRP         xDURN2  0.119675180
85    xAVGSKDAVAIL          AVGSQ -0.113720147
277          AVGSQ   xAVGSKDAVAIL -0.113720147
29      TRNRANKGRP      SKDARRSTA -0.105802023
189      SKDARRSTA     TRNRANKGRP -0.105802023
164     DEPRANKGRP      ARRBUCKET -0.105057984
180      ARRBUCKET     DEPRANKGRP -0.105057984
153   xAVGSKDAVAIL DOWNLINEATCIMP  0.102577364
281 DOWNLINEATCIMP   xAVGSKDAVAIL  0.102577364
113     DEPRANKGRP   UPLINEATCIMP -0.097218129
177   UPLINEATCIMP     DEPRANKGRP -0.097218129
114     TRNRANKGRP   UPLINEATCIMP -0.097037814
194   UPLINEATCIMP     TRNRANKGRP -0.097037814
21          SKDEPS      SKDARRSTA -0.096699169
53       SKDARRSTA         SKDEPS -0.096699169
60  DOWNLINEATCIMP         SKDEPS -0.095568613
140         SKDEPS DOWNLINEATCIMP -0.095568613
23       AVGLOFATC      SKDARRSTA -0.095234466
87       SKDARRSTA      AVGLOFATC -0.095234466
20          SKDEQP      SKDARRSTA  0.094073459
36       SKDARRSTA         SKDEQP  0.094073459
27       ARRBUCKET      SKDARRSTA  0.092625400
155      SKDARRSTA      ARRBUCKET  0.092625400
165     TRNRANKGRP      ARRBUCKET -0.092415252
197      ARRBUCKET     TRNRANKGRP -0.092415252
204   xAVGSKDAVAIL     TRNRANKGRP  0.092011501
284     TRNRANKGRP   xAVGSKDAVAIL  0.092011501
17    xAVGSKDAVAIL      SKDDEPSTA  0.088580325
273      SKDDEPSTA   xAVGSKDAVAIL  0.088580325
50          xDURN2         SKDEQP  0.086170070
258         SKDEQP         xDURN2  0.086170070
96      DEPRANKGRP      AVGLOFATC  0.085474019
176      AVGLOFATC     DEPRANKGRP  0.085474019
92    UPLINEATCIMP      AVGLOFATC -0.085180887
108      AVGLOFATC   UPLINEATCIMP -0.085180887
200     ARRRANKGRP     TRNRANKGRP  0.083906762
216     TRNRANKGRP     ARRRANKGRP  0.083906762
218       DEPSPOKE     ARRRANKGRP  0.083162083
234     ARRRANKGRP       DEPSPOKE  0.083162083
22           AVGSQ      SKDARRSTA  0.082898864
70       SKDARRSTA          AVGSQ  0.082898864
64      ARRRANKGRP         SKDEPS  0.080398834
208         SKDEPS     ARRRANKGRP  0.080398834
68    xAVGSKDAVAIL         SKDEPS  0.075169577
276         SKDEPS   xAVGSKDAVAIL  0.075169577
132     ARRRANKGRP   DEPSTAATCIMP  0.073371196
212   DEPSTAATCIMP     ARRRANKGRP  0.073371196
112      ARRBUCKET   UPLINEATCIMP  0.071409699
160   UPLINEATCIMP      ARRBUCKET  0.071409699
115     ARRRANKGRP   UPLINEATCIMP -0.069790367
211   UPLINEATCIMP     ARRRANKGRP -0.069790367
13      ARRRANKGRP      SKDDEPSTA  0.068927801
205      SKDDEPSTA     ARRRANKGRP  0.068927801
49        ARRSPOKE         SKDEQP  0.066579707
241         SKDEQP       ARRSPOKE  0.066579707
75    UPLINEATCIMP          AVGSQ  0.062631172
107          AVGSQ   UPLINEATCIMP  0.062631172
98      ARRRANKGRP      AVGLOFATC -0.061491190
210      AVGLOFATC     ARRRANKGRP -0.061491190
219       ARRSPOKE     ARRRANKGRP -0.057002549
251     ARRRANKGRP       ARRSPOKE -0.057002549
102   xAVGSKDAVAIL      AVGLOFATC -0.056264979
278      AVGLOFATC   xAVGSKDAVAIL -0.056264979
6        AVGLOFATC      SKDDEPSTA -0.044946507
86       SKDDEPSTA      AVGLOFATC -0.044946507
95       ARRBUCKET      AVGLOFATC -0.043093769
159      AVGLOFATC      ARRBUCKET -0.043093769
47      ARRRANKGRP         SKDEQP -0.042512956
207         SKDEQP     ARRRANKGRP -0.042512956
76    DEPSTAATCIMP          AVGSQ -0.040428658
124          AVGSQ   DEPSTAATCIMP -0.040428658
56           AVGSQ         SKDEPS -0.038820886
72          SKDEPS          AVGSQ -0.038820886
100       ARRSPOKE      AVGLOFATC -0.034402462
244      AVGLOFATC       ARRSPOKE -0.034402462
51    xAVGSKDAVAIL         SKDEQP  0.031863410
275         SKDEQP   xAVGSKDAVAIL  0.031863410
63      TRNRANKGRP         SKDEPS  0.030883560
191         SKDEPS     TRNRANKGRP  0.030883560
33          xDURN2      SKDARRSTA  0.027576751
257      SKDARRSTA         xDURN2  0.027576751
74       AVGLOFATC          AVGSQ -0.027382453
90           AVGSQ      AVGLOFATC -0.027382453
34    xAVGSKDAVAIL      SKDARRSTA  0.027225219
274      SKDARRSTA   xAVGSKDAVAIL  0.027225219
62      DEPRANKGRP         SKDEPS  0.027025501
174         SKDEPS     DEPRANKGRP  0.027025501
4           SKDEPS      SKDDEPSTA -0.024267794
52       SKDDEPSTA         SKDEPS -0.024267794
41    UPLINEATCIMP         SKDEQP -0.019807499
105         SKDEQP   UPLINEATCIMP -0.019807499
48        DEPSPOKE         SKDEQP  0.019755644
224         SKDEQP       DEPSPOKE  0.019755644
272   xAVGSKDAVAIL         xDURN2 -0.019255572
288         xDURN2   xAVGSKDAVAIL -0.019255572
221   xAVGSKDAVAIL     ARRRANKGRP -0.018743432
285     ARRRANKGRP   xAVGSKDAVAIL -0.018743432
135         xDURN2   DEPSTAATCIMP -0.017999758
263   DEPSTAATCIMP         xDURN2 -0.017999758
43  DOWNLINEATCIMP         SKDEQP -0.017658860
139         SKDEQP DOWNLINEATCIMP -0.017658860
66        ARRSPOKE         SKDEPS  0.017573485
242         SKDEPS       ARRSPOKE  0.017573485
61       ARRBUCKET         SKDEPS  0.017414895
157         SKDEPS      ARRBUCKET  0.017414895
30      ARRRANKGRP      SKDARRSTA  0.016733374
206      SKDARRSTA     ARRRANKGRP  0.016733374
39           AVGSQ         SKDEQP  0.010218807
71          SKDEQP          AVGSQ  0.010218807
44       ARRBUCKET         SKDEQP  0.009926479
156         SKDEQP      ARRBUCKET  0.009926479
99        DEPSPOKE      AVGLOFATC -0.008540402
227      AVGLOFATC       DEPSPOKE -0.008540402
57       AVGLOFATC         SKDEPS  0.008240563
89          SKDEPS      AVGLOFATC  0.008240563
42    DEPSTAATCIMP         SKDEQP -0.005922601
122         SKDEQP   DEPSTAATCIMP -0.005922601
40       AVGLOFATC         SKDEQP -0.004889040
88          SKDEQP      AVGLOFATC -0.004889040
65        DEPSPOKE         SKDEPS -0.004617067
225         SKDEPS       DEPSPOKE -0.004617067
58    UPLINEATCIMP         SKDEPS  0.004016263
106         SKDEPS   UPLINEATCIMP  0.004016263
67          xDURN2         SKDEPS  0.001748012
259         SKDEPS         xDURN2  0.001748012

> ### Models
> 
> ## Try GBM (gradient boosting). Works well for mixed data.
> ## And there is a tutorial for it with caret.
> 
> ## Training controller and big grid
> ## Check the ROC (my preferred.)
> 
> # I'm not using this at the moment.
> 
> tr.cols <- colnames(trainDescr)

> tr.cols
 [1] "SKDDEPSTA"      "SKDARRSTA"      "SKDEQP"         "SKDEPS"        
 [5] "AVGSQ"          "AVGLOFATC"      "UPLINEATCIMP"   "DEPSTAATCIMP"  
 [9] "DOWNLINEATCIMP" "ARRBUCKET"      "DEPRANKGRP"     "TRNRANKGRP"    
[13] "ARRRANKGRP"     "DEPSPOKE"       "ARRSPOKE"       "xDURN2"        
[17] "xAVGSKDAVAIL"  

> tr.icols <- grep("((STA|EQP)$)|(^xD)", tr.cols)

> tr.icols <- rev(tr.icols)

> fitControl <- trainControl(## 10-fold CV
+     method = "repeatedcv",
+     number = 10,
+     ## repeated ten times
+     repeats = 10,
+     classProbs = TRUE)

> ## Some trial and error with variables to branch and boost.
> ## Try all variables
> 
> gbmGrid <- expand.grid(interaction.depth = 
+                            length(colnames(trainDescr)),
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.2,
+                 .... [TRUNCATED] 

> set.seed(seed.mine)

> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "Kapp ..." ... [TRUNCATED] 
Loading required package: gbm
Loading required package: survival

Attaching package: 'survival'

The following object is masked from 'package:caret':

    cluster

Loading required package: splines
Loaded gbm 2.1.1
Loading required package: plyr

> gbmFit1
Stochastic Gradient Boosting 

248 samples
 17 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 222, 223, 223, 224, 223, 223, ... 

Resampling results across tuning parameters:

  n.trees  Accuracy   Kappa      Accuracy SD  Kappa SD 
    90     0.6954692  0.3836359  0.08482022   0.1704299
   180     0.6910500  0.3751434  0.08627847   0.1733828
   270     0.6862987  0.3667062  0.09006253   0.1793185
   360     0.6919308  0.3774407  0.09192631   0.1831561
   450     0.6907154  0.3757586  0.09255716   0.1847381
   540     0.6911295  0.3758421  0.08330361   0.1660767
   630     0.6924128  0.3784519  0.08637576   0.1735639
   720     0.6919500  0.3772551  0.08966293   0.1798301
   810     0.6871179  0.3670198  0.09280642   0.1863877
   900     0.6906705  0.3742676  0.09229337   0.1854482
   990     0.6883179  0.3698920  0.08906502   0.1783406
  1080     0.6894859  0.3728813  0.09443082   0.1891615
  1170     0.6899513  0.3729319  0.09380186   0.1886172
  1260     0.6879679  0.3688166  0.09492558   0.1905843
  1350     0.6859026  0.3645989  0.09231017   0.1855656
  1440     0.6839026  0.3604087  0.09483585   0.1905349
  1530     0.6827013  0.3581044  0.09222280   0.1854832
  1620     0.6802359  0.3530317  0.09190503   0.1845291
  1710     0.6814692  0.3562326  0.09330204   0.1870588
  1800     0.6846359  0.3636661  0.08915125   0.1778567
  1890     0.6874705  0.3714554  0.08627074   0.1710699
  1980     0.6882859  0.3746663  0.08908307   0.1764702
  2070     0.6890385  0.3772973  0.08486118   0.1680159
  2160     0.6861885  0.3726555  0.08513307   0.1678601
  2250     0.6882051  0.3784040  0.08595929   0.1691957
  2340     0.6854359  0.3738831  0.09179637   0.1801828
  2430     0.6838846  0.3715411  0.08720876   0.1717480
  2520     0.6819013  0.3687875  0.09179245   0.1801141
  2610     0.6798821  0.3654703  0.08864252   0.1739423
  2700     0.6758974  0.3584123  0.08804518   0.1728355

Tuning parameter 'interaction.depth' was held constant at a value of 17

Tuning parameter 'shrinkage' was held constant at a value of 0.2

Tuning parameter 'n.minobsinnode' was held constant at a value of 10
Kappa was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 90, interaction.depth =
 17, shrinkage = 0.2 and n.minobsinnode = 10. 

> ## The acid test is dissapointing, but I've seen worse.
> 
> testPred <- predict(gbmFit1, testDescr)

> postResample(testPred, testClass)
 Accuracy     Kappa 
 0.375000 -0.223565 

> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     12   17
    Weak       28   15
                                         
               Accuracy : 0.375          
                 95% CI : (0.2636, 0.497)
    No Information Rate : 0.5556         
    P-Value [Acc > NIR] : 0.9993         
                                         
                  Kappa : -0.2236        
 Mcnemar's Test P-Value : 0.1360         
                                         
            Sensitivity : 0.4688         
            Specificity : 0.3000         
         Pos Pred Value : 0.3488         
         Neg Pred Value : 0.4138         
             Prevalence : 0.4444         
         Detection Rate : 0.2083         
   Detection Prevalence : 0.5972         
      Balanced Accuracy : 0.3844         
                                         
       'Positive' Class : Weak           
                                         

> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)

> postResample(trainPred, trainClass)
Accuracy    Kappa 
       1        1 

> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    137    0
    Weak        0  111
                                     
               Accuracy : 1          
                 95% CI : (0.9852, 1)
    No Information Rate : 0.5524     
    P-Value [Acc > NIR] : < 2.2e-16  
                                     
                  Kappa : 1          
 Mcnemar's Test P-Value : NA         
                                     
            Sensitivity : 1.0000     
            Specificity : 1.0000     
         Pos Pred Value : 1.0000     
         Neg Pred Value : 1.0000     
             Prevalence : 0.4476     
         Detection Rate : 0.4476     
   Detection Prevalence : 0.4476     
      Balanced Accuracy : 1.0000     
                                     
       'Positive' Class : Weak       
                                     
Warning messages:
1: In eval(expr, envir, enclos) : adjusting
2: In eval(expr, envir, enclos) :
  overfitting: correlations: err.trainDescr: SDEPHR, DEPBUCKET
> trellis.par.set(caretTheme())
Warning message:
In trellis.par.set(caretTheme()) :
  Note: The default device has been opened to honour attempt to modify trellis settings
> plot(gbmFit1, metric = "Kappa")
> jpeg(width=1024, height=640)
> trellis.par.set(caretTheme())
> plot(gbmFit1, metric = "Kappa")
> dev.off()
null device 
          1 
> head(testPred)
[1] Weak   Strong Weak   Weak   Weak   Strong
Levels: Strong Weak
> testClass
 [1] Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak  
[11] Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak  
[21] Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak  
[31] Weak   Weak   Strong Strong Strong Strong Strong Strong Strong Strong
[41] Strong Strong Strong Strong Strong Strong Strong Strong Strong Strong
[51] Strong Strong Strong Strong Strong Strong Strong Strong Strong Strong
[61] Strong Strong Strong Strong Strong Strong Strong Strong Strong Strong
[71] Strong Strong
Levels: Strong Weak
> testPred
 [1] Weak   Strong Weak   Weak   Weak   Strong Strong Strong Strong Strong
[11] Strong Weak   Strong Strong Weak   Weak   Strong Weak   Strong Weak  
[21] Strong Strong Weak   Weak   Strong Weak   Weak   Strong Strong Weak  
[31] Strong Weak   Strong Weak   Weak   Weak   Weak   Weak   Strong Weak  
[41] Weak   Weak   Weak   Strong Weak   Weak   Weak   Strong Strong Weak  
[51] Weak   Strong Weak   Strong Weak   Weak   Strong Weak   Weak   Strong
[61] Weak   Strong Weak   Weak   Weak   Weak   Weak   Strong Strong Weak  
[71] Weak   Weak  
Levels: Strong Weak
> testClass
 [1] Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak  
[11] Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak  
[21] Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak  
[31] Weak   Weak   Strong Strong Strong Strong Strong Strong Strong Strong
[41] Strong Strong Strong Strong Strong Strong Strong Strong Strong Strong
[51] Strong Strong Strong Strong Strong Strong Strong Strong Strong Strong
[61] Strong Strong Strong Strong Strong Strong Strong Strong Strong Strong
[71] Strong Strong
Levels: Strong Weak
> scale(testPred)
Error in colMeans(x, na.rm = TRUE) : 'x' must be numeric
> as.numeric(testPred)
 [1] 2 1 2 2 2 1 1 1 1 1 1 2 1 1 2 2 1 2 1 2 1 1 2 2 1 2 2 1 1 2 1 2 1 2 2 2 2 2
[39] 1 2 2 2 2 1 2 2 2 1 1 2 2 1 2 1 2 2 1 2 2 1 2 1 2 2 2 2 2 1 1 2 2 2
> scale(as.numeric(testPred), centered=FALSE)
Error in scale(as.numeric(testPred), centered = FALSE) : 
  unused argument (centered = FALSE)
> ?scale
> scale(as.numeric(testPred), center=FALSE)
           [,1]
 [1,] 1.1886696
 [2,] 0.5943348
 [3,] 1.1886696
 [4,] 1.1886696
 [5,] 1.1886696
 [6,] 0.5943348
 [7,] 0.5943348
 [8,] 0.5943348
 [9,] 0.5943348
[10,] 0.5943348
[11,] 0.5943348
[12,] 1.1886696
[13,] 0.5943348
[14,] 0.5943348
[15,] 1.1886696
[16,] 1.1886696
[17,] 0.5943348
[18,] 1.1886696
[19,] 0.5943348
[20,] 1.1886696
[21,] 0.5943348
[22,] 0.5943348
[23,] 1.1886696
[24,] 1.1886696
[25,] 0.5943348
[26,] 1.1886696
[27,] 1.1886696
[28,] 0.5943348
[29,] 0.5943348
[30,] 1.1886696
[31,] 0.5943348
[32,] 1.1886696
[33,] 0.5943348
[34,] 1.1886696
[35,] 1.1886696
[36,] 1.1886696
[37,] 1.1886696
[38,] 1.1886696
[39,] 0.5943348
[40,] 1.1886696
[41,] 1.1886696
[42,] 1.1886696
[43,] 1.1886696
[44,] 0.5943348
[45,] 1.1886696
[46,] 1.1886696
[47,] 1.1886696
[48,] 0.5943348
[49,] 0.5943348
[50,] 1.1886696
[51,] 1.1886696
[52,] 0.5943348
[53,] 1.1886696
[54,] 0.5943348
[55,] 1.1886696
[56,] 1.1886696
[57,] 0.5943348
[58,] 1.1886696
[59,] 1.1886696
[60,] 0.5943348
[61,] 1.1886696
[62,] 0.5943348
[63,] 1.1886696
[64,] 1.1886696
[65,] 1.1886696
[66,] 1.1886696
[67,] 1.1886696
[68,] 0.5943348
[69,] 0.5943348
[70,] 1.1886696
[71,] 1.1886696
[72,] 1.1886696
attr(,"scaled:scale")
[1] 1.682553
> test.pred <- scale(as.numeric(testPred), center=FALSE)
> test.class <- scale(as.numeric(testClass), center=FALSE)
> testClass
 [1] Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak  
[11] Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak  
[21] Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak  
[31] Weak   Weak   Strong Strong Strong Strong Strong Strong Strong Strong
[41] Strong Strong Strong Strong Strong Strong Strong Strong Strong Strong
[51] Strong Strong Strong Strong Strong Strong Strong Strong Strong Strong
[61] Strong Strong Strong Strong Strong Strong Strong Strong Strong Strong
[71] Strong Strong
Levels: Strong Weak
> test.res <- data.frame(pred=scale(as.numeric(testPred)), obs=scale(as.numeric(testClass)))
> test.res
        pred        obs
1   0.815507  1.1102427
2  -1.209200  1.1102427
3   0.815507  1.1102427
4   0.815507  1.1102427
5   0.815507  1.1102427
6  -1.209200  1.1102427
7  -1.209200  1.1102427
8  -1.209200  1.1102427
9  -1.209200  1.1102427
10 -1.209200  1.1102427
11 -1.209200  1.1102427
12  0.815507  1.1102427
13 -1.209200  1.1102427
14 -1.209200  1.1102427
15  0.815507  1.1102427
16  0.815507  1.1102427
17 -1.209200  1.1102427
18  0.815507  1.1102427
19 -1.209200  1.1102427
20  0.815507  1.1102427
21 -1.209200  1.1102427
22 -1.209200  1.1102427
23  0.815507  1.1102427
24  0.815507  1.1102427
25 -1.209200  1.1102427
26  0.815507  1.1102427
27  0.815507  1.1102427
28 -1.209200  1.1102427
29 -1.209200  1.1102427
30  0.815507  1.1102427
31 -1.209200  1.1102427
32  0.815507  1.1102427
33 -1.209200 -0.8881942
34  0.815507 -0.8881942
35  0.815507 -0.8881942
36  0.815507 -0.8881942
37  0.815507 -0.8881942
38  0.815507 -0.8881942
39 -1.209200 -0.8881942
40  0.815507 -0.8881942
41  0.815507 -0.8881942
42  0.815507 -0.8881942
43  0.815507 -0.8881942
44 -1.209200 -0.8881942
45  0.815507 -0.8881942
46  0.815507 -0.8881942
47  0.815507 -0.8881942
48 -1.209200 -0.8881942
49 -1.209200 -0.8881942
50  0.815507 -0.8881942
51  0.815507 -0.8881942
52 -1.209200 -0.8881942
53  0.815507 -0.8881942
54 -1.209200 -0.8881942
55  0.815507 -0.8881942
56  0.815507 -0.8881942
57 -1.209200 -0.8881942
58  0.815507 -0.8881942
59  0.815507 -0.8881942
60 -1.209200 -0.8881942
61  0.815507 -0.8881942
62 -1.209200 -0.8881942
63  0.815507 -0.8881942
64  0.815507 -0.8881942
65  0.815507 -0.8881942
66  0.815507 -0.8881942
67  0.815507 -0.8881942
68 -1.209200 -0.8881942
69 -1.209200 -0.8881942
70  0.815507 -0.8881942
71  0.815507 -0.8881942
72  0.815507 -0.8881942
> plot.roc(test.res$pred, test.res$obs)

Call:
plot.roc.default(x = test.res$pred, predictor = test.res$obs)

Data: test.res$obs in 29 controls (test.res$pred -1.20920004588069) > 43 cases (test.res$pred 0.815507007686974).
Area under the curve: 0.6187
> test.res$p <- predict(gbmFit1, testDescr, type = "prob"
+ 
+ )
> test.res$obs1 <- testClass
> head(test.res)
       pred      obs   p.Strong     p.Weak obs1
1  0.815507 1.110243 0.12710589 0.87289411 Weak
2 -1.209200 1.110243 0.98320634 0.01679366 Weak
3  0.815507 1.110243 0.05501535 0.94498465 Weak
4  0.815507 1.110243 0.48418588 0.51581412 Weak
5  0.815507 1.110243 0.31785015 0.68214985 Weak
6 -1.209200 1.110243 0.72847063 0.27152937 Weak
> densityplot(~test.res$p.Weak, groups = testData$obs1, auto.key = TRUE) 
Error in eval(expr, envir, enclos) : object 'testData' not found
> densityplot(~test.res$p.Weak, groups = test.res$obs1, auto.key = TRUE) 
Warning messages:
1: In (function (x, darg, groups = NULL, weights = NULL, subscripts = TRUE,  :
  NAs introduced by coercion
2: In panel.superpose(x, darg = darg, plot.points = plot.points, ref = FALSE,  :
  NAs introduced by coercion
> x.testData <- data.frame(x = c(rnorm(200), rnorm(200) + 1),
                       group = factor(rep(letters[1:2], each = 200)))
x.testData <- data.frame(x = c(rnorm(200), rnorm(200) + 1),
+                        group = factor(rep(letters[1:2], each = 200)))
> head(x.testData)
            x group
1  1.34992494     a
2  0.95096884     a
3  2.33494236     a
4 -0.09467106     a
5 -0.80805584     a
6 -0.90171874     a
> densityplot(~x.testData$x, groups = x.testData$group, auto.key = TRUE)
> densityplot(~test.res$p.Weak, groups = test.res$obs1, auto.key = TRUE)
Warning messages:
1: In (function (x, darg, groups = NULL, weights = NULL, subscripts = TRUE,  :
  NAs introduced by coercion
2: In panel.superpose(x, darg = darg, plot.points = plot.points, ref = FALSE,  :
  NAs introduced by coercion
> test.res
        pred        obs    p.Strong      p.Weak   obs1
1   0.815507  1.1102427 0.127105893 0.872894107   Weak
2  -1.209200  1.1102427 0.983206339 0.016793661   Weak
3   0.815507  1.1102427 0.055015346 0.944984654   Weak
4   0.815507  1.1102427 0.484185881 0.515814119   Weak
5   0.815507  1.1102427 0.317850152 0.682149848   Weak
6  -1.209200  1.1102427 0.728470634 0.271529366   Weak
7  -1.209200  1.1102427 0.712065611 0.287934389   Weak
8  -1.209200  1.1102427 0.857296542 0.142703458   Weak
9  -1.209200  1.1102427 0.636860772 0.363139228   Weak
10 -1.209200  1.1102427 0.986896761 0.013103239   Weak
11 -1.209200  1.1102427 0.854018240 0.145981760   Weak
12  0.815507  1.1102427 0.136575228 0.863424772   Weak
13 -1.209200  1.1102427 0.524677822 0.475322178   Weak
14 -1.209200  1.1102427 0.957758110 0.042241890   Weak
15  0.815507  1.1102427 0.005374134 0.994625866   Weak
16  0.815507  1.1102427 0.077444615 0.922555385   Weak
17 -1.209200  1.1102427 0.786514164 0.213485836   Weak
18  0.815507  1.1102427 0.470088373 0.529911627   Weak
19 -1.209200  1.1102427 0.963917867 0.036082133   Weak
20  0.815507  1.1102427 0.479819369 0.520180631   Weak
21 -1.209200  1.1102427 0.841105827 0.158894173   Weak
22 -1.209200  1.1102427 0.983711412 0.016288588   Weak
23  0.815507  1.1102427 0.339937178 0.660062822   Weak
24  0.815507  1.1102427 0.332490556 0.667509444   Weak
25 -1.209200  1.1102427 0.976165543 0.023834457   Weak
26  0.815507  1.1102427 0.069290468 0.930709532   Weak
27  0.815507  1.1102427 0.004748120 0.995251880   Weak
28 -1.209200  1.1102427 0.927815839 0.072184161   Weak
29 -1.209200  1.1102427 0.885192175 0.114807825   Weak
30  0.815507  1.1102427 0.079898748 0.920101252   Weak
31 -1.209200  1.1102427 0.983996316 0.016003684   Weak
32  0.815507  1.1102427 0.004066933 0.995933067   Weak
33 -1.209200 -0.8881942 0.608739045 0.391260955 Strong
34  0.815507 -0.8881942 0.022935327 0.977064673 Strong
35  0.815507 -0.8881942 0.044462611 0.955537389 Strong
36  0.815507 -0.8881942 0.012780175 0.987219825 Strong
37  0.815507 -0.8881942 0.267863591 0.732136409 Strong
38  0.815507 -0.8881942 0.001477149 0.998522851 Strong
39 -1.209200 -0.8881942 0.732925153 0.267074847 Strong
40  0.815507 -0.8881942 0.459239235 0.540760765 Strong
41  0.815507 -0.8881942 0.114303216 0.885696784 Strong
42  0.815507 -0.8881942 0.382229125 0.617770875 Strong
43  0.815507 -0.8881942 0.138815116 0.861184884 Strong
44 -1.209200 -0.8881942 0.911494674 0.088505326 Strong
45  0.815507 -0.8881942 0.388125495 0.611874505 Strong
46  0.815507 -0.8881942 0.186297184 0.813702816 Strong
47  0.815507 -0.8881942 0.073868153 0.926131847 Strong
48 -1.209200 -0.8881942 0.913065041 0.086934959 Strong
49 -1.209200 -0.8881942 0.967802319 0.032197681 Strong
50  0.815507 -0.8881942 0.000482228 0.999517772 Strong
51  0.815507 -0.8881942 0.101718751 0.898281249 Strong
52 -1.209200 -0.8881942 0.682449738 0.317550262 Strong
53  0.815507 -0.8881942 0.343771598 0.656228402 Strong
54 -1.209200 -0.8881942 0.979619649 0.020380351 Strong
55  0.815507 -0.8881942 0.118027473 0.881972527 Strong
56  0.815507 -0.8881942 0.002453611 0.997546389 Strong
57 -1.209200 -0.8881942 0.987711374 0.012288626 Strong
58  0.815507 -0.8881942 0.307476954 0.692523046 Strong
59  0.815507 -0.8881942 0.021590637 0.978409363 Strong
60 -1.209200 -0.8881942 0.729092338 0.270907662 Strong
61  0.815507 -0.8881942 0.057078989 0.942921011 Strong
62 -1.209200 -0.8881942 0.710198674 0.289801326 Strong
63  0.815507 -0.8881942 0.011051854 0.988948146 Strong
64  0.815507 -0.8881942 0.041065119 0.958934881 Strong
65  0.815507 -0.8881942 0.010470611 0.989529389 Strong
66  0.815507 -0.8881942 0.024280143 0.975719857 Strong
67  0.815507 -0.8881942 0.078641443 0.921358557 Strong
68 -1.209200 -0.8881942 0.994795958 0.005204042 Strong
69 -1.209200 -0.8881942 0.982097739 0.017902261 Strong
70  0.815507 -0.8881942 0.063652931 0.936347069 Strong
71  0.815507 -0.8881942 0.003255772 0.996744228 Strong
72  0.815507 -0.8881942 0.085016094 0.914983906 Strong
> test.res[["p.Weak"]]
NULL
> test.res[, "p.Weak"]
Error in `[.data.frame`(test.res, , "p.Weak") : 
  undefined columns selected
> test.res[, 4]
 [1] Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak  
[11] Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak  
[21] Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak   Weak  
[31] Weak   Weak   Strong Strong Strong Strong Strong Strong Strong Strong
[41] Strong Strong Strong Strong Strong Strong Strong Strong Strong Strong
[51] Strong Strong Strong Strong Strong Strong Strong Strong Strong Strong
[61] Strong Strong Strong Strong Strong Strong Strong Strong Strong Strong
[71] Strong Strong
Levels: Strong Weak
> test.res[, 3]
        Strong        Weak
1  0.127105893 0.872894107
2  0.983206339 0.016793661
3  0.055015346 0.944984654
4  0.484185881 0.515814119
5  0.317850152 0.682149848
6  0.728470634 0.271529366
7  0.712065611 0.287934389
8  0.857296542 0.142703458
9  0.636860772 0.363139228
10 0.986896761 0.013103239
11 0.854018240 0.145981760
12 0.136575228 0.863424772
13 0.524677822 0.475322178
14 0.957758110 0.042241890
15 0.005374134 0.994625866
16 0.077444615 0.922555385
17 0.786514164 0.213485836
18 0.470088373 0.529911627
19 0.963917867 0.036082133
20 0.479819369 0.520180631
21 0.841105827 0.158894173
22 0.983711412 0.016288588
23 0.339937178 0.660062822
24 0.332490556 0.667509444
25 0.976165543 0.023834457
26 0.069290468 0.930709532
27 0.004748120 0.995251880
28 0.927815839 0.072184161
29 0.885192175 0.114807825
30 0.079898748 0.920101252
31 0.983996316 0.016003684
32 0.004066933 0.995933067
33 0.608739045 0.391260955
34 0.022935327 0.977064673
35 0.044462611 0.955537389
36 0.012780175 0.987219825
37 0.267863591 0.732136409
38 0.001477149 0.998522851
39 0.732925153 0.267074847
40 0.459239235 0.540760765
41 0.114303216 0.885696784
42 0.382229125 0.617770875
43 0.138815116 0.861184884
44 0.911494674 0.088505326
45 0.388125495 0.611874505
46 0.186297184 0.813702816
47 0.073868153 0.926131847
48 0.913065041 0.086934959
49 0.967802319 0.032197681
50 0.000482228 0.999517772
51 0.101718751 0.898281249
52 0.682449738 0.317550262
53 0.343771598 0.656228402
54 0.979619649 0.020380351
55 0.118027473 0.881972527
56 0.002453611 0.997546389
57 0.987711374 0.012288626
58 0.307476954 0.692523046
59 0.021590637 0.978409363
60 0.729092338 0.270907662
61 0.057078989 0.942921011
62 0.710198674 0.289801326
63 0.011051854 0.988948146
64 0.041065119 0.958934881
65 0.010470611 0.989529389
66 0.024280143 0.975719857
67 0.078641443 0.921358557
68 0.994795958 0.005204042
69 0.982097739 0.017902261
70 0.063652931 0.936347069
71 0.003255772 0.996744228
72 0.085016094 0.914983906
> test.res[, 3[2]]
Error in `[.data.frame`(test.res, , 3[2]) : undefined columns selected
> 
> test.res[,"p.Weak"]
Error in `[.data.frame`(test.res, , "p.Weak") : 
  undefined columns selected
> test.res[,"p"]
        Strong        Weak
1  0.127105893 0.872894107
2  0.983206339 0.016793661
3  0.055015346 0.944984654
4  0.484185881 0.515814119
5  0.317850152 0.682149848
6  0.728470634 0.271529366
7  0.712065611 0.287934389
8  0.857296542 0.142703458
9  0.636860772 0.363139228
10 0.986896761 0.013103239
11 0.854018240 0.145981760
12 0.136575228 0.863424772
13 0.524677822 0.475322178
14 0.957758110 0.042241890
15 0.005374134 0.994625866
16 0.077444615 0.922555385
17 0.786514164 0.213485836
18 0.470088373 0.529911627
19 0.963917867 0.036082133
20 0.479819369 0.520180631
21 0.841105827 0.158894173
22 0.983711412 0.016288588
23 0.339937178 0.660062822
24 0.332490556 0.667509444
25 0.976165543 0.023834457
26 0.069290468 0.930709532
27 0.004748120 0.995251880
28 0.927815839 0.072184161
29 0.885192175 0.114807825
30 0.079898748 0.920101252
31 0.983996316 0.016003684
32 0.004066933 0.995933067
33 0.608739045 0.391260955
34 0.022935327 0.977064673
35 0.044462611 0.955537389
36 0.012780175 0.987219825
37 0.267863591 0.732136409
38 0.001477149 0.998522851
39 0.732925153 0.267074847
40 0.459239235 0.540760765
41 0.114303216 0.885696784
42 0.382229125 0.617770875
43 0.138815116 0.861184884
44 0.911494674 0.088505326
45 0.388125495 0.611874505
46 0.186297184 0.813702816
47 0.073868153 0.926131847
48 0.913065041 0.086934959
49 0.967802319 0.032197681
50 0.000482228 0.999517772
51 0.101718751 0.898281249
52 0.682449738 0.317550262
53 0.343771598 0.656228402
54 0.979619649 0.020380351
55 0.118027473 0.881972527
56 0.002453611 0.997546389
57 0.987711374 0.012288626
58 0.307476954 0.692523046
59 0.021590637 0.978409363
60 0.729092338 0.270907662
61 0.057078989 0.942921011
62 0.710198674 0.289801326
63 0.011051854 0.988948146
64 0.041065119 0.958934881
65 0.010470611 0.989529389
66 0.024280143 0.975719857
67 0.078641443 0.921358557
68 0.994795958 0.005204042
69 0.982097739 0.017902261
70 0.063652931 0.936347069
71 0.003255772 0.996744228
72 0.085016094 0.914983906
> test.res[,"p"][,2]
 [1] 0.872894107 0.016793661 0.944984654 0.515814119 0.682149848 0.271529366
 [7] 0.287934389 0.142703458 0.363139228 0.013103239 0.145981760 0.863424772
[13] 0.475322178 0.042241890 0.994625866 0.922555385 0.213485836 0.529911627
[19] 0.036082133 0.520180631 0.158894173 0.016288588 0.660062822 0.667509444
[25] 0.023834457 0.930709532 0.995251880 0.072184161 0.114807825 0.920101252
[31] 0.016003684 0.995933067 0.391260955 0.977064673 0.955537389 0.987219825
[37] 0.732136409 0.998522851 0.267074847 0.540760765 0.885696784 0.617770875
[43] 0.861184884 0.088505326 0.611874505 0.813702816 0.926131847 0.086934959
[49] 0.032197681 0.999517772 0.898281249 0.317550262 0.656228402 0.020380351
[55] 0.881972527 0.997546389 0.012288626 0.692523046 0.978409363 0.270907662
[61] 0.942921011 0.289801326 0.988948146 0.958934881 0.989529389 0.975719857
[67] 0.921358557 0.005204042 0.017902261 0.936347069 0.996744228 0.914983906
> 
> 
> 
> head(test.res)
       pred      obs       Weak obs1
1  0.815507 1.110243 0.87289411 Weak
2 -1.209200 1.110243 0.01679366 Weak
3  0.815507 1.110243 0.94498465 Weak
4  0.815507 1.110243 0.51581412 Weak
5  0.815507 1.110243 0.68214985 Weak
6 -1.209200 1.110243 0.27152937 Weak
> densityplot(~test.res$Weak, groups = test.res$obs1, auto.key = TRUE)
Warning messages:
1: In (function (x, darg, groups = NULL, weights = NULL, subscripts = TRUE,  :
  NAs introduced by coercion
2: In panel.superpose(x, darg = darg, plot.points = plot.points, ref = FALSE,  :
  NAs introduced by coercion
> densityplot(test.res$Weak, groups = test.res$obs1, auto.key = TRUE)
Error in UseMethod("densityplot") : 
  no applicable method for 'densityplot' applied to an object of class "NULL"
> densityplot(~test.res$Weak, groups = test.res$obs1, auto.key = TRUE)
Warning messages:
1: In (function (x, darg, groups = NULL, weights = NULL, subscripts = TRUE,  :
  NAs introduced by coercion
2: In panel.superpose(x, darg = darg, plot.points = plot.points, ref = FALSE,  :
  NAs introduced by coercion
> test.res
        pred        obs        Weak   obs1
1   0.815507  1.1102427 0.872894107   Weak
2  -1.209200  1.1102427 0.016793661   Weak
3   0.815507  1.1102427 0.944984654   Weak
4   0.815507  1.1102427 0.515814119   Weak
5   0.815507  1.1102427 0.682149848   Weak
6  -1.209200  1.1102427 0.271529366   Weak
7  -1.209200  1.1102427 0.287934389   Weak
8  -1.209200  1.1102427 0.142703458   Weak
9  -1.209200  1.1102427 0.363139228   Weak
10 -1.209200  1.1102427 0.013103239   Weak
11 -1.209200  1.1102427 0.145981760   Weak
12  0.815507  1.1102427 0.863424772   Weak
13 -1.209200  1.1102427 0.475322178   Weak
14 -1.209200  1.1102427 0.042241890   Weak
15  0.815507  1.1102427 0.994625866   Weak
16  0.815507  1.1102427 0.922555385   Weak
17 -1.209200  1.1102427 0.213485836   Weak
18  0.815507  1.1102427 0.529911627   Weak
19 -1.209200  1.1102427 0.036082133   Weak
20  0.815507  1.1102427 0.520180631   Weak
21 -1.209200  1.1102427 0.158894173   Weak
22 -1.209200  1.1102427 0.016288588   Weak
23  0.815507  1.1102427 0.660062822   Weak
24  0.815507  1.1102427 0.667509444   Weak
25 -1.209200  1.1102427 0.023834457   Weak
26  0.815507  1.1102427 0.930709532   Weak
27  0.815507  1.1102427 0.995251880   Weak
28 -1.209200  1.1102427 0.072184161   Weak
29 -1.209200  1.1102427 0.114807825   Weak
30  0.815507  1.1102427 0.920101252   Weak
31 -1.209200  1.1102427 0.016003684   Weak
32  0.815507  1.1102427 0.995933067   Weak
33 -1.209200 -0.8881942 0.391260955 Strong
34  0.815507 -0.8881942 0.977064673 Strong
35  0.815507 -0.8881942 0.955537389 Strong
36  0.815507 -0.8881942 0.987219825 Strong
37  0.815507 -0.8881942 0.732136409 Strong
38  0.815507 -0.8881942 0.998522851 Strong
39 -1.209200 -0.8881942 0.267074847 Strong
40  0.815507 -0.8881942 0.540760765 Strong
41  0.815507 -0.8881942 0.885696784 Strong
42  0.815507 -0.8881942 0.617770875 Strong
43  0.815507 -0.8881942 0.861184884 Strong
44 -1.209200 -0.8881942 0.088505326 Strong
45  0.815507 -0.8881942 0.611874505 Strong
46  0.815507 -0.8881942 0.813702816 Strong
47  0.815507 -0.8881942 0.926131847 Strong
48 -1.209200 -0.8881942 0.086934959 Strong
49 -1.209200 -0.8881942 0.032197681 Strong
50  0.815507 -0.8881942 0.999517772 Strong
51  0.815507 -0.8881942 0.898281249 Strong
52 -1.209200 -0.8881942 0.317550262 Strong
53  0.815507 -0.8881942 0.656228402 Strong
54 -1.209200 -0.8881942 0.020380351 Strong
55  0.815507 -0.8881942 0.881972527 Strong
56  0.815507 -0.8881942 0.997546389 Strong
57 -1.209200 -0.8881942 0.012288626 Strong
58  0.815507 -0.8881942 0.692523046 Strong
59  0.815507 -0.8881942 0.978409363 Strong
60 -1.209200 -0.8881942 0.270907662 Strong
61  0.815507 -0.8881942 0.942921011 Strong
62 -1.209200 -0.8881942 0.289801326 Strong
63  0.815507 -0.8881942 0.988948146 Strong
64  0.815507 -0.8881942 0.958934881 Strong
65  0.815507 -0.8881942 0.989529389 Strong
66  0.815507 -0.8881942 0.975719857 Strong
67  0.815507 -0.8881942 0.921358557 Strong
68 -1.209200 -0.8881942 0.005204042 Strong
69 -1.209200 -0.8881942 0.017902261 Strong
70  0.815507 -0.8881942 0.936347069 Strong
71  0.815507 -0.8881942 0.996744228 Strong
72  0.815507 -0.8881942 0.914983906 Strong
> test.res$pred <- NULL
> test.res$obs <- NULL
> head(test.res)
        Weak obs1
1 0.87289411 Weak
2 0.01679366 Weak
3 0.94498465 Weak
4 0.51581412 Weak
5 0.68214985 Weak
6 0.27152937 Weak
> 
> 
Warning messages:
1: In (function (x, darg, groups = NULL, weights = NULL, subscripts = TRUE,  :
  NAs introduced by coercion
2: In panel.superpose(x, darg = darg, plot.points = plot.points, ref = FALSE,  :
  NAs introduced by coercion
> x.testData
               x group
1    1.349924940     a
2    0.950968837     a
3    2.334942361     a
4   -0.094671055     a
5   -0.808055845     a
6   -0.901718737     a
7    2.085573222     a
8    0.420459910     a
9    0.521826818     a
10   1.334159797     a
11   1.882323740     a
12  -0.766235404     a
13  -1.837576801     a
14  -0.374122706     a
15   0.560508863     a
16  -1.391945229     a
17  -1.722387126     a
18  -0.224109118     a
19   1.624534553     a
20   0.599366554     a
21   0.538783571     a
22  -1.974662021     a
23  -0.810988388     a
24   0.002361255     a
25   1.302195562     a
26   2.694797420     a
27   0.326156706     a
28  -1.402818899     a
29  -2.280233605     a
30  -0.897236850     a
31  -1.512163435     a
32   0.535073844     a
33   1.384056859     a
34   0.185676179     a
35  -1.043129467     a
36  -0.478950507     a
37  -0.803563680     a
38  -0.109722983     a
39  -0.485745370     a
40  -0.183063263     a
41  -0.673545691     a
42  -1.137922190     a
43  -1.017329996     a
44   0.090928376     a
45   0.724379980     a
46   0.886738276     a
47  -0.138423204     a
48  -1.207949174     a
49  -0.541170197     a
50  -0.628381615     a
51  -1.524914993     a
52  -1.117980300     a
53  -0.562056638     a
54  -0.693445584     a
55   0.443848872     a
56   1.235457780     a
57  -0.975522908     a
58  -0.662114906     a
59   1.318427453     a
60  -0.582887574     a
61  -0.128434581     a
62  -1.715539939     a
63  -1.896882715     a
64  -0.169621575     a
65   1.667547705     a
66  -0.519688073     a
67  -2.182955055     a
68   0.748961904     a
69  -1.398167492     a
70   2.071961882     a
71  -1.331680275     a
72   0.789928562     a
73   1.902674474     a
74  -0.358142915     a
75   0.912541349     a
76  -2.698059341     a
77  -0.498378099     a
78   1.072120461     a
79  -0.631736197     a
80   0.250918031     a
81   0.528100957     a
82  -0.749486140     a
83  -0.128783304     a
84  -0.308028735     a
85  -0.233680322     a
86   0.300917432     a
87   1.594470672     a
88  -0.088499196     a
89   0.887682867     a
90   1.498342461     a
91   0.548984922     a
92  -1.253775163     a
93  -1.856334336     a
94  -1.552235385     a
95   2.135641325     a
96   1.025432040     a
97   0.056591338     a
98  -1.060309301     a
99   0.500666882     a
100 -2.479693237     a
101  0.324669755     a
102 -1.392347578     a
103  1.011504994     a
104  1.237498065     a
105  0.029207744     a
106 -1.267334078     a
107 -1.424337586     a
108 -0.385880000     a
109  0.968418006     a
110 -0.589221572     a
111 -1.259245431     a
112  0.263172654     a
113  0.142412650     a
114 -0.373128529     a
115  1.393994322     a
116 -0.532097693     a
117 -0.701396852     a
118 -1.151256711     a
119 -0.163794340     a
120 -0.129200276     a
121  1.147303170     a
122 -0.943991395     a
123  0.192589252     a
124 -1.170655047     a
125 -0.710585323     a
126 -2.716323725     a
127 -0.611800101     a
128  0.645285577     a
129 -1.328994854     a
130 -0.411097582     a
131 -0.710080064     a
132  0.059759543     a
133 -2.010068089     a
134 -0.503027085     a
135  0.288419666     a
136  0.959589911     a
137  0.491468416     a
138 -0.690182347     a
139  0.970941919     a
140  1.407445118     a
141  0.127013672     a
142 -0.091802710     a
143  1.094195577     a
144 -0.845287253     a
145 -0.452439021     a
146  1.779820647     a
147  1.699799124     a
148 -0.941910053     a
149  0.908916130     a
150 -0.555947726     a
151  0.634264663     a
152  0.215563175     a
153 -1.159637813     a
154 -0.588082086     a
155  0.489639987     a
156 -0.049636822     a
157  0.182464999     a
158  0.040673645     a
159  1.058675574     a
160 -1.857228662     a
161 -0.242198303     a
162  0.953807137     a
163  2.029778749     a
164  0.693674354     a
165 -1.081252401     a
166  0.751523764     a
167 -0.036309676     a
168  0.415721346     a
169 -1.449175729     a
170  0.962272101     a
171  0.943641195     a
172 -0.712253091     a
173  0.663494617     a
174  0.407689175     a
175 -2.957558297     a
176 -0.066743812     a
177  0.358814359     a
178 -0.071565846     a
179  0.864804470     a
180 -2.005455080     a
181  0.523729136     a
182  0.264911957     a
183 -0.848525504     a
184  1.511920749     a
185 -0.411694381     a
186 -0.377054776     a
187  1.601204686     a
188  0.810594182     a
189  0.564529084     a
190  1.652341742     a
191 -1.404848887     a
192  0.243716750     a
193 -0.017840871     a
194 -1.960516465     a
195 -0.970390173     a
196  0.732080182     a
197  0.498385064     a
198  2.085604061     a
199  0.491034431     a
200 -1.962846115     a
201  3.335973969     b
202  0.611743719     b
203  2.356282741     b
204  1.756193438     b
205 -2.466231230     b
206  0.137391010     b
207  0.641591279     b
208  1.665680956     b
209  0.186936943     b
210 -0.377106294     b
211  1.376752776     b
212  0.447904234     b
213 -0.023628155     b
214  1.286757390     b
215  3.369124380     b
216 -0.125261476     b
217  0.397060331     b
218  1.133785511     b
219  0.222609905     b
220  0.542801431     b
221  1.119539801     b
222  2.934276628     b
223  0.554411095     b
224 -1.464148900     b
225  2.363920080     b
226  1.023246796     b
227  2.401592612     b
228  0.424403720     b
229  3.492662467     b
230  0.207069737     b
231 -0.285135922     b
232  2.774092657     b
233  0.932726345     b
234  0.307356282     b
235 -0.177748926     b
236  0.601300916     b
237  0.741936802     b
238  1.309871928     b
239  1.013624443     b
240 -0.159602350     b
241  3.326280879     b
242 -0.474760671     b
243  1.583865187     b
244 -0.437052144     b
245  0.963513093     b
246  0.184049852     b
247  0.832764525     b
248  2.750569459     b
249 -1.715479575     b
250  1.447252960     b
251  2.259225559     b
252  0.242249016     b
253  1.421668983     b
254  0.559499322     b
255  1.216297944     b
256  2.696129747     b
257  0.576349491     b
258  0.888296753     b
259  0.791319418     b
260  0.450938727     b
261  1.459301375     b
262  1.886163978     b
263  2.975258129     b
264  2.554448560     b
265  1.819750271     b
266  0.757427999     b
267  0.985648356     b
268  3.105730224     b
269  1.910646655     b
270  1.719198550     b
271 -0.881673232     b
272  0.002119816     b
273  0.540737724     b
274  0.497165335     b
275  1.202674282     b
276  1.319647962     b
277  1.879789253     b
278  1.268259517     b
279  1.438582688     b
280  2.094939074     b
281  1.541688812     b
282  2.155974933     b
283  1.816490913     b
284 -0.110102866     b
285  0.960645478     b
286  2.550269832     b
287 -1.063571135     b
288  0.970495302     b
289  0.027859404     b
290 -1.863286309     b
291  1.666374881     b
292  1.644898758     b
293  0.140284308     b
294  1.910703083     b
295 -0.852754797     b
296  2.181823943     b
297  1.565014368     b
298  2.784173925     b
299  0.934202197     b
300  1.133064525     b
301  1.367116930     b
302  0.700370109     b
303 -0.331991428     b
304 -0.345633289     b
305  1.440396110     b
306  1.110061197     b
307  0.012125323     b
308  0.176625732     b
309 -0.217760507     b
310  1.090895617     b
311  1.144298771     b
312  1.189838445     b
313 -0.093057407     b
314  1.915076670     b
315  0.909353697     b
316 -0.130361828     b
317  1.281536629     b
318  0.187307077     b
319  2.830840111     b
320  0.002288346     b
321  0.548077057     b
322  2.115718007     b
323  1.067338090     b
324  0.444829394     b
325  0.543631409     b
326 -0.534622834     b
327  2.031259357     b
328  0.338334850     b
329  1.463680388     b
330  0.316925944     b
331  0.831325847     b
332  0.770132816     b
333 -0.034638444     b
334  1.533430536     b
335  0.491723013     b
336  0.216658544     b
337  1.045729276     b
338  1.389361364     b
339 -0.047815798     b
340 -0.153720332     b
341 -0.804799819     b
342  0.794457229     b
343  2.497567092     b
344  3.050723957     b
345  1.308518343     b
346  0.195772008     b
347  1.639334310     b
348  1.619376342     b
349  0.419326503     b
350  1.490964235     b
351  1.494287205     b
352  2.106036519     b
353  1.412728384     b
354 -2.390531348     b
355 -0.140148712     b
356  0.790539791     b
357 -1.943748856     b
358  2.375832789     b
359  1.141894023     b
360  1.058671899     b
361  0.168241926     b
362  0.186220627     b
363 -0.044118294     b
364 -0.489937230     b
365  1.097287285     b
366  1.222252463     b
367  0.607027462     b
368  0.619046742     b
369  2.279839636     b
370  0.322815399     b
371  2.502026939     b
372  1.639402510     b
373  1.149622903     b
374  1.791346031     b
375  1.101884523     b
376  0.868691265     b
377  1.895573120     b
378 -0.195779447     b
379  1.746150754     b
380 -0.560719555     b
381 -0.633866094     b
382  0.199583049     b
383  0.935190543     b
384  0.214252999     b
385  2.122002169     b
386  0.795102987     b
387  2.111474311     b
388  0.286954271     b
389  0.543090022     b
390  1.654467565     b
391  0.578674338     b
392  1.257537838     b
393  0.835223697     b
394  1.105400238     b
395  1.146458883     b
396  1.635944264     b
397  1.089720570     b
398  1.106610628     b
399  1.483545187     b
400  0.467880468     b
> class(x.testData$x)
[1] "numeric"
> x.testData
               x group
1    1.349924940     a
2    0.950968837     a
3    2.334942361     a
4   -0.094671055     a
5   -0.808055845     a
6   -0.901718737     a
7    2.085573222     a
8    0.420459910     a
9    0.521826818     a
10   1.334159797     a
11   1.882323740     a
12  -0.766235404     a
13  -1.837576801     a
14  -0.374122706     a
15   0.560508863     a
16  -1.391945229     a
17  -1.722387126     a
18  -0.224109118     a
19   1.624534553     a
20   0.599366554     a
21   0.538783571     a
22  -1.974662021     a
23  -0.810988388     a
24   0.002361255     a
25   1.302195562     a
26   2.694797420     a
27   0.326156706     a
28  -1.402818899     a
29  -2.280233605     a
30  -0.897236850     a
31  -1.512163435     a
32   0.535073844     a
33   1.384056859     a
34   0.185676179     a
35  -1.043129467     a
36  -0.478950507     a
37  -0.803563680     a
38  -0.109722983     a
39  -0.485745370     a
40  -0.183063263     a
41  -0.673545691     a
42  -1.137922190     a
43  -1.017329996     a
44   0.090928376     a
45   0.724379980     a
46   0.886738276     a
47  -0.138423204     a
48  -1.207949174     a
49  -0.541170197     a
50  -0.628381615     a
51  -1.524914993     a
52  -1.117980300     a
53  -0.562056638     a
54  -0.693445584     a
55   0.443848872     a
56   1.235457780     a
57  -0.975522908     a
58  -0.662114906     a
59   1.318427453     a
60  -0.582887574     a
61  -0.128434581     a
62  -1.715539939     a
63  -1.896882715     a
64  -0.169621575     a
65   1.667547705     a
66  -0.519688073     a
67  -2.182955055     a
68   0.748961904     a
69  -1.398167492     a
70   2.071961882     a
71  -1.331680275     a
72   0.789928562     a
73   1.902674474     a
74  -0.358142915     a
75   0.912541349     a
76  -2.698059341     a
77  -0.498378099     a
78   1.072120461     a
79  -0.631736197     a
80   0.250918031     a
81   0.528100957     a
82  -0.749486140     a
83  -0.128783304     a
84  -0.308028735     a
85  -0.233680322     a
86   0.300917432     a
87   1.594470672     a
88  -0.088499196     a
89   0.887682867     a
90   1.498342461     a
91   0.548984922     a
92  -1.253775163     a
93  -1.856334336     a
94  -1.552235385     a
95   2.135641325     a
96   1.025432040     a
97   0.056591338     a
98  -1.060309301     a
99   0.500666882     a
100 -2.479693237     a
101  0.324669755     a
102 -1.392347578     a
103  1.011504994     a
104  1.237498065     a
105  0.029207744     a
106 -1.267334078     a
107 -1.424337586     a
108 -0.385880000     a
109  0.968418006     a
110 -0.589221572     a
111 -1.259245431     a
112  0.263172654     a
113  0.142412650     a
114 -0.373128529     a
115  1.393994322     a
116 -0.532097693     a
117 -0.701396852     a
118 -1.151256711     a
119 -0.163794340     a
120 -0.129200276     a
121  1.147303170     a
122 -0.943991395     a
123  0.192589252     a
124 -1.170655047     a
125 -0.710585323     a
126 -2.716323725     a
127 -0.611800101     a
128  0.645285577     a
129 -1.328994854     a
130 -0.411097582     a
131 -0.710080064     a
132  0.059759543     a
133 -2.010068089     a
134 -0.503027085     a
135  0.288419666     a
136  0.959589911     a
137  0.491468416     a
138 -0.690182347     a
139  0.970941919     a
140  1.407445118     a
141  0.127013672     a
142 -0.091802710     a
143  1.094195577     a
144 -0.845287253     a
145 -0.452439021     a
146  1.779820647     a
147  1.699799124     a
148 -0.941910053     a
149  0.908916130     a
150 -0.555947726     a
151  0.634264663     a
152  0.215563175     a
153 -1.159637813     a
154 -0.588082086     a
155  0.489639987     a
156 -0.049636822     a
157  0.182464999     a
158  0.040673645     a
159  1.058675574     a
160 -1.857228662     a
161 -0.242198303     a
162  0.953807137     a
163  2.029778749     a
164  0.693674354     a
165 -1.081252401     a
166  0.751523764     a
167 -0.036309676     a
168  0.415721346     a
169 -1.449175729     a
170  0.962272101     a
171  0.943641195     a
172 -0.712253091     a
173  0.663494617     a
174  0.407689175     a
175 -2.957558297     a
176 -0.066743812     a
177  0.358814359     a
178 -0.071565846     a
179  0.864804470     a
180 -2.005455080     a
181  0.523729136     a
182  0.264911957     a
183 -0.848525504     a
184  1.511920749     a
185 -0.411694381     a
186 -0.377054776     a
187  1.601204686     a
188  0.810594182     a
189  0.564529084     a
190  1.652341742     a
191 -1.404848887     a
192  0.243716750     a
193 -0.017840871     a
194 -1.960516465     a
195 -0.970390173     a
196  0.732080182     a
197  0.498385064     a
198  2.085604061     a
199  0.491034431     a
200 -1.962846115     a
201  3.335973969     b
202  0.611743719     b
203  2.356282741     b
204  1.756193438     b
205 -2.466231230     b
206  0.137391010     b
207  0.641591279     b
208  1.665680956     b
209  0.186936943     b
210 -0.377106294     b
211  1.376752776     b
212  0.447904234     b
213 -0.023628155     b
214  1.286757390     b
215  3.369124380     b
216 -0.125261476     b
217  0.397060331     b
218  1.133785511     b
219  0.222609905     b
220  0.542801431     b
221  1.119539801     b
222  2.934276628     b
223  0.554411095     b
224 -1.464148900     b
225  2.363920080     b
226  1.023246796     b
227  2.401592612     b
228  0.424403720     b
229  3.492662467     b
230  0.207069737     b
231 -0.285135922     b
232  2.774092657     b
233  0.932726345     b
234  0.307356282     b
235 -0.177748926     b
236  0.601300916     b
237  0.741936802     b
238  1.309871928     b
239  1.013624443     b
240 -0.159602350     b
241  3.326280879     b
242 -0.474760671     b
243  1.583865187     b
244 -0.437052144     b
245  0.963513093     b
246  0.184049852     b
247  0.832764525     b
248  2.750569459     b
249 -1.715479575     b
250  1.447252960     b
251  2.259225559     b
252  0.242249016     b
253  1.421668983     b
254  0.559499322     b
255  1.216297944     b
256  2.696129747     b
257  0.576349491     b
258  0.888296753     b
259  0.791319418     b
260  0.450938727     b
261  1.459301375     b
262  1.886163978     b
263  2.975258129     b
264  2.554448560     b
265  1.819750271     b
266  0.757427999     b
267  0.985648356     b
268  3.105730224     b
269  1.910646655     b
270  1.719198550     b
271 -0.881673232     b
272  0.002119816     b
273  0.540737724     b
274  0.497165335     b
275  1.202674282     b
276  1.319647962     b
277  1.879789253     b
278  1.268259517     b
279  1.438582688     b
280  2.094939074     b
281  1.541688812     b
282  2.155974933     b
283  1.816490913     b
284 -0.110102866     b
285  0.960645478     b
286  2.550269832     b
287 -1.063571135     b
288  0.970495302     b
289  0.027859404     b
290 -1.863286309     b
291  1.666374881     b
292  1.644898758     b
293  0.140284308     b
294  1.910703083     b
295 -0.852754797     b
296  2.181823943     b
297  1.565014368     b
298  2.784173925     b
299  0.934202197     b
300  1.133064525     b
301  1.367116930     b
302  0.700370109     b
303 -0.331991428     b
304 -0.345633289     b
305  1.440396110     b
306  1.110061197     b
307  0.012125323     b
308  0.176625732     b
309 -0.217760507     b
310  1.090895617     b
311  1.144298771     b
312  1.189838445     b
313 -0.093057407     b
314  1.915076670     b
315  0.909353697     b
316 -0.130361828     b
317  1.281536629     b
318  0.187307077     b
319  2.830840111     b
320  0.002288346     b
321  0.548077057     b
322  2.115718007     b
323  1.067338090     b
324  0.444829394     b
325  0.543631409     b
326 -0.534622834     b
327  2.031259357     b
328  0.338334850     b
329  1.463680388     b
330  0.316925944     b
331  0.831325847     b
332  0.770132816     b
333 -0.034638444     b
334  1.533430536     b
335  0.491723013     b
336  0.216658544     b
337  1.045729276     b
338  1.389361364     b
339 -0.047815798     b
340 -0.153720332     b
341 -0.804799819     b
342  0.794457229     b
343  2.497567092     b
344  3.050723957     b
345  1.308518343     b
346  0.195772008     b
347  1.639334310     b
348  1.619376342     b
349  0.419326503     b
350  1.490964235     b
351  1.494287205     b
352  2.106036519     b
353  1.412728384     b
354 -2.390531348     b
355 -0.140148712     b
356  0.790539791     b
357 -1.943748856     b
358  2.375832789     b
359  1.141894023     b
360  1.058671899     b
361  0.168241926     b
362  0.186220627     b
363 -0.044118294     b
364 -0.489937230     b
365  1.097287285     b
366  1.222252463     b
367  0.607027462     b
368  0.619046742     b
369  2.279839636     b
370  0.322815399     b
371  2.502026939     b
372  1.639402510     b
373  1.149622903     b
374  1.791346031     b
375  1.101884523     b
376  0.868691265     b
377  1.895573120     b
378 -0.195779447     b
379  1.746150754     b
380 -0.560719555     b
381 -0.633866094     b
382  0.199583049     b
383  0.935190543     b
384  0.214252999     b
385  2.122002169     b
386  0.795102987     b
387  2.111474311     b
388  0.286954271     b
389  0.543090022     b
390  1.654467565     b
391  0.578674338     b
392  1.257537838     b
393  0.835223697     b
394  1.105400238     b
395  1.146458883     b
396  1.635944264     b
397  1.089720570     b
398  1.106610628     b
399  1.483545187     b
400  0.467880468     b
> class(x.testData$group)
[1] "factor"
> class(test.res$Weak)
[1] "NULL"
> test.res
          Weak   obs1
1  0.872894107   Weak
2  0.016793661   Weak
3  0.944984654   Weak
4  0.515814119   Weak
5  0.682149848   Weak
6  0.271529366   Weak
7  0.287934389   Weak
8  0.142703458   Weak
9  0.363139228   Weak
10 0.013103239   Weak
11 0.145981760   Weak
12 0.863424772   Weak
13 0.475322178   Weak
14 0.042241890   Weak
15 0.994625866   Weak
16 0.922555385   Weak
17 0.213485836   Weak
18 0.529911627   Weak
19 0.036082133   Weak
20 0.520180631   Weak
21 0.158894173   Weak
22 0.016288588   Weak
23 0.660062822   Weak
24 0.667509444   Weak
25 0.023834457   Weak
26 0.930709532   Weak
27 0.995251880   Weak
28 0.072184161   Weak
29 0.114807825   Weak
30 0.920101252   Weak
31 0.016003684   Weak
32 0.995933067   Weak
33 0.391260955 Strong
34 0.977064673 Strong
35 0.955537389 Strong
36 0.987219825 Strong
37 0.732136409 Strong
38 0.998522851 Strong
39 0.267074847 Strong
40 0.540760765 Strong
41 0.885696784 Strong
42 0.617770875 Strong
43 0.861184884 Strong
44 0.088505326 Strong
45 0.611874505 Strong
46 0.813702816 Strong
47 0.926131847 Strong
48 0.086934959 Strong
49 0.032197681 Strong
50 0.999517772 Strong
51 0.898281249 Strong
52 0.317550262 Strong
53 0.656228402 Strong
54 0.020380351 Strong
55 0.881972527 Strong
56 0.997546389 Strong
57 0.012288626 Strong
58 0.692523046 Strong
59 0.978409363 Strong
60 0.270907662 Strong
61 0.942921011 Strong
62 0.289801326 Strong
63 0.988948146 Strong
64 0.958934881 Strong
65 0.989529389 Strong
66 0.975719857 Strong
67 0.921358557 Strong
68 0.005204042 Strong
69 0.017902261 Strong
70 0.936347069 Strong
71 0.996744228 Strong
72 0.914983906 Strong
> class(test.res$Weak)
[1] "NULL"
> as.numeric(test.res$Weak)
numeric(0)
> test.res$Weak
NULL
> test.res[,"Weak"]
Error in `[.data.frame`(test.res, , "Weak") : undefined columns selected
> test.res[,1]
          Weak
1  0.872894107
2  0.016793661
3  0.944984654
4  0.515814119
5  0.682149848
6  0.271529366
7  0.287934389
8  0.142703458
9  0.363139228
10 0.013103239
11 0.145981760
12 0.863424772
13 0.475322178
14 0.042241890
15 0.994625866
16 0.922555385
17 0.213485836
18 0.529911627
19 0.036082133
20 0.520180631
21 0.158894173
22 0.016288588
23 0.660062822
24 0.667509444
25 0.023834457
26 0.930709532
27 0.995251880
28 0.072184161
29 0.114807825
30 0.920101252
31 0.016003684
32 0.995933067
33 0.391260955
34 0.977064673
35 0.955537389
36 0.987219825
37 0.732136409
38 0.998522851
39 0.267074847
40 0.540760765
41 0.885696784
42 0.617770875
43 0.861184884
44 0.088505326
45 0.611874505
46 0.813702816
47 0.926131847
48 0.086934959
49 0.032197681
50 0.999517772
51 0.898281249
52 0.317550262
53 0.656228402
54 0.020380351
55 0.881972527
56 0.997546389
57 0.012288626
58 0.692523046
59 0.978409363
60 0.270907662
61 0.942921011
62 0.289801326
63 0.988948146
64 0.958934881
65 0.989529389
66 0.975719857
67 0.921358557
68 0.005204042
69 0.017902261
70 0.936347069
71 0.996744228
72 0.914983906
> class(test.res[,1])
[1] "data.frame"
> class(predict(gbmFit1, testDescr, type = "prob")[2])
[1] "data.frame"
> as.list(predict(gbmFit1, testDescr, type = "prob")[2])
$Weak
 [1] 0.872894107 0.016793661 0.944984654 0.515814119 0.682149848 0.271529366
 [7] 0.287934389 0.142703458 0.363139228 0.013103239 0.145981760 0.863424772
[13] 0.475322178 0.042241890 0.994625866 0.922555385 0.213485836 0.529911627
[19] 0.036082133 0.520180631 0.158894173 0.016288588 0.660062822 0.667509444
[25] 0.023834457 0.930709532 0.995251880 0.072184161 0.114807825 0.920101252
[31] 0.016003684 0.995933067 0.391260955 0.977064673 0.955537389 0.987219825
[37] 0.732136409 0.998522851 0.267074847 0.540760765 0.885696784 0.617770875
[43] 0.861184884 0.088505326 0.611874505 0.813702816 0.926131847 0.086934959
[49] 0.032197681 0.999517772 0.898281249 0.317550262 0.656228402 0.020380351
[55] 0.881972527 0.997546389 0.012288626 0.692523046 0.978409363 0.270907662
[61] 0.942921011 0.289801326 0.988948146 0.958934881 0.989529389 0.975719857
[67] 0.921358557 0.005204042 0.017902261 0.936347069 0.996744228 0.914983906

> test.res$p <- as.list(predict(gbmFit1, testDescr, type = "prob")[2])
> test.res
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        p
1  0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
2  0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
3  0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
4  0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
5  0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
6  0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
7  0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
8  0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
9  0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
10 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
11 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
12 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
13 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
14 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
15 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
16 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
17 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
18 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
19 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
20 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
21 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
22 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
23 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
24 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
25 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
26 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
27 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
28 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
29 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
30 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
31 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
32 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
33 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
34 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
35 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
36 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
37 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
38 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
39 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
40 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
41 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
42 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
43 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
44 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
45 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
46 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
47 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
48 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
49 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
50 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
51 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
52 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
53 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
54 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
55 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
56 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
57 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
58 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
59 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
60 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
61 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
62 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
63 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
64 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
65 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
66 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
67 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
68 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
69 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
70 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
71 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
72 0.872894107, 0.016793661, 0.944984654, 0.515814119, 0.682149848, 0.271529366, 0.287934389, 0.142703458, 0.363139228, 0.013103239, 0.145981760, 0.863424772, 0.475322178, 0.042241890, 0.994625866, 0.922555385, 0.213485836, 0.529911627, 0.036082133, 0.520180631, 0.158894173, 0.016288588, 0.660062822, 0.667509444, 0.023834457, 0.930709532, 0.995251880, 0.072184161, 0.114807825, 0.920101252, 0.016003684, 0.995933067, 0.391260955, 0.977064673, 0.955537389, 0.987219825, 0.732136409, 0.998522851, 0.267074847, 0.540760765, 0.885696784, 0.617770875, 0.861184884, 0.088505326, 0.611874505, 0.813702816, 0.926131847, 0.086934959, 0.032197681, 0.999517772, 0.898281249, 0.317550262, 0.656228402, 0.020380351, 0.881972527, 0.997546389, 0.012288626, 0.692523046, 0.978409363, 0.270907662, 0.942921011, 0.289801326, 0.988948146, 0.958934881, 0.989529389, 0.975719857, 0.921358557, 0.005204042, 0.017902261, 0.936347069, 0.996744228, 0.914983906
     obs1
1    Weak
2    Weak
3    Weak
4    Weak
5    Weak
6    Weak
7    Weak
8    Weak
9    Weak
10   Weak
11   Weak
12   Weak
13   Weak
14   Weak
15   Weak
16   Weak
17   Weak
18   Weak
19   Weak
20   Weak
21   Weak
22   Weak
23   Weak
24   Weak
25   Weak
26   Weak
27   Weak
28   Weak
29   Weak
30   Weak
31   Weak
32   Weak
33 Strong
34 Strong
35 Strong
36 Strong
37 Strong
38 Strong
39 Strong
40 Strong
41 Strong
42 Strong
43 Strong
44 Strong
45 Strong
46 Strong
47 Strong
48 Strong
49 Strong
50 Strong
51 Strong
52 Strong
53 Strong
54 Strong
55 Strong
56 Strong
57 Strong
58 Strong
59 Strong
60 Strong
61 Strong
62 Strong
63 Strong
64 Strong
65 Strong
66 Strong
67 Strong
68 Strong
69 Strong
70 Strong
71 Strong
72 Strong
> test.res$p <- NULL
> predict(gbmFit1, testDescr, type = "prob")[2]
          Weak
1  0.872894107
2  0.016793661
3  0.944984654
4  0.515814119
5  0.682149848
6  0.271529366
7  0.287934389
8  0.142703458
9  0.363139228
10 0.013103239
11 0.145981760
12 0.863424772
13 0.475322178
14 0.042241890
15 0.994625866
16 0.922555385
17 0.213485836
18 0.529911627
19 0.036082133
20 0.520180631
21 0.158894173
22 0.016288588
23 0.660062822
24 0.667509444
25 0.023834457
26 0.930709532
27 0.995251880
28 0.072184161
29 0.114807825
30 0.920101252
31 0.016003684
32 0.995933067
33 0.391260955
34 0.977064673
35 0.955537389
36 0.987219825
37 0.732136409
38 0.998522851
39 0.267074847
40 0.540760765
41 0.885696784
42 0.617770875
43 0.861184884
44 0.088505326
45 0.611874505
46 0.813702816
47 0.926131847
48 0.086934959
49 0.032197681
50 0.999517772
51 0.898281249
52 0.317550262
53 0.656228402
54 0.020380351
55 0.881972527
56 0.997546389
57 0.012288626
58 0.692523046
59 0.978409363
60 0.270907662
61 0.942921011
62 0.289801326
63 0.988948146
64 0.958934881
65 0.989529389
66 0.975719857
67 0.921358557
68 0.005204042
69 0.017902261
70 0.936347069
71 0.996744228
72 0.914983906
> x.p <- predict(gbmFit1, testDescr, type = "prob")[2]
> x.p
          Weak
1  0.872894107
2  0.016793661
3  0.944984654
4  0.515814119
5  0.682149848
6  0.271529366
7  0.287934389
8  0.142703458
9  0.363139228
10 0.013103239
11 0.145981760
12 0.863424772
13 0.475322178
14 0.042241890
15 0.994625866
16 0.922555385
17 0.213485836
18 0.529911627
19 0.036082133
20 0.520180631
21 0.158894173
22 0.016288588
23 0.660062822
24 0.667509444
25 0.023834457
26 0.930709532
27 0.995251880
28 0.072184161
29 0.114807825
30 0.920101252
31 0.016003684
32 0.995933067
33 0.391260955
34 0.977064673
35 0.955537389
36 0.987219825
37 0.732136409
38 0.998522851
39 0.267074847
40 0.540760765
41 0.885696784
42 0.617770875
43 0.861184884
44 0.088505326
45 0.611874505
46 0.813702816
47 0.926131847
48 0.086934959
49 0.032197681
50 0.999517772
51 0.898281249
52 0.317550262
53 0.656228402
54 0.020380351
55 0.881972527
56 0.997546389
57 0.012288626
58 0.692523046
59 0.978409363
60 0.270907662
61 0.942921011
62 0.289801326
63 0.988948146
64 0.958934881
65 0.989529389
66 0.975719857
67 0.921358557
68 0.005204042
69 0.017902261
70 0.936347069
71 0.996744228
72 0.914983906
> class(x.p$Weak)
[1] "numeric"
> test.res$p <- x.p$Weak
> class(test.res$p)
[1] "numeric"
> densityplot(~test.res$p, groups = test.res$obs1, auto.key = TRUE)
> roc(test.res$p, test.res$group)
Error in roc.default(test.res$p, test.res$group) : 
  No valid data provided.
> roc(test.res$p, test.res$obs1)
Error in roc.default(test.res$p, test.res$obs1) : 
  Predictor must be numeric or ordered.
> test.res$p
 [1] 0.872894107 0.016793661 0.944984654 0.515814119 0.682149848 0.271529366
 [7] 0.287934389 0.142703458 0.363139228 0.013103239 0.145981760 0.863424772
[13] 0.475322178 0.042241890 0.994625866 0.922555385 0.213485836 0.529911627
[19] 0.036082133 0.520180631 0.158894173 0.016288588 0.660062822 0.667509444
[25] 0.023834457 0.930709532 0.995251880 0.072184161 0.114807825 0.920101252
[31] 0.016003684 0.995933067 0.391260955 0.977064673 0.955537389 0.987219825
[37] 0.732136409 0.998522851 0.267074847 0.540760765 0.885696784 0.617770875
[43] 0.861184884 0.088505326 0.611874505 0.813702816 0.926131847 0.086934959
[49] 0.032197681 0.999517772 0.898281249 0.317550262 0.656228402 0.020380351
[55] 0.881972527 0.997546389 0.012288626 0.692523046 0.978409363 0.270907662
[61] 0.942921011 0.289801326 0.988948146 0.958934881 0.989529389 0.975719857
[67] 0.921358557 0.005204042 0.017902261 0.936347069 0.996744228 0.914983906
> head(test.res)
  obs1          p
1 Weak 0.87289411
2 Weak 0.01679366
3 Weak 0.94498465
4 Weak 0.51581412
5 Weak 0.68214985
6 Weak 0.27152937
> roc(test.res$p, test.res$obs1)
Error in roc.default(test.res$p, test.res$obs1) : 
  Predictor must be numeric or ordered.
> class(test.res$p)
[1] "numeric"
> ?roc
> roc(obs ~ p, test.res)
Error in eval(expr, envir, enclos) : object 'obs' not found
> roc(obs1 ~ p, test.res)

Call:
roc.formula(formula = obs1 ~ p, data = test.res)

Data: p in 40 controls (obs1 Strong) > 32 cases (obs1 Weak).
Area under the curve: 0.6578
> test.roc <- roc(obs1 ~ p, test.res)
> plot(test.roc)

Call:
roc.formula(formula = obs1 ~ p, data = test.res)

Data: p in 40 controls (obs1 Strong) > 32 cases (obs1 Weak).
Area under the curve: 0.6578
> x.p <- predict(gbmFit1, testDescr, type = "prob")[2]
> data.frame(Weak=x.p$Weak, Obs=testClass)
          Weak    Obs
1  0.872894107   Weak
2  0.016793661   Weak
3  0.944984654   Weak
4  0.515814119   Weak
5  0.682149848   Weak
6  0.271529366   Weak
7  0.287934389   Weak
8  0.142703458   Weak
9  0.363139228   Weak
10 0.013103239   Weak
11 0.145981760   Weak
12 0.863424772   Weak
13 0.475322178   Weak
14 0.042241890   Weak
15 0.994625866   Weak
16 0.922555385   Weak
17 0.213485836   Weak
18 0.529911627   Weak
19 0.036082133   Weak
20 0.520180631   Weak
21 0.158894173   Weak
22 0.016288588   Weak
23 0.660062822   Weak
24 0.667509444   Weak
25 0.023834457   Weak
26 0.930709532   Weak
27 0.995251880   Weak
28 0.072184161   Weak
29 0.114807825   Weak
30 0.920101252   Weak
31 0.016003684   Weak
32 0.995933067   Weak
33 0.391260955 Strong
34 0.977064673 Strong
35 0.955537389 Strong
36 0.987219825 Strong
37 0.732136409 Strong
38 0.998522851 Strong
39 0.267074847 Strong
40 0.540760765 Strong
41 0.885696784 Strong
42 0.617770875 Strong
43 0.861184884 Strong
44 0.088505326 Strong
45 0.611874505 Strong
46 0.813702816 Strong
47 0.926131847 Strong
48 0.086934959 Strong
49 0.032197681 Strong
50 0.999517772 Strong
51 0.898281249 Strong
52 0.317550262 Strong
53 0.656228402 Strong
54 0.020380351 Strong
55 0.881972527 Strong
56 0.997546389 Strong
57 0.012288626 Strong
58 0.692523046 Strong
59 0.978409363 Strong
60 0.270907662 Strong
61 0.942921011 Strong
62 0.289801326 Strong
63 0.988948146 Strong
64 0.958934881 Strong
65 0.989529389 Strong
66 0.975719857 Strong
67 0.921358557 Strong
68 0.005204042 Strong
69 0.017902261 Strong
70 0.936347069 Strong
71 0.996744228 Strong
72 0.914983906 Strong
> predict(gbmFit1, testDescr, type = "prob")[2]["Weak"]
          Weak
1  0.872894107
2  0.016793661
3  0.944984654
4  0.515814119
5  0.682149848
6  0.271529366
7  0.287934389
8  0.142703458
9  0.363139228
10 0.013103239
11 0.145981760
12 0.863424772
13 0.475322178
14 0.042241890
15 0.994625866
16 0.922555385
17 0.213485836
18 0.529911627
19 0.036082133
20 0.520180631
21 0.158894173
22 0.016288588
23 0.660062822
24 0.667509444
25 0.023834457
26 0.930709532
27 0.995251880
28 0.072184161
29 0.114807825
30 0.920101252
31 0.016003684
32 0.995933067
33 0.391260955
34 0.977064673
35 0.955537389
36 0.987219825
37 0.732136409
38 0.998522851
39 0.267074847
40 0.540760765
41 0.885696784
42 0.617770875
43 0.861184884
44 0.088505326
45 0.611874505
46 0.813702816
47 0.926131847
48 0.086934959
49 0.032197681
50 0.999517772
51 0.898281249
52 0.317550262
53 0.656228402
54 0.020380351
55 0.881972527
56 0.997546389
57 0.012288626
58 0.692523046
59 0.978409363
60 0.270907662
61 0.942921011
62 0.289801326
63 0.988948146
64 0.958934881
65 0.989529389
66 0.975719857
67 0.921358557
68 0.005204042
69 0.017902261
70 0.936347069
71 0.996744228
72 0.914983906
> class(predict(gbmFit1, testDescr, type = "prob")[2]["Weak"])
[1] "data.frame"
> x.p <- predict(gbmFit1, testDescr, type = "prob")[2]
> test.df <- data.frame(Weak=x.p$Weak, Obs=testClass)
> x.p <- predict(gbmFit1, testDescr, type = "prob")[2]
> test.df <- data.frame(Weak=x.p$Weak, Obs=testClass)
> densityplot(~test.df$Weak, groups = test.df$Obs, auto.key = TRUE)
> roc(Obs ~ Weak, test.df)

Call:
roc.formula(formula = Obs ~ Weak, data = test.df)

Data: Weak in 40 controls (Obs Strong) > 32 cases (Obs Weak).
Area under the curve: 0.6578
> test.roc <- roc(Obs ~ Weak, test.df)
> 

Call:
roc.formula(formula = Obs ~ Weak, data = test.df)

Data: Weak in 40 controls (Obs Strong) > 32 cases (Obs Weak).
Area under the curve: 0.6578
> jpeg(width=1024, height=640)
>densityplot(~test.df$Weak, groups = test.df$Obs, auto.key = TRUE)
> plot.roc(test.roc)

Call:
roc.formula(formula = Obs ~ Weak, data = test.df)

Data: Weak in 40 controls (Obs Strong) > 32 cases (Obs Weak).
Area under the curve: 0.6578
>  dev.off
function (which = dev.cur()) 
{
    if (which == 1) 
        stop("cannot shut down device 1 (the null device)")
    .External(C_devoff, as.integer(which))
    dev.cur()
}
<bytecode: 0xbc187f8>
<environment: namespace:grDevices>
>  dev.off()
X11cairo 
       2 
> ### weaves
> 
> ## Processing for flights data.
> 
> ## Following the caret vignette.
> 
> ###################################################
> ### code chunk number 1: loadLibs
> ###################################################
> library(MASS)
> library(caret)
> library(mlbench)
> library(pROC)
> library(pls)
> 
> library(doMC)
> registerDoMC(cores = 4)
> 
> options(useFancyQuotes = FALSE) 
> 
> # Accounting info.
> getInfo <- function(what = "Suggests")
+ {
+   text <- packageDescription("caret")[what][[1]]
+   text <- gsub("\n", ", ", text, fixed = TRUE)
+   text <- gsub(">=", "$\\\\ge$", text, fixed = TRUE)
+   eachPkg <- strsplit(text, ", ", fixed = TRUE)[[1]]
+   eachPkg <- gsub(",", "", eachPkg, fixed = TRUE)
+   # out <- paste("\\\\pkg{", eachPkg[order(tolower(eachPkg))], "}", sep = "")
+   # paste(out, collapse = ", ")
+   length(eachPkg)
+ }
> 
> ### project-specific: begin
> ## Set-seed, load original CSV file, order it
> ## and do some simple-cleaning
> ## Various datasets 
> 
> seed.mine = 107
> set.seed(seed.mine)                     # helpful for testing
> 
> flight <- read.csv("../bak/flight.csv")
> flight <- flight[order(flight$D00),]
> 
> # Backup
> flight.raw <- flight
> 
> # To check adjustment, there is test code in flight-nb.R
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"
> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"
> 
> # And some deletions
> 
> t.cols <- colnames(flight)
> 
> t.drops <- t.cols[grep("^RANK*", t.cols)]
> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])
> t.drops <- c(t.drops, "D80THPCTL")
> 
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR
> flight$xHNGR <- flight$xDURN < 0
> 
> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+ }
> 
> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))
> 
> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE
> t.cols <- colnames(flight)
> 
> t.drops <- c("SARRHR", "xDURN")
> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]
> 
> ## Backup
> 
> flight00 <- flight
> 
> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]
> 
> paste("samples in use: ", dim(flight)[1])
[1] "samples in use:  320"
> 
> ## Data insights
> 
> ## *Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> ### Numeric variables
> 
> ### Try and impute the AVG, it might have more information than the
> ### bucket.
> 
> flight$xAVAILBUCKET <- as.numeric(gsub("^[A<]+", "", flight$AVAILBUCKET))
> 
> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1
> 
> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]
> 
> preProcValues <- preProcess(flight.na, method = c("knnImpute"))
> flight.na1 <- predict(preProcValues, flight.na)
> 
> ## I'll add the new imputed value and drop the others
> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL
> flight$AVGSKDAVAIL <- NULL
> flight$xAVAILBUCKET <- NULL
> flight$AVAILBUCKET <- NULL
> 
> flight$xHNGR <- NULL
> 
> ## Check some more numeric correlations, I haven't scaled everything yet.
> ## I'd cut correlations above 0.65 to 0.75 because of overfitting.
> 
> x1 <- as.data.frame(as.matrix(sapply(flight, class)))
> 
> flight.num <- flight[,names(x1[which(x1$V1 %in% c("numeric", "integer")),])]
> 
> flight.nzv <- nearZeroVar(flight.num, saveMetrics = TRUE)
> flight.nzv
             freqRatio percentUnique zeroVar   nzv
SDEPHR        1.038462        5.9375   FALSE FALSE
SKDEPS        1.000000       19.0625   FALSE FALSE
D00           1.166667       75.3125   FALSE FALSE
AVGSQ         6.333333       82.8125   FALSE FALSE
AVGLOFATC     1.000000       78.4375   FALSE FALSE
xDURN2        1.428571        2.5000   FALSE FALSE
xAVGSKDAVAIL 18.500000       87.8125   FALSE FALSE
> 
> # annoying NA should be gone.
> flight.cor <- cor(flight.num, use = "pairwise.complete.obs")
> 
> descrCorr <- findCorrelation(flight.cor, cutoff = .65, verbose=TRUE)
Considering row	 4 column	 1 value	 0.956 
  Flagging column	 4 
Considering row	 1 column	 3 value	 0.43 
Considering row	 1 column	 7 value	 0.053 
Considering row	 1 column	 6 value	 0.204 
Considering row	 1 column	 5 value	 0.131 
Considering row	 1 column	 2 value	 0.054 
Considering row	 3 column	 7 value	 0.401 
Considering row	 3 column	 6 value	 0.071 
Considering row	 3 column	 5 value	 0.114 
Considering row	 3 column	 2 value	 0.006 
Considering row	 7 column	 6 value	 0.019 
Considering row	 7 column	 5 value	 0.07 
Considering row	 7 column	 2 value	 0.113 
Considering row	 6 column	 5 value	 0.137 
Considering row	 6 column	 2 value	 0.005 
Considering row	 5 column	 2 value	 0.041 
> 
> colnames(flight.num)[descrCorr]
[1] "AVGSQ"
> 
> ## And I'll leave the centered and scale values in for now.
> ## and delete the troublesome ones
> 
> ## Re-classing
> ## Check warnings to see it adjustment has taken place.
> ## We want the proportion in the training class to be about 0.55 0.45
> ## Strong to Weak
> ## I've achieved this heuristically
> src.adjust <- TRUE
> source(file = "flight1.R")
Warning message:
In eval(expr, envir, enclos) : adjusting
> flight1 <- flight
> 
> ## This should be deleted, leave it in and the results
> ## are ideal because it defines LEGTYPE.
> flight$D00 <- NULL
> 
> ## Keep the results but don't change the order.
> outcomes.flight <- flight$LEGTYPE
> 
> flight$LEGTYPE <- NULL
> 
> ## If you know your factors are definitely factors, you don't need this
> ##  asNumeric <- function(x) as.numeric(as.character(x))
> 
> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))
> 
> flight.num0 <- factors.numeric(flight)
> 
> flight.scl0 <- scale(flight.num0)
> 
> ## Now split the samples
> ## we need at least 60 to test with, p at 0.77 gives about 75.
> ## Difficulty here is the bias in the table
> ## Because we only have [3.1, 4.4] the proportion of Weak is higher.
> ## see prop.table(results)
> 
> set.seed(seed.mine)
> inTrain <- createDataPartition(outcomes.flight, p = 0.77, list = FALSE)
> 
> trainDescr <- flight.scl0[inTrain,]
> testDescr <- flight.scl0[-inTrain,]
> 
> trainClass <- outcomes.flight[inTrain]
> testClass <- outcomes.flight[-inTrain]
> 
> prop.table(table(trainClass))
trainClass
   Strong      Weak 
0.5524194 0.4475806 
> dim(trainDescr)
[1] 248  19
> 
> prop.table(table(testClass))
testClass
   Strong      Weak 
0.5555556 0.4444444 
> dim(testDescr)
[1] 72 19
> 
> ## Check Near-zero variance
> 
> nzv <- nearZeroVar(trainDescr, saveMetrics= TRUE)
> stopifnot( all(nzv$nzv == FALSE) )
> 
> # It's imputed and behaves well, no need for this.
> # descrCorr <- cor(scale(trainDescr), use = "pairwise.complete.obs")
> 
> descrCorr <- cor(scale(trainDescr))
> 
> ## This cut-off should be under src.adjust control.
> ## I'm under Git, so I can tinker with it.
> highCorr <- findCorrelation(descrCorr, cutoff = .99, verbose = TRUE)
Considering row	 17 column	 16 value	 0.85 
Considering row	 17 column	 10 value	 0.671 
Considering row	 17 column	 1 value	 0.279 
Considering row	 17 column	 11 value	 0.277 
Considering row	 17 column	 6 value	 0.22 
Considering row	 17 column	 12 value	 0.226 
Considering row	 17 column	 2 value	 0.298 
Considering row	 17 column	 9 value	 0.586 
Considering row	 17 column	 14 value	 0.226 
Considering row	 17 column	 13 value	 0.23 
Considering row	 17 column	 8 value	 0.541 
Considering row	 17 column	 3 value	 0.346 
Considering row	 17 column	 18 value	 0.261 
Considering row	 17 column	 19 value	 0.138 
Considering row	 17 column	 15 value	 0.057 
Considering row	 17 column	 4 value	 0.067 
Considering row	 17 column	 7 value	 0.034 
Considering row	 17 column	 5 value	 0.018 
Considering row	 16 column	 10 value	 0.568 
Considering row	 16 column	 1 value	 0.236 
Considering row	 16 column	 11 value	 0.231 
Considering row	 16 column	 6 value	 0.189 
Considering row	 16 column	 12 value	 0.19 
Considering row	 16 column	 2 value	 0.333 
Considering row	 16 column	 9 value	 0.671 
Considering row	 16 column	 14 value	 0.242 
Considering row	 16 column	 13 value	 0.208 
Considering row	 16 column	 8 value	 0.6 
Considering row	 16 column	 3 value	 0.318 
Considering row	 16 column	 18 value	 0.279 
Considering row	 16 column	 19 value	 0.213 
Considering row	 16 column	 15 value	 0.083 
Considering row	 16 column	 4 value	 0.02 
Considering row	 16 column	 7 value	 0.009 
Considering row	 16 column	 5 value	 0.005 
Considering row	 10 column	 1 value	 0.281 
Considering row	 10 column	 11 value	 0.275 
Considering row	 10 column	 6 value	 0.298 
Considering row	 10 column	 12 value	 0.255 
Considering row	 10 column	 2 value	 0.286 
Considering row	 10 column	 9 value	 0.404 
Considering row	 10 column	 14 value	 0.224 
Considering row	 10 column	 13 value	 0.199 
Considering row	 10 column	 8 value	 0.366 
Considering row	 10 column	 3 value	 0.462 
Considering row	 10 column	 18 value	 0.226 
Considering row	 10 column	 19 value	 0.103 
Considering row	 10 column	 15 value	 0.274 
Considering row	 10 column	 4 value	 0.018 
Considering row	 10 column	 7 value	 0.127 
Considering row	 10 column	 5 value	 0.096 
Considering row	 1 column	 11 value	 0.988 
Considering row	 1 column	 6 value	 0.955 
Considering row	 1 column	 12 value	 0.905 
Considering row	 1 column	 2 value	 0.174 
Considering row	 1 column	 9 value	 0.149 
Considering row	 1 column	 14 value	 0.171 
Considering row	 1 column	 13 value	 0.159 
Considering row	 1 column	 8 value	 0.143 
Considering row	 1 column	 3 value	 0.079 
Considering row	 1 column	 18 value	 0.206 
Considering row	 1 column	 19 value	 0.064 
Considering row	 1 column	 15 value	 0.142 
Considering row	 1 column	 4 value	 0.043 
Considering row	 1 column	 7 value	 0.064 
Considering row	 1 column	 5 value	 0.007 
Considering row	 11 column	 6 value	 0.945 
Considering row	 11 column	 12 value	 0.889 
Considering row	 11 column	 2 value	 0.165 
Considering row	 11 column	 9 value	 0.139 
Considering row	 11 column	 14 value	 0.171 
Considering row	 11 column	 13 value	 0.156 
Considering row	 11 column	 8 value	 0.145 
Considering row	 11 column	 3 value	 0.073 
Considering row	 11 column	 18 value	 0.183 
Considering row	 11 column	 19 value	 0.053 
Considering row	 11 column	 15 value	 0.142 
Considering row	 11 column	 4 value	 0.037 
Considering row	 11 column	 7 value	 0.053 
Considering row	 11 column	 5 value	 0.03 
Considering row	 6 column	 12 value	 0.883 
Considering row	 6 column	 2 value	 0.151 
Considering row	 6 column	 9 value	 0.04 
Considering row	 6 column	 14 value	 0.188 
Considering row	 6 column	 13 value	 0.161 
Considering row	 6 column	 8 value	 0.063 
Considering row	 6 column	 3 value	 0.083 
Considering row	 6 column	 18 value	 0.197 
Considering row	 6 column	 19 value	 0.114 
Considering row	 6 column	 15 value	 0.159 
Considering row	 6 column	 4 value	 0.01 
Considering row	 6 column	 7 value	 0.027 
Considering row	 6 column	 5 value	 0.039 
Considering row	 12 column	 2 value	 0.121 
Considering row	 12 column	 9 value	 0.128 
Considering row	 12 column	 14 value	 0.092 
Considering row	 12 column	 13 value	 0.105 
Considering row	 12 column	 8 value	 0.071 
Considering row	 12 column	 3 value	 0.093 
Considering row	 12 column	 18 value	 0.126 
Considering row	 12 column	 19 value	 0.171 
Considering row	 12 column	 15 value	 0.13 
Considering row	 12 column	 4 value	 0.01 
Considering row	 12 column	 7 value	 0.043 
Considering row	 12 column	 5 value	 0.017 
Considering row	 2 column	 9 value	 0.423 
Considering row	 2 column	 14 value	 0.574 
Considering row	 2 column	 13 value	 0.557 
Considering row	 2 column	 8 value	 0.165 
Considering row	 2 column	 3 value	 0.263 
Considering row	 2 column	 18 value	 0.128 
Considering row	 2 column	 19 value	 0.089 
Considering row	 2 column	 15 value	 0.069 
Considering row	 2 column	 4 value	 0.27 
Considering row	 2 column	 7 value	 0.045 
Considering row	 2 column	 5 value	 0.024 
Considering row	 9 column	 14 value	 0.147 
Considering row	 9 column	 13 value	 0.125 
Considering row	 9 column	 8 value	 0.449 
Considering row	 9 column	 3 value	 0.322 
Considering row	 9 column	 18 value	 0.018 
Considering row	 9 column	 19 value	 0.141 
Considering row	 9 column	 15 value	 0.073 
Considering row	 9 column	 4 value	 0.006 
Considering row	 9 column	 7 value	 0.136 
Considering row	 9 column	 5 value	 0.123 
Considering row	 14 column	 13 value	 0.659 
Considering row	 14 column	 8 value	 0.097 
Considering row	 14 column	 3 value	 0.106 
Considering row	 14 column	 18 value	 0.361 
Considering row	 14 column	 19 value	 0.092 
Considering row	 14 column	 15 value	 0.084 
Considering row	 14 column	 4 value	 0.263 
Considering row	 14 column	 7 value	 0.139 
Considering row	 14 column	 5 value	 0.031 
Considering row	 13 column	 8 value	 0.097 
Considering row	 13 column	 3 value	 0.167 
Considering row	 13 column	 18 value	 0.18 
Considering row	 13 column	 19 value	 0.131 
Considering row	 13 column	 15 value	 0.137 
Considering row	 13 column	 4 value	 0.24 
Considering row	 13 column	 7 value	 0.085 
Considering row	 13 column	 5 value	 0.027 
Considering row	 8 column	 3 value	 0.224 
Considering row	 8 column	 18 value	 0.173 
Considering row	 8 column	 19 value	 0.235 
Considering row	 8 column	 15 value	 0.07 
Considering row	 8 column	 4 value	 0.02 
Considering row	 8 column	 7 value	 0.085 
Considering row	 8 column	 5 value	 0.004 
Considering row	 3 column	 18 value	 0.028 
Considering row	 3 column	 19 value	 0.027 
Considering row	 3 column	 15 value	 0.017 
Considering row	 3 column	 4 value	 0.094 
Considering row	 3 column	 7 value	 0.095 
Considering row	 3 column	 5 value	 0.097 
Considering row	 18 column	 19 value	 0.019 
Considering row	 18 column	 15 value	 0.12 
Considering row	 18 column	 4 value	 0.086 
Considering row	 18 column	 7 value	 0.132 
Considering row	 18 column	 5 value	 0.002 
Considering row	 19 column	 15 value	 0.019 
Considering row	 19 column	 4 value	 0.032 
Considering row	 19 column	 7 value	 0.056 
Considering row	 19 column	 5 value	 0.075 
Considering row	 15 column	 4 value	 0.043 
Considering row	 15 column	 7 value	 0.061 
Considering row	 15 column	 5 value	 0.08 
Considering row	 4 column	 7 value	 0.005 
Considering row	 4 column	 5 value	 0.213 
Considering row	 7 column	 5 value	 0.008 
> 
> colnames(trainDescr)[highCorr]
character(0)
> 
> descr.ncol0 <- ncol(trainDescr)
> 
> # I've switched off the correlation remover and the results are better.
> if (sum(highCorr) > 0) {
+     warning("overfitting: correlations: err.trainDescr: ", paste(colnames(trainDescr)[highCorr], collapse = ", ") )
+     err.trainDescr <- trainDescr
+     trainDescr <- trainDescr[,-highCorr]
+ }
> 
> descr.ncol1 <- ncol(trainDescr)
> 
> paste("Dropped: ", as.character(descr.ncol0 - descr.ncol1))
[1] "Dropped:  0"
> 
> descrCorr <- cor(trainDescr)
> summary(descrCorr[upper.tri(descrCorr)])
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
-0.85020 -0.14210 -0.01766  0.02755  0.12610  0.98780 
> 
> ## Dominant correlations
> ## At 0.9, there are some big ones that might need re-thinking.
> 
> table.descrCorr <- as.data.frame(as.table(descrCorr))
> table.descrCorr <- table.descrCorr[which(table.descrCorr$Var1 != table.descrCorr$Var2),]
> table.descrCorr[order(abs(table.descrCorr$Freq), decreasing = TRUE),]
              Var1           Var2         Freq
11       DEPBUCKET         SDEPHR  0.987828666
191         SDEPHR      DEPBUCKET  0.987828666
6            AVGSQ         SDEPHR  0.954804414
96          SDEPHR          AVGSQ  0.954804414
106      DEPBUCKET          AVGSQ  0.944870657
196          AVGSQ      DEPBUCKET  0.944870657
12       ARRBUCKET         SDEPHR  0.904546667
210         SDEPHR      ARRBUCKET  0.904546667
202      ARRBUCKET      DEPBUCKET  0.889095737
220      DEPBUCKET      ARRBUCKET  0.889095737
107      ARRBUCKET          AVGSQ  0.882590635
215          AVGSQ      ARRBUCKET  0.882590635
302       ARRSPOKE       DEPSPOKE -0.850165355
320       DEPSPOKE       ARRSPOKE -0.850165355
168       DEPSPOKE   DEPSTAATCIMP  0.671264566
294   DEPSTAATCIMP       DEPSPOKE  0.671264566
188       ARRSPOKE DOWNLINEATCIMP  0.671009330
314 DOWNLINEATCIMP       ARRSPOKE  0.671009330
242     TRNRANKGRP     DEPRANKGRP  0.658724662
260     DEPRANKGRP     TRNRANKGRP  0.658724662
149       DEPSPOKE   UPLINEATCIMP -0.600008252
293   UPLINEATCIMP       DEPSPOKE -0.600008252
169       ARRSPOKE   DEPSTAATCIMP -0.586442959
313   DEPSTAATCIMP       ARRSPOKE -0.586442959
33      TRNRANKGRP      SKDDEPSTA  0.574035134
249      SKDDEPSTA     TRNRANKGRP  0.574035134
187       DEPSPOKE DOWNLINEATCIMP -0.567682494
295 DOWNLINEATCIMP       DEPSPOKE -0.567682494
32      DEPRANKGRP      SKDDEPSTA  0.557399203
230      SKDDEPSTA     DEPRANKGRP  0.557399203
150       ARRSPOKE   UPLINEATCIMP  0.540734833
312   UPLINEATCIMP       ARRSPOKE  0.540734833
48  DOWNLINEATCIMP      SKDARRSTA  0.462378131
174      SKDARRSTA DOWNLINEATCIMP  0.462378131
142   DEPSTAATCIMP   UPLINEATCIMP -0.449249986
160   UPLINEATCIMP   DEPSTAATCIMP -0.449249986
28    DEPSTAATCIMP      SKDDEPSTA  0.423425796
154      SKDDEPSTA   DEPSTAATCIMP  0.423425796
162 DOWNLINEATCIMP   DEPSTAATCIMP -0.403695561
180   DEPSTAATCIMP DOWNLINEATCIMP -0.403695561
143 DOWNLINEATCIMP   UPLINEATCIMP  0.365833687
179   UPLINEATCIMP DOWNLINEATCIMP  0.365833687
265         xDURN2     TRNRANKGRP  0.361347207
337     TRNRANKGRP         xDURN2  0.361347207
55        ARRSPOKE      SKDARRSTA  0.345987375
307      SKDARRSTA       ARRSPOKE  0.345987375
35        DEPSPOKE      SKDDEPSTA  0.332823310
287      SKDDEPSTA       DEPSPOKE  0.332823310
47    DEPSTAATCIMP      SKDARRSTA -0.322204878
155      SKDARRSTA   DEPSTAATCIMP -0.322204878
54        DEPSPOKE      SKDARRSTA -0.318093195
288      SKDARRSTA       DEPSPOKE -0.318093195
105 DOWNLINEATCIMP          AVGSQ  0.298096458
177          AVGSQ DOWNLINEATCIMP  0.298096458
36        ARRSPOKE      SKDDEPSTA -0.298036487
306      SKDDEPSTA       ARRSPOKE -0.298036487
29  DOWNLINEATCIMP      SKDDEPSTA -0.285911992
173      SKDDEPSTA DOWNLINEATCIMP -0.285911992
10  DOWNLINEATCIMP         SDEPHR  0.280539472
172         SDEPHR DOWNLINEATCIMP  0.280539472
303         xDURN2       DEPSPOKE  0.279030910
339       DEPSPOKE         xDURN2  0.279030910
17        ARRSPOKE         SDEPHR  0.278505248
305         SDEPHR       ARRSPOKE  0.278505248
207       ARRSPOKE      DEPBUCKET  0.276615722
315      DEPBUCKET       ARRSPOKE  0.276615722
182      DEPBUCKET DOWNLINEATCIMP  0.275167866
200 DOWNLINEATCIMP      DEPBUCKET  0.275167866
186     ARRRANKGRP DOWNLINEATCIMP -0.274110143
276 DOWNLINEATCIMP     ARRRANKGRP -0.274110143
23          SKDEQP      SKDDEPSTA  0.270065872
59       SKDDEPSTA         SKDEQP  0.270065872
22       SKDARRSTA      SKDDEPSTA -0.263453106
40       SKDDEPSTA      SKDARRSTA -0.263453106
71      TRNRANKGRP         SKDEQP  0.262837233
251         SKDEQP     TRNRANKGRP  0.262837233
322         xDURN2       ARRSPOKE -0.261107447
340       ARRSPOKE         xDURN2 -0.261107447
183      ARRBUCKET DOWNLINEATCIMP  0.255480148
219 DOWNLINEATCIMP      ARRBUCKET  0.255480148
263       DEPSPOKE     TRNRANKGRP  0.242138220
299     TRNRANKGRP       DEPSPOKE  0.242138220
70      DEPRANKGRP         SKDEQP  0.239915140
232         SKDEQP     DEPRANKGRP  0.239915140
16        DEPSPOKE         SDEPHR -0.236049001
286         SDEPHR       DEPSPOKE -0.236049001
152   xAVGSKDAVAIL   UPLINEATCIMP  0.234867014
350   UPLINEATCIMP   xAVGSKDAVAIL  0.234867014
206       DEPSPOKE      DEPBUCKET -0.231298301
296      DEPBUCKET       DEPSPOKE -0.231298301
245       ARRSPOKE     DEPRANKGRP -0.229640758
317     DEPRANKGRP       ARRSPOKE -0.229640758
189         xDURN2 DOWNLINEATCIMP -0.226093423
333 DOWNLINEATCIMP         xDURN2 -0.226093423
226       ARRSPOKE      ARRBUCKET  0.225890655
316      ARRBUCKET       ARRSPOKE  0.225890655
264       ARRSPOKE     TRNRANKGRP -0.225591539
318     TRNRANKGRP       ARRSPOKE -0.225591539
185     TRNRANKGRP DOWNLINEATCIMP -0.224193213
257 DOWNLINEATCIMP     TRNRANKGRP -0.224193213
46    UPLINEATCIMP      SKDARRSTA  0.223824406
136      SKDARRSTA   UPLINEATCIMP  0.223824406
112       ARRSPOKE          AVGSQ  0.219975654
310          AVGSQ       ARRSPOKE  0.219975654
304   xAVGSKDAVAIL       DEPSPOKE -0.212821518
358       DEPSPOKE   xAVGSKDAVAIL -0.212821518
62          SKDEPS         SKDEQP  0.212586898
80          SKDEQP         SKDEPS  0.212586898
244       DEPSPOKE     DEPRANKGRP  0.208188512
298     DEPRANKGRP       DEPSPOKE  0.208188512
18          xDURN2         SDEPHR -0.206018338
324         SDEPHR         xDURN2 -0.206018338
184     DEPRANKGRP DOWNLINEATCIMP -0.199411990
238 DOWNLINEATCIMP     DEPRANKGRP -0.199411990
113         xDURN2          AVGSQ -0.197447957
329          AVGSQ         xDURN2 -0.197447957
225       DEPSPOKE      ARRBUCKET -0.189934966
297      ARRBUCKET       DEPSPOKE -0.189934966
111       DEPSPOKE          AVGSQ -0.188666787
291          AVGSQ       DEPSPOKE -0.188666787
109     TRNRANKGRP          AVGSQ -0.188226304
253          AVGSQ     TRNRANKGRP -0.188226304
208         xDURN2      DEPBUCKET -0.183349624
334      DEPBUCKET         xDURN2 -0.183349624
246         xDURN2     DEPRANKGRP  0.180043357
336     DEPRANKGRP         xDURN2  0.180043357
2        SKDDEPSTA         SDEPHR -0.174400985
20          SDEPHR      SKDDEPSTA -0.174400985
151         xDURN2   UPLINEATCIMP -0.173240320
331   UPLINEATCIMP         xDURN2 -0.173240320
14      TRNRANKGRP         SDEPHR -0.171407823
248         SDEPHR     TRNRANKGRP -0.171407823
228   xAVGSKDAVAIL      ARRBUCKET -0.170644257
354      ARRBUCKET   xAVGSKDAVAIL -0.170644257
204     TRNRANKGRP      DEPBUCKET -0.170618431
258      DEPBUCKET     TRNRANKGRP -0.170618431
51      DEPRANKGRP      SKDARRSTA -0.167375913
231      SKDARRSTA     DEPRANKGRP -0.167375913
30       DEPBUCKET      SKDDEPSTA -0.165029385
192      SKDDEPSTA      DEPBUCKET -0.165029385
27    UPLINEATCIMP      SKDDEPSTA -0.164964952
135      SKDDEPSTA   UPLINEATCIMP -0.164964952
108     DEPRANKGRP          AVGSQ -0.161451853
234          AVGSQ     DEPRANKGRP -0.161451853
110     ARRRANKGRP          AVGSQ -0.159135469
272          AVGSQ     ARRRANKGRP -0.159135469
13      DEPRANKGRP         SDEPHR -0.158537017
229         SDEPHR     DEPRANKGRP -0.158537017
203     DEPRANKGRP      DEPBUCKET -0.155547085
239      DEPBUCKET     DEPRANKGRP -0.155547085
25           AVGSQ      SKDDEPSTA -0.150522366
97       SKDDEPSTA          AVGSQ -0.150522366
9     DEPSTAATCIMP         SDEPHR -0.148514693
153         SDEPHR   DEPSTAATCIMP -0.148514693
166     TRNRANKGRP   DEPSTAATCIMP -0.147409309
256   DEPSTAATCIMP     TRNRANKGRP -0.147409309
144      DEPBUCKET   UPLINEATCIMP  0.144940797
198   UPLINEATCIMP      DEPBUCKET  0.144940797
8     UPLINEATCIMP         SDEPHR  0.143217211
134         SDEPHR   UPLINEATCIMP  0.143217211
205     ARRRANKGRP      DEPBUCKET -0.142348062
277      DEPBUCKET     ARRRANKGRP -0.142348062
15      ARRRANKGRP         SDEPHR -0.141835526
267         SDEPHR     ARRRANKGRP -0.141835526
171   xAVGSKDAVAIL   DEPSTAATCIMP -0.141077194
351   DEPSTAATCIMP   xAVGSKDAVAIL -0.141077194
128     TRNRANKGRP      AVGLOFATC  0.139184315
254      AVGLOFATC     TRNRANKGRP  0.139184315
163      DEPBUCKET   DEPSTAATCIMP -0.138581846
199   DEPSTAATCIMP      DEPBUCKET -0.138581846
323   xAVGSKDAVAIL       ARRSPOKE  0.137677242
359       ARRSPOKE   xAVGSKDAVAIL  0.137677242
243     ARRRANKGRP     DEPRANKGRP  0.136562948
279     DEPRANKGRP     ARRRANKGRP  0.136562948
123   DEPSTAATCIMP      AVGLOFATC -0.135778614
159      AVGLOFATC   DEPSTAATCIMP -0.135778614
132         xDURN2      AVGLOFATC -0.132084629
330      AVGLOFATC         xDURN2 -0.132084629
247   xAVGSKDAVAIL     DEPRANKGRP  0.130574789
355     DEPRANKGRP   xAVGSKDAVAIL  0.130574789
224     ARRRANKGRP      ARRBUCKET -0.129698517
278      ARRBUCKET     ARRRANKGRP -0.129698517
164      ARRBUCKET   DEPSTAATCIMP -0.127726148
218   DEPSTAATCIMP      ARRBUCKET -0.127726148
37          xDURN2      SKDDEPSTA  0.127598189
325      SKDDEPSTA         xDURN2  0.127598189
124 DOWNLINEATCIMP      AVGLOFATC -0.126763572
178      AVGLOFATC DOWNLINEATCIMP -0.126763572
227         xDURN2      ARRBUCKET -0.125836459
335      ARRBUCKET         xDURN2 -0.125836459
165     DEPRANKGRP   DEPSTAATCIMP  0.124672682
237   DEPSTAATCIMP     DEPRANKGRP  0.124672682
85    DEPSTAATCIMP         SKDEPS -0.123445793
157         SKDEPS   DEPSTAATCIMP -0.123445793
31       ARRBUCKET      SKDDEPSTA -0.120728212
211      SKDDEPSTA      ARRBUCKET -0.120728212
284         xDURN2     ARRRANKGRP  0.119675180
338     ARRRANKGRP         xDURN2  0.119675180
114   xAVGSKDAVAIL          AVGSQ -0.113720147
348          AVGSQ   xAVGSKDAVAIL -0.113720147
52      TRNRANKGRP      SKDARRSTA -0.105802023
250      SKDARRSTA     TRNRANKGRP -0.105802023
222     DEPRANKGRP      ARRBUCKET -0.105057984
240      ARRBUCKET     DEPRANKGRP -0.105057984
190   xAVGSKDAVAIL DOWNLINEATCIMP  0.102577364
352 DOWNLINEATCIMP   xAVGSKDAVAIL  0.102577364
146     DEPRANKGRP   UPLINEATCIMP -0.097218129
236   UPLINEATCIMP     DEPRANKGRP -0.097218129
147     TRNRANKGRP   UPLINEATCIMP -0.097037814
255   UPLINEATCIMP     TRNRANKGRP -0.097037814
43          SKDEPS      SKDARRSTA -0.096699169
79       SKDARRSTA         SKDEPS -0.096699169
86  DOWNLINEATCIMP         SKDEPS -0.095568613
176         SKDEPS DOWNLINEATCIMP -0.095568613
45       AVGLOFATC      SKDARRSTA -0.095234466
117      SKDARRSTA      AVGLOFATC -0.095234466
42          SKDEQP      SKDARRSTA  0.094073459
60       SKDARRSTA         SKDEQP  0.094073459
50       ARRBUCKET      SKDARRSTA  0.092625400
212      SKDARRSTA      ARRBUCKET  0.092625400
223     TRNRANKGRP      ARRBUCKET -0.092415252
259      ARRBUCKET     TRNRANKGRP -0.092415252
266   xAVGSKDAVAIL     TRNRANKGRP  0.092011501
356     TRNRANKGRP   xAVGSKDAVAIL  0.092011501
38    xAVGSKDAVAIL      SKDDEPSTA  0.088580325
344      SKDDEPSTA   xAVGSKDAVAIL  0.088580325
75          xDURN2         SKDEQP  0.086170070
327         SKDEQP         xDURN2  0.086170070
127     DEPRANKGRP      AVGLOFATC  0.085474019
235      AVGLOFATC     DEPRANKGRP  0.085474019
122   UPLINEATCIMP      AVGLOFATC -0.085180887
140      AVGLOFATC   UPLINEATCIMP -0.085180887
262     ARRRANKGRP     TRNRANKGRP  0.083906762
280     TRNRANKGRP     ARRRANKGRP  0.083906762
282       DEPSPOKE     ARRRANKGRP  0.083162083
300     ARRRANKGRP       DEPSPOKE  0.083162083
44           AVGSQ      SKDARRSTA  0.082898864
98       SKDARRSTA          AVGSQ  0.082898864
91      ARRRANKGRP         SKDEPS  0.080398834
271         SKDEPS     ARRRANKGRP  0.080398834
3        SKDARRSTA         SDEPHR  0.079427004
39          SDEPHR      SKDARRSTA  0.079427004
95    xAVGSKDAVAIL         SKDEPS  0.075169577
347         SKDEPS   xAVGSKDAVAIL  0.075169577
167     ARRRANKGRP   DEPSTAATCIMP  0.073371196
275   DEPSTAATCIMP     ARRRANKGRP  0.073371196
49       DEPBUCKET      SKDARRSTA  0.072910977
193      SKDARRSTA      DEPBUCKET  0.072910977
145      ARRBUCKET   UPLINEATCIMP  0.071409699
217   UPLINEATCIMP      ARRBUCKET  0.071409699
148     ARRRANKGRP   UPLINEATCIMP -0.069790367
274   UPLINEATCIMP     ARRRANKGRP -0.069790367
34      ARRRANKGRP      SKDDEPSTA  0.068927801
268      SKDDEPSTA     ARRRANKGRP  0.068927801
74        ARRSPOKE         SKDEQP  0.066579707
308         SKDEQP       ARRSPOKE  0.066579707
19    xAVGSKDAVAIL         SDEPHR -0.064363931
343         SDEPHR   xAVGSKDAVAIL -0.064363931
7        AVGLOFATC         SDEPHR -0.063746211
115         SDEPHR      AVGLOFATC -0.063746211
103   UPLINEATCIMP          AVGSQ  0.062631172
139          AVGSQ   UPLINEATCIMP  0.062631172
129     ARRRANKGRP      AVGLOFATC -0.061491190
273      AVGLOFATC     ARRRANKGRP -0.061491190
283       ARRSPOKE     ARRRANKGRP -0.057002549
319     ARRRANKGRP       ARRSPOKE -0.057002549
133   xAVGSKDAVAIL      AVGLOFATC -0.056264979
349      AVGLOFATC   xAVGSKDAVAIL -0.056264979
125      DEPBUCKET      AVGLOFATC -0.053357134
197      AVGLOFATC      DEPBUCKET -0.053357134
209   xAVGSKDAVAIL      DEPBUCKET -0.053125467
353      DEPBUCKET   xAVGSKDAVAIL -0.053125467
26       AVGLOFATC      SKDDEPSTA -0.044946507
116      SKDDEPSTA      AVGLOFATC -0.044946507
126      ARRBUCKET      AVGLOFATC -0.043093769
216      AVGLOFATC      ARRBUCKET -0.043093769
4           SKDEQP         SDEPHR  0.042612138
58          SDEPHR         SKDEQP  0.042612138
72      ARRRANKGRP         SKDEQP -0.042512956
270         SKDEQP     ARRRANKGRP -0.042512956
104   DEPSTAATCIMP          AVGSQ -0.040428658
158          AVGSQ   DEPSTAATCIMP -0.040428658
82           AVGSQ         SKDEPS -0.038820886
100         SKDEPS          AVGSQ -0.038820886
68       DEPBUCKET         SKDEQP  0.037125178
194         SKDEQP      DEPBUCKET  0.037125178
131       ARRSPOKE      AVGLOFATC -0.034402462
311      AVGLOFATC       ARRSPOKE -0.034402462
76    xAVGSKDAVAIL         SKDEQP  0.031863410
346         SKDEQP   xAVGSKDAVAIL  0.031863410
90      TRNRANKGRP         SKDEPS  0.030883560
252         SKDEPS     TRNRANKGRP  0.030883560
87       DEPBUCKET         SKDEPS -0.030101407
195         SKDEPS      DEPBUCKET -0.030101407
56          xDURN2      SKDARRSTA  0.027576751
326      SKDARRSTA         xDURN2  0.027576751
102      AVGLOFATC          AVGSQ -0.027382453
120          AVGSQ      AVGLOFATC -0.027382453
57    xAVGSKDAVAIL      SKDARRSTA  0.027225219
345      SKDARRSTA   xAVGSKDAVAIL  0.027225219
89      DEPRANKGRP         SKDEPS  0.027025501
233         SKDEPS     DEPRANKGRP  0.027025501
24          SKDEPS      SKDDEPSTA -0.024267794
78       SKDDEPSTA         SKDEPS -0.024267794
65    UPLINEATCIMP         SKDEQP -0.019807499
137         SKDEQP   UPLINEATCIMP -0.019807499
73        DEPSPOKE         SKDEQP  0.019755644
289         SKDEQP       DEPSPOKE  0.019755644
342   xAVGSKDAVAIL         xDURN2 -0.019255572
360         xDURN2   xAVGSKDAVAIL -0.019255572
285   xAVGSKDAVAIL     ARRRANKGRP -0.018743432
357     ARRRANKGRP   xAVGSKDAVAIL -0.018743432
170         xDURN2   DEPSTAATCIMP -0.017999758
332   DEPSTAATCIMP         xDURN2 -0.017999758
67  DOWNLINEATCIMP         SKDEQP -0.017658860
175         SKDEQP DOWNLINEATCIMP -0.017658860
93        ARRSPOKE         SKDEPS  0.017573485
309         SKDEPS       ARRSPOKE  0.017573485
88       ARRBUCKET         SKDEPS  0.017414895
214         SKDEPS      ARRBUCKET  0.017414895
53      ARRRANKGRP      SKDARRSTA  0.016733374
269      SKDARRSTA     ARRRANKGRP  0.016733374
63           AVGSQ         SKDEQP  0.010218807
99          SKDEQP          AVGSQ  0.010218807
69       ARRBUCKET         SKDEQP  0.009926479
213         SKDEQP      ARRBUCKET  0.009926479
130       DEPSPOKE      AVGLOFATC -0.008540402
292      AVGLOFATC       DEPSPOKE -0.008540402
83       AVGLOFATC         SKDEPS  0.008240563
119         SKDEPS      AVGLOFATC  0.008240563
5           SKDEPS         SDEPHR -0.007166433
77          SDEPHR         SKDEPS -0.007166433
66    DEPSTAATCIMP         SKDEQP -0.005922601
156         SKDEQP   DEPSTAATCIMP -0.005922601
64       AVGLOFATC         SKDEQP -0.004889040
118         SKDEQP      AVGLOFATC -0.004889040
92        DEPSPOKE         SKDEPS -0.004617067
290         SKDEPS       DEPSPOKE -0.004617067
84    UPLINEATCIMP         SKDEPS  0.004016263
138         SKDEPS   UPLINEATCIMP  0.004016263
94          xDURN2         SKDEPS  0.001748012
328         SKDEPS         xDURN2  0.001748012
> 
> ### Models
> 
> ## Try GBM (gradient boosting). Works well for mixed data.
> ## And there is a tutorial for it with caret.
> 
> ## Training controller and big grid
> ## Check the ROC (my preferred.)
> 
> # I'm not using this at the moment.
> 
> tr.cols <- colnames(trainDescr)
> tr.cols
 [1] "SDEPHR"         "SKDDEPSTA"      "SKDARRSTA"      "SKDEQP"        
 [5] "SKDEPS"         "AVGSQ"          "AVGLOFATC"      "UPLINEATCIMP"  
 [9] "DEPSTAATCIMP"   "DOWNLINEATCIMP" "DEPBUCKET"      "ARRBUCKET"     
[13] "DEPRANKGRP"     "TRNRANKGRP"     "ARRRANKGRP"     "DEPSPOKE"      
[17] "ARRSPOKE"       "xDURN2"         "xAVGSKDAVAIL"  
> tr.icols <- grep("((STA|EQP)$)|(^xD)", tr.cols)
> tr.icols <- rev(tr.icols)
> 
> fitControl <- trainControl(## 10-fold CV
+     method = "repeatedcv",
+     number = 10,
+     ## repeated ten times
+     repeats = 10,
+     classProbs = TRUE)
> 
> ## Some trial and error with variables to branch and boost.
> ## Try all variables
> 
> gbmGrid <- expand.grid(interaction.depth = 
+                            length(colnames(trainDescr)),
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.2,
+                         n.minobsinnode = 10)
> 
> set.seed(seed.mine)
> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "Kappa",
+                  verbose = FALSE)
> gbmFit1
Stochastic Gradient Boosting 

248 samples
 19 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 222, 223, 223, 224, 223, 223, ... 

Resampling results across tuning parameters:

  n.trees  Accuracy   Kappa      Accuracy SD  Kappa SD 
    90     0.6892436  0.3718731  0.09149622   0.1847568
   180     0.6822756  0.3563973  0.08716175   0.1758211
   270     0.6823090  0.3555315  0.08383181   0.1695097
   360     0.6823564  0.3564232  0.08486068   0.1729529
   450     0.6786744  0.3496848  0.09185347   0.1854427
   540     0.6798949  0.3520832  0.09018435   0.1818497
   630     0.6774090  0.3469474  0.09403673   0.1900628
   720     0.6814295  0.3551381  0.09301993   0.1872286
   810     0.6786910  0.3497725  0.09235792   0.1858930
   900     0.6787397  0.3504452  0.09096149   0.1830129
   990     0.6795577  0.3521107  0.09213133   0.1851213
  1080     0.6807090  0.3541811  0.09197718   0.1850766
  1170     0.6819436  0.3568134  0.09359183   0.1881068
  1260     0.6835628  0.3596405  0.09205828   0.1857198
  1350     0.6831282  0.3589361  0.08954495   0.1802363
  1440     0.6839128  0.3602391  0.09139707   0.1846850
  1530     0.6806782  0.3537382  0.08998077   0.1809558
  1620     0.6811115  0.3552119  0.08937003   0.1795259
  1710     0.6811423  0.3561377  0.08766142   0.1760042
  1800     0.6799269  0.3552568  0.08743967   0.1750193
  1890     0.6847141  0.3671230  0.08621719   0.1708143
  1980     0.6839782  0.3673781  0.08462134   0.1663832
  2070     0.6892141  0.3786265  0.08383537   0.1660518
  2160     0.6867987  0.3753817  0.08362710   0.1650538
  2250     0.6892154  0.3814460  0.08512066   0.1667953
  2340     0.6859654  0.3756721  0.08753400   0.1713510
  2430     0.6871487  0.3794306  0.08517312   0.1668973
  2520     0.6839615  0.3741069  0.08827583   0.1729468
  2610     0.6819295  0.3711190  0.08619096   0.1684462
  2700     0.6799923  0.3678154  0.08807045   0.1724535

Tuning parameter 'interaction.depth' was held constant at a value of 19

Tuning parameter 'shrinkage' was held constant at a value of 0.2

Tuning parameter 'n.minobsinnode' was held constant at a value of 10
Kappa was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 2250, interaction.depth
 = 19, shrinkage = 0.2 and n.minobsinnode = 10. 
> 
> ## The acid test is dissapointing, but I've seen worse.
> 
> testPred <- predict(gbmFit1, testDescr)
> postResample(testPred, testClass)
 Accuracy     Kappa 
0.6666667 0.3291925 
> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     27   11
    Weak       13   21
                                          
               Accuracy : 0.6667          
                 95% CI : (0.5457, 0.7734)
    No Information Rate : 0.5556          
    P-Value [Acc > NIR] : 0.03646         
                                          
                  Kappa : 0.3292          
 Mcnemar's Test P-Value : 0.83826         
                                          
            Sensitivity : 0.6562          
            Specificity : 0.6750          
         Pos Pred Value : 0.6176          
         Neg Pred Value : 0.7105          
             Prevalence : 0.4444          
         Detection Rate : 0.2917          
   Detection Prevalence : 0.4722          
      Balanced Accuracy : 0.6656          
                                          
       'Positive' Class : Weak            
                                          
> 
> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)
> postResample(trainPred, trainClass)
Accuracy    Kappa 
       1        1 
> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    137    0
    Weak        0  111
                                     
               Accuracy : 1          
                 95% CI : (0.9852, 1)
    No Information Rate : 0.5524     
    P-Value [Acc > NIR] : < 2.2e-16  
                                     
                  Kappa : 1          
 Mcnemar's Test P-Value : NA         
                                     
            Sensitivity : 1.0000     
            Specificity : 1.0000     
         Pos Pred Value : 1.0000     
         Neg Pred Value : 1.0000     
             Prevalence : 0.4476     
         Detection Rate : 0.4476     
   Detection Prevalence : 0.4476     
      Balanced Accuracy : 1.0000     
                                     
       'Positive' Class : Weak       
                                     
> 
> ## Get a density and a ROC
> 
> x.p <- predict(gbmFit1, testDescr, type = "prob")[2]
> test.df <- data.frame(Weak=x.p$Weak, Obs=testClass)
> test.roc <- roc(Obs ~ Weak, test.df)
> densityplot(~test.df$Weak, groups = test.df$Obs, auto.key = TRUE)
> plot.roc(test.roc)

Call:
roc.formula(formula = Obs ~ Weak, data = test.df)

Data: Weak in 40 controls (Obs Strong) < 32 cases (Obs Weak).
Area under the curve: 0.7367
> jpeg(width=1024, height=640)
> densityplot(~test.df$Weak, groups = test.df$Obs, auto.key = TRUE)
> plot.roc(test.roc)

Call:
roc.formula(formula = Obs ~ Weak, data = test.df)

Data: Weak in 40 controls (Obs Strong) < 32 cases (Obs Weak).
Area under the curve: 0.7367
> dev.off()
null device 
          1 
> quit()
Save workspace image? [y/n/c]: n

Process R finished at Sat May  7 09:20:35 2016


R version 3.2.5 (2016-04-14) -- "Very, Very Secure Dishes"
Copyright (C) 2016 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> > options(STERM='iESS', str.dendrogram.last="'", editor='emacsclient', show.error.locations=TRUE)
> 
+ . + 
> ### weaves
> 
> ## Processing for flights data.
> 
> ## Following the caret vignette.
> 
> ###################################################
> ### code chunk number 1: loadLibs
> ###################################################
> library(MASS)

> library(caret)
Loading required package: lattice
Loading required package: ggplot2

> library(mlbench)

> library(pROC)
Type 'citation("pROC")' for a citation.

Attaching package: 'pROC'

The following objects are masked from 'package:stats':

    cov, smooth, var


> library(pls)

Attaching package: 'pls'

The following object is masked from 'package:caret':

    R2

The following object is masked from 'package:stats':

    loadings


> library(doMC)
Loading required package: foreach
foreach: simple, scalable parallel programming from Revolution Analytics
Use Revolution R for scalability, fault tolerance and more.
http://www.revolutionanalytics.com
Loading required package: iterators
Loading required package: parallel

> registerDoMC(cores = 4)

> options(useFancyQuotes = FALSE) 

> # Accounting info.
> getInfo <- function(what = "Suggests")
+ {
+   text <- packageDescription("caret")[what][[1]]
+   text <- gsub("\n", ", ", text, fixed = TRUE)
+   text <- gsub(">=", "$\\\\ge$", text, fixed = TRUE)
+   eachPkg <- strsplit(text, ", ", fixed = TRUE)[[1]]
+   eachPkg <- gsub(",", .... [TRUNCATED] 

> ### project-specific: begin
> ## Set-seed, load original CSV file, order it
> ## and do some simple-cleaning
> ## Various datasets 
> 
> seed.mine = 107

> set.seed(seed.mine)                     # helpful for testing

> flight <- read.csv("../bak/flight.csv")

> flight <- flight[order(flight$D00),]

> # Backup
> flight.raw <- flight

> # To check adjustment, there is test code in flight-nb.R
> 
> # Some additions
> 
> flight$DEPSPOKE <- flight$DEPGRP == "Spoke"

> flight$ARRSPOKE <- flight$ARRGRP == "Spoke"

> # And some deletions
> 
> t.cols <- colnames(flight)

> t.drops <- t.cols[grep("^RANK*", t.cols)]

> t.drops <- c(t.drops, t.cols[grep("^(ARR|DEP)GRP$", t.cols)])

> t.drops <- c(t.drops, "D80THPCTL")

> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]

> ## Let's do the flight duration logic see the flight logic the notes.
> 
> flight$xDURN <- flight$SARRHR - flight$SDEPHR

> flight$xHNGR <- flight$xDURN < 0

> ## I don't think there is any hangaring. I have to clean this up.
> 
> ## Max flight time is 8 hours for the positives, but red-eyes can
> ## take longer
> 
> hr.wrap <- function(d0, a0) {
+     t0 <- a0 - d0
+     if (t0 >= 0) return(t0)
+     t0 <- 24 - d0
+     t0 <- t0 + a0
+     return(t0)
+  .... [TRUNCATED] 

> flight$xDURN2 <- apply(flight[,c("SDEPHR", "SARRHR")], 1, 
+                        function(y) hr.wrap(y['SDEPHR'], y['SARRHR']))

> flight[which(flight$xDURN2 != flight$xDURN), c("SDEPHR", "SARRHR", "xDURN","xDURN2", "xHNGR")]
     SDEPHR SARRHR xDURN xDURN2 xHNGR
19       22      0   -22      2  TRUE
107      22      0   -22      2  TRUE
111      23      5   -18      6  TRUE
121      21      0   -21      3  TRUE
186      22      0   -22      2  TRUE
203      20      0   -20      4  TRUE
220      21      0   -21      3  TRUE
261      23      7   -16      8  TRUE
285      22      6   -16      8  TRUE
328      18      9    -9     15  TRUE
367      22      6   -16      8  TRUE
443      22      6   -16      8  TRUE
554      22     11   -11     13  TRUE
559      19      0   -19      5  TRUE
595      21     15    -6     18  TRUE
611      22      6   -16      8  TRUE
621      22      0   -22      2  TRUE
625      22      6   -16      8  TRUE
636      20      8   -12     12  TRUE
652      18      7   -11     13  TRUE
654      20     11    -9     15  TRUE
666      21      8   -13     11  TRUE
670      22      5   -17      7  TRUE
686      21      9   -12     12  TRUE
718      18      8   -10     14  TRUE
722      18      7   -11     13  TRUE
742      22      6   -16      8  TRUE
748      18      8   -10     14  TRUE
749      20     10   -10     14  TRUE
785      19      1   -18      6  TRUE
799      18      8   -10     14  TRUE
853      22      6   -16      8  TRUE
855      23      7   -16      8  TRUE
863      18      7   -11     13  TRUE
883      16      6   -10     14  TRUE
905      22      0   -22      2  TRUE
967      22      7   -15      9  TRUE
984      22      0   -22      2  TRUE
1011     22      6   -16      8  TRUE
1012     22      6   -16      8  TRUE
1043     23      6   -17      7  TRUE
1096     22      6   -16      8  TRUE
1148     22      5   -17      7  TRUE
1288     23      8   -15      9  TRUE
1372     23      8   -15      9  TRUE
1384     23      8   -15      9  TRUE
1386     23      5   -18      6  TRUE
1388     23      8   -15      9  TRUE

> t.cols <- colnames(flight)

> t.drops <- c("SARRHR", "xDURN")

> flight <- flight[ , t.cols[!(t.cols %in% t.drops)] ]

> ## Backup
> 
> flight00 <- flight

> # And we drop many, many rows because R slows with large datasets.
> # These are the ranges we have been asked to predict on.
> 
> flight <- flight[flight$AVGLOFATC >= 3.1 & flight$AVGLOFATC <= 4.4,]

> paste("samples in use: ", dim(flight)[1])
[1] "samples in use:  320"

> ## Data insights
> 
> ## *Run from here.
> 
> ## Using the D00 and LEGTYPE dataset, I have this concern that D00 is
> ## a derived probit and we should ignore it.
> 
> ### Numeric variables
> 
> ### Try and impute the AVG, it might have more information than the
> ### bucket.
> 
> flight$xAVAILBUC .... [TRUNCATED] 

> ## Arbitrary choice to set to -1.
> flight[which(flight$AVAILBUCKET == 'A<0'), "xAVAILBUCKET" ] <- -1

> flight.na <- flight[, c("AVGSKDAVAIL", "xAVAILBUCKET")]

> preProcValues <- preProcess(flight.na, method = c("knnImpute"))

> flight.na1 <- predict(preProcValues, flight.na)

> ## I'll add the new imputed value and drop the others
> flight$xAVGSKDAVAIL <- flight.na1$AVGSKDAVAIL

> flight$AVGSKDAVAIL <- NULL

> flight$xAVAILBUCKET <- NULL

> flight$AVAILBUCKET <- NULL

> flight$xHNGR <- NULL

> ## Check some more numeric correlations, I haven't scaled everything yet.
> ## I'd cut correlations above 0.65 to 0.75 because of overfitting.
> 
> x1 <- as.data.frame(as.matrix(sapply(flight, class)))

> flight.num <- flight[,names(x1[which(x1$V1 %in% c("numeric", "integer")),])]

> flight.nzv <- nearZeroVar(flight.num, saveMetrics = TRUE)

> flight.nzv
             freqRatio percentUnique zeroVar   nzv
SDEPHR        1.038462        5.9375   FALSE FALSE
SKDEPS        1.000000       19.0625   FALSE FALSE
D00           1.166667       75.3125   FALSE FALSE
AVGSQ         6.333333       82.8125   FALSE FALSE
AVGLOFATC     1.000000       78.4375   FALSE FALSE
xDURN2        1.428571        2.5000   FALSE FALSE
xAVGSKDAVAIL 18.500000       87.8125   FALSE FALSE

> # annoying NA should be gone.
> flight.cor <- cor(flight.num, use = "pairwise.complete.obs")

> descrCorr <- findCorrelation(flight.cor, cutoff = .65, verbose=TRUE)
Considering row	 4 column	 1 value	 0.956 
  Flagging column	 4 
Considering row	 1 column	 3 value	 0.43 
Considering row	 1 column	 7 value	 0.053 
Considering row	 1 column	 6 value	 0.204 
Considering row	 1 column	 5 value	 0.131 
Considering row	 1 column	 2 value	 0.054 
Considering row	 3 column	 7 value	 0.401 
Considering row	 3 column	 6 value	 0.071 
Considering row	 3 column	 5 value	 0.114 
Considering row	 3 column	 2 value	 0.006 
Considering row	 7 column	 6 value	 0.019 
Considering row	 7 column	 5 value	 0.07 
Considering row	 7 column	 2 value	 0.113 
Considering row	 6 column	 5 value	 0.137 
Considering row	 6 column	 2 value	 0.005 
Considering row	 5 column	 2 value	 0.041 

> colnames(flight.num)[descrCorr]
[1] "AVGSQ"

> ## And I'll leave the centered and scale values in for now.
> ## and delete the troublesome ones
> 
> ## Re-classing
> ## Check warnings to see it adjustment has taken place.
> ## We want the proportion in the training class to be about 0.55 0.45
> ## Strong to Weak
> ## I've achieved this heurist .... [TRUNCATED] 

> source(file = "flight1.R")

> flight1 <- flight

> ## This should be deleted, leave it in and the results
> ## are ideal because it defines LEGTYPE.
> flight$D00 <- NULL

> ## Keep the results but don't change the order.
> outcomes.flight <- flight$LEGTYPE

> flight$LEGTYPE <- NULL

> ## If you know your factors are definitely factors, you don't need this
> ##  asNumeric <- function(x) as.numeric(as.character(x))
> 
> factors.numeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)], as.numeric))

> flight.num0 <- factors.numeric(flight)

> flight.scl0 <- scale(flight.num0)

> ## Now split the samples
> ## we need at least 60 to test with, p at 0.77 gives about 75.
> ## Difficulty here is the bias in the table
> ## Because we only have [3.1, 4.4] the proportion of Weak is higher.
> ## see prop.table(results)
> 
> set.seed(seed.mine)

> inTrain <- createDataPartition(outcomes.flight, p = 0.77, list = FALSE)

> trainDescr <- flight.scl0[inTrain,]

> testDescr <- flight.scl0[-inTrain,]

> trainClass <- outcomes.flight[inTrain]

> testClass <- outcomes.flight[-inTrain]

> prop.table(table(trainClass))
trainClass
   Strong      Weak 
0.5524194 0.4475806 

> dim(trainDescr)
[1] 248  19

> prop.table(table(testClass))
testClass
   Strong      Weak 
0.5555556 0.4444444 

> dim(testDescr)
[1] 72 19

> ## Check Near-zero variance
> 
> nzv <- nearZeroVar(trainDescr, saveMetrics= TRUE)

> stopifnot( all(nzv$nzv == FALSE) )

> # It's imputed and behaves well, no need for this.
> # descrCorr <- cor(scale(trainDescr), use = "pairwise.complete.obs")
> 
> descrCorr <- cor(scale(trainDescr))

> ## This cut-off should be under src.adjust control.
> ## I'm under Git, so I can tinker with it.
> highCorr <- findCorrelation(descrCorr, cutoff = .99, verbose = TRUE)
Considering row	 17 column	 16 value	 0.85 
Considering row	 17 column	 10 value	 0.671 
Considering row	 17 column	 1 value	 0.279 
Considering row	 17 column	 11 value	 0.277 
Considering row	 17 column	 6 value	 0.22 
Considering row	 17 column	 12 value	 0.226 
Considering row	 17 column	 2 value	 0.298 
Considering row	 17 column	 9 value	 0.586 
Considering row	 17 column	 14 value	 0.226 
Considering row	 17 column	 13 value	 0.23 
Considering row	 17 column	 8 value	 0.541 
Considering row	 17 column	 3 value	 0.346 
Considering row	 17 column	 18 value	 0.261 
Considering row	 17 column	 19 value	 0.138 
Considering row	 17 column	 15 value	 0.057 
Considering row	 17 column	 4 value	 0.067 
Considering row	 17 column	 7 value	 0.034 
Considering row	 17 column	 5 value	 0.018 
Considering row	 16 column	 10 value	 0.568 
Considering row	 16 column	 1 value	 0.236 
Considering row	 16 column	 11 value	 0.231 
Considering row	 16 column	 6 value	 0.189 
Considering row	 16 column	 12 value	 0.19 
Considering row	 16 column	 2 value	 0.333 
Considering row	 16 column	 9 value	 0.671 
Considering row	 16 column	 14 value	 0.242 
Considering row	 16 column	 13 value	 0.208 
Considering row	 16 column	 8 value	 0.6 
Considering row	 16 column	 3 value	 0.318 
Considering row	 16 column	 18 value	 0.279 
Considering row	 16 column	 19 value	 0.213 
Considering row	 16 column	 15 value	 0.083 
Considering row	 16 column	 4 value	 0.02 
Considering row	 16 column	 7 value	 0.009 
Considering row	 16 column	 5 value	 0.005 
Considering row	 10 column	 1 value	 0.281 
Considering row	 10 column	 11 value	 0.275 
Considering row	 10 column	 6 value	 0.298 
Considering row	 10 column	 12 value	 0.255 
Considering row	 10 column	 2 value	 0.286 
Considering row	 10 column	 9 value	 0.404 
Considering row	 10 column	 14 value	 0.224 
Considering row	 10 column	 13 value	 0.199 
Considering row	 10 column	 8 value	 0.366 
Considering row	 10 column	 3 value	 0.462 
Considering row	 10 column	 18 value	 0.226 
Considering row	 10 column	 19 value	 0.103 
Considering row	 10 column	 15 value	 0.274 
Considering row	 10 column	 4 value	 0.018 
Considering row	 10 column	 7 value	 0.127 
Considering row	 10 column	 5 value	 0.096 
Considering row	 1 column	 11 value	 0.988 
Considering row	 1 column	 6 value	 0.955 
Considering row	 1 column	 12 value	 0.905 
Considering row	 1 column	 2 value	 0.174 
Considering row	 1 column	 9 value	 0.149 
Considering row	 1 column	 14 value	 0.171 
Considering row	 1 column	 13 value	 0.159 
Considering row	 1 column	 8 value	 0.143 
Considering row	 1 column	 3 value	 0.079 
Considering row	 1 column	 18 value	 0.206 
Considering row	 1 column	 19 value	 0.064 
Considering row	 1 column	 15 value	 0.142 
Considering row	 1 column	 4 value	 0.043 
Considering row	 1 column	 7 value	 0.064 
Considering row	 1 column	 5 value	 0.007 
Considering row	 11 column	 6 value	 0.945 
Considering row	 11 column	 12 value	 0.889 
Considering row	 11 column	 2 value	 0.165 
Considering row	 11 column	 9 value	 0.139 
Considering row	 11 column	 14 value	 0.171 
Considering row	 11 column	 13 value	 0.156 
Considering row	 11 column	 8 value	 0.145 
Considering row	 11 column	 3 value	 0.073 
Considering row	 11 column	 18 value	 0.183 
Considering row	 11 column	 19 value	 0.053 
Considering row	 11 column	 15 value	 0.142 
Considering row	 11 column	 4 value	 0.037 
Considering row	 11 column	 7 value	 0.053 
Considering row	 11 column	 5 value	 0.03 
Considering row	 6 column	 12 value	 0.883 
Considering row	 6 column	 2 value	 0.151 
Considering row	 6 column	 9 value	 0.04 
Considering row	 6 column	 14 value	 0.188 
Considering row	 6 column	 13 value	 0.161 
Considering row	 6 column	 8 value	 0.063 
Considering row	 6 column	 3 value	 0.083 
Considering row	 6 column	 18 value	 0.197 
Considering row	 6 column	 19 value	 0.114 
Considering row	 6 column	 15 value	 0.159 
Considering row	 6 column	 4 value	 0.01 
Considering row	 6 column	 7 value	 0.027 
Considering row	 6 column	 5 value	 0.039 
Considering row	 12 column	 2 value	 0.121 
Considering row	 12 column	 9 value	 0.128 
Considering row	 12 column	 14 value	 0.092 
Considering row	 12 column	 13 value	 0.105 
Considering row	 12 column	 8 value	 0.071 
Considering row	 12 column	 3 value	 0.093 
Considering row	 12 column	 18 value	 0.126 
Considering row	 12 column	 19 value	 0.171 
Considering row	 12 column	 15 value	 0.13 
Considering row	 12 column	 4 value	 0.01 
Considering row	 12 column	 7 value	 0.043 
Considering row	 12 column	 5 value	 0.017 
Considering row	 2 column	 9 value	 0.423 
Considering row	 2 column	 14 value	 0.574 
Considering row	 2 column	 13 value	 0.557 
Considering row	 2 column	 8 value	 0.165 
Considering row	 2 column	 3 value	 0.263 
Considering row	 2 column	 18 value	 0.128 
Considering row	 2 column	 19 value	 0.089 
Considering row	 2 column	 15 value	 0.069 
Considering row	 2 column	 4 value	 0.27 
Considering row	 2 column	 7 value	 0.045 
Considering row	 2 column	 5 value	 0.024 
Considering row	 9 column	 14 value	 0.147 
Considering row	 9 column	 13 value	 0.125 
Considering row	 9 column	 8 value	 0.449 
Considering row	 9 column	 3 value	 0.322 
Considering row	 9 column	 18 value	 0.018 
Considering row	 9 column	 19 value	 0.141 
Considering row	 9 column	 15 value	 0.073 
Considering row	 9 column	 4 value	 0.006 
Considering row	 9 column	 7 value	 0.136 
Considering row	 9 column	 5 value	 0.123 
Considering row	 14 column	 13 value	 0.659 
Considering row	 14 column	 8 value	 0.097 
Considering row	 14 column	 3 value	 0.106 
Considering row	 14 column	 18 value	 0.361 
Considering row	 14 column	 19 value	 0.092 
Considering row	 14 column	 15 value	 0.084 
Considering row	 14 column	 4 value	 0.263 
Considering row	 14 column	 7 value	 0.139 
Considering row	 14 column	 5 value	 0.031 
Considering row	 13 column	 8 value	 0.097 
Considering row	 13 column	 3 value	 0.167 
Considering row	 13 column	 18 value	 0.18 
Considering row	 13 column	 19 value	 0.131 
Considering row	 13 column	 15 value	 0.137 
Considering row	 13 column	 4 value	 0.24 
Considering row	 13 column	 7 value	 0.085 
Considering row	 13 column	 5 value	 0.027 
Considering row	 8 column	 3 value	 0.224 
Considering row	 8 column	 18 value	 0.173 
Considering row	 8 column	 19 value	 0.235 
Considering row	 8 column	 15 value	 0.07 
Considering row	 8 column	 4 value	 0.02 
Considering row	 8 column	 7 value	 0.085 
Considering row	 8 column	 5 value	 0.004 
Considering row	 3 column	 18 value	 0.028 
Considering row	 3 column	 19 value	 0.027 
Considering row	 3 column	 15 value	 0.017 
Considering row	 3 column	 4 value	 0.094 
Considering row	 3 column	 7 value	 0.095 
Considering row	 3 column	 5 value	 0.097 
Considering row	 18 column	 19 value	 0.019 
Considering row	 18 column	 15 value	 0.12 
Considering row	 18 column	 4 value	 0.086 
Considering row	 18 column	 7 value	 0.132 
Considering row	 18 column	 5 value	 0.002 
Considering row	 19 column	 15 value	 0.019 
Considering row	 19 column	 4 value	 0.032 
Considering row	 19 column	 7 value	 0.056 
Considering row	 19 column	 5 value	 0.075 
Considering row	 15 column	 4 value	 0.043 
Considering row	 15 column	 7 value	 0.061 
Considering row	 15 column	 5 value	 0.08 
Considering row	 4 column	 7 value	 0.005 
Considering row	 4 column	 5 value	 0.213 
Considering row	 7 column	 5 value	 0.008 

> colnames(trainDescr)[highCorr]
character(0)

> descr.ncol0 <- ncol(trainDescr)

> # I've switched off the correlation remover and the results are better.
> if (sum(highCorr) > 0) {
+     warning("overfitting: correlations: err.trainDescr: ", paste(colnames(trainDescr)[highCorr], collapse = ", ") )
+     err.trainDescr <- trainDescr
+     trainDescr <- trainDescr[,-highCorr]
+ }

> descr.ncol1 <- ncol(trainDescr)

> paste("Dropped: ", as.character(descr.ncol0 - descr.ncol1))
[1] "Dropped:  0"

> descrCorr <- cor(trainDescr)

> summary(descrCorr[upper.tri(descrCorr)])
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
-0.85020 -0.14210 -0.01766  0.02755  0.12610  0.98780 

> ## Dominant correlations
> ## At 0.9, there are some big ones that might need re-thinking.
> 
> table.descrCorr <- as.data.frame(as.table(descrCorr))

> table.descrCorr <- table.descrCorr[which(table.descrCorr$Var1 != table.descrCorr$Var2),]

> table.descrCorr[order(abs(table.descrCorr$Freq), decreasing = TRUE),]
              Var1           Var2         Freq
11       DEPBUCKET         SDEPHR  0.987828666
191         SDEPHR      DEPBUCKET  0.987828666
6            AVGSQ         SDEPHR  0.954804414
96          SDEPHR          AVGSQ  0.954804414
106      DEPBUCKET          AVGSQ  0.944870657
196          AVGSQ      DEPBUCKET  0.944870657
12       ARRBUCKET         SDEPHR  0.904546667
210         SDEPHR      ARRBUCKET  0.904546667
202      ARRBUCKET      DEPBUCKET  0.889095737
220      DEPBUCKET      ARRBUCKET  0.889095737
107      ARRBUCKET          AVGSQ  0.882590635
215          AVGSQ      ARRBUCKET  0.882590635
302       ARRSPOKE       DEPSPOKE -0.850165355
320       DEPSPOKE       ARRSPOKE -0.850165355
168       DEPSPOKE   DEPSTAATCIMP  0.671264566
294   DEPSTAATCIMP       DEPSPOKE  0.671264566
188       ARRSPOKE DOWNLINEATCIMP  0.671009330
314 DOWNLINEATCIMP       ARRSPOKE  0.671009330
242     TRNRANKGRP     DEPRANKGRP  0.658724662
260     DEPRANKGRP     TRNRANKGRP  0.658724662
149       DEPSPOKE   UPLINEATCIMP -0.600008252
293   UPLINEATCIMP       DEPSPOKE -0.600008252
169       ARRSPOKE   DEPSTAATCIMP -0.586442959
313   DEPSTAATCIMP       ARRSPOKE -0.586442959
33      TRNRANKGRP      SKDDEPSTA  0.574035134
249      SKDDEPSTA     TRNRANKGRP  0.574035134
187       DEPSPOKE DOWNLINEATCIMP -0.567682494
295 DOWNLINEATCIMP       DEPSPOKE -0.567682494
32      DEPRANKGRP      SKDDEPSTA  0.557399203
230      SKDDEPSTA     DEPRANKGRP  0.557399203
150       ARRSPOKE   UPLINEATCIMP  0.540734833
312   UPLINEATCIMP       ARRSPOKE  0.540734833
48  DOWNLINEATCIMP      SKDARRSTA  0.462378131
174      SKDARRSTA DOWNLINEATCIMP  0.462378131
142   DEPSTAATCIMP   UPLINEATCIMP -0.449249986
160   UPLINEATCIMP   DEPSTAATCIMP -0.449249986
28    DEPSTAATCIMP      SKDDEPSTA  0.423425796
154      SKDDEPSTA   DEPSTAATCIMP  0.423425796
162 DOWNLINEATCIMP   DEPSTAATCIMP -0.403695561
180   DEPSTAATCIMP DOWNLINEATCIMP -0.403695561
143 DOWNLINEATCIMP   UPLINEATCIMP  0.365833687
179   UPLINEATCIMP DOWNLINEATCIMP  0.365833687
265         xDURN2     TRNRANKGRP  0.361347207
337     TRNRANKGRP         xDURN2  0.361347207
55        ARRSPOKE      SKDARRSTA  0.345987375
307      SKDARRSTA       ARRSPOKE  0.345987375
35        DEPSPOKE      SKDDEPSTA  0.332823310
287      SKDDEPSTA       DEPSPOKE  0.332823310
47    DEPSTAATCIMP      SKDARRSTA -0.322204878
155      SKDARRSTA   DEPSTAATCIMP -0.322204878
54        DEPSPOKE      SKDARRSTA -0.318093195
288      SKDARRSTA       DEPSPOKE -0.318093195
105 DOWNLINEATCIMP          AVGSQ  0.298096458
177          AVGSQ DOWNLINEATCIMP  0.298096458
36        ARRSPOKE      SKDDEPSTA -0.298036487
306      SKDDEPSTA       ARRSPOKE -0.298036487
29  DOWNLINEATCIMP      SKDDEPSTA -0.285911992
173      SKDDEPSTA DOWNLINEATCIMP -0.285911992
10  DOWNLINEATCIMP         SDEPHR  0.280539472
172         SDEPHR DOWNLINEATCIMP  0.280539472
303         xDURN2       DEPSPOKE  0.279030910
339       DEPSPOKE         xDURN2  0.279030910
17        ARRSPOKE         SDEPHR  0.278505248
305         SDEPHR       ARRSPOKE  0.278505248
207       ARRSPOKE      DEPBUCKET  0.276615722
315      DEPBUCKET       ARRSPOKE  0.276615722
182      DEPBUCKET DOWNLINEATCIMP  0.275167866
200 DOWNLINEATCIMP      DEPBUCKET  0.275167866
186     ARRRANKGRP DOWNLINEATCIMP -0.274110143
276 DOWNLINEATCIMP     ARRRANKGRP -0.274110143
23          SKDEQP      SKDDEPSTA  0.270065872
59       SKDDEPSTA         SKDEQP  0.270065872
22       SKDARRSTA      SKDDEPSTA -0.263453106
40       SKDDEPSTA      SKDARRSTA -0.263453106
71      TRNRANKGRP         SKDEQP  0.262837233
251         SKDEQP     TRNRANKGRP  0.262837233
322         xDURN2       ARRSPOKE -0.261107447
340       ARRSPOKE         xDURN2 -0.261107447
183      ARRBUCKET DOWNLINEATCIMP  0.255480148
219 DOWNLINEATCIMP      ARRBUCKET  0.255480148
263       DEPSPOKE     TRNRANKGRP  0.242138220
299     TRNRANKGRP       DEPSPOKE  0.242138220
70      DEPRANKGRP         SKDEQP  0.239915140
232         SKDEQP     DEPRANKGRP  0.239915140
16        DEPSPOKE         SDEPHR -0.236049001
286         SDEPHR       DEPSPOKE -0.236049001
152   xAVGSKDAVAIL   UPLINEATCIMP  0.234867014
350   UPLINEATCIMP   xAVGSKDAVAIL  0.234867014
206       DEPSPOKE      DEPBUCKET -0.231298301
296      DEPBUCKET       DEPSPOKE -0.231298301
245       ARRSPOKE     DEPRANKGRP -0.229640758
317     DEPRANKGRP       ARRSPOKE -0.229640758
189         xDURN2 DOWNLINEATCIMP -0.226093423
333 DOWNLINEATCIMP         xDURN2 -0.226093423
226       ARRSPOKE      ARRBUCKET  0.225890655
316      ARRBUCKET       ARRSPOKE  0.225890655
264       ARRSPOKE     TRNRANKGRP -0.225591539
318     TRNRANKGRP       ARRSPOKE -0.225591539
185     TRNRANKGRP DOWNLINEATCIMP -0.224193213
257 DOWNLINEATCIMP     TRNRANKGRP -0.224193213
46    UPLINEATCIMP      SKDARRSTA  0.223824406
136      SKDARRSTA   UPLINEATCIMP  0.223824406
112       ARRSPOKE          AVGSQ  0.219975654
310          AVGSQ       ARRSPOKE  0.219975654
304   xAVGSKDAVAIL       DEPSPOKE -0.212821518
358       DEPSPOKE   xAVGSKDAVAIL -0.212821518
62          SKDEPS         SKDEQP  0.212586898
80          SKDEQP         SKDEPS  0.212586898
244       DEPSPOKE     DEPRANKGRP  0.208188512
298     DEPRANKGRP       DEPSPOKE  0.208188512
18          xDURN2         SDEPHR -0.206018338
324         SDEPHR         xDURN2 -0.206018338
184     DEPRANKGRP DOWNLINEATCIMP -0.199411990
238 DOWNLINEATCIMP     DEPRANKGRP -0.199411990
113         xDURN2          AVGSQ -0.197447957
329          AVGSQ         xDURN2 -0.197447957
225       DEPSPOKE      ARRBUCKET -0.189934966
297      ARRBUCKET       DEPSPOKE -0.189934966
111       DEPSPOKE          AVGSQ -0.188666787
291          AVGSQ       DEPSPOKE -0.188666787
109     TRNRANKGRP          AVGSQ -0.188226304
253          AVGSQ     TRNRANKGRP -0.188226304
208         xDURN2      DEPBUCKET -0.183349624
334      DEPBUCKET         xDURN2 -0.183349624
246         xDURN2     DEPRANKGRP  0.180043357
336     DEPRANKGRP         xDURN2  0.180043357
2        SKDDEPSTA         SDEPHR -0.174400985
20          SDEPHR      SKDDEPSTA -0.174400985
151         xDURN2   UPLINEATCIMP -0.173240320
331   UPLINEATCIMP         xDURN2 -0.173240320
14      TRNRANKGRP         SDEPHR -0.171407823
248         SDEPHR     TRNRANKGRP -0.171407823
228   xAVGSKDAVAIL      ARRBUCKET -0.170644257
354      ARRBUCKET   xAVGSKDAVAIL -0.170644257
204     TRNRANKGRP      DEPBUCKET -0.170618431
258      DEPBUCKET     TRNRANKGRP -0.170618431
51      DEPRANKGRP      SKDARRSTA -0.167375913
231      SKDARRSTA     DEPRANKGRP -0.167375913
30       DEPBUCKET      SKDDEPSTA -0.165029385
192      SKDDEPSTA      DEPBUCKET -0.165029385
27    UPLINEATCIMP      SKDDEPSTA -0.164964952
135      SKDDEPSTA   UPLINEATCIMP -0.164964952
108     DEPRANKGRP          AVGSQ -0.161451853
234          AVGSQ     DEPRANKGRP -0.161451853
110     ARRRANKGRP          AVGSQ -0.159135469
272          AVGSQ     ARRRANKGRP -0.159135469
13      DEPRANKGRP         SDEPHR -0.158537017
229         SDEPHR     DEPRANKGRP -0.158537017
203     DEPRANKGRP      DEPBUCKET -0.155547085
239      DEPBUCKET     DEPRANKGRP -0.155547085
25           AVGSQ      SKDDEPSTA -0.150522366
97       SKDDEPSTA          AVGSQ -0.150522366
9     DEPSTAATCIMP         SDEPHR -0.148514693
153         SDEPHR   DEPSTAATCIMP -0.148514693
166     TRNRANKGRP   DEPSTAATCIMP -0.147409309
256   DEPSTAATCIMP     TRNRANKGRP -0.147409309
144      DEPBUCKET   UPLINEATCIMP  0.144940797
198   UPLINEATCIMP      DEPBUCKET  0.144940797
8     UPLINEATCIMP         SDEPHR  0.143217211
134         SDEPHR   UPLINEATCIMP  0.143217211
205     ARRRANKGRP      DEPBUCKET -0.142348062
277      DEPBUCKET     ARRRANKGRP -0.142348062
15      ARRRANKGRP         SDEPHR -0.141835526
267         SDEPHR     ARRRANKGRP -0.141835526
171   xAVGSKDAVAIL   DEPSTAATCIMP -0.141077194
351   DEPSTAATCIMP   xAVGSKDAVAIL -0.141077194
128     TRNRANKGRP      AVGLOFATC  0.139184315
254      AVGLOFATC     TRNRANKGRP  0.139184315
163      DEPBUCKET   DEPSTAATCIMP -0.138581846
199   DEPSTAATCIMP      DEPBUCKET -0.138581846
323   xAVGSKDAVAIL       ARRSPOKE  0.137677242
359       ARRSPOKE   xAVGSKDAVAIL  0.137677242
243     ARRRANKGRP     DEPRANKGRP  0.136562948
279     DEPRANKGRP     ARRRANKGRP  0.136562948
123   DEPSTAATCIMP      AVGLOFATC -0.135778614
159      AVGLOFATC   DEPSTAATCIMP -0.135778614
132         xDURN2      AVGLOFATC -0.132084629
330      AVGLOFATC         xDURN2 -0.132084629
247   xAVGSKDAVAIL     DEPRANKGRP  0.130574789
355     DEPRANKGRP   xAVGSKDAVAIL  0.130574789
224     ARRRANKGRP      ARRBUCKET -0.129698517
278      ARRBUCKET     ARRRANKGRP -0.129698517
164      ARRBUCKET   DEPSTAATCIMP -0.127726148
218   DEPSTAATCIMP      ARRBUCKET -0.127726148
37          xDURN2      SKDDEPSTA  0.127598189
325      SKDDEPSTA         xDURN2  0.127598189
124 DOWNLINEATCIMP      AVGLOFATC -0.126763572
178      AVGLOFATC DOWNLINEATCIMP -0.126763572
227         xDURN2      ARRBUCKET -0.125836459
335      ARRBUCKET         xDURN2 -0.125836459
165     DEPRANKGRP   DEPSTAATCIMP  0.124672682
237   DEPSTAATCIMP     DEPRANKGRP  0.124672682
85    DEPSTAATCIMP         SKDEPS -0.123445793
157         SKDEPS   DEPSTAATCIMP -0.123445793
31       ARRBUCKET      SKDDEPSTA -0.120728212
211      SKDDEPSTA      ARRBUCKET -0.120728212
284         xDURN2     ARRRANKGRP  0.119675180
338     ARRRANKGRP         xDURN2  0.119675180
114   xAVGSKDAVAIL          AVGSQ -0.113720147
348          AVGSQ   xAVGSKDAVAIL -0.113720147
52      TRNRANKGRP      SKDARRSTA -0.105802023
250      SKDARRSTA     TRNRANKGRP -0.105802023
222     DEPRANKGRP      ARRBUCKET -0.105057984
240      ARRBUCKET     DEPRANKGRP -0.105057984
190   xAVGSKDAVAIL DOWNLINEATCIMP  0.102577364
352 DOWNLINEATCIMP   xAVGSKDAVAIL  0.102577364
146     DEPRANKGRP   UPLINEATCIMP -0.097218129
236   UPLINEATCIMP     DEPRANKGRP -0.097218129
147     TRNRANKGRP   UPLINEATCIMP -0.097037814
255   UPLINEATCIMP     TRNRANKGRP -0.097037814
43          SKDEPS      SKDARRSTA -0.096699169
79       SKDARRSTA         SKDEPS -0.096699169
86  DOWNLINEATCIMP         SKDEPS -0.095568613
176         SKDEPS DOWNLINEATCIMP -0.095568613
45       AVGLOFATC      SKDARRSTA -0.095234466
117      SKDARRSTA      AVGLOFATC -0.095234466
42          SKDEQP      SKDARRSTA  0.094073459
60       SKDARRSTA         SKDEQP  0.094073459
50       ARRBUCKET      SKDARRSTA  0.092625400
212      SKDARRSTA      ARRBUCKET  0.092625400
223     TRNRANKGRP      ARRBUCKET -0.092415252
259      ARRBUCKET     TRNRANKGRP -0.092415252
266   xAVGSKDAVAIL     TRNRANKGRP  0.092011501
356     TRNRANKGRP   xAVGSKDAVAIL  0.092011501
38    xAVGSKDAVAIL      SKDDEPSTA  0.088580325
344      SKDDEPSTA   xAVGSKDAVAIL  0.088580325
75          xDURN2         SKDEQP  0.086170070
327         SKDEQP         xDURN2  0.086170070
127     DEPRANKGRP      AVGLOFATC  0.085474019
235      AVGLOFATC     DEPRANKGRP  0.085474019
122   UPLINEATCIMP      AVGLOFATC -0.085180887
140      AVGLOFATC   UPLINEATCIMP -0.085180887
262     ARRRANKGRP     TRNRANKGRP  0.083906762
280     TRNRANKGRP     ARRRANKGRP  0.083906762
282       DEPSPOKE     ARRRANKGRP  0.083162083
300     ARRRANKGRP       DEPSPOKE  0.083162083
44           AVGSQ      SKDARRSTA  0.082898864
98       SKDARRSTA          AVGSQ  0.082898864
91      ARRRANKGRP         SKDEPS  0.080398834
271         SKDEPS     ARRRANKGRP  0.080398834
3        SKDARRSTA         SDEPHR  0.079427004
39          SDEPHR      SKDARRSTA  0.079427004
95    xAVGSKDAVAIL         SKDEPS  0.075169577
347         SKDEPS   xAVGSKDAVAIL  0.075169577
167     ARRRANKGRP   DEPSTAATCIMP  0.073371196
275   DEPSTAATCIMP     ARRRANKGRP  0.073371196
49       DEPBUCKET      SKDARRSTA  0.072910977
193      SKDARRSTA      DEPBUCKET  0.072910977
145      ARRBUCKET   UPLINEATCIMP  0.071409699
217   UPLINEATCIMP      ARRBUCKET  0.071409699
148     ARRRANKGRP   UPLINEATCIMP -0.069790367
274   UPLINEATCIMP     ARRRANKGRP -0.069790367
34      ARRRANKGRP      SKDDEPSTA  0.068927801
268      SKDDEPSTA     ARRRANKGRP  0.068927801
74        ARRSPOKE         SKDEQP  0.066579707
308         SKDEQP       ARRSPOKE  0.066579707
19    xAVGSKDAVAIL         SDEPHR -0.064363931
343         SDEPHR   xAVGSKDAVAIL -0.064363931
7        AVGLOFATC         SDEPHR -0.063746211
115         SDEPHR      AVGLOFATC -0.063746211
103   UPLINEATCIMP          AVGSQ  0.062631172
139          AVGSQ   UPLINEATCIMP  0.062631172
129     ARRRANKGRP      AVGLOFATC -0.061491190
273      AVGLOFATC     ARRRANKGRP -0.061491190
283       ARRSPOKE     ARRRANKGRP -0.057002549
319     ARRRANKGRP       ARRSPOKE -0.057002549
133   xAVGSKDAVAIL      AVGLOFATC -0.056264979
349      AVGLOFATC   xAVGSKDAVAIL -0.056264979
125      DEPBUCKET      AVGLOFATC -0.053357134
197      AVGLOFATC      DEPBUCKET -0.053357134
209   xAVGSKDAVAIL      DEPBUCKET -0.053125467
353      DEPBUCKET   xAVGSKDAVAIL -0.053125467
26       AVGLOFATC      SKDDEPSTA -0.044946507
116      SKDDEPSTA      AVGLOFATC -0.044946507
126      ARRBUCKET      AVGLOFATC -0.043093769
216      AVGLOFATC      ARRBUCKET -0.043093769
4           SKDEQP         SDEPHR  0.042612138
58          SDEPHR         SKDEQP  0.042612138
72      ARRRANKGRP         SKDEQP -0.042512956
270         SKDEQP     ARRRANKGRP -0.042512956
104   DEPSTAATCIMP          AVGSQ -0.040428658
158          AVGSQ   DEPSTAATCIMP -0.040428658
82           AVGSQ         SKDEPS -0.038820886
100         SKDEPS          AVGSQ -0.038820886
68       DEPBUCKET         SKDEQP  0.037125178
194         SKDEQP      DEPBUCKET  0.037125178
131       ARRSPOKE      AVGLOFATC -0.034402462
311      AVGLOFATC       ARRSPOKE -0.034402462
76    xAVGSKDAVAIL         SKDEQP  0.031863410
346         SKDEQP   xAVGSKDAVAIL  0.031863410
90      TRNRANKGRP         SKDEPS  0.030883560
252         SKDEPS     TRNRANKGRP  0.030883560
87       DEPBUCKET         SKDEPS -0.030101407
195         SKDEPS      DEPBUCKET -0.030101407
56          xDURN2      SKDARRSTA  0.027576751
326      SKDARRSTA         xDURN2  0.027576751
102      AVGLOFATC          AVGSQ -0.027382453
120          AVGSQ      AVGLOFATC -0.027382453
57    xAVGSKDAVAIL      SKDARRSTA  0.027225219
345      SKDARRSTA   xAVGSKDAVAIL  0.027225219
89      DEPRANKGRP         SKDEPS  0.027025501
233         SKDEPS     DEPRANKGRP  0.027025501
24          SKDEPS      SKDDEPSTA -0.024267794
78       SKDDEPSTA         SKDEPS -0.024267794
65    UPLINEATCIMP         SKDEQP -0.019807499
137         SKDEQP   UPLINEATCIMP -0.019807499
73        DEPSPOKE         SKDEQP  0.019755644
289         SKDEQP       DEPSPOKE  0.019755644
342   xAVGSKDAVAIL         xDURN2 -0.019255572
360         xDURN2   xAVGSKDAVAIL -0.019255572
285   xAVGSKDAVAIL     ARRRANKGRP -0.018743432
357     ARRRANKGRP   xAVGSKDAVAIL -0.018743432
170         xDURN2   DEPSTAATCIMP -0.017999758
332   DEPSTAATCIMP         xDURN2 -0.017999758
67  DOWNLINEATCIMP         SKDEQP -0.017658860
175         SKDEQP DOWNLINEATCIMP -0.017658860
93        ARRSPOKE         SKDEPS  0.017573485
309         SKDEPS       ARRSPOKE  0.017573485
88       ARRBUCKET         SKDEPS  0.017414895
214         SKDEPS      ARRBUCKET  0.017414895
53      ARRRANKGRP      SKDARRSTA  0.016733374
269      SKDARRSTA     ARRRANKGRP  0.016733374
63           AVGSQ         SKDEQP  0.010218807
99          SKDEQP          AVGSQ  0.010218807
69       ARRBUCKET         SKDEQP  0.009926479
213         SKDEQP      ARRBUCKET  0.009926479
130       DEPSPOKE      AVGLOFATC -0.008540402
292      AVGLOFATC       DEPSPOKE -0.008540402
83       AVGLOFATC         SKDEPS  0.008240563
119         SKDEPS      AVGLOFATC  0.008240563
5           SKDEPS         SDEPHR -0.007166433
77          SDEPHR         SKDEPS -0.007166433
66    DEPSTAATCIMP         SKDEQP -0.005922601
156         SKDEQP   DEPSTAATCIMP -0.005922601
64       AVGLOFATC         SKDEQP -0.004889040
118         SKDEQP      AVGLOFATC -0.004889040
92        DEPSPOKE         SKDEPS -0.004617067
290         SKDEPS       DEPSPOKE -0.004617067
84    UPLINEATCIMP         SKDEPS  0.004016263
138         SKDEPS   UPLINEATCIMP  0.004016263
94          xDURN2         SKDEPS  0.001748012
328         SKDEPS         xDURN2  0.001748012

> ### Models
> 
> ## Try GBM (gradient boosting). Works well for mixed data.
> ## And there is a tutorial for it with caret.
> 
> ## Training controller and big grid
> ## Check the ROC (my preferred.)
> 
> # I'm not using this at the moment.
> 
> tr.cols <- colnames(trainDescr)

> tr.cols
 [1] "SDEPHR"         "SKDDEPSTA"      "SKDARRSTA"      "SKDEQP"        
 [5] "SKDEPS"         "AVGSQ"          "AVGLOFATC"      "UPLINEATCIMP"  
 [9] "DEPSTAATCIMP"   "DOWNLINEATCIMP" "DEPBUCKET"      "ARRBUCKET"     
[13] "DEPRANKGRP"     "TRNRANKGRP"     "ARRRANKGRP"     "DEPSPOKE"      
[17] "ARRSPOKE"       "xDURN2"         "xAVGSKDAVAIL"  

> tr.icols <- grep("((STA|EQP)$)|(^xD)", tr.cols)

> tr.icols <- rev(tr.icols)

> fitControl <- trainControl(## 10-fold CV
+     method = "repeatedcv",
+     number = 10,
+     ## repeated ten times
+     repeats = 10,
+     classProbs = TRUE)

> ## Some trial and error with variables to branch and boost.
> ## Try all variables
> 
> gbmGrid <- expand.grid(interaction.depth = 
+                            length(colnames(trainDescr)),
+                         n.trees = (1:30)*90,
+                         shrinkage = 0.2,
+                 .... [TRUNCATED] 

> set.seed(seed.mine)

> gbmFit1 <- train(trainDescr, trainClass,
+                  method = "gbm",
+                  trControl = fitControl,
+                  ## This last option is actually one
+                  ## for gbm() that passes through
+                  tuneGrid = gbmGrid,
+                  metric = "Kapp ..." ... [TRUNCATED] 
Loading required package: gbm
Loading required package: survival

Attaching package: 'survival'

The following object is masked from 'package:caret':

    cluster

Loading required package: splines
Loaded gbm 2.1.1
Loading required package: plyr

> gbmFit1
Stochastic Gradient Boosting 

248 samples
 19 predictor
  2 classes: 'Strong', 'Weak' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 

Summary of sample sizes: 222, 223, 223, 224, 223, 223, ... 

Resampling results across tuning parameters:

  n.trees  Accuracy   Kappa      Accuracy SD  Kappa SD 
    90     0.6980333  0.3888821  0.08788899   0.1769196
   180     0.6967500  0.3867469  0.07870037   0.1570591
   270     0.6927538  0.3784137  0.08049464   0.1608493
   360     0.6861885  0.3653945  0.08372398   0.1667924
   450     0.6922872  0.3778011  0.08678923   0.1734019
   540     0.6874026  0.3686650  0.08806412   0.1746636
   630     0.6866026  0.3669275  0.08738965   0.1743712
   720     0.6822679  0.3585591  0.08576677   0.1704273
   810     0.6873885  0.3685992  0.08606086   0.1709217
   900     0.6842167  0.3622736  0.08664037   0.1723145
   990     0.6838000  0.3606694  0.08541255   0.1693203
  1080     0.6841833  0.3614542  0.08695034   0.1730094
  1170     0.6834167  0.3595734  0.08468830   0.1683301
  1260     0.6826474  0.3574159  0.08489090   0.1683194
  1350     0.6806795  0.3532024  0.08756257   0.1741105
  1440     0.6811769  0.3550489  0.08709817   0.1728634
  1530     0.6811628  0.3548515  0.08488980   0.1686298
  1620     0.6839808  0.3605239  0.08607742   0.1709460
  1710     0.6823462  0.3578438  0.08297428   0.1646826
  1800     0.6815436  0.3576411  0.08636558   0.1711367
  1890     0.6828423  0.3620445  0.08813634   0.1738650
  1980     0.6818974  0.3620374  0.08297116   0.1632072
  2070     0.6815487  0.3629851  0.09063542   0.1780234
  2160     0.6835526  0.3681025  0.09624771   0.1888827
  2250     0.6863846  0.3747578  0.09650422   0.1901491
  2340     0.6889013  0.3808078  0.09607296   0.1891577
  2430     0.6876346  0.3791025  0.09236803   0.1820121
  2520     0.6896192  0.3838791  0.09617369   0.1891599
  2610     0.6868192  0.3796591  0.09595404   0.1876743
  2700     0.6823808  0.3716712  0.09640343   0.1888419

Tuning parameter 'interaction.depth' was held constant at a value of 19

Tuning parameter 'shrinkage' was held constant at a value of 0.2

Tuning parameter 'n.minobsinnode' was held constant at a value of 10
Kappa was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 90, interaction.depth =
 19, shrinkage = 0.2 and n.minobsinnode = 10. 

> ## The acid test is dissapointing, but I've seen worse.
> 
> testPred <- predict(gbmFit1, testDescr)

> postResample(testPred, testClass)
 Accuracy     Kappa 
0.7361111 0.4571429 

> confusionMatrix(testPred, testClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong     33   12
    Weak        7   20
                                        
               Accuracy : 0.7361        
                 95% CI : (0.619, 0.833)
    No Information Rate : 0.5556        
    P-Value [Acc > NIR] : 0.00122       
                                        
                  Kappa : 0.4571        
 Mcnemar's Test P-Value : 0.35880       
                                        
            Sensitivity : 0.6250        
            Specificity : 0.8250        
         Pos Pred Value : 0.7407        
         Neg Pred Value : 0.7333        
             Prevalence : 0.4444        
         Detection Rate : 0.2778        
   Detection Prevalence : 0.3750        
      Balanced Accuracy : 0.7250        
                                        
       'Positive' Class : Weak          
                                        

> ## The training set is exact even with the correlation cut-offs
> ## As one would hope - but 
> trainPred <- predict(gbmFit1, trainDescr)

> postResample(trainPred, trainClass)
Accuracy    Kappa 
       1        1 

> confusionMatrix(trainPred, trainClass, positive = "Weak")
Confusion Matrix and Statistics

          Reference
Prediction Strong Weak
    Strong    137    0
    Weak        0  111
                                     
               Accuracy : 1          
                 95% CI : (0.9852, 1)
    No Information Rate : 0.5524     
    P-Value [Acc > NIR] : < 2.2e-16  
                                     
                  Kappa : 1          
 Mcnemar's Test P-Value : NA         
                                     
            Sensitivity : 1.0000     
            Specificity : 1.0000     
         Pos Pred Value : 1.0000     
         Neg Pred Value : 1.0000     
             Prevalence : 0.4476     
         Detection Rate : 0.4476     
   Detection Prevalence : 0.4476     
      Balanced Accuracy : 1.0000     
                                     
       'Positive' Class : Weak       
                                     

> ## Get a density and a ROC
> 
> x.p <- predict(gbmFit1, testDescr, type = "prob")[2]

> test.df <- data.frame(Weak=x.p$Weak, Obs=testClass)

> test.roc <- roc(Obs ~ Weak, test.df)
Warning message:
In eval(expr, envir, enclos) : adjusting
> 